[{"title":"实现私有Yum仓库","url":"/posts/f49cc7ae/","content":"\n<meta name=\"referrer\" content=\"no-referrer\"/>\n\n# 实现私有Yum仓库\n\n## 架构图\n\n![yum](../img/%E5%AE%9E%E7%8E%B0%E7%A7%81%E6%9C%89Yum%E4%BB%93%E5%BA%93.assets/2a5fb169729de5d58421f2d71902d64755933597.png)\n\n每个系统的最后的路径都不一样，所以要看清，尽量跟大厂路径对齐，起始最重要的就是Packages和repodata，你看阿里云的路径，我们只要走到有repedata的文件夹下，就说明走对了，不用往下走了\n\n## 主机拓扑\n\n|   主机名   |       ip       |       os        |\n| :--------: | :------------: | :-------------: |\n| yum server | 192.168.48.128 |    Rocker8.9    |\n|  client1   | 192.168.48.11  | Centos Stream 8 |\n|  client2   | 192.168.48.10  |    Centos 7     |\n\n前情提要：所有要进行上传yum源的机子都要挂载光盘，也可以选择网络备份\n\n## 自动挂载光盘\n\n```bash\n#自动挂载\nyum install autofs -y\nsystemctl enable --now autofs\nsed -i '/^[[:space:]]*#.*misc.*\\/etc\\/auto.misc/ s/^#//' /etc/auto.master\nsystemctl restart autofs\nls /misc/cd\n```\n\n## 部署yum server\n\n操作节点：【yum server】\n\n### Rocky8\n\n```bash\nyum install -y httpd\nsystemctl disable --now firewalld.service\nsystemctl enable --now httpd.service\n\n#自己看前面的教程实现rocky8的光盘自动挂载\n\n#将本地光盘中的内容CP到web目录中，给客户端使用\nmkdir -p /var/www/html/rockylinux/8/{BaseOS,AppStream}\ncp -r /misc/cd/BaseOS/* /var/www/html/rockylinux/8/BaseOS\ncp -r /mnt/BaseOS/repodata /var/www/html/rockylinux/8/BaseOS/\ncp -r /misc/cd/AppStream/* /var/www/html/rockylinux/8/AppStream\ncp -r /mnt/AppStream/repodata /var/www/html/rockylinux/8/AppStream/\n#这里可能有点慢，因为要拷贝的文件有点多\n```\n\n现在一些基本的文件都拷过去了访问网页就可以看见了\n\n```bash\nhttp://192.168.48.128/rockylinux/8/\n```\n\n![image-20250711231852237](../img/%E5%AE%9E%E7%8E%B0%E7%A7%81%E6%9C%89Yum%E4%BB%93%E5%BA%93.assets/c07c2cc67d66a746994222cc2db1833855933597.png)\n\n假设我还有个`extras`源想拷过去呢？前面那个是走本地，这个可以走网络，这时候就可以用到`yum仓同步工具`\n\n```bash\nhttps://mirrors.aliyun.com/rockylinux/8/extras/x86_64/os/\n```\n\n![image-20250711232003433](../img/%E5%AE%9E%E7%8E%B0%E7%A7%81%E6%9C%89Yum%E4%BB%93%E5%BA%93.assets/d3c34126c0d8cda84560441748a75a1555933597.png)\n\n```bash\n#备份自己的源\nmkdir -p repo.bak\nmv /etc/yum.repos.d/* repo.bak/\n#这是私网yum server自己用的repo\ncat > /etc/yum.repos.d/qianyios.repo<<\"EOF2\"\n[AppStream]\nname=AppStream\nbaseurl=file:///var/www/html/rockylinux/8/AppStream/x86_64/os/\ngpgkey=/etc/pki/rpm-gpg/RPM-GPG-KEY-rockyofficial\ngpgcheck=1\nenabled=1\n[BaseOS]\nname=BaseOS\nbaseurl=file:///var/www/html/rockylinux/8/BaseOS/x86_64/os/\ngpgkey=/etc/pki/rpm-gpg/RPM-GPG-KEY-rockyofficial\ngpgcheck=1\nenabled=1\n[extras]\nname=extras\nbaseurl=file:///var/www/html/rockylinux/8/extras/x86_64/os/\ngpgkey=/etc/pki/rpm-gpg/RPM-GPG-KEY-rockyofficial\ngpgcheck=1\nenabled=1\nEOF2\n#这是公网用来同步的的repo\ncat > /etc/yum.repos.d/qianyios-external-rocky8.repo<<\"EOF2\"\n[AppStream-external-rocky8]\nname=AppStream-external-rocky8\nbaseurl=https://mirrors.aliyun.com/rockylinux/8/AppStream/x86_64/os/\ngpgkey=/etc/pki/rpm-gpg/RPM-GPG-KEY-rockyofficial\ngpgcheck=1\nenabled=1\n[BaseOS-external-rocky8]\nname=BaseOS-external-rocky8\nbaseurl=https://mirrors.aliyun.com/rockylinux/8/BaseOS/x86_64/os/\ngpgkey=/etc/pki/rpm-gpg/RPM-GPG-KEY-rockyofficial\ngpgcheck=1\nenabled=1\n[extras-external-rocky8]\nname=extras-external-rocky8\nbaseurl=https://mirrors.aliyun.com/rockylinux/8/extras/x86_64/os/\ngpgkey=/etc/pki/rpm-gpg/RPM-GPG-KEY-rockyofficial\ngpgcheck=1\nenabled=1\nEOF2\n```\n\n```bash\n#CentOS 8 dnf 工具集成 REPOID是那个repo里的[]里的名字\ndnf reposync --repoid=REPOID --download-metadata -p /path \ndnf reposync --help #查看帮助\n#CentOS 7 以前版本，reposync工具来自于yum-utils包\nreposync --repoid=REPOID --download-metadata -p /path\n```\n\n```bash\n#创建好对应的路径，由于AppStream和BaseOS已经手动拉过去了，但是路径不对，我们就手动移一下\ncd /var/www/html/rockylinux/8\nmkdir -p AppStream/x86_64/os/\nmkdir -p BaseOS/x86_64/os/\nmv AppStream/{Packages,repodata} AppStream/x86_64/os/\nmv BaseOS/{Packages,repodata} BaseOS/x86_64/os/\n#开始同步，这里最后-p 路径的就不用加extras\nmkdir -p /var/www/html/rockylinux/8/\nyum reposync --repoid=extras-external-rocky8 --download-metadata -p /var/www/html/rockylinux/8/\n#但是这个时候他的名字是extras-external-rocky8，所以你要把他下面的内容移动到extras去，还要注意有没有x86_64/os/\nmv /var/www/html/rockylinux/8/{extras-external-rocky8,extras}\nmkdir -p extras/x86_64/os/\nmv extras/{Packages,repodata} extras/x86_64/os/\n```\n\n![image-20250712000955889](../img/%E5%AE%9E%E7%8E%B0%E7%A7%81%E6%9C%89Yum%E4%BB%93%E5%BA%93.assets/df8dc0c90c40f5ce752128a090c3e2b655933597.png)\n\n这就是成果\n\n测试自己是否能创建缓存成功\n\n```bash\n#用的是私有repo，记得把其他的repo移走\n[root@localhost 8]# yum clean all && yum makecache\n75 个文件已删除\nAppStream                                                   410 MB/s | 8.7 MB     00:00\nBaseOS                                                      237 MB/s | 2.6 MB     00:00\nextras                                                      6.4 MB/s |  15 kB     00:00\n元数据缓存已建立。\n```\n\n### Centos Strem 8\n\n#### 远程同步\n\n操作节点：【Centos Strem 8】\n\n从Centos Strem 8复制到yumserver，如果你没有centos stream 8的机子，那就直接选网络同步\n\n```bash\n#自己看前面的教程实现rocky8的光盘自动挂载\n#将本地光盘中的内容CP到yum server 的web目录中\nscp -r /misc/cd/BaseOS 192.168.48.128:/var/www/html/centos/8-stream/\nscp -r /misc/cd/AppStream 192.168.48.128:/var/www/html/centos/8-stream/\n```\n\n#### 网络同步\n\n操作节点：【yum server】\n\n```bash\n#公网\ncat > /etc/yum.repos.d/qianyios-external--Centos-Strem-8.repo<<\"EOF2\"\n[AppStream-external-Centos-Strem-8]\nname=AppStream-external-Centos-Strem-8\nbaseurl=https://mirrors.aliyun.com/centos/8-stream/AppStream/x86_64/os/\ngpgkey=https://mirrors.aliyun.com/centos/RPM-GPG-KEY-CentOS-Official\ngpgcheck=1\nenabled=1\n[BaseOS-external-Centos-Strem-8]\nname=BaseOS-external-Centos-Strem-8\nbaseurl=https://mirrors.aliyun.com/centos/8-stream/BaseOS/x86_64/os/\ngpgkey=https://mirrors.aliyun.com/centos/RPM-GPG-KEY-CentOS-Official\ngpgcheck=1\nenabled=1\n[extras-external-Centos-Strem-8]\nname=extras-external-Centos-Strem-8\nbaseurl=https://mirrors.aliyun.com/centos/8-stream/extras/x86_64/os/\ngpgkey=https://mirrors.aliyun.com/centos/RPM-GPG-KEY-CentOS-Official\ngpgcheck=1\nenabled=1\nEOF2\n```\n\n```bash\n#前面已经复制过了AppStream和BaseOS，这里就不做演示了,如果你手动之后还想网络同步，我的建议是删掉手动的文件夹再来拉去取网络的\n#AppStream\nyum reposync --repoid=AppStream-external-Centos-Strem-8 --download-metadata -p /var/www/html/centos/8-stream/\n#BaseOS\nyum reposync --repoid=BaseOS-external-Centos-Strem-8 --download-metadata -p /var/www/html/centos/8-stream/\n#extras\nyum reposync --repoid=extras-external-Centos-Strem-8 --download-metadata -p /var/www/html/centos/8-stream/\n#注意修改名字哦\nmv /var/www/html/centos/8-stream/{AppStream-external-Centos-Strem-8,AppStream}\nmv /var/www/html/centos/8-stream/{BaseOS-external-Centos-Strem-8,BaseOS}\nmv /var/www/html/centos/8-stream/{extras-external-Centos-Strem-8,extras}\ncd /var/www/html/centos/8-stream/extras\nmv Packages x86_64/os/\nmv repodata x86_64/os/\n```\n\n![image-20250712004912125](../img/%E5%AE%9E%E7%8E%B0%E7%A7%81%E6%9C%89Yum%E4%BB%93%E5%BA%93.assets/9e0d6eba9193a80736495d0d8bf901b255933597.png)\n\n### centos7\n\n手动的我就不写了一个意思，这里我就写网络的\n\n```bash\n#公网\ncat > /etc/yum.repos.d/qianyios-external-centos7.repo<<\"EOF2\"\n[base-external-centos7]\nname=BaseOS-external-centos7\nbaseurl=https://mirrors.aliyun.com/centos/7/os/x86_64\ngpgkey=https://mirrors.aliyun.com/centos/7/os/x86_64/RPM-GPG-KEY-CentOS-7\ngpgcheck=1\nenabled=1\n[extras-external-centos7]\nname=extras-external-centos7\nbaseurl=https://mirrors.aliyun.com/centos/7/extras/x86_64/\ngpgkey=https://mirrors.aliyun.com/centos/7/os/x86_64/RPM-GPG-KEY-CentOS-7\ngpgcheck=1\nenabled=1\nEOF2\n```\n\n```bash\nmkdir -p /var/www/html/centos/7/os/x86_64/\n#bash\nyum reposync --repoid=base-external-centos7 --download-metadata -p /var/www/html/centos/7/\n#extras\nyum reposync --repoid=extras-external-centos7 --download-metadata -p /var/www/html/centos/7/\n#注意修改名字哦\nmv /var/www/html/centos/7/{base-external-centos7,base}\ncd /var/www/html/centos/7\nmv base os/x86_64/\n\nmv /var/www/html/centos/7/{extras-external-centos7,extras}\ncd /var/www/html/centos/7/extras\nmv Packages x86_64/\nmv repodata x86_64/\n```\n\n![image-20250712010733973](../img/%E5%AE%9E%E7%8E%B0%E7%A7%81%E6%9C%89Yum%E4%BB%93%E5%BA%93.assets/512888a0524d84f3de2d2685b08394e855933597.png)\n\n## 客户端使用\n\n操作节点：【Centos Stream 8】\n\n```bash\n#备份原有的repo\nmkdir repo.bak\nmv /etc/yum.repos.d/* repo.bak/\n\n#公网\ncat > /etc/yum.repos.d/qianyios-external-Centos-Strem-8.repo<<\"EOF2\"\n[AppStream-external-Centos-Strem-8]\nname=AppStream-external-Centos-Strem-8\nbaseurl=http://192.168.48.128/centos/8-stream/AppStream/x86_64/os/\ngpgkey=file:///etc/pki/rpm-gpg/RPM-GPG-KEY-centosofficial\ngpgcheck=1\nenabled=1\n[BaseOS-external-Centos-Strem-8]\nname=BaseOS-external-Centos-Strem-8\nbaseurl=http://192.168.48.128/centos/8-stream/BaseOS/x86_64/os/\ngpgkey=file:///etc/pki/rpm-gpg/RPM-GPG-KEY-centosofficial\ngpgcheck=1\nenabled=1\n[extras-external-Centos-Strem-8]\nname=extras-external-Centos-Strem-8\nbaseurl=http://192.168.48.128/centos/8-stream/extras/x86_64/os/\ngpgkey=file:///etc/pki/rpm-gpg/RPM-GPG-KEY-centosofficial\ngpgcheck=1\nenabled=1\nEOF2\nyum clean all && yum makecache\n#成功\n[root@qianyi ~]# yum clean all && yum makecache                                             13 files removed\nAppStream-external-Centos-Strem-8                           205 MB/s | 7.9 MB     00:00\nBaseOS-external-Centos-Strem-8                              158 MB/s | 2.7 MB     00:00\nextras-external-Centos-Strem-8                              6.2 MB/s |  18 kB     00:00\nMetadata cache created.\n[root@qianyi ~]#\n\n```\n\n如果他报这个错，你要确保你的extras下的那个路径有没有repodata这个文件夹，或者看看路径对不对\n\n![image-20250712130750985](../img/%E5%AE%9E%E7%8E%B0%E7%A7%81%E6%9C%89Yum%E4%BB%93%E5%BA%93.assets/b67970571469859a6390c591bbe3be0455933597.png)\n\n\n\n\n\n操作节点：【centos7】\n\n```bash\n#备份原有的repo\nmkdir repo.bak\nmv /etc/yum.repos.d/* repo.bak/\n\ncat > /etc/yum.repos.d/qianyios-external-centos7.repo<<\"EOF2\"\n[base-external-centos7]\nname=BaseOS-external-centos7\nbaseurl=http://192.168.48.128/centos/7/os/x86_64/\ngpgkey=file:///etc/pki/rpm-gpg/RPM-GPG-KEY-CentOS-7\ngpgcheck=1\nenabled=1\n[extras-external-centos7]\nname=extras-external-centos7\nbaseurl=http://192.168.48.128/centos/7/extras/x86_64/\ngpgkey=file:///etc/pki/rpm-gpg/RPM-GPG-KEY-CentOS-7\ngpgcheck=1\nenabled=1\nEOF2\nyum clean all && yum makecache\n\n#成功\n[root@localhost ~]# yum clean all && yum makecache\nLoaded plugins: fastestmirror, langpacks\nCleaning repos: base-external-centos7 extras-external-centos7\nCleaning up list of fastest mirrors\nOther repos take up 102 M of disk space (use --verbose for details)\nLoaded plugins: fastestmirror, langpacks\nDetermining fastest mirrors\nbase-external-centos7                                                | 3.6 kB  00:00:00\nextras-external-centos7                                              | 2.9 kB  00:00:00\n(1/7): base-external-centos7/group_gz                                | 153 kB  00:00:00\n(2/7): base-external-centos7/filelists_db                            | 3.3 MB  00:00:00\n(3/7): base-external-centos7/other_db                                | 1.3 MB  00:00:00\n(4/7): base-external-centos7/primary_db                              | 3.3 MB  00:00:00\n(5/7): extras-external-centos7/primary_db                            | 253 kB  00:00:00\n(6/7): extras-external-centos7/filelists_db                          | 305 kB  00:00:00\n(7/7): extras-external-centos7/other_db                              | 154 kB  00:00:00\nMetadata Cache Created\n[root@localhost ~]#\n\n```\n\n\n\n## 总结\n\n1.你要下那个源仓库，你就走到对应的路径，如果看见`repodata文件夹`，那就是这个路径了\n\n![image-20250712132539806](../img/%E5%AE%9E%E7%8E%B0%E7%A7%81%E6%9C%89Yum%E4%BB%93%E5%BA%93.assets/6c849744d3cce48161d75a0b435288c955933597.png)\n\n2.如果你是本地测试，拉的文件太多很大，你终止了你可能拉不到repodata，所以你可以通过光盘里的scp过去yum server\n\n3.万事都要确定好路径喔，如果repo写错了，你就看看他那个报错的路径下有没有repodata\n\n<div class=\"tbsm\" style=\"margin-top:54px;\">\n<div class=\"tbsm-top\"><span><svg t=\"1674654360507\" class=\"icon\" viewBox=\"0 0 1024 1024\" version=\"1.1\" xmlns=\"http://www.w3.org/2000/svg\" p-id=\"987\" data-spm-anchor-id=\"a313x.7781069.0.i0\" width=\"35\" height=\"35\"><path d=\"M410.49 97.74H155.08a56.74 56.74 0 0 0-56.84 56.73V410a56.84 56.84 0 0 0 56.84 56.84h255.41A56.83 56.83 0 0 0 467.32 410V154.58a56.83 56.83 0 0 0-56.83-56.84zM410.49 558.74H155.08a56.74 56.74 0 0 0-56.84 56.73V871a56.84 56.84 0 0 0 56.84 56.84h255.41A56.83 56.83 0 0 0 467.32 871V615.58a56.83 56.83 0 0 0-56.83-56.84zM871.49 558.74H616.08a56.74 56.74 0 0 0-56.84 56.73V871a56.84 56.84 0 0 0 56.84 56.84h255.41A56.83 56.83 0 0 0 928.32 871V615.58a56.83 56.83 0 0 0-56.83-56.84z\" fill=\"#66EEFF\" p-id=\"988\"></path><path d=\"M410.49 558.74h-4.14A475 475 0 0 0 299.52 859.6a481.16 481.16 0 0 0 4.84 68.22h106.13A56.83 56.83 0 0 0 467.32 871V615.58a56.83 56.83 0 0 0-56.83-56.84zM871.49 558.74H616.08a56.74 56.74 0 0 0-56.84 56.73V871a56.84 56.84 0 0 0 56.84 56.84h255.41A56.83 56.83 0 0 0 928.32 871V615.58a56.83 56.83 0 0 0-56.83-56.84z\" fill=\"#C2F8FF\" p-id=\"989\"></path></svg></span><span style=\"font-size:30px;\"> 特别声明</span></div>\n<div class=\"tbsm-wz\">千屹博客旗下的所有文章，是通过本人课堂学习和课外自学所精心整理的知识巨著<br/>难免会有出错的地方<br/>如果细心的你发现了小失误，可以在下方评论区告诉我，或者私信我！<br />非常感谢大家的热烈支持！</div>\n</div>","tags":["Yum"],"categories":["云原生"]},{"title":"Rancher容器管理平台","url":"/posts/e650e0d0/","content":"\n<meta name=\"referrer\" content=\"no-referrer\"/>\n\n# Rancher容器管理平台\n\n<img style=\"border-radius:15px;max-width:350px;max-height :100%;display:block;margin:0 auto 1.5rem\" src=\"https://blog.qianyios.top/img/Rancher%E5%AE%B9%E5%99%A8%E7%AE%A1%E7%90%86%E5%B9%B3%E5%8F%B0.assets/image-20250707005635650.png\" />\n\nRancher 中文文档: https://docs.rancher.cn/\n\n## 什么是 Rancher？\n\nRancher 是一个 `Kubernetes` 管理工具，让你能在`任何地方`和`任何提供商`上部署和运行集群。\n\nRancher 可以创建来自 Kubernetes 托管服务提供商的集群，创建节点并安装 Kubernetes，或者`导入`在任何地方运行的`现有 Kubernetes 集群`。\n\nRancher 基于 Kubernetes 添加了新的功能，包括统一所有集群的身份验证和 RBAC，让系统管理员从一个位置控制全部集群的访问。\n\n此外，Rancher 可以为集群和资源提供更精细的监控和告警，将日志发送到外部提供商，并通过应用商店（Application Catalog）直接集成  Helm。如果你拥有外部 CI/CD 系统，你可以将其与 Rancher 对接。没有的话，你也可以使用 Rancher 提供的 Fleet  自动部署和升级工作负载。\n\nRancher 是一个 *全栈式* 的 Kubernetes 容器管理平台，为你提供在任何地方都能成功运行 Kubernetes 的工具。\n\n\n\n## Docker部署Rancher\n\n`仅需三步！开启Rancher之旅`\n\n准备一台Linux主机 要求4GB内存，并且已经安装Docker\n\n安装教程：[使用 Docker 将 Rancher 安装到单个节点中](https://ranchermanager.docs.rancher.com/zh/getting-started/installation-and-upgrade/other-installation-methods/rancher-on-a-single-node-with-docker)\n\n> **`Docker 安装在生产环境中不支持。`**这些说明仅用于测试和开发目的。请不要使用此方法在生产环境中安装 Rancher。`Rancher 的 Docker 安装仅推荐用于开发和测试环境中`\n\n1.基础配置\n\nRancher 容器内部启动了 `k3s`，它依赖于底层宿主机具备 **iptables 支持**（用于网络转发、容器间通信等），否则会因为 **缺少 iptable_nat / iptable_filter 模块** 而导致：\n\n```bash\nyum install -y iptables\nmodprobe iptable_nat\nmodprobe iptable_filter\nsudo tee /etc/modules-load.d/modules.conf >/dev/null <<EOF \niptable_nat\niptable_filter\nEOF\nreboot\n```\n\n1.创建rancher挂在目录\n\n```bash\ndocker rm -f qianyios_rancher\nrm -rf /data/rancher_home/rancher/*\nrm -rf /data/rancher_home/auditlog/*\n\nmkdir -p /data/rancher_home/rancher\nmkdir -p /data/rancher_home/auditlog\n```\n\n2.安装rancher\n\n```bash\ndocker run -d --privileged --restart=unless-stopped \\\n  -p 8080:80 -p 4431:443 \\\n  -v /data/rancher_home/rancher:/var/lib/rancher \\\n  -v /data/rancher_home/auditlog:/var/log/auditlog \\\n  --name qianyios_rancher registry.cn-guangzhou.aliyuncs.com/qianyios/rancher:stable\n```\n\n-p `8080`:80   **外部端口**：8080（宿主机端口）：**内部端口**：80（容器端口）\n\n-p `4431`:443  **外部端口**：4431（宿主机端口）：**内部端口**：443（容器端口）\n\n`registry.cn-guangzhou.aliyuncs.com/qianyios/rancher:stable`是我自己构建的镜像（不定期更新，可能会落后版本），如果有条件可以下载原版镜像 `rancher/rancher:stable`\n\n或者用国内构建的官方镜像`registry.cn-hangzhou.aliyuncs.com/qianyios/rancher:版本号`这个你需要携带版本号\n\n`--privileged` 标志会给容器内的进程几乎相同于宿主机的特权。这意味着容器内的进程可以访问宿主机的所有设备，并且可以执行一些通常需要特权的操作，比如加载内核模块等\n\n> 访问地址：https://192.168.48.10:4431\n>\n\n![image-20250620191750583](../img/Rancher%E5%AE%B9%E5%99%A8%E7%AE%A1%E7%90%86%E5%B9%B3%E5%8F%B0.assets/8fc1b94d68716a37104f030e8f1b6601697559838.png)\n\n查看密码\n\n```bash\ndocker logs qianyios_rancher  2>&1 | grep \"Bootstrap Password:\"\n```\n\n`qianyios_rancher`是我前面创建容器的一个名字\n\n> Bootstrap Password: `5qnwrp6gm9q28zsqnkbd2ktjxpkqkbt9rdbpb46c5xzf5qqkr8snx7`\n>\n\n设置自定义密码\n\n![image-20250620192043119](../img/Rancher%E5%AE%B9%E5%99%A8%E7%AE%A1%E7%90%86%E5%B9%B3%E5%8F%B0.assets/fa54d0b14f1c0f868f28c79d453b9cf3697559838.png)\n\n![image-20250620192152598](../img/Rancher%E5%AE%B9%E5%99%A8%E7%AE%A1%E7%90%86%E5%B9%B3%E5%8F%B0.assets/d5b4fde8571d20f8cd8c85f976a139eb697559838.png)\n\n首页就这样了，安装成功\n\n设置中文\n\n![image-20250630171010286](../img/Rancher%E5%AE%B9%E5%99%A8%E7%AE%A1%E7%90%86%E5%B9%B3%E5%8F%B0.assets/a452f53a6758d5d6ceccd363348e3d26697559838.png)\n\n\n\n## 添加已\n\n## 在Kubernetes上部署Rancher\n\n在此之前添加一个环境变量\n\n操作节点：[所有的server]\n\n在root用户下\n\n```bash\nsudo echo \"export KUBECONFIG=/etc/rancher/k3s/k3s.yaml\" >> /etc/profile\nsudo echo \"export KUBECONFIG=/etc/rancher/k3s/k3s.yaml\" >> ~/.bashrc\nsource /etc/profile\nsource ~/.bashrc\nsudo kubectl config view --raw >>~/.kube/config\necho $KUBECONFIG\n```\n\n\n\n### 先决条件\n\n\n\n- [helm3](#Helm3)\n- [Kubernetes 集群](#Kubernetes 集群)\n- [Ingress Controller](#Ingress Controller)\n- [CLI 工具](https://ranchermanager.docs.rancher.com/zh/getting-started/installation-and-upgrade/install-upgrade-on-a-kubernetes-cluster#cli-工具)\n\n\n\n#### Helm3\n\n`建议所有的server节点都安装`\n\n官网教程：[Helm3 安装](https://www.zhaowenyu.com/helm-doc/install/helm3-install.html)\n\n本教材默认你使用的是helm3，如果没安装请按照以下教程安装，安装了就略过\n\n```bash\nsudo curl https://qygit.qianyisky.cn/https://raw.githubusercontent.com/helm/helm/main/scripts/get-helm-3 | bash\n```\n\n![image-20250625174201913](../img/Rancher%E5%AE%B9%E5%99%A8%E7%AE%A1%E7%90%86%E5%B9%B3%E5%8F%B0.assets/cf22c9c4480fa141165e2f293a7e3c7f697559838.png)\n\n#### Kubernetes 集群\n\n自行部署一个Kubernetes集群\n\n已经测试过的Kubernetes\n\n[基于OpenEuler部署K3S](https://blog.qianyios.top/posts/998bbc2f/)\n\n[基于Centos7部署k3s](https://blog.qianyios.top/posts/df961508/)\n\n[OpenEuler-K8S高可用集群（内部etcd）](https://blog.qianyios.top/posts/62904/)\n\n\n\n#### Ingress Controller\n\nRancher UI 和 API 通过 Ingress 公开。换言之，安装 Rancher 的 Kubernetes 集群必须包含一个 Ingress Controller。\n\n对于 RKE、RKE2 和 `K3s`，你不需要手动安装 Ingress Controller，因为它是默认安装的。\n\n对于默认不包含 Ingress Controller 的发行版（例如 EKS、GKE 或 AKS 等托管 Kubernetes 集群），`你必须先部署  Ingress Controller`。请注意，Rancher Helm Chart 默认情况下不会在 Ingress 上设置 `ingressClassName`。因此，你必须将 Ingress Controller 配置为在没有 `ingressClassName` 的情况下也可以监视 Ingress。\n\n上面的 **Amazon EKS**、**AKS** 和 **GKE** 教程中包含了示例。\n\n\n\n如果不是RKE、RKE2 和 `K3s`的Kubernetes，你需要按照一下教程安装Ingress Controller\n\n```bash\nsudo helm repo add ingress-nginx https://kubernetes.github.io/ingress-nginx\nsudo helm repo update\nsudo helm search repo ingress-nginx -l\n```\n\n### 安装 Rancher Helm Chart\n\nRancher 是使用 Kubernetes 的 [Helm](https://helm.sh/) 包管理器安装的。Helm Chart 为 Kubernetes YAML 清单文件提供了模板语法。通过 Helm，用户可以创建可配置的 deployment，而不仅仅只能使用静态文件。\n\n如果系统无法直接访问互联网，请参见[离线环境：Kubernetes 安装](https://ranchermanager.docs.rancher.com/zh/getting-started/installation-and-upgrade/other-installation-methods/air-gapped-helm-cli-install/install-rancher-ha)。\n\n如果要指定安装的 Rancher 版本，请参见[选择 Rancher 版本](https://ranchermanager.docs.rancher.com/zh/getting-started/installation-and-upgrade/resources/choose-a-rancher-version)。\n\n如果要指定用于安装 Rancher 的 Helm 版本，请参见[Helm 版本要求](https://ranchermanager.docs.rancher.com/zh/getting-started/installation-and-upgrade/resources/helm-version-requirements)。\n\n\n\n`本安装指南假定你使用的是 Helm 3。`\n\n#### 添加 Helm Chart 仓库\n\n操作节点：[server1]\n\nLatest：建议用于试用最新功能\n\n```bash\nsudo helm repo add rancher-latest https://releases.rancher.com/server-charts/latest\n```\n\nStable：建议用于生产环境(`本实验实验这个`)\n\n```bash\nsudo helm repo add rancher-stable https://releases.rancher.com/server-charts/stable\n```\n\nAlpha：即将发布的实验性预览。\n\n```bash\nsudo helm repo add rancher-alpha https://releases.rancher.com/server-charts/alpha\n```\n\n 注意：不支持升级到 Alpha 版、从 Alpha 版升级或在 Alpha 版之间升级。\n\n####  为 Rancher 创建命名空间\n\n```bash\nkubectl create namespace cattle-system\n```\n\n#### 选择 SSL 配置\n\nRancher Management Server 默认需要 SSL/TLS 配置来保证访问的安全性。\n\n你可以从以下三种证书来源中选择一种，用于在 Rancher Server 中设置 TLS：\n\n- **Rancher 生成的 TLS 证书**：要求你在集群中安装 `cert-manager`。Rancher 使用 `cert-manager` 签发并维护证书。Rancher 会生成自己的 CA 证书，并使用该 CA 签署证书。然后 `cert-manager`负责管理该证书。\n- **Let's Encrypt**：Let's Encrypt 选项也需要使用 `cert-manager`。但是，在这种情况下，cert-manager 与 Let's Encrypt 的特殊颁发者相结合，该颁发者执行获取 Let's Encrypt 颁发的证书所需的所有操作（包括请求和验证）。此配置使用 HTTP 验证（`HTTP-01`），因此负载均衡器必须具有可以从互联网访问的公共 DNS 记录。\n- **你已有的证书**：使用已有的 CA 颁发的公有或私有证书。Rancher 将使用该证书来保护 WebSocket 和 HTTPS 流量。在这种情况下，你必须上传名称分别为 `tls.crt` 和 `tls.key`的 PEM 格式的证书以及相关的密钥。如果你使用私有 CA，则还必须上传该 CA 证书。这是由于你的节点可能不信任此私有 CA。Rancher  将获取该 CA 证书，并从中生成一个校验和，各种 Rancher 组件将使用该校验和来验证其与 Rancher 的连接。\n\n| 配置                       | Helm Chart 选项                  | 是否需要 cert-manager                                        |\n| -------------------------- | -------------------------------- | ------------------------------------------------------------ |\n| Rancher 生成的证书（默认） | `ingress.tls.source=rancher`     | [是](https://ranchermanager.docs.rancher.com/zh/getting-started/installation-and-upgrade/install-upgrade-on-a-kubernetes-cluster#4-安装-cert-manager) |\n| Let’s Encrypt              | `ingress.tls.source=letsEncrypt` | [是](https://ranchermanager.docs.rancher.com/zh/getting-started/installation-and-upgrade/install-upgrade-on-a-kubernetes-cluster#4-安装-cert-manager) |\n| 你已有的证书               | `ingress.tls.source=secret`      | 否                                                           |\n\n##### 安装 cert-manager\n\n建议提前下载这个镜像`rancher/mirrored-library-traefik:3.3.6`\n\n如果你使用自己的证书文件（`ingress.tls.source=secret`）或使用[外部负载均衡器的 TLS 设置](https://ranchermanager.docs.rancher.com/zh/getting-started/installation-and-upgrade/installation-references/helm-chart-options#外部-tls-终止)，你可以跳过此步骤。\n\n仅在使用 Rancher 生成的证书（`ingress.tls.source=rancher`）或 Let's Encrypt 颁发的证书（`ingress.tls.source=letsEncrypt`）时，才需要安装 cert-manager。\n\n```bash\n# 如果你手动安装了CRD，而不是在 Helm 安装命令（下面最后一条安装命令）中添加了 `--set installCRDs=true` 选项，你应该在升级 Helm Chart 之前升级 CRD 资源。\nsudo kubectl apply -f https://github.com/cert-manager/cert-manager/releases/download/<版本号>/cert-manager.crds.yaml\n\n# 添加 Jetstack Helm 仓库\nsudo helm repo add jetstack https://charts.jetstack.io\n\n# 更新本地 Helm Chart 仓库缓存\nsudo helm repo update\n\n# 安装 cert-manager Helm Chart\nsudo helm install cert-manager jetstack/cert-manager \\\n  --namespace cert-manager \\\n  --create-namespace \\\n  --set installCRDs=true \\\n  --kubeconfig /etc/rancher/k3s/k3s.yaml\n```\n\n![image-20250630155004149](../img/Rancher%E5%AE%B9%E5%99%A8%E7%AE%A1%E7%90%86%E5%B9%B3%E5%8F%B0.assets/c73c9ee0685da8df10031928ea894bc2697559838.png)\n\n这里可能要等个一两分钟\n\n```bash\nsudo kubectl get pods --namespace cert-manager\n```\n\n```bash\n[abc@server1 ~]$ sudo kubectl get pods --namespace cert-manager\nNAME                                       READY   STATUS    RESTARTS   AGE\ncert-manager-7ccbc46c67-w6bpt              1/1     Running   0          118s\ncert-manager-cainjector-655bb66698-gsqm6   1/1     Running   0          118s\ncert-manager-webhook-586666dcd7-mhcmn      1/1     Running   0          118s\n```\n\n如果要卸载就用下面的命令\n\n```bash\nhelm uninstall cert-manager --namespace cert-manager\nkubectl delete namespace cert-manager\n```\n\n### 根据你选择的证书选项，通过 Helm 安装 Rancher\n\n日期：2025年6月30日\n\n目前他会用到的进行过是`rancher/rancher:v2.11.3`但是拉去很慢。那你就用下面的命令，后面如果更新了，我就不知道了，下面是我自己构建的镜像，如果版本变量，你就自己构建镜像，然后自己打tag就行了\n\n```bash\nsudo docker pull registry.cn-guangzhou.aliyuncs.com/qianyios/rancher:v2.11.3\nsudo docker rmi rancher/rancher:v2.11.3\nsudo docker tag registry.cn-guangzhou.aliyuncs.com/qianyios/rancher:v2.11.3 rancher/rancher:v2.11.3\n```\n\n\n\n\n\n不同的证书配置需要使用不同的 Rancher 安装命令。\n\n但是，无论证书如何配置，Rancher 在 `cattle-system` 命名空间中的安装名称应该总是 `rancher`。\n\n> 测试和开发：\n>\n> 这个安装 Rancher 的最终命令需要一个将流量转发到 Rancher 的域名。如果你使用 Helm CLI 设置概念证明，则可以在传入 `hostname` 选项时使用伪域名。伪域名的一个例子是 `<IP_OF_LINUX_NODE>.sslip.io`，这会把 Rancher 暴露在它运行的 IP 上。生产安装中要求填写真实的域名。\n\n这里就用`Rancher 生成的证书`的方式，其他的方式需要自行访问官网[根据你选择的证书选项，通过 Helm 安装 Rancher](https://ranchermanager.docs.rancher.com/zh/getting-started/installation-and-upgrade/install-upgrade-on-a-kubernetes-cluster#5-%E6%A0%B9%E6%8D%AE%E4%BD%A0%E9%80%89%E6%8B%A9%E7%9A%84%E8%AF%81%E4%B9%A6%E9%80%89%E9%A1%B9%E9%80%9A%E8%BF%87-helm-%E5%AE%89%E8%A3%85-rancher)\n\n```bash\n#添加 Rancher 的 Helm 仓库\nsudo helm uninstall rancher --namespace cattle-system\nsudo helm repo add rancher-stable https://releases.rancher.com/server-charts/stable\nsudo helm repo update\n```\n\n#### 域名安装方式\n\n默认情况是使用 Rancher 生成 CA，并使用 `cert-manager` 颁发用于访问 Rancher Server 接口的证书。\n\n由于 `rancher` 是 `ingress.tls.source` 的默认选项，因此在执行 `helm install` 命令时，我们不需要指定 `ingress.tls.source`。\n\n- 将 `hostname` 设置为解析到你的负载均衡器的 DNS 名称。\n- 将 `bootstrapPassword` 设置为 `admin` 用户独有的值。\n- 如果你需要安装指定的 Rancher 版本，使用 `--version` 标志，例如 `--version 2.7.0`。\n- 对于 Kubernetes v1.25 或更高版本，使用 Rancher v2.7.2-v2.7.4 时，将 `global.cattle.psp.enabled` 设置为 `false`。对于 Rancher v2.7.5 及更高版本来说，这不是必需的，但你仍然可以手动设置该选项。\n\n`你要自行更改域名`\n\n```bash\nsudo helm install rancher rancher-stable/rancher \\\n  --namespace cattle-system \\\n  --create-namespace \\\n  --set hostname=qianyios.top \\\n  --set bootstrapPassword=admin \\\n  --set global.cattle.psp.enabled=false\n```\n\n如果你安装的是 alpha 版本，Helm 会要求你在安装命令中添加 `--devel` 选项：\n\n![image-20250630160806666](../img/Rancher%E5%AE%B9%E5%99%A8%E7%AE%A1%E7%90%86%E5%B9%B3%E5%8F%B0.assets/1c210fea20ece83a4b857246be0b533d697559838.png)\n\n如果你希望使用域名访问 Rancher，可以在宿主机上配置 `hosts` 文件，并将 Helm 安装命令中的 `hostname` 参数改为域名。\n\n#### **NodePort**（本实验用这个）\n\n如果你不想配置域名，也可以通过配置 Kubernetes 的 `NodePort` 或 `LoadBalancer` 来访问 Rancher。\n\n```bash\nsudo helm install rancher rancher-stable/rancher \\\n  --namespace cattle-system \\\n  --create-namespace \\\n  --set hostname=192.168.48.200 \\\n  --set bootstrapPassword=admin \\\n  --set global.cattle.psp.enabled=false \\\n  --set ingress.enabled=false \\\n  --set service.type=NodePort\n```\n\n```\nsudo kubectl get pods,svc -n cattle-system\n```\n\n![image-20250630165640476](../img/Rancher%E5%AE%B9%E5%99%A8%E7%AE%A1%E7%90%86%E5%B9%B3%E5%8F%B0.assets/60097f1cc73bd3a54f18537208eb0374697559838.png)\n\nRancher的访问地址就是https://192.168.48.200:32684\n\n#### **LoadBalancer**\n\n- 如果你的 Kubernetes 环境支持 `LoadBalancer`，可以将 `service.type` 设置为 `LoadBalancer`：\n\n```bash\nsudo helm install rancher rancher-stable/rancher \\\n  --namespace cattle-system \\\n  --create-namespace \\\n  --set hostname=192.168.48.200 \\\n  --set bootstrapPassword=admin \\\n  --set global.cattle.psp.enabled=false \\\n  --set ingress.enabled=false \\\n  --set service.type=LoadBalancer\n```\n\n\n\n\n\n等待 Rancher 运行：\n\n```bash\nkubectl -n cattle-system rollout status \n```\n\n```bash\n[root@server1 ~]# kubectl -n cattle-system rollout status deploy/rancher\ndeployment \"rancher\" successfully rolled out\n[root@server1 ~]#\n```\n\nRancher Chart 有许多选项，用于为你的具体环境自定义安装。以下是一些常见的高级方案：\n\n- [HTTP 代理](https://ranchermanager.docs.rancher.com/zh/getting-started/installation-and-upgrade/installation-references/helm-chart-options#http-代理)\n- [私有容器镜像仓库](https://ranchermanager.docs.rancher.com/zh/getting-started/installation-and-upgrade/installation-references/helm-chart-options#私有仓库和离线安装)\n- [外部负载均衡器上的 TLS 终止](https://ranchermanager.docs.rancher.com/zh/getting-started/installation-and-upgrade/installation-references/helm-chart-options#外部-tls-终止)\n\n如需获取完整的选项列表，请参见 [Chart 选项](https://ranchermanager.docs.rancher.com/zh/getting-started/installation-and-upgrade/installation-references/helm-chart-options)。\n\n### 验证 Rancher Server 是否部署成功\n\n```bash\nkubectl -n cattle-system get deploy rancher\n```\n\n```bash\n[root@server1 ~]# kubectl -n cattle-system get deploy rancher\nNAME      READY   UP-TO-DATE   AVAILABLE   AGE\nrancher   3/3     3            3           36m\n[root@server1 ~]#\n```\n\n`DESIRED` 和 `AVAILABLE`的个数应该相同。\n\n### 页面访问\n\n![image-20250630170634387](../img/Rancher%E5%AE%B9%E5%99%A8%E7%AE%A1%E7%90%86%E5%B9%B3%E5%8F%B0.assets/46768f413a4fee2cf38b452320d74d16697559838.png)\n\n![image-20250630170754565](../img/Rancher%E5%AE%B9%E5%99%A8%E7%AE%A1%E7%90%86%E5%B9%B3%E5%8F%B0.assets/97eb8a21995ffccc9062c97c4d1ba8e0697559838.png)\n\n设置中文\n\n![image-20250630171010286](../img/Rancher%E5%AE%B9%E5%99%A8%E7%AE%A1%E7%90%86%E5%B9%B3%E5%8F%B0.assets/a452f53a6758d5d6ceccd363348e3d26697559838.png)\n\n\n\n## 添加已有集群\n\n![image-20250630171252221](../img/Rancher%E5%AE%B9%E5%99%A8%E7%AE%A1%E7%90%86%E5%B9%B3%E5%8F%B0.assets/1bd5d286fde52077dd5fc1dff0427fba697559838.png)\n\n![image-20250630171312088](../img/Rancher%E5%AE%B9%E5%99%A8%E7%AE%A1%E7%90%86%E5%B9%B3%E5%8F%B0.assets/8ef3bbae7267d3833437912c5279d552697559838.png)\n\n![image-20250630171333429](../img/Rancher%E5%AE%B9%E5%99%A8%E7%AE%A1%E7%90%86%E5%B9%B3%E5%8F%B0.assets/72c2299ab24221f400f91faabac7dadf697559838.png)\n\n未完待续\n\n<div class=\"tbsm\" style=\"margin-top:54px;\">\n<div class=\"tbsm-top\"><span><svg t=\"1674654360507\" class=\"icon\" viewBox=\"0 0 1024 1024\" version=\"1.1\" xmlns=\"http://www.w3.org/2000/svg\" p-id=\"987\" data-spm-anchor-id=\"a313x.7781069.0.i0\" width=\"35\" height=\"35\"><path d=\"M410.49 97.74H155.08a56.74 56.74 0 0 0-56.84 56.73V410a56.84 56.84 0 0 0 56.84 56.84h255.41A56.83 56.83 0 0 0 467.32 410V154.58a56.83 56.83 0 0 0-56.83-56.84zM410.49 558.74H155.08a56.74 56.74 0 0 0-56.84 56.73V871a56.84 56.84 0 0 0 56.84 56.84h255.41A56.83 56.83 0 0 0 467.32 871V615.58a56.83 56.83 0 0 0-56.83-56.84zM871.49 558.74H616.08a56.74 56.74 0 0 0-56.84 56.73V871a56.84 56.84 0 0 0 56.84 56.84h255.41A56.83 56.83 0 0 0 928.32 871V615.58a56.83 56.83 0 0 0-56.83-56.84z\" fill=\"#66EEFF\" p-id=\"988\"></path><path d=\"M410.49 558.74h-4.14A475 475 0 0 0 299.52 859.6a481.16 481.16 0 0 0 4.84 68.22h106.13A56.83 56.83 0 0 0 467.32 871V615.58a56.83 56.83 0 0 0-56.83-56.84zM871.49 558.74H616.08a56.74 56.74 0 0 0-56.84 56.73V871a56.84 56.84 0 0 0 56.84 56.84h255.41A56.83 56.83 0 0 0 928.32 871V615.58a56.83 56.83 0 0 0-56.83-56.84z\" fill=\"#C2F8FF\" p-id=\"989\"></path></svg></span><span style=\"font-size:30px;\"> 特别声明</span></div>\n<div class=\"tbsm-wz\">千屹博客旗下的所有文章，是通过本人课堂学习和课外自学所精心整理的知识巨著<br/>难免会有出错的地方<br/>如果细心的你发现了小失误，可以在下方评论区告诉我，或者私信我！<br />非常感谢大家的热烈支持！</div>\n</div>\n","tags":["K8s","K3s"],"categories":["云原生"]},{"title":"基于Centos7部署k3s","url":"/posts/df961508/","content":"\n<meta name=\"referrer\" content=\"no-referrer\"/>\n\n# 基于Centos7部署k3s\n\n## 主机拓扑\n\n| 主机名  |       ip       | CPU  | 内存  |\n| :-----: | :------------: | :--: | :---: |\n| Server1 | 192.168.48.101 |  ≧2  |  2G   |\n| Server2 | 192.168.48.102 |  ≧2  |  2G   |\n| Server3 | 192.168.48.103 |  ≧2  |  2G   |\n| Agent1  | 192.168.49.104 |  ≧1  | 512MB |\n\n如果你是只用单serve1只需要创建server1和若干台agent，部署教程请跳转[3.基础k3s](#基础k3s)\n\n如果你是高可用一定需要保留≥3台的server节点，部署教程请跳转[6.高可用k3s](#高可用k3s)\n\n前提是要完成[2.基础配置](#基础配置)\n\n## 基础配置\n\n高可用和基础k3s都要运行\n\n### 系统初始化\n\n操作节点:[所有节点]\n\n```\nsudo vi system_init.sh\n```\n\n```bash\n#!/bin/bash\nif [ $# -eq 2 ];then\n  echo \"设置主机名为：$1\"\n  echo \"ens33设置IP地址为：192.168.48.$2\"\nelse\n  echo  \"使用方法：sh $0 主机名 主机位\"\n  exit 2\nfi\n\necho \"--------------------------------------\"\necho \"1.正在设置主机名：$1\"\nhostnamectl set-hostname $1\n\necho \"2.正在关闭firewalld、selinux\"\nsystemctl disable firewalld &> /dev/null\nsystemctl stop firewalld\nsed -i \"s#SELINUX=enforcing#SELINUX=disabled#g\" /etc/selinux/config\nsetenforce 0\n\necho \"3.正在设置ens33：192.168.48.$2\"\ncat > /etc/sysconfig/network-scripts/ifcfg-ens33 <<EOF\nTYPE=Ethernet\nPROXY_METHOD=none\nBROWSER_ONLY=no\nBOOTPROTO=static\nDEFROUTE=yes\nIPV4_FAILURE_FATAL=no\nIPV6INIT=yes\nIPV6_AUTOCONF=yes\nIPV6_DEFROUTE=yes\nIPV6_FAILURE_FATAL=no\nNAME=ens33\nUUID=53b402ff-5865-47dd-a853-7afcd6521738\nDEVICE=ens33\nONBOOT=yes\nIPADDR=192.168.48.$2\nGATEWAY=192.168.48.2\nPREFIX=24\nDNS1=192.168.48.2\nDNS2=114.114.114.114\nEOF\nnmcli c reload\nnmcli c up ens33\n\necho \"4.更新yum源软件包缓存\"\nyum clean all && yum makecache\n\necho \"5.添加hosts解析\"\ncat > /etc/hosts <<EOF\n127.0.0.1   localhost localhost.localdomain localhost4 localhost4.localdomain4\n::1         localhost localhost.localdomain localhost6 localhost6.localdomain6\n192.168.48.101 Server1\n192.168.48.102 Server2\n192.168.48.103 Server3\n192.168.48.104 Agent1\nEOF\n\necho \"6.必备工具安装\"\nyum install wget psmisc vim net-tools telnet socat device-mapper-persistent-data lvm2 git gcc -y\n\necho \"7.重启系统\"\nreboot\n```\n\n```\nsudo chmod +x system_init.sh\n[Server1] sudo sh system_init.sh Server1 101\n[Server2] sudo sh system_init.sh Server2 102\n[Server3] sudo sh system_init.sh Server3 103\n[Agent1] sudo sh system_init.sh Agent1 104\n```\n\n### 安装容器工具\n\n请你考虑好，你的集群要以什么为运行时，下面提供了，docker和containerd，自行选择\n\n`只能二选一！！！`\n\n`只能二选一！！！`\n\n`只能二选一！！！`\n\n#### 安装docker\n\n操作节点:[所有节点]\n\n```bash\nsudo curl -L \"https://qygit.qianyisky.cn/https://github.com/docker/compose/releases/download/v2.35.1/docker-compose-linux-x86_64\" -o /usr/local/bin/docker-compose\n#卸载旧版本\nsudo yum -y remove docker \\\n                  docker-client \\\n                  docker-client-latest \\\n                  docker-common \\\n                  docker-latest \\\n                  docker-latest-logrotate \\\n                  docker-logrotate \\\n                  docker-selinux \\\n                  docker-engine-selinux \\\n                  docker-engine\nsudo yum remove docker-ce docker-ce-cli containerd.io docker-compose docker-machine docker-swarm -y\nsudo rm /etc/yum.repos.d/docker-ce.repo\nsudo rm -rf /var/lib/docker\n\nsudo yum install -y yum-utils device-mapper-persistent-data lvm2\nsudo yum-config-manager --add-repo https://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo\nsudo yum install docker-ce -y\nsudo systemctl enable --now docker\nsudo chmod +x /usr/local/bin/docker-compose\nsudo tee /etc/docker/daemon.json > /dev/null <<'EOF'\n{\n  \"registry-mirrors\": [\n    \"https://docker.xuanyuan.me\",\n    \"https://docker.m.daocloud.io\",\n    \"https://docker.1ms.run\",\n    \"https://docker.1panel.live\",\n    \"https://registry.cn-hangzhou.aliyuncs.com\",\n    \"https://docker.qianyios.top\"\n  ],\n  \"max-concurrent-downloads\": 10,\n  \"log-driver\": \"json-file\",\n  \"log-level\": \"warn\",\n  \"log-opts\": {\n    \"max-size\": \"10m\",\n    \"max-file\": \"3\"\n  },\n  \"data-root\": \"/var/lib/docker\"\n}\nEOF\nsudo systemctl daemon-reload\nsudo systemctl restart docker\nsudo docker-compose --version\nsudo docker version\n\n```\n\n#### 安装containerd\n\n操作节点:[所有节点]\n\n```bash\nsudo yum install -y yum-utils\nsudo yum-config-manager --add-repo https://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo\nsudo yum clean all && yum makecache\nsudo yum install -y containerd.io\n\nsudo mkdir -p /etc/containerd/certs.d/docker.io\nsudo mkdir -p /etc/containerd/certs.d/registry.k8s.io\nsudo mkdir -p /etc/containerd/certs.d/k8s.gcr.io\nsudo mkdir -p /etc/containerd/certs.d/ghcr.io\nsudo mkdir -p /etc/containerd/certs.d/gcr.io\nsudo mkdir -p /etc/containerd/certs.d/quay.io\nsudo mkdir -p /etc/containerd/certs.d/registry-1.docker.io\n\nsudo tee /etc/containerd/certs.d/docker.io/hosts.toml > /dev/null <<'EOF'\nserver = \"https://docker.io\" \n\n[host.\"https://registry.cn-hangzhou.aliyuncs.com/\"]\n  capabilities = [\"pull\", \"resolve\"]\n[host.\"https://docker.xuanyuan.me\"]\n  capabilities = [\"pull\", \"resolve\"]\n[host.\"https://docker.m.daocloud.io\"]\n  capabilities = [\"pull\", \"resolve\"]\n[host.\"https://docker.1ms.run\"]\n  capabilities = [\"pull\", \"resolve\"]\n[host.\"https://docker.1panel.live\"]\n  capabilities = [\"pull\", \"resolve\"]\n[host.\"https://docker.qianyios.top/\"] \n  capabilities = [\"pull\", \"resolve\"]\n[host.\"https://reg-mirror.giniu.com\"] \n  capabilities = [\"pull\", \"resolve\"]\nEOF\n\nsudo tee /etc/containerd/certs.d/registry-1.docker.io/hosts.toml > /dev/null <<'EOF'\nserver = \"https://registry-1.docker.io\"\n\n[host.\"https://registry.cn-hangzhou.aliyuncs.com/\"]\n  capabilities = [\"pull\", \"resolve\"]\n[host.\"https://docker.xuanyuan.me\"]\n  capabilities = [\"pull\", \"resolve\"]\n[host.\"https://docker.m.daocloud.io\"]\n  capabilities = [\"pull\", \"resolve\"]\n[host.\"https://docker.1ms.run\"]\n  capabilities = [\"pull\", \"resolve\"]\n[host.\"https://docker.1panel.live\"]\n  capabilities = [\"pull\", \"resolve\"]\n[host.\"https://docker.qianyios.top/\"] \n  capabilities = [\"pull\", \"resolve\"]\n[host.\"https://reg-mirror.giniu.com\"] \n  capabilities = [\"pull\", \"resolve\"]\nEOF\n\n\nsudo tee /etc/containerd/certs.d/k8s.gcr.io/hosts.toml > /dev/null <<'EOF'\nserver = \"https://k8s.gcr.io\"\n\n[host.\"https://registry.aliyuncs.com/google_containers\"]\n  capabilities = [\"pull\", \"resolve\"]\nEOF\n\nsudo tee /etc/containerd/certs.d/ghcr.io/hosts.toml > /dev/null <<'EOF'\nserver = \"https://ghcr.io\"\n\n[host.\"https://ghcr.m.daocloud.io/\"]\n  capabilities = [\"pull\", \"resolve\"]\nEOF\n\nsudo tee /etc/containerd/certs.d/gcr.io/hosts.toml > /dev/null <<'EOF'\nserver = \"https://gcr.io\"\n\n[host.\"https://gcr.m.daocloud.io/\"]\n  capabilities = [\"pull\", \"resolve\"]\nEOF\n\nsudo tee /etc/containerd/certs.d/registry.k8s.io/hosts.toml > /dev/null <<'EOF'\nserver = \"registry.k8s.io\"\n\n[host.\"k8s.m.daocloud.io\"]\n  capabilities = [\"pull\", \"resolve\", \"push\"]\n[host.\"https://registry.aliyuncs.com/v2/google_containers\"]\n  capabilities = [\"pull\", \"resolve\"]\nEOF\n\nsudo tee /etc/containerd/certs.d/quay.io/hosts.toml > /dev/null <<'EOF'\nserver = \"https://quay.io\"\n\n[host.\"https://quay.tencentcloudcr.com/\"]\n  capabilities = [\"pull\", \"resolve\"]\nEOF\n\nsudo sh -c 'containerd config default > /etc/containerd/config.toml'\nsudo sed -i 's#sandbox_image = \"registry.k8s.io/pause:.*\"#sandbox_image = \"registry.aliyuncs.com/google_containers/pause:3.10\"#' /etc/containerd/config.toml\nsudo sed -i 's/SystemdCgroup = false/SystemdCgroup = true/g' /etc/containerd/config.toml\nsed -i '/\\[plugins\\.\"io\\.containerd\\.grpc\\.v1\\.cri\"\\.registry\\]/!b;n;s/config_path = \"\"/config_path = \"\\/etc\\/containerd\\/certs.d\"/' /etc/containerd/config.toml\n# 重启 containerd 服务\nsudo systemctl daemon-reload\nsudo systemctl restart containerd.service\nsudo ctr image ls\n```\n\n### 添加镜像源\n\n操作节点:[所有节点]\n\n```bash\nsudo mkdir -p /etc/rancher/k3s\nsudo tee /etc/rancher/k3s/registries.yaml > /dev/null <<'EOF'\nmirrors:\n  docker.io:\n    endpoint:\n      - \"https://registry.cn-hangzhou.aliyuncs.com/\" \n      - \"https://docker.xuanyuan.me\" \n      - \"https://docker.m.daocloud.io\" \n      - \"https://docker.1ms.run\" \n      - \"https://docker.1panel.live\" \n      - \"https://hub.rat.dev\" \n      - \"https://docker-mirror.aigc2d.com\" \n      - \"https://docker.qianyios.top/\"\n  quay.io:\n    endpoint:\n      - \"https://quay.tencentcloudcr.com/\"   \n  registry.k8s.io:\n    endpoint:\n      - \"https://registry.aliyuncs.com/v2/google_containers\"   \n  gcr.io:\n    endpoint:\n      - \"https://gcr.m.daocloud.io/\"   \n  k8s.gcr.io:\n    endpoint:\n      - \"https://registry.aliyuncs.com/google_containers\"   \n  ghcr.io:\n    endpoint:\n      - \"https://ghcr.m.daocloud.io/\"   \nEOF\n```\n\n建议在这里打个快照\n\n## 基础k3s\n\n确保`所有节点`都下载了k3s安装脚本\n\n```bash\nsudo wget https://rancher-mirror.rancher.cn/k3s/k3s-install.sh\nsudo chmod +x k3s-install.sh\n```\n\n这里目前只需要用到`Server1`和`Agent1`，也就是单server1情况\n\n### 部署Server\n\n操作节点：[Server1]\n\n如需在单个服务器上安装 K3s，可以在 server 节点上执行如下操作：\n\n`要注意你选的是哪个容器工具哈`\n\n`要注意你选的是哪个容器工具哈`\n\n`要注意你选的是哪个容器工具哈`\n\n#### 基于docker\n\n`如果有参数的值数错了，可以改一下，然后重新运行命令即可`\n\n`--docke`一定要放在所有参数的最前面\n\n```bash\nsudo \\\nINSTALL_K3S_MIRROR=cn \\\nINSTALL_K3S_REGISTRIES=\"https://registry.cn-hangzhou.aliyuncs.com,https://registry.aliyuncs.com/google_containers\" \\\n./k3s-install.sh --docker \\\n--system-default-registry \"registry.cn-hangzhou.aliyuncs.com\"\n```\n\n![image-20250616205458407](../img/%E5%9F%BA%E4%BA%8ECentos7%E9%83%A8%E7%BD%B2k3s.assets/bde1ec698699808fb7751fdde90a7dcd697559838.png)\n\n自行完成 [9.解决非root用户使用kubectl等命令显示无命令的办法](#解决非root用户使用kubectl等命令显示无命令的办法)\n\n#### 基于containerd\n\n`如果有参数的值数错了，可以改一下，然后重新运行命令即可`\n\n```bash\nsudo \\\nINSTALL_K3S_MIRROR=cn \\\nINSTALL_K3S_REGISTRIES=\"https://registry.cn-hangzhou.aliyuncs.com,https://registry.aliyuncs.com/google_containers\" \\\n./k3s-install.sh \\\n--system-default-registry \"registry.cn-hangzhou.aliyuncs.com\"\n```\n\n![image-20250613193916684](../img/%E5%9F%BA%E4%BA%8ECentos7%E9%83%A8%E7%BD%B2k3s.assets/12f9e6a5a1135484d1e4bc7a8ada5256697559838.png)\n\n自行完成 [9.解决非root用户使用kubectl等命令显示无命令的办法](#解决非root用户使用kubectl等命令显示无命令的办法)\n\n\n\n### 部署Agent节点\n\n操作节点：[Server1]\n\n#### 查看token\n\n```\nsudo cat /var/lib/rancher/k3s/server/node-token\n```\n\n> K107eca1d1c601a2d308c7dd0b639ef08fa9414f729c720c0cc04337126aa966884::server:`035b03761950e59b30e9f5310b92310c`\n\n`要注意你选的是哪个容器工具哈`\n\n`要注意你选的是哪个容器工具哈`\n\n`要注意你选的是哪个容器工具哈`\n\n#### 基于docker\n\n操作节点：[Agent1]\n\n`如果有参数的值数错了，可以改一下，然后重新运行命令即可`\n\n`--docke`一定要放在所有参数的最前面\n\n```bash\nsudo \\\nINSTALL_K3S_MIRROR=cn \\\nK3S_URL=https://192.168.48.101:6443  \\\nK3S_TOKEN=035b03761950e59b30e9f5310b92310c \\\nINSTALL_K3S_REGISTRIES=\"https://registry.cn-hangzhou.aliyuncs.com,https://registry.aliyuncs.com/google_containers\" \\\n./k3s-install.sh --docker\n```\n\n· `035b03761950e59b30e9f5310b92310c` 是前面`server1`获取的`token`\n\n· `192.168.48.101`是`server1`的ip\n\n![image-20250616210407492](../img/%E5%9F%BA%E4%BA%8ECentos7%E9%83%A8%E7%BD%B2k3s.assets/15e3404f50570f307b5dded0292238d3697559838.png)\n\n这时候在server1查看是否成功加入集群\n\n```\nsudo kubectl get nodes\n```\n\n![image-20250613194651483](../img/%E5%9F%BA%E4%BA%8ECentos7%E9%83%A8%E7%BD%B2k3s.assets/0f97418fbf0e0118e49005e7542d0e46697559838.png)\n\n如果需要部署dashboard请跳转[7.安装dashboard](#安装dashboard)\n\n#### 基于containerd\n\n操作节点：[Agent1]\n\n`如果有参数的值数错了，可以改一下，然后重新运行命令即可`\n\n```bash\nsudo \\\nINSTALL_K3S_MIRROR=cn \\\nK3S_URL=https://192.168.48.101:6443  \\\nK3S_TOKEN=035b03761950e59b30e9f5310b92310c \\\nINSTALL_K3S_REGISTRIES=\"https://registry.cn-hangzhou.aliyuncs.com,https://registry.aliyuncs.com/google_containers\" \\\n./k3s-install.sh \n```\n\n· `035b03761950e59b30e9f5310b92310c` 是前面`server1`获取的`token`\n\n· `192.168.48.101`是`server1`的ip\n\n![image-20250613194635932](../img/%E5%9F%BA%E4%BA%8ECentos7%E9%83%A8%E7%BD%B2k3s.assets/8e61bfe3289eeb8f6eddf5ac82a63dcb697559838.png)\n\n这时候在server1查看是否成功加入集群\n\n```\nsudo kubectl get nodes\n```\n\n![image-20250613194651483](../img/%E5%9F%BA%E4%BA%8ECentos7%E9%83%A8%E7%BD%B2k3s.assets/0f97418fbf0e0118e49005e7542d0e46697559838.png)\n\n如果需要部署dashboard请跳转[7.安装dashboard](#安装dashboard)\n\n\n\n## 高可用k3s\n\n确保`所有节点`都下载了k3s安装脚本\n\n```bash\nsudo wget https://rancher-mirror.rancher.cn/k3s/k3s-install.sh\nsudo chmod +x k3s-install.sh\n```\n\n\n\n\n\n### 配置集群负载均衡器\n\n官方教程：[集群负载均衡器](https://docs.k3s.io/datastore/cluster-loadbalancer)\n\n按理来说我们需要两台额外的节点来做负载均衡和高可用vip节点，但是为了测试方便，我们直接部署在\n\nserver节点，也就是图中的第二种方法\n\n![image-20250613122740304](../img/%E5%9F%BA%E4%BA%8ECentos7%E9%83%A8%E7%BD%B2k3s.assets/b60fa286a35dc9a7d720bda96d7eafe0697559838.png)\n\n操作节点：[所有的server]\n\n```bash\nsudo yum install -y haproxy keepalived\nsudo tee /etc/haproxy/haproxy.cfg > /dev/null <<'EOF'\nfrontend k3s-frontend\n    bind *:16443\n    mode tcp\n    option tcplog\n    default_backend k3s-backend\n\nbackend k3s-backend\n    mode tcp\n    option tcp-check\n    balance roundrobin\n    timeout connect 5s\n    timeout server 30s\n    timeout client 30s\n    default-server inter 10s downinter 5s\n    server server-1 192.168.48.101:6443 check\n    server server-2 192.168.48.102:6443 check\n    server server-3 192.168.48.103:6443 check\nEOF\n```\n\n操作节点:[Server1]\n\n```bash\nsudo tee /etc/keepalived/keepalived.conf > /dev/null <<'EOF'\nglobal_defs {\n  enable_script_security\n  script_user root\n}\n\nvrrp_script chk_haproxy {\n    script 'killall -0 haproxy'\n    interval 2\n}\n\nvrrp_instance haproxy-vip {\n    interface ens33  #这里要改，是你的网卡\n    state MASTER    #这里要改 server1是Master 其他都是Backup\n    priority 200\n\n    virtual_router_id 51\n\n    virtual_ipaddress {\n        192.168.48.200/24      #高可用ip\n    }\n\n    track_script {\n        chk_haproxy\n    }\n}\nEOF\n```\n\n操作节点:[Server2]\n\n```bash\nsudo tee /etc/keepalived/keepalived.conf > /dev/null <<'EOF'\nglobal_defs {\n  enable_script_security\n  script_user root\n}\n\nvrrp_script chk_haproxy {\n    script 'killall -0 haproxy'\n    interval 2\n}\n\nvrrp_instance haproxy-vip {\n    interface ens33  #这里要改，是你的网卡\n    state BACKUP    #这里要改 server1是Master 其他都是Backup\n    priority 150\n\n    virtual_router_id 51\n\n    virtual_ipaddress {\n        192.168.48.200/24      #高可用ip\n    }\n\n    track_script {\n        chk_haproxy\n    }\n}\nEOF\n```\n\n操作节点:[Server3]\n\n```bash\nsudo tee /etc/keepalived/keepalived.conf > /dev/null <<'EOF'\nglobal_defs {\n  enable_script_security\n  script_user root\n}\n\nvrrp_script chk_haproxy {\n    script 'killall -0 haproxy'\n    interval 2\n}\n\nvrrp_instance haproxy-vip {\n    interface ens33  #这里要改，是你的网卡\n    state BACKUP    #这里要改 server1是Master 其他都是Backup\n    priority 100\n\n    virtual_router_id 51\n\n    virtual_ipaddress {\n        192.168.48.200/24      #高可用ip\n    }\n\n    track_script {\n        chk_haproxy\n    }\n}\nEOF\n```\n\n操作节点：[所有的Server]\n\n```\nsudo systemctl restart haproxy keepalived\nsudo systemctl enable --now haproxy keepalived\n```\n\n现在来查看vip是否生成\n\n操作节点：[Server1]\n\n```\nip a\n```\n\n![image-20250613123125034](../img/%E5%9F%BA%E4%BA%8ECentos7%E9%83%A8%E7%BD%B2k3s.assets/a590e445a0e0a85df625e3bc22ed6e28697559838.png)\n\n### 初始化第一个server\n\n操作节点:[server1]\n\n\n\n`要注意你选的是哪个容器工具哈`\n\n`要注意你选的是哪个容器工具哈`\n\n`要注意你选的是哪个容器工具哈`\n\n\n\n#### 基于docker\n\n`如果有参数的值数错了，可以改一下，然后重新运行命令即可`\n\n> `--docke`一定要放在所有参数的最前面\n\n```bash\nsudo \\\nINSTALL_K3S_MIRROR=cn \\\nK3S_TOKEN=qianyiosQianyios12345 \\\nINSTALL_K3S_REGISTRIES=\"https://registry.cn-hangzhou.aliyuncs.com,https://registry.aliyuncs.com/google_containers\" \\\n./k3s-install.sh --docker --cluster-init - server  \\\n--system-default-registry \"registry.cn-hangzhou.aliyuncs.com\" \\\n--tls-san= 192.168.48.200 \n```\n\n`qianyiosQianyios12345`是作为集群间的共享密钥，可自定义\n\n![image-20250616210830594](../img/%E5%9F%BA%E4%BA%8ECentos7%E9%83%A8%E7%BD%B2k3s.assets/d5d187541485a0092c117127cce849d5697559838.png)\n\n自行完成 [9.解决非root用户使用kubectl等命令显示无命令的办法](#解决非root用户使用kubectl等命令显示无命令的办法)\n\n\n\n#### 基于containerd\n\n`如果有参数的值数错了，可以改一下，然后重新运行命令即可`\n\n```bash\nsudo \\\nINSTALL_K3S_MIRROR=cn \\\nK3S_TOKEN=qianyiosQianyios12345 \\\nINSTALL_K3S_REGISTRIES=\"https://registry.cn-hangzhou.aliyuncs.com,https://registry.aliyuncs.com/google_containers\" \\\n./k3s-install.sh  --cluster-init - server \\\n--system-default-registry \"registry.cn-hangzhou.aliyuncs.com\" \\\n--tls-san= 192.168.48.200\n```\n\n`qianyiosQianyios12345`是作为集群间的共享密钥，可自定义\n\n自行完成 [9.解决非root用户使用kubectl等命令显示无命令的办法](#解决非root用户使用kubectl等命令显示无命令的办法)\n\n\n\n\n\n### 其他server加入集群\n\n#### 基于docker\n\n`如果有参数的值数错了，可以改一下，然后重新运行命令即可`\n\n`--docke`一定要放在所有参数的最前面\n\n```bash\nsudo \\\nINSTALL_K3S_MIRROR=cn \\\nK3S_TOKEN=qianyiosQianyios12345 \\\nINSTALL_K3S_REGISTRIES=\"https://registry.cn-hangzhou.aliyuncs.com,https://registry.aliyuncs.com/google_containers\" \\\n./k3s-install.sh --docker \\\n--server https://192.168.48.101:6443  \\\n--system-default-registry \"registry.cn-hangzhou.aliyuncs.com\" \\\n--tls-san= 192.168.48.200\n```\n\n`qianyiosQianyios12345`是作为第一个server1共享出来的密钥\n\n--server https://192.168.48.101:6443 改成serve1的ip地址即可\n\n自行完成 [9.解决非root用户使用kubectl等命令显示无命令的办法](#解决非root用户使用kubectl等命令显示无命令的办法)\n\n\n\n#### 基于containerd\n\n`如果有参数的值数错了，可以改一下，然后重新运行命令即可`\n\n```bash\nsudo \\\nINSTALL_K3S_MIRROR=cn \\\nK3S_TOKEN=qianyiosQianyios12345 \\\nINSTALL_K3S_REGISTRIES=\"https://registry.cn-hangzhou.aliyuncs.com,https://registry.aliyuncs.com/google_containers\" \\\n./k3s-install.sh \\\n--system-default-registry \"registry.cn-hangzhou.aliyuncs.com\" \\\n--server https://192.168.48.101:6443  \\\n--tls-san= 192.168.48.200\n```\n\n`qianyiosQianyios12345`是作为第一个server1共享出来的密钥\n\n--server https://192.168.48.101:6443 改成serve1的ip地址即可\n\n自行完成 [9.解决非root用户使用kubectl等命令显示无命令的办法](#解决非root用户使用kubectl等命令显示无命令的办法)\n\n\n\n### 其他Agent加入集群\n\n#### 基于docker\n\n`如果有参数的值数错了，可以改一下，然后重新运行命令即可`\n\n`--docke`一定要放在所有参数的最前面\n\n```bash\nsudo \\\nINSTALL_K3S_MIRROR=cn \\\nK3S_TOKEN=qianyiosQianyios12345 \\\nK3S_URL=https://192.168.48.101:6443  \\\nINSTALL_K3S_REGISTRIES=\"https://registry.cn-hangzhou.aliyuncs.com,https://registry.aliyuncs.com/google_containers\" \\\n./k3s-install.sh --docker - agent \n```\n\n#### 基于containerd\n\n`如果有参数的值数错了，可以改一下，然后重新运行命令即可`\n\n```bash\nsudo \\\nINSTALL_K3S_MIRROR=cn \\\nK3S_TOKEN=qianyiosQianyios12345 \\\nK3S_URL=https://192.168.48.101:6443  \\\nINSTALL_K3S_REGISTRIES=\"https://registry.cn-hangzhou.aliyuncs.com,https://registry.aliyuncs.com/google_containers\" \\\n./k3s-install.sh - agent\n```\n\n\n\n这时候在Server可以查看node情况\n\n```\nsudo kubectl get nodes\n```\n\n![image-20250613112245716](../img/%E5%9F%BA%E4%BA%8ECentos7%E9%83%A8%E7%BD%B2k3s.assets/a9ccac4fb814c1504457caf23fe59a19697559838.png)\n\n\n\n## 安装dashboard\n\n在基础或高可用k3s都可以使用\n\n操作节点:[Server1]\n\n```bash\nsudo wget https://raw.githubusercontent.com/kubernetes/dashboard/v2.7.0/aio/deploy/recommended.yaml && \\\nsudo sed -i 's/kubernetesui\\/dashboard:v2.7.0/registry.cn-hangzhou.aliyuncs.com\\/qianyios\\/dashboard:v2.7.0/g' recommended.yaml \nsleep 3\nsudo sed -i 's/kubernetesui\\/metrics-scraper:v1.0.8/registry.cn-hangzhou.aliyuncs.com\\/qianyios\\/metrics-scraper:v1.0.8/g' recommended.yaml \nsudo sed -i '/targetPort: 8443/a\\      nodePort: 30001' recommended.yaml \nsudo sed -i '/nodePort: 30001/a\\  type: NodePort' recommended.yaml\n\n```\n\n运行pod\n\n```bash\nsudo kubectl apply -f recommended.yaml\n```\n\n创建token\n\n```bash\n#创建service account并绑定默认cluster-admin管理员群角色\n#创建用户\nsudo kubectl create serviceaccount dashboard-admin -n kubernetes-dashboard\n#用户授权\nsudo kubectl create clusterrolebinding dashboard-admin \\\n--clusterrole=cluster-admin \\\n--serviceaccount=kubernetes-dashboard:dashboard-admin\n#临时获取用户Token（默认只有 30 分钟 ）\nsudo kubectl create token dashboard-admin -n kubernetes-dashboard\n#永久获取用户Token\nsudo cat <<EOF | sudo kubectl apply -f -\napiVersion: v1\nkind: Secret\nmetadata:\n  name: dashboard-admin-token\n  namespace: kubernetes-dashboard\n  annotations:\n    kubernetes.io/service-account.name: dashboard-admin\ntype: kubernetes.io/service-account-token\nEOF\n\nKUBECONFIG_FILE=\"dashboard-kubeconfig.yaml\"\n\n# 自动获取 API Server 地址\nAPISERVER=$(sudo kubectl config view --minify -o jsonpath='{.clusters[0].cluster.server}')\n\n# 自动获取 CA 证书\nCA_CERT=$(sudo kubectl config view --raw -o jsonpath='{.clusters[0].cluster.certificate-authority-data}')\n\n# 自动从 Secret 获取 Token（你提到的正确方式）\nTOKEN=$(sudo kubectl get secret dashboard-admin-token -n kubernetes-dashboard -o jsonpath='{.data.token}' | base64 --decode)\n\n# 生成 kubeconfig 文件\nsudo cat <<EOF > ${KUBECONFIG_FILE}\napiVersion: v1\nkind: Config\nclusters:\n  - name: kubernetes\n    cluster:\n      server: ${APISERVER}\n      certificate-authority-data: ${CA_CERT}\nusers:\n  - name: dashboard-admin\n    user:\n      token: ${TOKEN}\ncontexts:\n  - name: dashboard-context\n    context:\n      cluster: kubernetes\n      user: dashboard-admin\ncurrent-context: dashboard-context\nEOF\n\necho \"✅ kubeconfig 文件已生成：${KUBECONFIG_FILE}\"\n```\n\n这时候就会提示你\n\n`✅ kubeconfig 文件已生成：dashboard-kubeconfig.yaml`\n\n你就把这个文件上传到dashboard的kubeconfig就可以免密登入了\n\n这个192.168.48.200是高可用地址\n\n![image-20250613124501754](../img/%E5%9F%BA%E4%BA%8ECentos7%E9%83%A8%E7%BD%B2k3s.assets/7d51bc1aeca562d4be1dcc3326dbb63e697559838.png)\n\n## 高可用模拟宕机测试\n\n查看dashboard部署在哪个节点\n\n```\nsudo kubectl get pods -A -l k8s-app=kubernetes-dashboard -o wide\nsudo kubectl get nodes\n```\n\n我这里显示的是dashboard部署在Server1\n\n那么我们就对Server1进行powerof关机，来模拟宕机看看dashboard能否被k3s自动调度到其他节点\n\n但是我发现pod还在running的状态,且server1的状态还是ready\n\n![image-20250613125547207](../img/%E5%9F%BA%E4%BA%8ECentos7%E9%83%A8%E7%BD%B2k3s.assets/8b9c60575353e9f37f0eaf5a1186de39697559838.png)\n\n> **server2 已经被标记为 NotReady**\n>\n> 说明 Kubernetes 已感知到它不可用（可能是关机、网络不通或 kubelet 崩溃等），但：\n>\n> - 如果 Pod 的副本数是 `1`，Kubernetes **不会自动创建新的 Pod** 。\n> - 默认的节点失联容忍时间较长（5分钟），所以即使节点 NotReady，也不会立刻触发 Pod 驱逐。\n\n方案一 等待五分钟\n\n经过漫长等待，dashboard的pod进行了重新分配\n\n![image-20250607230458318](../img/%E5%9F%BA%E4%BA%8ECentos7%E9%83%A8%E7%BD%B2k3s.assets/501b0e08678ce2ef780e38410057b3e4697559838.png)\n\n```\nkubectl get pods -A -l k8s-app=kubernetes-dashboard -o wide\n```\n\n经过查看已经被调度到了Agent1节点\n\n![image-20250613130344022](../img/%E5%9F%BA%E4%BA%8ECentos7%E9%83%A8%E7%BD%B2k3s.assets/8d07a02ce5f6c91f607ccf5c03675e41697559838.png)\n\n而且，原本server1的高可用ip，现已经漂移到了server2了，同样也可以用高可用ip访问k3s内的所有pod\n\n![image-20250613130447595](../img/%E5%9F%BA%E4%BA%8ECentos7%E9%83%A8%E7%BD%B2k3s.assets/08c9d6eb391eb0fa04187073fbc82ebb697559838.png)\n\n\n\n结论：高可用实验，实验成功，且页面可以正常访问\n\n\n\n方案二 手动删除 Pod 强制重建（推荐测试）\n\n由于刚刚经过方案一的测试，被调度到了Agent1，所以这次对Agent1进行模拟宕机，然后手动删除pod\n\n```\nsudo kubectl delete pod -n kubernetes-dashboard pod名字\n```\n\n![image-20250613130645950](../img/%E5%9F%BA%E4%BA%8ECentos7%E9%83%A8%E7%BD%B2k3s.assets/7a94f2b88cea969d1dec856cde53ecad697559838.png)\n\n经过手动删除，立马触发自动调度，已经被调度到了Server3节点\n\n结论：高可用实验，实验成功，且页面可以正常访问\n\n\n\n方案三 缩短节点失联容忍时间（适用于生产环境）\n\n如果你希望 Kubernetes 更快地响应节点故障，可以在 K3s 启动参数中添加以下内容：\n\n```bash\n--node-monitor-grace-period=20s \\\n--pod-eviction-timeout=30s\n```\n\n⚠️ 注意：这会影响整个集群的行为，适用于生产环境或需要快速故障恢复的场景。 \n\n## 修改启动参数\n\n如果你在安装的时候有些参数输入错了，或者想改，可以在这里改\n\n首先，停止 K3s 服务以避免在更新过程中出现冲突：\n\n```bash\nsudo systemctl stop k3s\n```\n\n修改k3s启动参数\n\n```\nsudo vi /etc/systemd/system/k3s.service\n```\n\n![image-20250613170641600](../img/%E5%9F%BA%E4%BA%8ECentos7%E9%83%A8%E7%BD%B2k3s.assets/11583dba92ff2427d6336567eb3aa384697559838.png)\n\n假设你的--tls-san的高可用地址输入错了，要改成别的，你就改完，记得保存\n\n然后删除旧证书\n\n```bash\nsudo rm -f /var/lib/rancher/k3s/server/tls/serving-kube-apiserver*\nsudo rm -f /var/lib/rancher/k3s/server/tls/server*\n```\n\n重启服务\n\n```bash\nsudo systemctl daemon-reload\nsudo systemctl start k3s\n```\n\n## 卸载K3S\n\n官方教程：[Uninstalling K3s | K3s](https://docs.k3s.io/installation/uninstall)\n\n### 卸载Server\n\n要从服务器节点卸载 K3s，请运行：\n\n```bash\n/usr/local/bin/k3s-uninstall.sh\n```\n\n### 卸载Agent\n\n要从代理节点卸载 K3s，请运行：\n\n```bash\n/usr/local/bin/k3s-agent-uninstall.sh\n```\n\n\n\n## 解决非root用户使用kubectl等命令显示无命令的办法\n\n这时候运行查看节点命令，提示找不到命令\n\n```\nsudo kubectl get nodes\n```\n\n一看发现只有具体到指定路径才可以正常运行，并且用户和权限组都是root\n\n![image-20250613105655993](../img/%E5%9F%BA%E4%BA%8ECentos7%E9%83%A8%E7%BD%B2k3s.assets/d2f6f6e28d0e9a0af95230b6e6fc77b8697559838.png)\n\n这时候在普通用户查看visudo\n\n```\nsudo visudo\n```\n\n![image-20250613105736470](../img/%E5%9F%BA%E4%BA%8ECentos7%E9%83%A8%E7%BD%B2k3s.assets/21748195328130ac5fdcdaed79a8ad49697559838.png)\n\n一看地址，他并没有`/usr/local/bin`的路径，所以普通用户是没办法继承root的路径的，所以你要设置普通用户默认的环境变量（生成环境，建议仔细斟酌要不要添加，不然就只能用绝对路径）\n\n```\n/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin\n```\n\n![image-20250613110011514](../img/%E5%9F%BA%E4%BA%8ECentos7%E9%83%A8%E7%BD%B2k3s.assets/014bcd88aadaf8de3808363bcb41677a697559838.png)\n\n这时候再次运行k3s命令\n\n```\nsudo kubectl get nodes\nsudo crictl images\n```\n\n![image-20250613110125426](../img/%E5%9F%BA%E4%BA%8ECentos7%E9%83%A8%E7%BD%B2k3s.assets/ffe7d121595518b42f9147014a8558d9697559838.png)\n\n\n\n\n\n\n\n<div class=\"tbsm\" style=\"margin-top:54px;\">\n<div class=\"tbsm-top\"><span><svg t=\"1674654360507\" class=\"icon\" viewBox=\"0 0 1024 1024\" version=\"1.1\" xmlns=\"http://www.w3.org/2000/svg\" p-id=\"987\" data-spm-anchor-id=\"a313x.7781069.0.i0\" width=\"35\" height=\"35\"><path d=\"M410.49 97.74H155.08a56.74 56.74 0 0 0-56.84 56.73V410a56.84 56.84 0 0 0 56.84 56.84h255.41A56.83 56.83 0 0 0 467.32 410V154.58a56.83 56.83 0 0 0-56.83-56.84zM410.49 558.74H155.08a56.74 56.74 0 0 0-56.84 56.73V871a56.84 56.84 0 0 0 56.84 56.84h255.41A56.83 56.83 0 0 0 467.32 871V615.58a56.83 56.83 0 0 0-56.83-56.84zM871.49 558.74H616.08a56.74 56.74 0 0 0-56.84 56.73V871a56.84 56.84 0 0 0 56.84 56.84h255.41A56.83 56.83 0 0 0 928.32 871V615.58a56.83 56.83 0 0 0-56.83-56.84z\" fill=\"#66EEFF\" p-id=\"988\"></path><path d=\"M410.49 558.74h-4.14A475 475 0 0 0 299.52 859.6a481.16 481.16 0 0 0 4.84 68.22h106.13A56.83 56.83 0 0 0 467.32 871V615.58a56.83 56.83 0 0 0-56.83-56.84zM871.49 558.74H616.08a56.74 56.74 0 0 0-56.84 56.73V871a56.84 56.84 0 0 0 56.84 56.84h255.41A56.83 56.83 0 0 0 928.32 871V615.58a56.83 56.83 0 0 0-56.83-56.84z\" fill=\"#C2F8FF\" p-id=\"989\"></path></svg></span><span style=\"font-size:30px;\"> 特别声明</span></div>\n<div class=\"tbsm-wz\">千屹博客旗下的所有文章，是通过本人课堂学习和课外自学所精心整理的知识巨著<br/>难免会有出错的地方<br/>如果细心的你发现了小失误，可以在下方评论区告诉我，或者私信我！<br />非常感谢大家的热烈支持！</div>\n</div>","tags":["Centos 7","K3s"],"categories":["云原生"]},{"title":"基于OpenEuler部署K3S","url":"/posts/998bbc2f/","content":"\n<meta name=\"referrer\" content=\"no-referrer\"/>\n\n# 基于OpenEuler部署K3S\n\n## 介绍\n\n**什么是K3s**\n\nK3s 是一个轻量级的 Kubernetes 发行版，它针对边缘计算、物联网等场景进行了高度优化。K3s 有以下增强功能：\n\n- 打包为单个二进制文件。\n- 使用基于 sqlite3 的轻量级存储后端作为默认存储机制。同时支持使用 etcd3、MySQL 和 PostgreSQL 作为存储机制。\n- 封装在简单的启动程序中，通过该启动程序处理很多复杂的 TLS 和选项。\n- 默认情况下是安全的，对轻量级环境有合理的默认值。\n- 添加了简单但功能强大的batteries-included功能，例如：本地存储提供程序，服务负载均衡器，Helm controller 和 Traefik Ingress controller。\n- 所有 Kubernetes control-plane 组件的操作都封装在单个二进制文件和进程中，使 K3s 具有自动化和管理包括证书分发在内的复杂集群操作的能力。\n- 最大程度减轻了外部依赖性，K3s 仅需要 kernel 和 cgroup 挂载。\n\nopeneuler社区教程：[K3s部署指南 | openEuler社区 | v24.03_LTS](https://docs.openeuler.openatom.cn/zh/docs/24.03_LTS/docs/K3s/K3s部署指南.html#)\n\nK3s的更多用法可以参考K3s官网\n\nhttps://rancher.com/docs/k3s/latest/en/ \n\nhttps://docs.rancher.cn/k3s/\n\nK3s官网采用下载对应架构二进制可执行文件的格式，通过install.sh脚本进行离线安装，openEuler社区将该二进制文件的编译过程移植到社区中，并编译出RPM包。此处可通过yum命令直接进行下载安装。\n\n## 主机拓扑\n\n| 主机名  |       ip       | CPU  | 内存  |\n| :-----: | :------------: | :--: | :---: |\n| Server1 | 192.168.48.101 |  ≧2  |  2G   |\n| Server2 | 192.168.48.102 |  ≧2  |  2G   |\n| Server3 | 192.168.48.103 |  ≧2  |  2G   |\n| Agent1  | 192.168.49.104 |  ≧1  | 512MB |\n\n如果你是只用单serve1只需要创建server1和若干台agent，部署教程请跳转[4.基础k3s](#基础K3S)\n\n如果你是高可用一定需要`≥3`台的server节点，部署教程请跳转[5.高可用K3S（内部etcd）](#高可用K3S（内部etcd）)\n\n前提是要完成[3.基础配置](#基础配置)\n\n## 基础配置\n\n### 系统初始化\n\n确保server节点及agent节点主机名不一致\n\n```bash\nvi system_init.sh\n```\n\n```bash\n#!/bin/bash\nif [ $# -eq 2 ];then\n  echo \"设置主机名为：$1\"\n  echo \"ens33设置IP地址为：192.168.48.$2\"\nelse\n  echo  \"使用方法：sh $0 主机名 主机位\"\n  exit 2\nfi\n\necho \"--------------------------------------\"\necho \"1.正在设置主机名：$1\"\nhostnamectl set-hostname $1\n\necho \"2.正在关闭firewalld、selinux\"\nsystemctl disable firewalld &> /dev/null\nsystemctl stop firewalld\nsed -i \"s#SELINUX=enforcing#SELINUX=disabled#g\" /etc/selinux/config\nsetenforce 0\n\necho \"3.正在设置ens33：192.168.48.$2\"\ncat > /etc/sysconfig/network-scripts/ifcfg-ens33 <<EOF\nTYPE=Ethernet\nPROXY_METHOD=none\nBROWSER_ONLY=no\nBOOTPROTO=static\nDEFROUTE=yes\nIPV4_FAILURE_FATAL=no\nIPV6INIT=yes\nIPV6_AUTOCONF=yes\nIPV6_DEFROUTE=yes\nIPV6_FAILURE_FATAL=no\nNAME=ens33\nUUID=53b402ff-5865-47dd-a853-7afcd6521738\nDEVICE=ens33\nONBOOT=yes\nIPADDR=192.168.48.$2\nGATEWAY=192.168.48.2\nPREFIX=24\nDNS1=192.168.48.2\nDNS2=114.114.114.114\nEOF\nnmcli c reload\nnmcli c up ens33\n\necho \"4.更新yum源软件包缓存\"\nyum clean all && yum makecache\n\necho \"5.添加hosts解析\"\ncat > /etc/hosts <<EOF\n127.0.0.1   localhost localhost.localdomain localhost4 localhost4.localdomain4\n::1         localhost localhost.localdomain localhost6 localhost6.localdomain6\n192.168.48.101 Server1\n192.168.48.102 Agent1\nEOF\n\necho \"6.必备工具安装\"\nyum install wget psmisc vim net-tools telnet socat device-mapper-persistent-data lvm2 git gcc -y\n\necho \"7.重启系统\"\nreboot\n```\n\n```bash\nsh system_init.sh 主机名  主机位\n\n[Server1] sh system_init.sh Server1 101\n[Agent1] sh system_init.sh Agent1 102\n```\n\n### 安装容器工具\n\n请你考虑好，你的集群要以什么为运行时，下面提供了，docker和containerd，自行选择\n\n`只能二选一！！！`\n\n`只能二选一！！！`\n\n`只能二选一！！！`\n\n#### 安装docker\n\n操作节点:[所有节点]\n\n```bash\nsudo curl -L \"https://qygit.qianyisky.cn/https://github.com/docker/compose/releases/download/v2.35.1/docker-compose-linux-x86_64\" -o /usr/local/bin/docker-compose\n#卸载旧版本\nsudo yum -y remove docker \\\n                  docker-client \\\n                  docker-client-latest \\\n                  docker-common \\\n                  docker-latest \\\n                  docker-latest-logrotate \\\n                  docker-logrotate \\\n                  docker-selinux \\\n                  docker-engine-selinux \\\n                  docker-engine\nsudo yum remove docker-ce docker-ce-cli containerd.io docker-compose docker-machine docker-swarm -y\nsudo rm /etc/yum.repos.d/docker-ce.repo\nsudo rm -rf /var/lib/docker\n\nsudo yum install -y device-mapper-persistent-data lvm2\nsudo yum-config-manager --add-repo https://download.docker.com/linux/centos/docker-ce.repo\nsudo sed -i 's/\\$releasever/8/g' /etc/yum.repos.d/docker-ce.repo\nsudo yum install docker-ce docker-ce-cli containerd.io -y\nsudo systemctl enable --now docker\nsudo chmod +x /usr/local/bin/docker-compose\nsudo tee /etc/docker/daemon.json > /dev/null <<'EOF'\n{\n  \"registry-mirrors\": [\n    \"https://docker.xuanyuan.me\",\n    \"https://docker.m.daocloud.io\",\n    \"https://docker.1ms.run\",\n    \"https://docker.1panel.live\",\n    \"https://registry.cn-hangzhou.aliyuncs.com\",\n    \"https://docker.qianyios.top\"\n  ],\n  \"max-concurrent-downloads\": 10,\n  \"log-driver\": \"json-file\",\n  \"log-level\": \"warn\",\n  \"log-opts\": {\n    \"max-size\": \"10m\",\n    \"max-file\": \"3\"\n  },\n  \"data-root\": \"/var/lib/docker\"\n}\nEOF\nsystemctl daemon-reload\nsystemctl restart docker\ndocker-compose --version\ndocker version\n```\n\n#### 安装containerd\n\n操作节点:[所有节点]\n\n```bash\nsudo yum install -y yum-utils\nsudo yum-config-manager --add-repo https://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo\nsudo yum clean all && yum makecache\nsudo yum install -y containerd.io\n\nsudo mkdir -p /etc/containerd/certs.d/docker.io\nsudo mkdir -p /etc/containerd/certs.d/registry.k8s.io\nsudo mkdir -p /etc/containerd/certs.d/k8s.gcr.io\nsudo mkdir -p /etc/containerd/certs.d/ghcr.io\nsudo mkdir -p /etc/containerd/certs.d/gcr.io\nsudo mkdir -p /etc/containerd/certs.d/quay.io\nsudo mkdir -p /etc/containerd/certs.d/registry-1.docker.io\n\nsudo tee /etc/containerd/certs.d/docker.io/hosts.toml > /dev/null <<'EOF'\nserver = \"https://docker.io\" \n\n[host.\"https://registry.cn-hangzhou.aliyuncs.com/\"]\n  capabilities = [\"pull\", \"resolve\"]\n[host.\"https://docker.xuanyuan.me\"]\n  capabilities = [\"pull\", \"resolve\"]\n[host.\"https://docker.m.daocloud.io\"]\n  capabilities = [\"pull\", \"resolve\"]\n[host.\"https://docker.1ms.run\"]\n  capabilities = [\"pull\", \"resolve\"]\n[host.\"https://docker.1panel.live\"]\n  capabilities = [\"pull\", \"resolve\"]\n[host.\"https://docker.qianyios.top/\"] \n  capabilities = [\"pull\", \"resolve\"]\n[host.\"https://reg-mirror.giniu.com\"] \n  capabilities = [\"pull\", \"resolve\"]\nEOF\n\nsudo tee /etc/containerd/certs.d/registry-1.docker.io/hosts.toml > /dev/null <<'EOF'\nserver = \"https://registry-1.docker.io\"\n\n[host.\"https://registry.cn-hangzhou.aliyuncs.com/\"]\n  capabilities = [\"pull\", \"resolve\"]\n[host.\"https://docker.xuanyuan.me\"]\n  capabilities = [\"pull\", \"resolve\"]\n[host.\"https://docker.m.daocloud.io\"]\n  capabilities = [\"pull\", \"resolve\"]\n[host.\"https://docker.1ms.run\"]\n  capabilities = [\"pull\", \"resolve\"]\n[host.\"https://docker.1panel.live\"]\n  capabilities = [\"pull\", \"resolve\"]\n[host.\"https://docker.qianyios.top/\"] \n  capabilities = [\"pull\", \"resolve\"]\n[host.\"https://reg-mirror.giniu.com\"] \n  capabilities = [\"pull\", \"resolve\"]\nEOF\n\n\nsudo tee /etc/containerd/certs.d/k8s.gcr.io/hosts.toml > /dev/null <<'EOF'\nserver = \"https://k8s.gcr.io\"\n\n[host.\"https://registry.aliyuncs.com/google_containers\"]\n  capabilities = [\"pull\", \"resolve\"]\nEOF\n\nsudo tee /etc/containerd/certs.d/ghcr.io/hosts.toml > /dev/null <<'EOF'\nserver = \"https://ghcr.io\"\n\n[host.\"https://ghcr.m.daocloud.io/\"]\n  capabilities = [\"pull\", \"resolve\"]\nEOF\n\nsudo tee /etc/containerd/certs.d/gcr.io/hosts.toml > /dev/null <<'EOF'\nserver = \"https://gcr.io\"\n\n[host.\"https://gcr.m.daocloud.io/\"]\n  capabilities = [\"pull\", \"resolve\"]\nEOF\n\nsudo tee /etc/containerd/certs.d/registry.k8s.io/hosts.toml > /dev/null <<'EOF'\nserver = \"registry.k8s.io\"\n\n[host.\"k8s.m.daocloud.io\"]\n  capabilities = [\"pull\", \"resolve\", \"push\"]\n[host.\"https://registry.aliyuncs.com/v2/google_containers\"]\n  capabilities = [\"pull\", \"resolve\"]\nEOF\n\nsudo tee /etc/containerd/certs.d/quay.io/hosts.toml > /dev/null <<'EOF'\nserver = \"https://quay.io\"\n\n[host.\"https://quay.tencentcloudcr.com/\"]\n  capabilities = [\"pull\", \"resolve\"]\nEOF\n\nsudo sh -c 'containerd config default > /etc/containerd/config.toml'\nsudo sed -i 's#sandbox_image = \"registry.k8s.io/pause:.*\"#sandbox_image = \"registry.aliyuncs.com/google_containers/pause:3.10\"#' /etc/containerd/config.toml\nsudo sed -i 's/SystemdCgroup = false/SystemdCgroup = true/g' /etc/containerd/config.toml\nsed -i '/\\[plugins\\.\"io\\.containerd\\.grpc\\.v1\\.cri\"\\.registry\\]/!b;n;s/config_path = \"\"/config_path = \"\\/etc\\/containerd\\/certs.d\"/' /etc/containerd/config.toml\n# 重启 containerd 服务\nsudo systemctl daemon-reload\nsudo systemctl restart containerd.service\nsudo ctr image ls\n```\n\n### 添加镜像源\n\n操作节点:[所有节点]\n\n```bash\nsudo mkdir -p /etc/rancher/k3s\nsudo tee /etc/rancher/k3s/registries.yaml > /dev/null <<'EOF'\nmirrors:\n  docker.io:\n    endpoint:\n      - \"https://registry.cn-hangzhou.aliyuncs.com/\" \n      - \"https://docker.xuanyuan.me\" \n      - \"https://docker.m.daocloud.io\" \n      - \"https://docker.1ms.run\" \n      - \"https://docker.1panel.live\" \n      - \"https://hub.rat.dev\" \n      - \"https://docker-mirror.aigc2d.com\" \n      - \"https://docker.qianyios.top/\"\n  quay.io:\n    endpoint:\n      - \"https://quay.tencentcloudcr.com/\"   \n  registry.k8s.io:\n    endpoint:\n      - \"https://registry.aliyuncs.com/v2/google_containers\"   \n  gcr.io:\n    endpoint:\n      - \"https://gcr.m.daocloud.io/\"   \n  k8s.gcr.io:\n    endpoint:\n      - \"https://registry.aliyuncs.com/google_containers\"   \n  ghcr.io:\n    endpoint:\n      - \"https://ghcr.m.daocloud.io/\"   \nEOF\n```\n\n建议在这里打个快照\n\n## 基础K3S\n\n### 部署K3s\n\n由于OpenEuler已经编译好RPM的包了，可以直接安装\n\n操作节点：[所有节点]\n\n```bash\nyum install -y k3s\n```\n\n### 部署server节点\n\n操作节点：[Server1]\n\n如需在单个服务器上安装 K3s，可以在 server 节点上执行如下操作：\n\n`要注意你选的是哪个容器工具哈`\n\n`要注意你选的是哪个容器工具哈`\n\n`要注意你选的是哪个容器工具哈`\n\n#### 基于docker\n\n`如果有参数的值数错了，可以改一下，然后重新运行命令即可`\n\n`--docke`一定要放在所有参数的最前面\n\n```bash\nINSTALL_K3S_SKIP_DOWNLOAD=true \\\nINSTALL_K3S_REGISTRIES=\"https://registry.cn-hangzhou.aliyuncs.com,https://registry.aliyuncs.com/google_containers\" \\\nk3s-install.sh --docker \\\n--system-default-registry \"registry.cn-hangzhou.aliyuncs.com\"\n```\n\n![image-20250617004334000](../img/%E5%9F%BA%E4%BA%8EOpenEuler%E5%AE%89%E8%A3%85K3S.assets/017af539defa578bc8bedea1df41f8bd697559838.png)\n\n自行完成 [9.解决非root用户使用kubectl等命令显示无命令的办法](#解决非root用户使用kubectl等命令显示无命令的办法)\n\n\n\n#### 基于containerd\n\n`如果有参数的值数错了，可以改一下，然后重新运行命令即可`\n\n```bash\nINSTALL_K3S_SKIP_DOWNLOAD=true \\\nINSTALL_K3S_REGISTRIES=\"https://registry.cn-hangzhou.aliyuncs.com,https://registry.aliyuncs.com/google_containers\" \\\nk3s-install.sh \\\n--system-default-registry \"registry.cn-hangzhou.aliyuncs.com\"\n```\n\n![image-20250604204942034](../img/%E5%9F%BA%E4%BA%8EOpenEuler%E5%AE%89%E8%A3%85K3S.assets/fbf400a017791c185a32a25b434a3161697559838.png)\n\n自行完成 [9.解决非root用户使用kubectl等命令显示无命令的办法](#解决非root用户使用kubectl等命令显示无命令的办法)\n\n\n\n查看镜像列表和pod情况\n\n```\ncrictl images\nkubectl get pod -A\n```\n\n![image-20250606143307535](../img/%E5%9F%BA%E4%BA%8EOpenEuler%E5%AE%89%E8%A3%85K3S.assets/f96abc979e77c4b83c1d1cec8f91eacb697559838.png)\n\n\n\n\n\n### 部署Agent节点\n\n操作节点：[Server1]\n\n#### 查看token\n\n```\ncat /var/lib/rancher/k3s/server/node-token\n```\n\n> `K10ed18fcd528981577fe508d419bd28fefeef1c372ccc246a79fff1fa4b371e5e1::server:a02d22a5169cdc2465bd989360029283`\n\n\n\n#### 基于docker\n\n操作节点：[Agent1]\n\n`如果有参数的值数错了，可以改一下，然后重新运行命令即可`\n\n`--docke`一定要放在所有参数的最前面\n\n```bash\nINSTALL_K3S_SKIP_DOWNLOAD=true \\\nK3S_URL=https://192.168.48.101:6443  \\\nK3S_TOKEN=a02d22a5169cdc2465bd989360029283 \\\nINSTALL_K3S_REGISTRIES=\"https://registry.cn-hangzhou.aliyuncs.com,https://registry.aliyuncs.com/google_containers\" \\\nk3s-install.sh --docker\n```\n\n· `a02d22a5169cdc2465bd989360029283` 是前面`server1`获取的`token`\n\n· `192.168.48.101`是`server1`的ip\n\n![image-20250616210407492](../img/%E5%9F%BA%E4%BA%8EOpenEuler%E5%AE%89%E8%A3%85K3S.assets/72eee756fcd019a4745d92de0ce1cabd697559838.png)\n\n这时候在server1查看是否成功加入集群\n\n```\nsudo kubectl get nodes\n```\n\n![image-20250613194651483](../img/%E5%9F%BA%E4%BA%8EOpenEuler%E5%AE%89%E8%A3%85K3S.assets/2057ac475b9b1a5e9b472e91218e1bd4697559838.png)\n\n如果需要部署dashboard请跳转[6.安装dashboard](#安装dashboard)\n\n#### 基于containerd\n\n`如果有参数的值数错了，可以改一下，然后重新运行命令即可`\n\n操作节点：[Agent1]\n\n```bash\nINSTALL_K3S_SKIP_DOWNLOAD=true \\\nK3S_URL=https://192.168.48.101:6443  \\\nK3S_TOKEN=a02d22a5169cdc2465bd989360029283 \\\nINSTALL_K3S_REGISTRIES=\"https://registry.cn-hangzhou.aliyuncs.com,https://registry.aliyuncs.com/google_containers\" \\\nk3s-install.sh \n```\n\n· `a02d22a5169cdc2465bd989360029283` 是前面`server1`获取的`token`\n\n· `192.168.48.101`是`server1`的ip\n\n![image-20250607175545654](../img/%E5%9F%BA%E4%BA%8EOpenEuler%E5%AE%89%E8%A3%85K3S.assets/6e765ea6a7006123a9773425ad9ab34d697559838.png)\n\n如果需要部署dashboard请跳转[6.安装dashboard](#安装dashboard)\n\n## 高可用K3S（内部etcd）\n\n官方教程：[高可用嵌入式 etcd](https://docs.k3s.io/zh/datastore/ha-embedded)\n\n具有嵌入式 etcd 的 HA K3s 集群由以下部分组成：\n\n- `三个或多个` **Server 节点**为 Kubernetes API 提供服务并运行其他 control plane 服务，以及托管嵌入式 etcd 数据存储。\n- 可选：零个或多个 **Agent 节点**，用于运行你的应用和服务\n- 可选：**固定注册地址**，供 Agent 节点注册到集群\n\n### 主机拓扑\n\n| 主机名  | ip             | CPU  | 内存  |\n| ------- | -------------- | ---- | ----- |\n| Server1 | 192.168.48.101 | ≧2   | 2G    |\n| Server2 | 192.168.48.102 | ≧2   | 2G    |\n| Server3 | 192.168.48.103 | ≧2   | 2G    |\n| Agent1  | 192.168.49.104 | ≧1   | 512MB |\n\n现在所有的机子都从[5.1部署K3s](#部署K3s)克隆这个`部署好K3s`的快照，也就是说现在所有机子的起点都在`5.1部署K3s`\n\n记得给agent改ip哈\n\n\n\n### 配置集群负载均衡器\n\n官方教程：[集群负载均衡器](https://docs.k3s.io/datastore/cluster-loadbalancer)\n\n按理来说我们需要两台额外的节点来做负载均衡和高可用vip节点，但是为了测试方便，我们直接部署在\n\nserver节点，也就是图中的第二种方法\n\n![image-20250607223109712](../img/%E5%9F%BA%E4%BA%8EOpenEuler%E5%AE%89%E8%A3%85K3S.assets/d8de9881adf5274324638bc7a40eadc3697559838.png)\n\n操作节点：[所有的server]\n\n```bash\nyum install -y haproxy keepalived\ncat > /etc/haproxy/haproxy.cfg <<\"EOF\"\nfrontend k3s-frontend\n    bind *:16443\n    mode tcp\n    option tcplog\n    default_backend k3s-backend\n\nbackend k3s-backend\n    mode tcp\n    option tcp-check\n    balance roundrobin\n    timeout connect 5s\n    timeout server 30s\n    timeout client 30s\n    default-server inter 10s downinter 5s\n    server server-1 192.168.48.101:6443 check\n    server server-2 192.168.48.102:6443 check\n    server server-3 192.168.48.103:6443 check\nEOF\n```\n\n操作节点:[Server1]\n\n```bash\ncat > /etc/keepalived/keepalived.conf <<\"EOF\"\nglobal_defs {\n  enable_script_security\n  script_user root\n}\n\nvrrp_script chk_haproxy {\n    script 'killall -0 haproxy'\n    interval 2\n}\n\nvrrp_instance haproxy-vip {\n    interface ens33  #这里要改，是你的网卡\n    state MASTER    #这里要改 server1是Master 其他都是Backup\n    priority 200\n\n    virtual_router_id 51\n\n    virtual_ipaddress {\n        192.168.48.200/24      #高可用ip\n    }\n\n    track_script {\n        chk_haproxy\n    }\n}\nEOF\n```\n\n操作节点:[Server2]\n\n```bash\ncat > /etc/keepalived/keepalived.conf <<\"EOF\"\nglobal_defs {\n  enable_script_security\n  script_user root\n}\n\nvrrp_script chk_haproxy {\n    script 'killall -0 haproxy'\n    interval 2\n}\n\nvrrp_instance haproxy-vip {\n    interface ens33  #这里要改，是你的网卡\n    state BACKUP    #这里要改 server1是Master 其他都是Backup\n    priority 150\n\n    virtual_router_id 51\n\n    virtual_ipaddress {\n        192.168.48.200/24      #高可用ip\n    }\n\n    track_script {\n        chk_haproxy\n    }\n}\nEOF\n```\n\n操作节点:[Server3]\n\n```bash\ncat > /etc/keepalived/keepalived.conf <<\"EOF\"\nglobal_defs {\n  enable_script_security\n  script_user root\n}\n\nvrrp_script chk_haproxy {\n    script 'killall -0 haproxy'\n    interval 2\n}\n\nvrrp_instance haproxy-vip {\n    interface ens33  #这里要改，是你的网卡\n    state BACKUP    #这里要改 server1是Master 其他都是Backup\n    priority 100\n\n    virtual_router_id 51\n\n    virtual_ipaddress {\n        192.168.48.200/24      #高可用ip\n    }\n\n    track_script {\n        chk_haproxy\n    }\n}\nEOF\n```\n\n操作节点：[所有的Server]\n\n```\nsudo systemctl restart haproxy keepalived\nsudo systemctl enable --now haproxy keepalived\n```\n\n现在来查看vip是否生成\n\n操作节点：[Server1]\n\n```\nip a\n```\n\n![image-20250607224346215](../img/%E5%9F%BA%E4%BA%8EOpenEuler%E5%AE%89%E8%A3%85K3S.assets/48f086e351e415726ecaf07f8dc5a5ee697559838.png)\n\n\n\n\n\n### 初始化第一个Server1\n\n`要注意你选的是哪个容器工具哈`\n\n`要注意你选的是哪个容器工具哈`\n\n`要注意你选的是哪个容器工具哈`\n\n\n\n#### 基于docker\n\n`如果有参数的值数错了，可以改一下，然后重新运行命令即可`\n\n> `--docke`一定要放在所有参数的最前面\n\n```bash\nK3S_TOKEN=qianyiosQianyios12345 \\\nINSTALL_K3S_SKIP_DOWNLOAD=true \\\nINSTALL_K3S_REGISTRIES=\"https://registry.cn-hangzhou.aliyuncs.com,https://registry.aliyuncs.com/google_containers\" \\\nk3s-install.sh --docker --cluster-init - server \\\n--system-default-registry \"registry.cn-hangzhou.aliyuncs.com\" \\\n--tls-san= 192.168.48.200\n```\n\n`qianyiosQianyios12345`是作为集群间的共享密钥，可自定义\n\n![image-20250616210830594](../img/%E5%9F%BA%E4%BA%8EOpenEuler%E5%AE%89%E8%A3%85K3S.assets/18e4d4da483660fb0d9d40c2aaf7f90b697559838.png)\n\n自行完成 [9.解决非root用户使用kubectl等命令显示无命令的办法](#解决非root用户使用kubectl等命令显示无命令的办法)\n\n\n\n#### 基于containerd\n\n`如果有参数的值数错了，可以改一下，然后重新运行命令即可`\n\n操作节点：[Server1]\n\n```bash\nK3S_TOKEN=qianyiosQianyios12345 \\\nINSTALL_K3S_SKIP_DOWNLOAD=true \\\nINSTALL_K3S_REGISTRIES=\"https://registry.cn-hangzhou.aliyuncs.com,https://registry.aliyuncs.com/google_containers\" \\\nk3s-install.sh --cluster-init - server \\\n--system-default-registry \"registry.cn-hangzhou.aliyuncs.com\" \\\n--tls-san= 192.168.48.200\n```\n\n`qianyiosQianyios12345`是作为集群间的共享密钥，可自定义\n\n自行完成 [9.解决非root用户使用kubectl等命令显示无命令的办法](#解决非root用户使用kubectl等命令显示无命令的办法)\n\n更多参数：[K3s Server 配置参考](https://docs.rancher.cn/docs/k3s/installation/install-options/server-config/_index/)\n\n### 其他server加入集群\n\n#### 基于docker\n\n`如果有参数的值数错了，可以改一下，然后重新运行命令即可`\n\n`--docke`一定要放在所有参数的最前面\n\n```bash\nK3S_TOKEN=qianyiosQianyios12345 \\\nINSTALL_K3S_SKIP_DOWNLOAD=true \\\nINSTALL_K3S_REGISTRIES=\"https://registry.cn-hangzhou.aliyuncs.com,https://registry.aliyuncs.com/google_containers\" \\\nk3s-install.sh --docker - server \\\n--system-default-registry \"registry.cn-hangzhou.aliyuncs.com\" \\\n--server https://192.168.48.101:6443  \\\n--tls-san= 192.168.48.200\n```\n\n`qianyiosQianyios12345`是作为第一个server1共享出来的密钥\n\n--server https://192.168.48.101:6443 改成serve1的ip地址即可\n\n自行完成 [9.解决非root用户使用kubectl等命令显示无命令的办法](#解决非root用户使用kubectl等命令显示无命令的办法)\n\n#### 基于containerd\n\n`如果有参数的值数错了，可以改一下，然后重新运行命令即可`\n\n```bash\nK3S_TOKEN=qianyiosQianyios12345 \\\nINSTALL_K3S_SKIP_DOWNLOAD=true \\\nINSTALL_K3S_REGISTRIES=\"https://registry.cn-hangzhou.aliyuncs.com,https://registry.aliyuncs.com/google_containers\" \\\nk3s-install.sh - server \\\n--system-default-registry \"registry.cn-hangzhou.aliyuncs.com\" \\\n--server https://192.168.48.101:6443  \\\n--tls-san= 192.168.48.200\n```\n\n`qianyiosQianyios12345`是作为第一个server1共享出来的密钥\n\n--server https://192.168.48.101:6443 改成serve1的ip地址即可\n\n自行完成 [9.解决非root用户使用kubectl等命令显示无命令的办法](#解决非root用户使用kubectl等命令显示无命令的办法)\n\n### 其他Agent加入集群\n\n#### 基于docker\n\n`如果有参数的值数错了，可以改一下，然后重新运行命令即可`\n\n`--docke`一定要放在所有参数的最前面\n\n```bash\nINSTALL_K3S_SKIP_DOWNLOAD=true \\\nK3S_TOKEN=qianyiosQianyios12345 \\\nK3S_URL=https://192.168.48.101:6443  \\\nINSTALL_K3S_REGISTRIES=\"https://registry.cn-hangzhou.aliyuncs.com,https://registry.aliyuncs.com/google_containers\" \\\nk3s-install.sh --docker - agent\n```\n\n#### 基于containerd\n\n`如果有参数的值数错了，可以改一下，然后重新运行命令即可`\n\n```bash\nINSTALL_K3S_SKIP_DOWNLOAD=true \\\nK3S_TOKEN=qianyiosQianyios12345 \\\nK3S_URL=https://192.168.48.101:6443  \\\nINSTALL_K3S_REGISTRIES=\"https://registry.cn-hangzhou.aliyuncs.com,https://registry.aliyuncs.com/google_containers\" \\\nk3s-install.sh - agent\n```\n\n这时候在Server可以查看node情况\n\n```\nkubectl get nodes\n```\n\n![image-20250607215850489](../img/%E5%9F%BA%E4%BA%8EOpenEuler%E5%AE%89%E8%A3%85K3S.assets/19f51d407f84c8024c11c09db25b905a697559838.png)\n\n`自行部署dashboard之后`,查看他在哪个节点上，部署教程[6.安装dashboard](#安装dashboard)\n\n```\nhttps://192.168.48.200:30001/\n```\n\n现在不是有高可用的vip吗。那么正好可以用vip访问，端口不变\n\n![image-20250607224828394](../img/%E5%9F%BA%E4%BA%8EOpenEuler%E5%AE%89%E8%A3%85K3S.assets/d3f4ac9e7c3b1b1b9905e4a842eb9793697559838.png)\n\n### 高可用模拟宕机测试\n\n查看dashboard部署在哪个节点\n\n```\nkubectl get pods -A -l k8s-app=kubernetes-dashboard -o wide\n```\n\n我这里显示的是dashboard部署在Server2\n\n那么我们就对Server2进行powerof关机，来模拟宕机看看dashboard能否被k3s自动调度到其他节点\n\n但是我发现pod还在running的状态\n\n```bash\n[root@Server3 ~]# kubectl get pods -A\nNAMESPACE              NAME                                        READY   STATUS      RESTARTS   AGE\nkubernetes-dashboard   kubernetes-dashboard-668679b698-nlpqc       1/1     Running     0          15m\n\n[root@Server3 ~]# kubectl get nodes\nNAME      STATUS     ROLES                       AGE   VERSION\nagent1    Ready      <none>                      35m   v1.24.2+k3s-\nserver1   Ready      control-plane,etcd,master   36m   v1.24.2+k3s-\nserver2   NotReady   control-plane,etcd,master   36m   v1.24.2+k3s-\nserver3   Ready      control-plane,etcd,master   36m   v1.24.2+k3s-\n[root@Server3 ~]#\n\n```\n\n> **server2 已经被标记为 NotReady**\n>\n> 说明 Kubernetes 已感知到它不可用（可能是关机、网络不通或 kubelet 崩溃等），但：\n>\n> - 如果 Pod 的副本数是 `1`，Kubernetes **不会自动创建新的 Pod** 。\n> - 默认的节点失联容忍时间较长（5分钟），所以即使节点 NotReady，也不会立刻触发 Pod 驱逐。\n\n方案一 等待五分钟\n\n经过漫长等待，dashboard的pod进行了重新分配\n\n![image-20250607230458318](../img/%E5%9F%BA%E4%BA%8EOpenEuler%E5%AE%89%E8%A3%85K3S.assets/8faee28140365b53f596aec16897afa6697559838.png)\n\n```\nkubectl get pods -A -l k8s-app=kubernetes-dashboard -o wide\n```\n\n经过查看已经被调度到了Server3节点\n\n结论：高可用实验，实验成功，且页面可以正常访问\n\n\n\n方案二 手动删除 Pod 强制重建（推荐测试）\n\n由于刚刚经过方案一的测试，被调度到了server3，所以这次对server3进行模拟宕机，然后手动删除pod\n\n```\nkubectl delete pod -n kubernetes-dashboard pod名字\n```\n\n![image-20250607231149105](../img/%E5%9F%BA%E4%BA%8EOpenEuler%E5%AE%89%E8%A3%85K3S.assets/cde631359f4f45e5a0d73c12ee05c0aa697559838.png)\n\n经过手动删除，立马触发自动调度，已经被调度到了Server2节点\n\n结论：高可用实验，实验成功，且页面可以正常访问\n\n\n\n方案三 缩短节点失联容忍时间（适用于生产环境）\n\n如果你希望 Kubernetes 更快地响应节点故障，可以在 K3s 启动参数中添加以下内容：\n\n```bash\n--node-monitor-grace-period=20s \\\n--pod-eviction-timeout=30s\n```\n\n⚠️ 注意：这会影响整个集群的行为，适用于生产环境或需要快速故障恢复的场景。 \n\n\n\n## 安装dashboard\n\n操作节点:[Server1]\n\n```bash\nsudo wget https://raw.githubusercontent.com/kubernetes/dashboard/v2.7.0/aio/deploy/recommended.yaml && \\\nsudo sed -i 's/kubernetesui\\/dashboard:v2.7.0/registry.cn-hangzhou.aliyuncs.com\\/qianyios\\/dashboard:v2.7.0/g' recommended.yaml \nsleep 3\nsudo sed -i 's/kubernetesui\\/metrics-scraper:v1.0.8/registry.cn-hangzhou.aliyuncs.com\\/qianyios\\/metrics-scraper:v1.0.8/g' recommended.yaml \nsudo sed -i '/targetPort: 8443/a\\      nodePort: 30001' recommended.yaml \nsudo sed -i '/nodePort: 30001/a\\  type: NodePort' recommended.yaml\n\n```\n\n运行pod\n\n```bash\nkubectl apply -f recommended.yaml\n```\n\n创建token\n\n```bash\n#创建service account并绑定默认cluster-admin管理员群角色\n#创建用户\nkubectl create serviceaccount dashboard-admin -n kubernetes-dashboard\n#用户授权\nkubectl create clusterrolebinding dashboard-admin \\\n--clusterrole=cluster-admin \\\n--serviceaccount=kubernetes-dashboard:dashboard-admin\n#临时获取用户Token（默认只有 30 分钟 ）\nkubectl create token dashboard-admin -n kubernetes-dashboard\n#永久获取用户Token\ncat <<EOF | kubectl apply -f -\napiVersion: v1\nkind: Secret\nmetadata:\n  name: dashboard-admin-token\n  namespace: kubernetes-dashboard\n  annotations:\n    kubernetes.io/service-account.name: dashboard-admin\ntype: kubernetes.io/service-account-token\nEOF\n\nKUBECONFIG_FILE=\"dashboard-kubeconfig.yaml\"\n\n# 自动获取 API Server 地址\nAPISERVER=$(kubectl config view --minify -o jsonpath='{.clusters[0].cluster.server}')\n\n# 自动获取 CA 证书\nCA_CERT=$(kubectl config view --raw -o jsonpath='{.clusters[0].cluster.certificate-authority-data}')\n\n# 自动从 Secret 获取 Token（你提到的正确方式）\nTOKEN=$(kubectl get secret dashboard-admin-token -n kubernetes-dashboard -o jsonpath='{.data.token}' | base64 --decode)\n\n# 生成 kubeconfig 文件\ncat <<EOF > ${KUBECONFIG_FILE}\napiVersion: v1\nkind: Config\nclusters:\n  - name: kubernetes\n    cluster:\n      server: ${APISERVER}\n      certificate-authority-data: ${CA_CERT}\nusers:\n  - name: dashboard-admin\n    user:\n      token: ${TOKEN}\ncontexts:\n  - name: dashboard-context\n    context:\n      cluster: kubernetes\n      user: dashboard-admin\ncurrent-context: dashboard-context\nEOF\n\necho \"✅ kubeconfig 文件已生成：${KUBECONFIG_FILE}\"\n```\n\n这时候就会提示你\n\n`✅ kubeconfig 文件已生成：dashboard-kubeconfig.yaml`\n\n你就把这个文件上传到dashboard的kubeconfig就可以免密登入了\n\n![image-20250607185120057](../img/%E5%9F%BA%E4%BA%8EOpenEuler%E5%AE%89%E8%A3%85K3S.assets/4c366c033e40fec33feac1b2784fc2e7697559838.png)\n\n## 修改启动参数\n\n如果你在安装的时候有些参数输入错了，或者想改，可以在这里改\n\n首先，停止 K3s 服务以避免在更新过程中出现冲突：\n\n```bash\nsudo systemctl stop k3s\n```\n\n修改k3s启动参数\n\n```\nsudo vi /etc/systemd/system/k3s.service\n```\n\n![image-20250613170641600](../img/%E5%9F%BA%E4%BA%8EOpenEuler%E5%AE%89%E8%A3%85K3S.assets/897c7de67c6720e2980294251b60693e697559838.png)\n\n假设你的--tls-san的高可用地址输入错了，要改成别的，你就改完，记得保存\n\n然后删除旧证书\n\n```bash\nsudo rm -f /var/lib/rancher/k3s/server/tls/serving-kube-apiserver*\nsudo rm -f /var/lib/rancher/k3s/server/tls/server*\n```\n\n重启服务\n\n```bash\nsudo systemctl daemon-reload\nsudo systemctl start k3s\n```\n\n## 卸载K3S\n\n官方教程：[Uninstalling K3s | K3s](https://docs.k3s.io/installation/uninstall)\n\n### 卸载Server\n\n要从服务器节点卸载 K3s，请运行：\n\n```bash\n/usr/local/bin/k3s-uninstall.sh\n```\n\n### 卸载Agent\n\n要从代理节点卸载 K3s，请运行：\n\n```bash\n/usr/local/bin/k3s-agent-uninstall.sh\n```\n\n## 解决非root用户使用kubectl等命令显示无命令的办法\n\n这时候运行查看节点命令，提示找不到命令\n\n```\nsudo kubectl get nodes\n```\n\n一看发现只有具体到指定路径才可以正常运行，并且用户和权限组都是root\n\n![image-20250613105655993](../img/%E5%9F%BA%E4%BA%8EOpenEuler%E5%AE%89%E8%A3%85K3S.assets/5d8026809ba73cc92f004f8d04ed49a7697559838.png)\n\n这时候在普通用户查看visudo\n\n```\nsudo visudo\n```\n\n![image-20250613105736470](../img/%E5%9F%BA%E4%BA%8EOpenEuler%E5%AE%89%E8%A3%85K3S.assets/9f47e5b52a2a68bdb37bfa8d683a59fd697559838.png)\n\n一看地址，他并没有`/usr/local/bin`的路径，所以普通用户是没办法继承root的路径的，所以你要设置普通用户默认的环境变量（生成环境，建议仔细斟酌要不要添加，不然就只能用绝对路径）\n\n```\n/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin\n```\n\n![image-20250613110011514](../img/%E5%9F%BA%E4%BA%8EOpenEuler%E5%AE%89%E8%A3%85K3S.assets/41f098932d33d303fd6a689a9149d6ad697559838.png)\n\n这时候再次运行k3s命令\n\n```\nsudo kubectl get nodes\nsudo crictl images\n```\n\n![image-20250613110125426](../img/%E5%9F%BA%E4%BA%8EOpenEuler%E5%AE%89%E8%A3%85K3S.assets/a818473ded0724b8015ec0e7c4c95042697559838.png)\n\n\n\n<div class=\"tbsm\" style=\"margin-top:54px;\">\n<div class=\"tbsm-top\"><span><svg t=\"1674654360507\" class=\"icon\" viewBox=\"0 0 1024 1024\" version=\"1.1\" xmlns=\"http://www.w3.org/2000/svg\" p-id=\"987\" data-spm-anchor-id=\"a313x.7781069.0.i0\" width=\"35\" height=\"35\"><path d=\"M410.49 97.74H155.08a56.74 56.74 0 0 0-56.84 56.73V410a56.84 56.84 0 0 0 56.84 56.84h255.41A56.83 56.83 0 0 0 467.32 410V154.58a56.83 56.83 0 0 0-56.83-56.84zM410.49 558.74H155.08a56.74 56.74 0 0 0-56.84 56.73V871a56.84 56.84 0 0 0 56.84 56.84h255.41A56.83 56.83 0 0 0 467.32 871V615.58a56.83 56.83 0 0 0-56.83-56.84zM871.49 558.74H616.08a56.74 56.74 0 0 0-56.84 56.73V871a56.84 56.84 0 0 0 56.84 56.84h255.41A56.83 56.83 0 0 0 928.32 871V615.58a56.83 56.83 0 0 0-56.83-56.84z\" fill=\"#66EEFF\" p-id=\"988\"></path><path d=\"M410.49 558.74h-4.14A475 475 0 0 0 299.52 859.6a481.16 481.16 0 0 0 4.84 68.22h106.13A56.83 56.83 0 0 0 467.32 871V615.58a56.83 56.83 0 0 0-56.83-56.84zM871.49 558.74H616.08a56.74 56.74 0 0 0-56.84 56.73V871a56.84 56.84 0 0 0 56.84 56.84h255.41A56.83 56.83 0 0 0 928.32 871V615.58a56.83 56.83 0 0 0-56.83-56.84z\" fill=\"#C2F8FF\" p-id=\"989\"></path></svg></span><span style=\"font-size:30px;\"> 特别声明</span></div>\n<div class=\"tbsm-wz\">千屹博客旗下的所有文章，是通过本人课堂学习和课外自学所精心整理的知识巨著<br/>难免会有出错的地方<br/>如果细心的你发现了小失误，可以在下方评论区告诉我，或者私信我！<br />非常感谢大家的热烈支持！</div>\n</div>\n","tags":["OpenEuler","K3s"],"categories":["云原生"]},{"title":"运维必备工具安装","url":"/posts/1b1a13ed/","content":"\n<meta name=\"referrer\" content=\"no-referrer\"/>\n\n# 运维必备工具安装\n\n系统测试：OpenEuler24.03LTS，Centos 8 stream\n\n理论上不限制系统，其他系统可对一些命令自行做修改即可\n\n## Nginx（RPM安装）\n\n资料来源：[Nginx入门笔记 | 严千屹博客](https://blog.qianyios.top/posts/c0d89ad/)\n\n官方文档：[nginx：Linux 软件包](https://nginx.org/en/linux_packages.html)\n\n截止2025年4月20日目前：nginx最新版本：1.26.3\n\n![image-20250420132345655](https://i0.hdslb.com/bfs/article/a772145aab4c5d5fd10c6270f4236f4955933597.png)\n\n`centos7或centos8`\n\n```bash\nsudo yum install -y tar gcc make pcre pcre-devel zlib zlib-devel openssl openssl-devel\nsudo yum install yum-utils -y\n#添加nginx源\nsudo cat >/etc/yum.repos.d/nginx.repo << \"EOF\"\n[nginx-stable]\nname=nginx stable repo\nbaseurl=http://nginx.org/packages/centos/$releasever/$basearch/\ngpgcheck=1\nenabled=1\ngpgkey=https://nginx.org/keys/nginx_signing.key\nmodule_hotfixes=true\n\n[nginx-mainline]\nname=nginx mainline repo\nbaseurl=http://nginx.org/packages/mainline/centos/$releasever/$basearch/\ngpgcheck=1\nenabled=0\ngpgkey=https://nginx.org/keys/nginx_signing.key\nmodule_hotfixes=true\nEOF\nsudo yum install nginx -y\nsudo systemctl enable nginx --now\nnginx -v\n```\n\n因为没有适配openeuler的版本，这里直接用centos8的来代替，兼容的没关系，你可以根据你的系统去自行替换\n\n原本是$releasever的，但是没有openeuler的版本直接用8来代替也就是centos8，`openeuler兼容centos`\n\n```bash\nsudo yum install -y tar gcc make pcre pcre-devel zlib zlib-devel openssl openssl-devel\nsudo cat >/etc/yum.repos.d/nginx.repo << \"EOF\"\n[nginx-stable]\nname=nginx stable repo\n#baseurl=http://nginx.org/packages/centos/$releasever/$basearch/\nbaseurl=http://nginx.org/packages/centos/8/$basearch/\ngpgcheck=1\nenabled=1\ngpgkey=https://nginx.org/keys/nginx_signing.key\nmodule_hotfixes=true\n[nginx-mainline]\nname=nginx mainline repo\n#baseurl=http://nginx.org/packages/mainline/centos/$releasever/$basearch/\nbaseurl=http://nginx.org/packages/mainline/centos/8/$basearch/\ngpgcheck=1\nenabled=0\ngpgkey=https://nginx.org/keys/nginx_signing.key\nmodule_hotfixes=true\nEOF\nsudo yum install nginx -y\nsudo systemctl enable nginx --now\nnginx -v\n```\n\n## Docker\n\n截止2025年4月20日目前：\n\ndocker-compose最新版[2.35.1 版](https://github.com/docker/compose/releases/tag/v2.35.1)\n\ndocker-ce最新版：[Docker 文档 26.1.3](https://docs.docker.com/engine/install/centos/)\n\n\n\n`centos7或centos8`\n\n```bash\nsudo curl -L \"https://qygit.qianyisky.cn/https://github.com/docker/compose/releases/download/v2.35.1/docker-compose-linux-x86_64\" -o /usr/local/bin/docker-compose\n#卸载旧版本\nsudo yum -y remove docker \\\n                  docker-client \\\n                  docker-client-latest \\\n                  docker-common \\\n                  docker-latest \\\n                  docker-latest-logrotate \\\n                  docker-logrotate \\\n                  docker-selinux \\\n                  docker-engine-selinux \\\n                  docker-engine\nsudo yum remove docker-ce docker-ce-cli containerd.io docker-compose docker-machine docker-swarm -y\nsudo rm /etc/yum.repos.d/docker-ce.repo\nsudo rm -rf /var/lib/docker\n\nsudo yum install -y yum-utils device-mapper-persistent-data lvm2\nsudo yum-config-manager --add-repo https://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo\nsudo yum install docker-ce -y\nsudo systemctl enable --now docker\nsudo chmod +x /usr/local/bin/docker-compose\nsudo tee /etc/docker/daemon.json > /dev/null <<'EOF'\n{\n  \"registry-mirrors\": [\n    \"https://docker.xuanyuan.me\",\n    \"https://docker.m.daocloud.io\",\n    \"https://docker.1ms.run\",\n    \"https://docker.1panel.live\",\n    \"https://registry.cn-hangzhou.aliyuncs.com\",\n    \"https://docker.qianyios.top\"\n  ],\n  \"max-concurrent-downloads\": 10,\n  \"log-driver\": \"json-file\",\n  \"log-level\": \"warn\",\n  \"log-opts\": {\n    \"max-size\": \"10m\",\n    \"max-file\": \"3\"\n  },\n  \"data-root\": \"/var/lib/docker\"\n}\nEOF\nsystemctl daemon-reload\nsystemctl restart docker\ndocker-compose --version\ndocker version\n```\n\n`openeuler`\n\n```bash\nsudo curl -L \"https://qygit.qianyisky.cn/https://github.com/docker/compose/releases/download/v2.35.1/docker-compose-linux-x86_64\" -o /usr/local/bin/docker-compose\n#卸载旧版本\nsudo yum -y remove docker \\\n                  docker-client \\\n                  docker-client-latest \\\n                  docker-common \\\n                  docker-latest \\\n                  docker-latest-logrotate \\\n                  docker-logrotate \\\n                  docker-selinux \\\n                  docker-engine-selinux \\\n                  docker-engine\nsudo yum remove docker-ce docker-ce-cli containerd.io docker-compose docker-machine docker-swarm -y\nsudo rm /etc/yum.repos.d/docker-ce.repo\nsudo rm -rf /var/lib/docker\n\nsudo yum install -y device-mapper-persistent-data lvm2\nsudo yum-config-manager --add-repo https://download.docker.com/linux/centos/docker-ce.repo\nsudo sed -i 's/\\$releasever/8/g' /etc/yum.repos.d/docker-ce.repo\nsudo yum install docker-ce docker-ce-cli containerd.io -y\nsudo systemctl enable --now docker\nsudo chmod +x /usr/local/bin/docker-compose\nsudo tee /etc/docker/daemon.json > /dev/null <<'EOF'\n{\n  \"registry-mirrors\": [\n    \"https://docker.xuanyuan.me\",\n    \"https://docker.m.daocloud.io\",\n    \"https://docker.1ms.run\",\n    \"https://docker.1panel.live\",\n    \"https://registry.cn-hangzhou.aliyuncs.com\",\n    \"https://docker.qianyios.top\"\n  ],\n  \"max-concurrent-downloads\": 10,\n  \"log-driver\": \"json-file\",\n  \"log-level\": \"warn\",\n  \"log-opts\": {\n    \"max-size\": \"10m\",\n    \"max-file\": \"3\"\n  },\n  \"data-root\": \"/var/lib/docker\"\n}\nEOF\nsystemctl daemon-reload\nsystemctl restart docker\ndocker-compose --version\ndocker version\n```\n\n## PHP(RPM)\n\n截止2025年4月20日目前：PHP最新版8.4.6\n\n`centos 8 stream`\n\n默认安装最新版8.3.19\n\n```bash\nyum update -y\nyum install yum-utils -y\nrpm -ivh https://dl.fedoraproject.org/pub/epel/epel-release-latest-8.noarch.rpm\nyum install -y php php-fpm php-cli php-common php-devel php-gd php-pdo php-mbstring php-bcmath php-xml php-process php-intl php-soap php-ldap php-opcache \n```\n\n\n\n`openeuler24.03lts`\n\n欧拉系统有自己的仓库,默认安装最新版8.3.19\n\n```\nyum update -y\nyum install -y php php-fpm php-cli php-common php-devel php-gd php-pdo php-mbstring php-bcmath php-xml php-process php-intl php-soap php-ldap php-opcache \nphp -v\n```\n\n\n\n## Mysql LTS\n\n截止2025年4月20日目前：Mysql LTS最新版8.4.5\n\n资料来源：[Linux安装Mysql8.4.2 LTS | 严千屹博客](https://blog.qianyios.top/posts/32ce47c9/?highlight=mysql)\n\n![image-20250420154015199](https://i0.hdslb.com/bfs/article/d07fe2c6eb9006156708495fb008233e55933597.png)\n\n![image-20250420154554656](https://i0.hdslb.com/bfs/article/05ff82f410aa71ba18458610a657434055933597.png)\n\n这是在root目录下,自行去到root目录，你也可以自己定义路径\n\n注意：如果需要搭载php使用，需要安装php7.2，因为rpm -ivh mysql-community-libs-compat是php的依赖。；如果不安装php，则无需安装php7.2的依赖。\n\n这里就演示需要php，版本7.2以上，[安装教程](#PHP(RPM))\n\n`centos 8 stream,openeuler`\n\n```bash\nmkdir mysql-install\ntar -xvf mysql-8.4*.rpm-bundle.tar -C mysql-install\ncd mysql-install\n\n# 卸载 mariadb 相关的包\nyum remove mariadb mariadb-config mariadb-libs -y\n# 如果之前安装过 MySQL 社区版，也需要一并移除\nyum remove mysql-community-common mysql-community-icu-data-files mysql-community-client-plugins mysql-community-libs mysql-community-client mysql-community-server mysql-community-libs-compat -y\n# 最好按照以下顺序按照，不然会报错\n#全局的依赖（common）\nrpm -ivh mysql-community-common-8.4.5-1.el8.x86_64.rpm\nrpm -ivh mysql-community-icu-data-files-8.4.5-1.el8.x86_64.rpm\nrpm -ivh mysql-community-client-plugins-8.4.5-1.el8.x86_64.rpm\nrpm -ivh mysql-community-libs-8.4.5-1.el8.x86_64.rpm\nrpm -ivh mysql-community-client-8.4.5-1.el8.x86_64.rpm\nrpm -ivh mysql-community-server-8.4.5-1.el8.x86_64.rpm\n#php依赖文件\nrpm -ivh mysql-community-libs-compat-8.4.5-1.el8.x86_64.rpm\nsystemctl enable mysqld --now\nmysqlpasswd=$(awk '/temporary password/ {print $NF}' /var/log/mysqld.log)\nmysql -u root -p\"$mysqlpasswd\"\n#Qianyios@007是修改后的密码\nALTER USER 'root'@'localhost' IDENTIFIED BY 'Qianyios@007';\nFLUSH PRIVILEGES;\nexit\nmysql -uroot -pQianyios@007\n```\n\n\n\n例子1：可以设置123456为密码\n\n```bash\nmysql -uroot -pQianyios@007\nALTER USER 'root'@'localhost' IDENTIFIED BY 'Qianyios@007';\nSHOW VARIABLES LIKE 'validate_password%';\nSET GLOBAL validate_password.policy = LOW;\nSET GLOBAL validate_password.length = 6;\nALTER USER 'root'@'localhost' IDENTIFIED BY '123456';\nFLUSH PRIVILEGES;\nexit\nmysql -uroot -p123456\n```\n\n\n\n## containerd\n\n```bash\nsudo yum install -y yum-utils\nsudo yum-config-manager --add-repo https://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo\nsudo yum clean all && yum makecache\nsudo yum install -y containerd.io\n\nsudo mkdir -p /etc/containerd/certs.d/docker.io\nsudo mkdir -p /etc/containerd/certs.d/registry.k8s.io\nsudo mkdir -p /etc/containerd/certs.d/k8s.gcr.io\nsudo mkdir -p /etc/containerd/certs.d/ghcr.io\nsudo mkdir -p /etc/containerd/certs.d/gcr.io\nsudo mkdir -p /etc/containerd/certs.d/quay.io\nsudo mkdir -p /etc/containerd/certs.d/registry-1.docker.io\n\nsudo tee /etc/containerd/certs.d/docker.io/hosts.toml > /dev/null <<'EOF'\nserver = \"https://docker.io\" \n\n[host.\"https://registry.cn-hangzhou.aliyuncs.com/\"]\n  capabilities = [\"pull\", \"resolve\"]\n[host.\"https://docker.xuanyuan.me\"]\n  capabilities = [\"pull\", \"resolve\"]\n[host.\"https://docker.m.daocloud.io\"]\n  capabilities = [\"pull\", \"resolve\"]\n[host.\"https://docker.1ms.run\"]\n  capabilities = [\"pull\", \"resolve\"]\n[host.\"https://docker.1panel.live\"]\n  capabilities = [\"pull\", \"resolve\"]\n[host.\"https://docker.qianyios.top/\"] \n  capabilities = [\"pull\", \"resolve\"]\n[host.\"https://reg-mirror.giniu.com\"] \n  capabilities = [\"pull\", \"resolve\"]\nEOF\n\nsudo tee /etc/containerd/certs.d/registry-1.docker.io/hosts.toml > /dev/null <<'EOF'\nserver = \"https://registry-1.docker.io\"\n\n[host.\"https://registry.cn-hangzhou.aliyuncs.com/\"]\n  capabilities = [\"pull\", \"resolve\"]\n[host.\"https://docker.xuanyuan.me\"]\n  capabilities = [\"pull\", \"resolve\"]\n[host.\"https://docker.m.daocloud.io\"]\n  capabilities = [\"pull\", \"resolve\"]\n[host.\"https://docker.1ms.run\"]\n  capabilities = [\"pull\", \"resolve\"]\n[host.\"https://docker.1panel.live\"]\n  capabilities = [\"pull\", \"resolve\"]\n[host.\"https://docker.qianyios.top/\"] \n  capabilities = [\"pull\", \"resolve\"]\n[host.\"https://reg-mirror.giniu.com\"] \n  capabilities = [\"pull\", \"resolve\"]\nEOF\n\n\nsudo tee /etc/containerd/certs.d/k8s.gcr.io/hosts.toml > /dev/null <<'EOF'\nserver = \"https://k8s.gcr.io\"\n\n[host.\"https://registry.aliyuncs.com/google_containers\"]\n  capabilities = [\"pull\", \"resolve\"]\nEOF\n\nsudo tee /etc/containerd/certs.d/ghcr.io/hosts.toml > /dev/null <<'EOF'\nserver = \"https://ghcr.io\"\n\n[host.\"https://ghcr.m.daocloud.io/\"]\n  capabilities = [\"pull\", \"resolve\"]\nEOF\n\nsudo tee /etc/containerd/certs.d/gcr.io/hosts.toml > /dev/null <<'EOF'\nserver = \"https://gcr.io\"\n\n[host.\"https://gcr.m.daocloud.io/\"]\n  capabilities = [\"pull\", \"resolve\"]\nEOF\n\nsudo tee /etc/containerd/certs.d/registry.k8s.io/hosts.toml > /dev/null <<'EOF'\nserver = \"registry.k8s.io\"\n\n[host.\"k8s.m.daocloud.io\"]\n  capabilities = [\"pull\", \"resolve\", \"push\"]\n[host.\"https://registry.aliyuncs.com/v2/google_containers\"]\n  capabilities = [\"pull\", \"resolve\"]\nEOF\n\nsudo tee /etc/containerd/certs.d/quay.io/hosts.toml > /dev/null <<'EOF'\nserver = \"https://quay.io\"\n\n[host.\"https://quay.tencentcloudcr.com/\"]\n  capabilities = [\"pull\", \"resolve\"]\nEOF\n\nsudo sh -c 'containerd config default > /etc/containerd/config.toml'\nsudo sed -i 's#sandbox_image = \"registry.k8s.io/pause:.*\"#sandbox_image = \"registry.aliyuncs.com/google_containers/pause:3.10\"#' /etc/containerd/config.toml\nsudo sed -i 's/SystemdCgroup = false/SystemdCgroup = true/g' /etc/containerd/config.toml\nsed -i '/\\[plugins\\.\"io\\.containerd\\.grpc\\.v1\\.cri\"\\.registry\\]/!b;n;s/config_path = \"\"/config_path = \"\\/etc\\/containerd\\/certs.d\"/' /etc/containerd/config.toml\n# 重启 containerd 服务\nsudo systemctl daemon-reload\nsudo systemctl restart containerd.service\nsudo ctr image ls\n```\n\n## 系统更换Yum源办法\n\n阿里网站：[repo安装包下载_开源镜像站-阿里云 (aliyun.com)](https://mirrors.aliyun.com/repo/)\n\nCentos Stream 8\n\n```bash\nmkdir repo.bak\nmv /etc/yum.repos.d/* repo.bak/\nwget -O /etc/yum.repos.d/CentOS-Stream-AppStream.repo https://mirrors.aliyun.com/repo/centos-stream/8/CentOS-Stream-AppStream.repo\nwget -O /etc/yum.repos.d/CentOS-Stream-BaseOS.repo https://mirrors.aliyun.com/repo/centos-stream/8/CentOS-Stream-BaseOS.repo\ndnf clean all && dnf makecache\n```\n\nCentos 7\n\n```bahs\nmkdir repo.bak\nmv /etc/yum.repos.d/* repo.bak/\nwget -O /etc/yum.repos.d/Centos-7.repo https://mirrors.aliyun.com/repo/Centos-7.repo\nyum clean all && yum makecache\n```\n\nCentos 8\n\n```bash\nmkdir repo.bak\nmv /etc/yum.repos.d/* repo.bak/\ncurl -o /etc/yum.repos.d/CentOS-Base.repo https://mirrors.aliyun.com/repo/Centos-vault-8.5.2111.repo\nyum clean all && yum makecache\n```\n\nRocky 系列\n\n```bash\nsed -e 's|^mirrorlist=|#mirrorlist=|g' \\\n    -e 's|^#baseurl=http://dl.rockylinux.org/$contentdir|baseurl=https://mirrors.aliyun.com/rockylinux|g' \\\n    -e\n's|^#baseurl=http://mirrors.rockylinux.org/$contentdir|baseurl=https://mirrors.aliyun.com/rockylinux|g' \\\n    -i.bak \\\n    /etc/yum.repos.d/Rocky-*.repo\n\nyum clean all && yum makecache\n```\n\n\n\n<div class=\"tbsm\" style=\"margin-top:54px;\">\n<div class=\"tbsm-top\"><span><svg t=\"1674654360507\" class=\"icon\" viewBox=\"0 0 1024 1024\" version=\"1.1\" xmlns=\"http://www.w3.org/2000/svg\" p-id=\"987\" data-spm-anchor-id=\"a313x.7781069.0.i0\" width=\"35\" height=\"35\"><path d=\"M410.49 97.74H155.08a56.74 56.74 0 0 0-56.84 56.73V410a56.84 56.84 0 0 0 56.84 56.84h255.41A56.83 56.83 0 0 0 467.32 410V154.58a56.83 56.83 0 0 0-56.83-56.84zM410.49 558.74H155.08a56.74 56.74 0 0 0-56.84 56.73V871a56.84 56.84 0 0 0 56.84 56.84h255.41A56.83 56.83 0 0 0 467.32 871V615.58a56.83 56.83 0 0 0-56.83-56.84zM871.49 558.74H616.08a56.74 56.74 0 0 0-56.84 56.73V871a56.84 56.84 0 0 0 56.84 56.84h255.41A56.83 56.83 0 0 0 928.32 871V615.58a56.83 56.83 0 0 0-56.83-56.84z\" fill=\"#66EEFF\" p-id=\"988\"></path><path d=\"M410.49 558.74h-4.14A475 475 0 0 0 299.52 859.6a481.16 481.16 0 0 0 4.84 68.22h106.13A56.83 56.83 0 0 0 467.32 871V615.58a56.83 56.83 0 0 0-56.83-56.84zM871.49 558.74H616.08a56.74 56.74 0 0 0-56.84 56.73V871a56.84 56.84 0 0 0 56.84 56.84h255.41A56.83 56.83 0 0 0 928.32 871V615.58a56.83 56.83 0 0 0-56.83-56.84z\" fill=\"#C2F8FF\" p-id=\"989\"></path></svg></span><span style=\"font-size:30px;\"> 特别声明</span></div>\n<div class=\"tbsm-wz\">千屹博客旗下的所有文章，是通过本人课堂学习和课外自学所精心整理的知识巨著<br/>难免会有出错的地方<br/>如果细心的你发现了小失误，可以在下方评论区告诉我，或者私信我！<br />非常感谢大家的热烈支持！</div>\n</div>\n","tags":["Centos 8","Docker","Centos 7","OpenEuler","Mysql","Nginx","Php"],"categories":["运维"]},{"title":"Linux配置DNS服务","url":"/posts/b29b8cd3/","content":"\n<meta name=\"referrer\" content=\"no-referrer\"/>\n\n# Linux配置DNS服务\n\n## DNS 简介\n\n**- 什么是域名**\n\n> 域名(DomainName)，简称域名、网域，是由一串用点分隔的名字组成的Internet上某一台计算机或计算机组的名称，用于在数据传输时标识计算机的电子方位。具有独一无二，不可重复的特性。\n\n**- 域名的关系和组成**\n\n常见域名：www.baidu.com\n完整域名：www.baidu.com.\n\n注意com 后面有一点\n\n```\n. ：根域，可省略不写。\n```\n\n```\ncom：顶级域，由ICANN组织指定和管理。\n```\n\n```\n分类：\n1、国家地区域名: (cn(中国)、hk(香港)、sg (新加坡)等。\n2、通用项级域名: com (商业机构)、org (非营利组织)、edu (教育机构)等。\n3、新通用顶级域名: red (红色、热情)、top (顶级、高端)等。\n4、com.cn属于“二级域名”，是cn项级域的子域。\n```\n\n```\nbaidu：级域(注册域) ，可由·个人或组织申请注册。\n```\n\n```\nwww：三级域(子域)，服务器网站名代表。（www.baidu.com）\n```\n\n![image-20250402083329281](../img/Linux%E9%85%8D%E7%BD%AEDNS%E6%9C%8D%E5%8A%A1/0c6c14644f92e63d3f8a3efe745af98c55933597.png)\n\n**- 什么是DNS?**\n\n域名系统(Domain Name System,缩写: DNS)是互联网的一项服务。域名解析是把域名指向网站空间IP,让人们通过注册的域名可以方便地访问到网站的一种服务。IP地址是网络上标识站点的数字地址，为了方便记忆，采用域名来代替IP地址标识站点地址。域名解析就是域名到IP地址的转换过程。域名的解析工作由DNS服务器完成。可以理解为DNS就是翻译官。\n\n正向解析：域名 --> IP地址。\n反向解析：IP地址 --> 域名。\n\n## DNS 工作过程\n\n![image-20250402084707783](../img/Linux%E9%85%8D%E7%BD%AEDNS%E6%9C%8D%E5%8A%A1/123.png)\n\n> 客户端在浏览器输入一个域名：www.baidu.com，浏览器自动补充域名：www.baidu.com：80。80端口是web服务器的端口\n\n1.在从自己本机中查询host文件，是否有此域名的解析记录，如果有则返回给浏览器\n\n2.如果host文件没有域名的解析记录，则会在本机上继续查询是否有DNS的解析缓存，如果有则返回给浏览器\n\n3.如果本机没有DNS的解析记录，则会在网卡设置的DNS服务器上，查询域名的解析结果\n\n4.如果DNS服务器上也没有查询到，则会从别人询问的结果的缓存中查找\n\n5.就迭代查询，顶级域名，二级域名，三级域名\n\n## DNS 配置文件\n\n- **/ etc / named.conf ：主配置文件**\n\n![image-20250402090006154](../img/Linux%E9%85%8D%E7%BD%AEDNS%E6%9C%8D%E5%8A%A1/81044cdb177ddfbfeacc60976d19b5cd55933597.png)\n\n- / **etc / named.rfc1912.zones：区域配置文件**\n\n![image-20250402090420936](../img/Linux%E9%85%8D%E7%BD%AEDNS%E6%9C%8D%E5%8A%A1/a6300906df748fe4f1984e9917013e5755933597.png)\n\n- **/ var / named / ：数据配置文件**\n\nnamed.ca：记录了13台根域服务器的位置\nnamed.localhost：正向代理\nnamed.loopback：反向代理\n\n![image-20250402092142493](../img/Linux%E9%85%8D%E7%BD%AEDNS%E6%9C%8D%E5%8A%A1/872d33ebc5c97da40f78925bab9dd8bb55933597.png)\n\n| 类型  | 描述                                                         |\n| ----- | ------------------------------------------------------------ |\n| A     | 地址记录，用来指定域名的 IPv4 地址的记录。                   |\n| CNAME | 将域名指向另一个域名，再由另一个域名提供 ip 地址，就需要添加 CNAME 记录。 |\n| TXT   | 可填写任何东西，长度限制 255。绝大多数的 TXT 记录是用来做 SPF 的（反垃圾邮件）。 |\n| NS    | 域名服务器记录，如果需要把子域名交给其他 DNS 服务商解析，就需要添加 NS 记录。 |\n| AAAA  | 地址记录，用来指定域名的 IPv6 地址的记录。                   |\n| MX    | 邮件交换记录，如果需要设置邮箱，让邮箱能收到邮件，就需要添加 MX 记录。 |\n\n- **软件名称：bind**\n- **服务名称：named**\n- **软件端口：**\n\n> UDP 53 数据通信(域名解析)\n> TCP 53 数据同步(主从同步)\n\n## DNS 服务搭建\n\n`配置DNS地址：/etc/resolv.conf`\n\n| 主机名 |       ip       | 内存 | 硬盘 | cpu  | OS      |\n| :----: | :------------: | :--: | :--: | :--: | ------- |\n| master | 192.168.48.101 |  2g  | 100g |  2v  | Centos7 |\n| slave  | 192.168.48.102 |  2g  | 100g |  2v  | Centos7 |\n| client | 192.168.48.103 |  2g  | 100g |  2v  | Centos7 |\n\n> 前情提要：以下是三台机的网卡dns配置,自行设置\n>\n> matser: DNS1=192.168.48.101\n>\n> slave: DNS1=192.168.48.102\n>\n> client: DNS1=192.168.48.101 , DNS2=192.168.48.102\n\n### 服务端配置\n\n一、安装\n\n```bash\nyum install -y bind bind-utils\n```\n\n二、配置文件\n\n操作节点：[master]\n\n1.配置主文件 vim /etc/named.conf\n\n```bash\nlisten-on port 53 { 192.168.48.101; }; //masterIP\nallow-query     { any; };\n```\n\n2、配置区域文件 vim /etc/named.rfc1912.zones\n\n```bash\ncat >> /etc/named.rfc1912.zones <<\"EOF\"\nzone \"aaa.com\" IN {\n        type master;\n        file \"aaa.com.zone\";\n};\nzone \"48.168.192.in-addr.arpa\" IN {\n        type master;\n        file \"aaa.loopback\";\n};\nEOF\n```\n\n3、编辑正向解析数据文件 vim /var/named/aaa.com.zone\n\n```\ncat > /var/named/aaa.com.zone <<\"EOF\"\n$TTL 1D\n@       IN SOA  aaa.com. rname.invalid. (\n                                        0       ; serial\n                                        1D      ; refresh\n                                        1H      ; retry\n                                        1W      ; expire\n                                        3H )    ; minimum\n        NS      dns.aaa.com.\ndns     A       192.168.48.129\nwww     A       192.168.48.128\nEOF\n```\n\n4、编辑反向解析数据文件 vim /var/named/aaa.loopback\n\n```\ncat > /var/named/aaa.loopback <<\"EOF\"\n$TTL 1D\n@       IN SOA  aaa.com. rname.invalid. (\n                                        0       ; serial\n                                        1D      ; refresh\n                                        1H      ; retry\n                                        1W      ; expire\n                                        3H )    ; minimum\n        NS      dns.aaa.com.\n129     PTR     dns.aaa.com.\n128     PTR     www.aaa.com.\nEOF\n```\n\n5.启动named服务\n\n```\nsystemctl start named --now\nsystemctl restart named\n```\n\n### **客户端配置**\n\n操作节点：[client]\n\n一、安装\n\n```bash\nyum install -y bind bind-utils\n```\n\n二、配置网卡dns\n\n这是我的网卡名称是ens33你自己按你自己的改\n\n```\nvim /etc/sysconfig/network-scripts/ifcfg-ens33\n```\n\n```\nDNS1=192.168.48.101\n```\n\n![image-20250402093721868](../img/Linux%E9%85%8D%E7%BD%AEDNS%E6%9C%8D%E5%8A%A1/980416801980eddd00ec6309c275cd4155933597.png)\n\n重启网卡\n\n```\nsystemctl restart network\n```\n\n**三、 测试 nslookup**\n\n- 正向解析测试\n\n```\nnslookup www.aaa.com\nnslookup dns.aaa.com\n```\n\n![image-20250402094701150](../img/Linux%E9%85%8D%E7%BD%AEDNS%E6%9C%8D%E5%8A%A1/c80e09e300a3e44126cd9010738c73b755933597.png)\n\n- 反向解析测试\n\n```\nhost 192.168.48.128\nhost 192.168.48.129\n```\n\n![image-20250402094743914](../img/Linux%E9%85%8D%E7%BD%AEDNS%E6%9C%8D%E5%8A%A1/3b9e6fd094d838e62932721bbc19c96e55933597.png)\n\n## 主从DNS服务器搭建\n\n减轻主服务器的压力，数据从 主服务器上复制到 从服务器上\n\n### 主服务器配置\n\n操作节点：[master]\n\n1.配置主文件 vim /etc/named.conf\n\n```bash\nlisten-on port 53 { 192.168.48.101; }; //masterIP\nallow-query     { any; };\n```\n\n2、配置区域文件 vim /etc/named.rfc1912.zones\n\n```bash\nzone \"aaa.com\" IN {\n        type master;\n        file \"aaa.com.zone\";\n        allow-update { 192.168.48.102; };  //从服务器的IP\n};\nzone \"48.168.192.in-addr.arpa\" IN {\n        type master;\n        file \"aaa.loopback\";\n        allow-update { 192.168.48.102; };  //从服务器的IP\n};\n```\n\n![image-20250402100049594](../img/Linux%E9%85%8D%E7%BD%AEDNS%E6%9C%8D%E5%8A%A1/688af3fbb47eb4eb6fb25605859c908b55933597.png)\n\n3、编辑正向解析数据文件 vim /var/named/aaa.com.zone\n\n```\ncat > /var/named/aaa.com.zone <<\"EOF\"\n$TTL 1D\n@       IN SOA  aaa.com. rname.invalid. (\n                                        0       ; serial\n                                        1D      ; refresh\n                                        1H      ; retry\n                                        1W      ; expire\n                                        3H )    ; minimum\n        NS      dns.aaa.com.\ndns     A       192.168.48.129\nwww     A       192.168.48.128\nEOF\n```\n\n4、编辑反向解析数据文件 vim /var/named/aaa.loopback\n\n```\ncat > /var/named/aaa.loopback <<\"EOF\"\n$TTL 1D\n@       IN SOA  aaa.com. rname.invalid. (\n                                        0       ; serial\n                                        1D      ; refresh\n                                        1H      ; retry\n                                        1W      ; expire\n                                        3H )    ; minimum\n        NS      dns.aaa.com.\n129     PTR     dns.aaa.com.\n128     PTR     www.aaa.com.\nEOF\n```\n\n### 从服务器配置\n\n操作节点：[slave]\n\n1.配置主文件 vim /etc/named.conf\n\n```bash\nlisten-on port 53 { 192.168.48.102; }; //slaveIP\nallow-query     { any; };\n```\n\n2、配置区域文件 vim /etc/named.rfc1912.zones\n\n```bash\nzone \"aaa.com\" IN {\n        type slave;\n        file \"slaves/aaa.com.zone\";\n        masters { 192.168.48.101; }; //主服务器的IP\n};\nzone \"48.168.192.in-addr.arpa\" IN {\n        type slave;\n        file \"slaves/aaa.loopback\";\n        masters { 192.168.48.101; }; //主服务器的IP\n};\n```\n\n![image-20250402100911225](../img/Linux%E9%85%8D%E7%BD%AEDNS%E6%9C%8D%E5%8A%A1/ce1825c2bae5eeac68b306ebdc60963155933597.png)\n\n如果主从同步之后区域数据文件会同步到/var/named/slaves这个目录下，现在还是空的\n\n```\n[root@slave ~]# ll /var/named/slaves\ntotal 0\n[root@slave ~]#\n```\n\nslave指定域名服务器为自己\n\n```\necho \"nameserver 192.168.48.102\" > /etc/resolv.conf\n```\n\n\n\n两台重启named服务\n\n`操作节点：[master,slave]`\n\n```\nsystemctl restart named\n```\n\n这时候经过两台服务器重启named之后，master里的两个文件就已经同步到slave的/var/named/slaves这个目录下\n\n![image-20250402100935884](../img/Linux%E9%85%8D%E7%BD%AEDNS%E6%9C%8D%E5%8A%A1/beb458319422f60b88ec225040bd450355933597.png)\n\n\n\n### 测试正反向解析\n\n- 正向解析测试\n\n```\nnslookup www.aaa.com\nnslookup dns.aaa.com\n```\n\n![image-20250402101152907](../img/Linux%E9%85%8D%E7%BD%AEDNS%E6%9C%8D%E5%8A%A1/d45de29d8863c31956211f5027511f5255933597.png)\n\n- 反向解析测试\n\n```\nhost 192.168.48.128\nhost 192.168.48.129\n```\n\n![image-20250402101204461](../img/Linux%E9%85%8D%E7%BD%AEDNS%E6%9C%8D%E5%8A%A1/2465e2987d014da9434ebd4b58c4302255933597.png)\n\n\n\n### 客户端配置\n\n修改网卡dns添加一个从服务器的ip\n\n```\nvim /etc/sysconfig/network-scripts/ifcfg-ens33\n```\n\n![image-20250402101403809](../img/Linux%E9%85%8D%E7%BD%AEDNS%E6%9C%8D%E5%8A%A1/975059c4da217acf17c63228e41008ee55933597.png)\n\n重启网卡\n\n```\nsystemctl restart network\n```\n\n\n\n### 测试主从服务\n\n当我们给master模拟named服务故障时，由从服务器进行接管\n\n测试前，是由master提供服务\n\n```\nnslookup www.aaa.com\nnslookup dns.aaa.com\n```\n\n![image-20250402101611671](../img/Linux%E9%85%8D%E7%BD%AEDNS%E6%9C%8D%E5%8A%A1/2c156d59ed0f997a8196c7d03cd8cc0955933597.png)\n\n断开master的named的服务\n\n```\n[root@master ~]# systemctl stop named\n[root@master ~]#\n```\n\n再次进行测试\n\n```\nnslookup www.aaa.com\nnslookup dns.aaa.com\n```\n\n```\nhost 192.168.48.128\nhost 192.168.48.129\n```\n\n![image-20250402102110369](../img/Linux%E9%85%8D%E7%BD%AEDNS%E6%9C%8D%E5%8A%A1/ffa15068a361d394dedf46a35ced861c55933597.png)\n\n![image-20250402102339217](../img/Linux%E9%85%8D%E7%BD%AEDNS%E6%9C%8D%E5%8A%A1/84f70efbaeb6b6e9ac4427145fa2455355933597.png)\n\n这时重启master的named，客户机又从主服务器查询域名了\n\n```\nsystemctl start named\n```\n\n![image-20250402102221795](../img/Linux%E9%85%8D%E7%BD%AEDNS%E6%9C%8D%E5%8A%A1/0da55ab950e937db333ff6d69401685c55933597.png)\n\n![image-20250402102355960](../img/Linux%E9%85%8D%E7%BD%AEDNS%E6%9C%8D%E5%8A%A1/33c1983cc54245c7297348d3c8590c7755933597.png)\n\n## 自动主从同步\n\n我们已经配置了主从服务器了，如果这时主服务器的区域数据文件中又添加了新的解析条目，怎么实现从服务器也能自动同步这个数据呢？很简单\n\n操作节点：[matser]\n\n1.在区域配置文件vim /etc/named.rfc1912.zones\n\n```\nnotify yes;\nalso-notify { 192.168.48.102; };\n```\n\n![image-20250402102940010](../img/Linux%E9%85%8D%E7%BD%AEDNS%E6%9C%8D%E5%8A%A1/b15605b3ba49350747c41105133db78055933597.png)\n\n2、`在主服务器的区域数据文件中添加新的条目的同时将序列号修改一个比之前更大的数值`，序列号最大10位，也可以小于10位\n\n2.1、配置正向区域数据文件\n\nvim /var/named/aaa.com.zone\n\n顺便添加一条新的解析\n\n![image-20250402103624647](../img/Linux%E9%85%8D%E7%BD%AEDNS%E6%9C%8D%E5%8A%A1/44b5f0183c7f2504e0efef92d2a378cb55933597.png)\n\n2.2、配置反向区域数据文件\n\nvim /var/named/aaa.loopback\n\n![image-20250402103754780](../img/Linux%E9%85%8D%E7%BD%AEDNS%E6%9C%8D%E5%8A%A1/4ace78fd093fa6abb0f74dce9c342aed55933597.png)\n\n\n\n3、测试\n\n测试前查看slave数据的文件时间\n\n![image-20250402103413907](../img/Linux%E9%85%8D%E7%BD%AEDNS%E6%9C%8D%E5%8A%A1/86ad7ff3faf53225bfdb3088c60c076955933597.png)\n\n重启master的named的服务\n\n```\nsystemctl restart named\n```\n\n![image-20250402103830941](../img/Linux%E9%85%8D%E7%BD%AEDNS%E6%9C%8D%E5%8A%A1/b2e77bdb36275dfee3b61193838f0b9655933597.png)\n\n这时候已经更新了，再次进行测试\n\n```\n[root@slave ~]# nslookup abc.aaa.com\nServer:         192.168.48.102\nAddress:        192.168.48.102#53\n\nName:   abc.aaa.com\nAddress: 192.168.48.130\n[root@slave ~]# host 192.168.48.130\n130.48.168.192.in-addr.arpa domain name pointer abc.aaa.com.\n```\n\n都能成功进行解析，主从自动同步成功\n\n\n\n`我有测试没修改序号就添加数据顺便重启，是没有同步成功的`\n\n![image-20250402104220815](../img/Linux%E9%85%8D%E7%BD%AEDNS%E6%9C%8D%E5%8A%A1/8e33f1cabcf312e0ad0b8676fc6caea755933597.png)\n\n![image-20250402104232912](../img/Linux%E9%85%8D%E7%BD%AEDNS%E6%9C%8D%E5%8A%A1/1ca5cedbc0c7dddc57ff5e23e315de4c55933597.png)\n\n重启之后\n\n```\n[root@master ~]# systemctl restart named\n[root@master ~]#\n```\n\nslave下的文件还是和原来一样\n\n```\n[root@slave ~]# ll /var/named/slaves/\ntotal 8\n-rw-r--r-- 1 named named 260 Apr  2 10:38 aaa.com.zone\n-rw-r--r-- 1 named named 367 Apr  2 10:38 aaa.loopback\n[root@slave ~]#\n```\n\n而且slave是解析不到我新添加的\n\n![image-20250402104409869](../img/Linux%E9%85%8D%E7%BD%AEDNS%E6%9C%8D%E5%8A%A1/4058ab4c533d1a869ae20233d768592855933597.png)\n\n只有当我`修改序号为2`时，再进行重启，才能进行同步\n\n![image-20250402104543824](../img/Linux%E9%85%8D%E7%BD%AEDNS%E6%9C%8D%E5%8A%A1/f498060bece711dc05b4ce563d2cab8b55933597.png)\n\n## ssh免密\n\n此步骤是为了方便以下自动脚本\n\n操作节点：【三台服务器】\n\n这是我的ip和主机名，你根据需要自行修改\n\n```\ncat >> /etc/hosts << \"EOF\"\n192.168.48.101 master\n192.168.48.102 slave\n192.168.48.103 client\nEOF\n```\n\n操作节点：【master】\n\n> 脚本里`password=\"123456\"`是我三台机的密码，我三台都一样，如何你是不一样，你自己自行进行手动免密了\n>\n> [master] yum install -y sshpass \n>\n> [master] ssh-keygen -t rsa -N \"\" -f ~/.ssh/id_rsa\n>\n> 以下这个命令的主机名，三个主机名都要输一遍，也就是三条命令了\n>\n> [master] sshpass -p \"密码\" ssh-copy-id -o StrictHostKeyChecking=no \"主机名\"\n>\n> 测试免密，三个主机名都要输一遍，也就是三条命令了\n>\n> [master] sshpass -p \"密码\" ssh -o StrictHostKeyChecking=no \"主机名\" \"echo '免密登录成功'\"\n\n```bash\nyum install -y sshpass \ncat > sshmianmi.sh << \"EOF\"\n#!/bin/bash\n# 目标主机列表\nhosts=(\"master\" \"slave\" \"client\")\n# 密码\npassword=\"123456\"\n# 生成 SSH 密钥对\nssh-keygen -t rsa -N \"\" -f ~/.ssh/id_rsa\n\n# 循环遍历目标主机\nfor host in \"${hosts[@]}\"\ndo\n    # 复制公钥到目标主机\n    sshpass -p \"$password\" ssh-copy-id -o StrictHostKeyChecking=no \"$host\"\n    \n    # 验证免密登录\n    sshpass -p \"$password\" ssh -o StrictHostKeyChecking=no \"$host\" \"echo '免密登录成功'\"\ndone\nEOF\n\nsh sshmianmi.sh\n```\n\n## 自动添加解析脚本\n\n你要做的就是修改脚本中的`SLAVE_IP=\"192.168.48.102\"`这是我的从节点的ip\n\n你要把你的主从节点做好`免密`之后，才可以进行以下操作\n\n操作节点:[master]\n\n```\nvim jx.sh\n```\n\n```bash\n#!/bin/bash\n\n# 检查参数数量\nif [ \"$#\" -ne 2 ]; then\n    echo \"Usage: $0 <IP_ADDRESS> <DOMAIN>\"\n    exit 1\nfi\n\nIP=\"$1\"\nDOMAIN=\"$2\"\n# 获取本机 IP 地址（假设主机只有一个有效 IP）\nMASTER_IP=$(hostname -I | awk '{print $1}')\n# 从服务器的 IP 地址\nSLAVE_IP=\"192.168.48.102\"\n\n# 解析域名和反向 IP\nBASE_DOMAIN=$(echo \"$DOMAIN\" | awk -F. '{print $(NF-1)\".\"$NF}')\nZONE_FILE=\"/var/named/$BASE_DOMAIN.zone\"\nREV_ZONE_FILE=\"/var/named/$(echo $IP | awk -F. '{print $3\".\"$2\".\"$1\".in-addr.arpa\"}').zone\"\nZONE_CONFIG=\"/etc/named.rfc1912.zones\"\n\n# 解析反向 IP 和主机名\nREV_IP=$(echo $IP | awk -F. '{print $3\".\"$2\".\"$1}')\nREV_HOST=$(echo $IP | awk -F. '{print $4}')\nSHORT_NAME=$(echo \"$DOMAIN\" | awk -F. '{print $1}')\n\n# 确保 /var/named 目录存在\nmkdir -p /var/named/\ntouch \"$ZONE_FILE\" \"$REV_ZONE_FILE\"\nchown named:named \"$ZONE_FILE\" \"$REV_ZONE_FILE\"\nchmod 644 \"$ZONE_FILE\" \"$REV_ZONE_FILE\"\n\n# 检查是否已存在相同的解析记录\nif grep -q \"^$SHORT_NAME[[:space:]]*A[[:space:]]*$IP\" \"$ZONE_FILE\"; then\n    echo \"记录 $DOMAIN -> $IP 已存在，无需添加\"\n    exit 0\nfi\n\n# **递增 serial 号**\nincrement_serial() {\n    # 提取当前 serial 值\n    current_serial=$(awk '/serial/{print $1}' \"$1\")\n    \n    if [[ -z \"$current_serial\" ]]; then\n        # 如果没有找到 serial（空），初始化为 1\n        current_serial=1\n    fi\n\n    # 递增 serial\n    new_serial=$((current_serial + 1))\n\n    # 替换 serial 行，保留前导空格和注释\n    sed -i \"s/\\([[:space:]]*\\)\\([0-9]\\+\\)\\([[:space:]]*; serial\\)/\\1$new_serial\\3/\" \"$1\"\n}\n\n\n\n# 添加正向解析区域配置（如果不存在）\nif ! grep -q \"zone \\\"$BASE_DOMAIN\\\" IN\" \"$ZONE_CONFIG\"; then\n    cat >> \"$ZONE_CONFIG\" <<EOF\nzone \"$BASE_DOMAIN\" IN {\n        type master;\n        file \"$ZONE_FILE\";\n        notify yes;\n        also-notify { $SLAVE_IP; };\n        allow-update { $SLAVE_IP; };\n};\nEOF\nfi\n\n# 添加反向解析区域配置（如果不存在）\nif ! grep -q \"zone \\\"$REV_IP.in-addr.arpa\\\" IN\" \"$ZONE_CONFIG\"; then\n    cat >> \"$ZONE_CONFIG\" <<EOF\nzone \"$REV_IP.in-addr.arpa\" IN {\n        type master;\n        file \"$REV_ZONE_FILE\";\n        notify yes;\n        also-notify { $SLAVE_IP; };\n        allow-update { $SLAVE_IP; };\n};\nEOF\nfi\n\n# **初始化 Zone 文件（正向解析）**\nif [ ! -s \"$ZONE_FILE\" ]; then\n    cat > \"$ZONE_FILE\" <<EOF\n\\$TTL 1D\n@       IN SOA  $BASE_DOMAIN rname.invalid. (\n                                        1       ; serial\n                                        1D      ; refresh\n                                        1H      ; retry\n                                        1W      ; expire\n                                        3H )    ; minimum\n        NS      $BASE_DOMAIN\n$BASE_DOMAIN     A   $MASTER_IP\n\nEOF\n    increment_serial \"$ZONE_FILE\"  # 初始化时递增 serial\nfi\n\n# **追加 A 记录（使用短名）**\nif ! grep -q \"^$SHORT_NAME[[:space:]]*A[[:space:]]*$IP\" \"$ZONE_FILE\"; then\n    echo \"$SHORT_NAME    A       $IP\" >> \"$ZONE_FILE\"\n    increment_serial \"$ZONE_FILE\"  # 追加记录后递增 serial\nfi\n\n# **初始化 Zone 文件（反向解析）**\nif [ ! -s \"$REV_ZONE_FILE\" ]; then\n    cat > \"$REV_ZONE_FILE\" <<EOF\n\\$TTL 1D\n@       IN SOA  $BASE_DOMAIN rname.invalid. (\n                                        1       ; serial\n                                        1D      ; refresh\n                                        1H      ; retry\n                                        1W      ; expire\n                                        3H )    ; minimum\n        NS      $BASE_DOMAIN\n$BASE_DOMAIN     A   $MASTER_IP        \n\nEOF\n    increment_serial \"$REV_ZONE_FILE\"  # 初始化时递增 serial\nfi\n\n# **追加 PTR 记录**\nif ! grep -q \"^$REV_HOST[[:space:]]*PTR[[:space:]]*$SHORT_NAME.$BASE_DOMAIN.\" \"$REV_ZONE_FILE\"; then\n    echo \"$REV_HOST     PTR     $SHORT_NAME.$BASE_DOMAIN.\" >> \"$REV_ZONE_FILE\"\n    increment_serial \"$REV_ZONE_FILE\"  # 追加记录后递增 serial\nfi\n\n# 在从服务器上追加主从同步配置\nssh -T root@$SLAVE_IP <<EOF\n# 检查从服务器配置文件是否已存在主从同步区域\nif ! grep -q \"zone \\\"$BASE_DOMAIN\\\" IN\" \"$ZONE_CONFIG\"; then\n    cat >> \"$ZONE_CONFIG\" <<EOT\nzone \"$BASE_DOMAIN\" IN { \n    type slave;\n    file \"slaves/$BASE_DOMAIN.zone\"; \n    masters { $MASTER_IP; }; # 主服务器的IP\n};\nEOT\nfi\n\n# 检查反向解析的从服务器配置\nif ! grep -q \"zone \\\"$REV_IP.in-addr.arpa\\\" IN\" \"$ZONE_CONFIG\"; then\n    cat >> \"$ZONE_CONFIG\" <<EOT\nzone \"$REV_IP.in-addr.arpa\" IN { \n    type slave;\n    file \"slaves/$REV_IP.loopback\";\n    masters { $MASTER_IP; }; # 主服务器的IP\n};\nEOT\nfi\nEOF\n\n# 重新加载主服务器的 Bind 配置\nsystemctl restart named\necho \"✅ DNS 记录已添加并重新加载 Bind 服务\"\n\n# 重新加载从服务器上的 Bind 配置\nssh -T root@$SLAVE_IP <<EOF\nsystemctl restart named\necho \"✅ 从服务器 $SLAVE_IP 配置已更新并重新加载 Bind 服务\"\nEOF\n\necho \"✅ 主从同步配置已成功添加到从服务器 $SLAVE_IP\"\n\n\nsystemctl restart named\n```\n\n```\nbash jx.sh 192.168.111.201 bs.qianyios12.top\nbash jx.sh 192.168.123.202 bs1.qianyios1245.top\nbash jx.sh 192.168.236.203 bs3.qianyios22224.top\n```\n\n![image-20250402132308000](../img/Linux%E9%85%8D%E7%BD%AEDNS%E6%9C%8D%E5%8A%A1/f230b52db6c93139ad3ba3558617ac4555933597.png)\n\n接下来进行测试，三台机都可以进行测试\n\n```\nnslookup bs.qianyios12.top\nnslookup bs1.qianyios1245.top\nnslookup bs3.qianyios22224.top\nhost 192.168.111.201\nhost 192.168.123.202\nhost 192.168.236.203\n```\n\nmaster\n\n![image-20250402132443227](../img/Linux%E9%85%8D%E7%BD%AEDNS%E6%9C%8D%E5%8A%A1/08b924dbafcd2789d0c5643b5fefec5e55933597.png)\n\nslave\n\n![image-20250402132517976](../img/Linux%E9%85%8D%E7%BD%AEDNS%E6%9C%8D%E5%8A%A1/7402fcc528d1408217337cafea518e6555933597.png)\n\nclient\n\n![image-20250402132543331](../img/Linux%E9%85%8D%E7%BD%AEDNS%E6%9C%8D%E5%8A%A1/12f6ed5447097cdf768cfe9d6d791b2755933597.png)\n\n<div class=\"tbsm\" style=\"margin-top:54px;\">\n<div class=\"tbsm-top\"><span><svg t=\"1674654360507\" class=\"icon\" viewBox=\"0 0 1024 1024\" version=\"1.1\" xmlns=\"http://www.w3.org/2000/svg\" p-id=\"987\" data-spm-anchor-id=\"a313x.7781069.0.i0\" width=\"35\" height=\"35\"><path d=\"M410.49 97.74H155.08a56.74 56.74 0 0 0-56.84 56.73V410a56.84 56.84 0 0 0 56.84 56.84h255.41A56.83 56.83 0 0 0 467.32 410V154.58a56.83 56.83 0 0 0-56.83-56.84zM410.49 558.74H155.08a56.74 56.74 0 0 0-56.84 56.73V871a56.84 56.84 0 0 0 56.84 56.84h255.41A56.83 56.83 0 0 0 467.32 871V615.58a56.83 56.83 0 0 0-56.83-56.84zM871.49 558.74H616.08a56.74 56.74 0 0 0-56.84 56.73V871a56.84 56.84 0 0 0 56.84 56.84h255.41A56.83 56.83 0 0 0 928.32 871V615.58a56.83 56.83 0 0 0-56.83-56.84z\" fill=\"#66EEFF\" p-id=\"988\"></path><path d=\"M410.49 558.74h-4.14A475 475 0 0 0 299.52 859.6a481.16 481.16 0 0 0 4.84 68.22h106.13A56.83 56.83 0 0 0 467.32 871V615.58a56.83 56.83 0 0 0-56.83-56.84zM871.49 558.74H616.08a56.74 56.74 0 0 0-56.84 56.73V871a56.84 56.84 0 0 0 56.84 56.84h255.41A56.83 56.83 0 0 0 928.32 871V615.58a56.83 56.83 0 0 0-56.83-56.84z\" fill=\"#C2F8FF\" p-id=\"989\"></path></svg></span><span style=\"font-size:30px;\"> 特别声明</span></div>\n<div class=\"tbsm-wz\">千屹博客旗下的所有文章，是通过本人课堂学习和课外自学所精心整理的知识巨著<br/>难免会有出错的地方<br/>如果细心的你发现了小失误，可以在下方评论区告诉我，或者私信我！<br />非常感谢大家的热烈支持！</div>\n</div>\n","tags":["OpenEuler","Linux","Dns"],"categories":["运维"]},{"title":"巨完美的Docker镜像加速方案","url":"/posts/69efb119/","content":"\n<meta name=\"referrer\" content=\"no-referrer\"/>\n\n# 最完美的Docker镜像加速方案\n\n## 注册账号\n\n现在这注册一个账号 [CNB - Cloud Native Build](https://cnb.cool/)\n\n## 创建组织\n\n![image-20250312130512416](../img/Docker%E5%8A%A0%E9%80%9F%E5%90%8C%E6%AD%A5%E6%96%B9%E6%A1%88/c9126180e0ef22f54ca024b9292ec590697559838.png)\n\n## vscode安装cnb插件\n\n![image-20250312130900409](../img/Docker%E5%8A%A0%E9%80%9F%E5%90%8C%E6%AD%A5%E6%96%B9%E6%A1%88/c80b8a70c8142239c5f6fa1feacb1b36697559838.png)\n\n![image-20250312130921303](../img/Docker%E5%8A%A0%E9%80%9F%E5%90%8C%E6%AD%A5%E6%96%B9%E6%A1%88/17427482007f50fb1fdd42e170a3ac45697559838.png)\n\n## 创建令牌\n\n按照上面的需要去权限进行创建令牌\n\n![image-20250312130749592](../img/Docker%E5%8A%A0%E9%80%9F%E5%90%8C%E6%AD%A5%E6%96%B9%E6%A1%88/d24343adbc6f9ff43662ca43d4d1a4f4697559838.png)\n\n![image-20250312131157890](../img/Docker%E5%8A%A0%E9%80%9F%E5%90%8C%E6%AD%A5%E6%96%B9%E6%A1%88/2ce45e76b807c4077cf16ac2a7ee3693697559838.png)\n\n![image-20250312131213531](../img/Docker%E5%8A%A0%E9%80%9F%E5%90%8C%E6%AD%A5%E6%96%B9%E6%A1%88/d7b0bad8ca361ed79bf0c53aa593c898697559838.png)\n\ncvXpcpkmqiNQA1c77TZOR5ke1EG\n\n## 创建仓库\n\n一定要是公开的\n\n![image-20250312131922242](../img/Docker%E5%8A%A0%E9%80%9F%E5%90%8C%E6%AD%A5%E6%96%B9%E6%A1%88/655ab6a23a75c35bdea1964a76078c71697559838.png)\n\n这时候这里就会读取到\n\n![image-20250312133043835](../img/Docker%E5%8A%A0%E9%80%9F%E5%90%8C%E6%AD%A5%E6%96%B9%E6%A1%88/21635cda0c0e6ca8d7cfad3c7ababafe697559838.png)\n\n## 开始同步\n\n假设有个镜像，是拉取不到的\n\n```\nk8s.gcr.io/pause:3.1\n```\n\n![image-20250312133649822](../img/Docker%E5%8A%A0%E9%80%9F%E5%90%8C%E6%AD%A5%E6%96%B9%E6%A1%88/76757b489123e5f11cb3fdc008b1bbe1697559838.png)\n\n![image-20250312133929159](../img/Docker%E5%8A%A0%E9%80%9F%E5%90%8C%E6%AD%A5%E6%96%B9%E6%A1%88/6ee75ebd2e40f65097e1ecee90dcaafc697559838.png)\n\n因为镜像有标签，所以在最下面有个带标签的地址\n\n![image-20250312134258046](../img/Docker%E5%8A%A0%E9%80%9F%E5%90%8C%E6%AD%A5%E6%96%B9%E6%A1%88/331860787d18274e68ce0f1f0e412dba697559838.png)\n\n![image-20250312143032690](../img/Docker%E5%8A%A0%E9%80%9F%E5%90%8C%E6%AD%A5%E6%96%B9%E6%A1%88/1d893daf57b348db8625114a1a28b9f6697559838.png)\n\n下载成功！","tags":["Docker"],"categories":["Docker"]},{"title":"大数据hadoop实验","url":"/posts/d721e715/","content":"\n<meta name=\"referrer\" content=\"no-referrer\"/>\n\n# 大数据hadoop实验\n\n镜像下载：[ubuntu-18.04.6-desktop-amd64.iso](https://mirrors.aliyun.com/ubuntu-releases/18.04.6/ubuntu-18.04.6-desktop-amd64.iso)\n\n## 大作业\n\n下面两个文档，自己选一个，那个你会用你就用，替换逻辑是一样的\n\nword文档：[大作业文档](https://alist.qianyios.top/d/%E6%B8%B8%E5%AE%A2/R2/%E4%BD%9C%E4%B8%9A/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%9F%BA%E4%BA%8E%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%B9%B3%E5%8F%B0%E7%9A%84%E9%A1%BE%E5%AE%A2%E8%B4%AD%E4%B9%B0%E8%A1%8C%E4%B8%BA%E8%B6%8B%E5%8A%BF%E5%88%86%E6%9E%90.docx?sign=WsZ6ay6lABomcaX8-x1_5j9nMcyrQp2Iz8stQ0d_4xw=:0)\n\nmarkdown文档：[markdown文档](https://alist.qianyios.top/d/%E6%B8%B8%E5%AE%A2/R2/%E4%BD%9C%E4%B8%9A/%E5%A4%A7%E6%95%B0%E6%8D%AE/markdowan%E5%A4%A7%E4%BD%9C%E4%B8%9A.7z?sign=4bhGZRq7XPtT7js_60e_OdpqaULHor-N2iQ3lQ1ladk=:0)\n\n下载之后，打开按Ctrl+H进行替换内容\n\n查找内容：`student/202206150540/yanjiaxi`\n\n替换为：`student/你的学号/你的名字`\n\n注意：`前后没有斜杠`\n\n确定之后你就可以自己复制代码运行了\n\n先给自己的虚拟机打快照，在做大作业\n\n![Snipaste_2025-06-03_21-46-51](../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/Snipaste_2025-06-03_21-46-51-1749470495094-1.png)\n\n## 安装ubuntu系统\n\n![image-20250306172718280](../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/ee3dfc4019e734c65139f7592b3d1047697559838-1743071004579-155-1746692007775-376-1747299497349-1-1747900721328-1-1749470495094-2.png)\n\n![image-20250306172858685](../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/f90c48f1768517a761ac0b29e7f1cbd4697559838-1743071004579-156-1746692007776-377-1747299497349-2-1747900721328-2-1749470495094-3.png)\n\n![image-20250306172955435](../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/2ffdc69cf1e6c8963b9d74ebf13149f8697559838-1743071004579-157-1746692007776-378-1747299497349-3-1747900721328-4-1749470495095-4.png)\n\n一路确定就行了\n\n![image-20250306173133874](../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/b9783bd5efab7f47366d1971be6de07b697559838-1743071004579-158-1746692007776-379-1747299497349-4-1747900721328-3-1749470495095-5.png)\n\n设置dhcp模式否则无法联网安装\n\n#dhcp服务\n\n![image-20250306181204335](../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/dfd278fb04265d5ea96ea487ce74d285697559838-1743071004579-159-1746692007776-380-1747299497349-5-1747900721328-5-1749470495095-6.png)\n\n然后开机，然后选择==中文==,然后按提示安装\n\n![image-20250306173400725](../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/1f98e04ec2b7adf765c360075093adc1697559838-1743071004579-160-1746692007776-381-1747299497349-6-1747900721328-6-1749470495095-8.png)\n\n![image-20250306173436631](../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/831b0baf3cb357789b20cbcee155f03b697559838-1743071004579-161-1746692007776-382-1747299497349-7-1747900721328-7-1749470495095-7.png)\n\n然后就开始安装就行了,到后面重启之后，可能会遇到这个界面\n\n![image-20250308211726292](../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/a1b540626e2a073bffee678729200d3c697559838-1743071004579-162-1746692007776-383-1747299497349-8-1747900721328-8-1749470495095-9.png)\n\n解决办法\n\n![image-20250308211858778](../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/001e630863c1f4c32a7f77e9f76eb2a1697559838-1743071004580-163-1746692007776-384-1747299497349-9-1747900721328-9-1749470495095-10.png)\n\n然后你再开机就行了\n\n切换阿里云镜像源\n\n![image-20250306182430499](../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/07352662ff84d9dc914cdd6e0a2a749d697559838-1743071004580-164-1746692007776-385-1747299497349-11-1747900721328-10-1749470495095-12.png)\n\n![image-20250306212359634](../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/dd8381e4110babef193c865e99493d03697559838-1743071004580-165-1746692007776-386-1747299497349-10-1747900721328-11-1749470495095-11.png)\n\n等待更新缓存\n\n\n\n到桌面后右键桌面空白处打开终端进行输入下面指令\n\n`一键安装vm-tools可以实现跨端复制粘贴`\n\n```bash\nsudo apt-get install -y wget\nsudo wget https://resource.qianyios.top/init.sh\nsudo chmod +x init.sh\nbash init.sh \n```\n\n接下来重启等待软件生效之后，你就`关机`，这时候你要`打个快照`，以便后面做项目出错可以恢复，然后开机\n\n![image-20250306174127049](../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/c91e76a873ad6af429f3fdc1edae8237697559838-1743071004580-166-1746692007776-387-1747299497349-12-1747900721328-12-1749470495095-13.png)\n\n\n\n## 创建hadoop用户\n\n创建hadoop用户并且设置密码\n\n```\nsudo useradd -m hadoop -s /bin/bash\nsudo passwd hadoop\n```\n\n![image-20250306180546505](../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/8aa05cb5a1b5dc9bf6af23d990b507ca697559838-1743071004580-167-1746692007776-388-1747299497349-13-1747900721328-13-1749470495095-14.png)\n\n给hadoop用户添加sudo权限\n\n```\nsudo adduser hadoop sudo\n```\n\n![image-20250306180700866](../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/51d052125ddfbbe9a9005e2a7e8e5dcf697559838-1743071004580-168-1746692007776-389-1747299497349-17-1747900721328-14-1749470495095-18.png)\n\n这时候桌面右上角注销账号切换成hadoop\n\n![image-20250306182143578](../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/387107b5560e971a6f550b631041a66d697559838-1743071004580-169-1746692007776-390-1747299497349-15-1747900721328-15-1749470495095-15.png)\n\n## 设置ssh免密\n\n一键全部复制，然后粘贴回车就会自动进行免密\n\n> 代码中有password=\"123456\",记得改成你的hadoop用户的密码\n\n```bash\nsudo cat >ssh.sh<<\"EOF\"\n#!/bin/bash\nsudo apt-get install openssh-server -y\nsudo systemctl disable ufw --now\n# 确保 PasswordAuthentication 设置为 yes\necho \"正在更新 SSH 配置...\"\nsudo sed -i 's/^#*PasswordAuthentication.*/PasswordAuthentication yes/' /etc/ssh/sshd_config\nsudo systemctl restart ssh\n\n# 安装 sshpass\necho \"正在安装 sshpass...\"\nsudo apt update\nsudo apt install -y sshpass || { echo \"安装 sshpass 失败\"; exit 1; }\necho \"sshpass 安装完成。\"\n\n# 创建 .ssh 目录并设置权限\necho \"正在检查 .ssh 目录...\"\nif [ ! -d ~/.ssh ]; then\n    sudo mkdir -p ~/.ssh\nfi\nsudo chmod 700 ~/.ssh\nsudo chown -R hadoop:hadoop ~/.ssh\n\n# 目标主机列表\nhosts=(\"localhost\")\n# 密码\npassword=\"123456\"\n\n# 生成 SSH 密钥对\necho \"正在生成 SSH 密钥对...\"\nif [ ! -f ~/.ssh/id_rsa ]; then\n    ssh-keygen -t rsa -N \"\" -f ~/.ssh/id_rsa || { echo \"生成 SSH 密钥对失败\"; exit 1; }\nfi\nchmod 600 ~/.ssh/id_rsa\nchmod 644 ~/.ssh/id_rsa.pub\necho \"SSH 密钥对已生成。\"\n\n# 循环遍历目标主机\nfor host in \"${hosts[@]}\"\ndo\n    echo \"正在为 $host 配置免密登录...\"\n    \n    # 确保目标主机的 .ssh 目录存在\n    sshpass -p \"$password\" ssh -o StrictHostKeyChecking=no \"$host\" \"mkdir -p ~/.ssh && chmod 700 ~/.ssh\"\n    \n    # 将公钥复制到目标主机\n    sshpass -p \"$password\" ssh-copy-id -i ~/.ssh/id_rsa.pub -o StrictHostKeyChecking=no \"$host\" || { echo \"复制公钥到 $host 失败\"; exit 1; }\n    \n    # 验证免密登录是否成功\n    sshpass -p \"$password\" ssh -o StrictHostKeyChecking=no \"$host\" \"echo '免密登录成功'\" || { echo \"验证免密登录失败\"; exit 1; }\ndone\n\necho \"所有配置已完成。\"\nEOF\n\n```\n\n运行脚本\n\n```\nbash ssh.sh\n```\n\n测试登入localhost是否可以实现无密码登入\n\n```\nssh localhost\n```\n\n![image-20250306185319755](../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/f6a283afd9c710caa08e8d0647868159697559838-1743071004580-170-1746692007776-391-1747299497349-14-1747900721328-16-1749470495095-16.png)\n\n成功\n\n## 安装java和hadoop\n\n将两个文件复制到下载的目录去\n\n![image-20250306190055853](../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/bf8992440f0c82cf90da81b76c08e388697559838-1743071004580-171-1746692007776-392-1747299497349-16-1747900721328-17-1749470495095-17.png)\n\n然后在这个文件夹下，空白处右键，打开终端\n\n![image-20250306190200797](../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/0efdb8f2156ff61db6acdd5f3d8bc9af697559838-1743071004580-172-1746692007776-393-1747299497349-18-1747900721328-18-1749470495095-19.png)\n\n```\n确认一下当前文件夹是不是有这两个文件\n```\n\n```\nls\n```\n\n![image-20250306190237227](../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/91661da6fad3b2b9fcc742360031d354697559838-1743071004580-173-1746692007776-394-1747299497349-19-1747900721328-20-1749470495095-20.png)\n\n以下的全部复制运行\n\n```bash\nsudo mkdir /usr/lib/jvm\n#安装java8\nsudo tar -xf jdk-8u162-linux-x64.tar.gz  -C /usr/lib/jvm\necho \"export JAVA_HOME=/usr/lib/jvm/jdk1.8.0_162\" >> ~/.bashrc\necho \"export PATH=\\$JAVA_HOME/bin:\\$PATH\" >> ~/.bashrc\nsource ~/.bashrc\njava -version\n\n#安装hadoop-3.1.3\nsudo tar -zxf hadoop-3.1.3.tar.gz -C /usr/local\nsudo mv /usr/local/hadoop-3.1.3/ /usr/local/hadoop\necho \"export HADOOP_HOME=/usr/local/hadoop\" >> ~/.bashrc\necho \"export PATH=\\$HADOOP_HOME/bin/:\\$HADOOP_HOME/sbin/:\\$PATH\" >> ~/.bashrc\nsource ~/.bashrc\nsudo chown -R hadoop /usr/local/hadoop\nhadoop version\n```\n\n> 这里是作业要截图的地方\n\n![image-20250306191054386](../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/a160c95403711706a1f827c8e4b2c908697559838-1743071004580-174-1746692007776-395-1747299497350-20-1747900721328-19-1749470495095-22.png)\n\n![image-20250306191150354](../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/1af756c5bb618a59a99925f484d38ba1697559838-1743071004580-175-1746692007776-396-1747299497350-22-1747900721328-21-1749470495095-21.png)\n\n这时候关机打个`快照`，命名为基础\n\n## 伪分布安装\n\n### 编写cort-site.yaml文件\n\n以下的全部复制运行\n\n```\ncat > /usr/local/hadoop/etc/hadoop/core-site.xml<< \"EOF\"\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<?xml-stylesheet type=\"text/xsl\" href=\"configuration.xsl\"?>\n<configuration>\n    <property>\n        <name>hadoop.tmp.dir</name>\n        <value>file:/usr/local/hadoop/tmp</value>\n        <description>Abase for other temporary directories.</description>\n    </property>\n    <property>\n        <name>fs.defaultFS</name>\n        <value>hdfs://localhost:9000</value>\n    </property>\n</configuration>\nEOF\n```\n\n### 编写hdfs-site.xml\n\n以下的全部复制运行\n\n```\ncat >/usr/local/hadoop/etc/hadoop/hdfs-site.xml<<\"EOF\"\n<configuration>\n    <property>\n        <name>dfs.replication</name>\n        <value>1</value>\n    </property>\n    <property>\n        <name>dfs.namenode.name.dir</name>\n        <value>file:/usr/local/hadoop/tmp/dfs/name</value>\n    </property>\n    <property>\n        <name>dfs.datanode.data.dir</name>\n        <value>file:/usr/local/hadoop/tmp/dfs/data</value>\n    </property>\n</configuration>\nEOF\n\n```\n\n### 启动hhdfs服务\n\n`hdfs初始化`\n\n`这条命令只需要运行一次，以后都不要再运行了！！！！！！`\n\n`这条命令只需要运行一次，以后都不要再运行了！！！！！！`\n\n`这条命令只需要运行一次，以后都不要再运行了！！！！！！`\n\n```\nhdfs namenode -format\n```\n\n![image-20250306191818068](../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/00af8b3b067332eed696bb3557ba8acf697559838-1743071004580-176-1746692007776-397-1747299497350-21-1747900721328-22-1749470495095-23.png)\n\n出现这个说明初始化成功\n\n### 添加hdfs yarn的环境变量\n\n以下的全部复制运行\n\n```bash\necho \"export HDFS_NAMENODE_USER=hadoop\" >> ~/.bashrc\necho \"export HDFS_DATANODE_USER=hadoop\" >> ~/.bashrc\necho \"export HDFS_SECONDARYNAMENODE_USER=hadoop\" >> ~/.bashrc\necho \"export YARN_RESOURCEMANAGER_USER=hadoop\" >> ~/.bashrc\necho \"export YARN_NODEMANAGER_USER=hadoop\" >> ~/.bashrc\nsource ~/.bashrc\necho \"export JAVA_HOME=/usr/lib/jvm/jdk1.8.0_162\" >> /usr/local/hadoop/etc/hadoop/hadoop-env.sh\n```\n\n```bash\n#开启hadoop的命令\nstart-all.sh\n#当你要关机的时候先运行下面的命令关掉hadoop先，再关机\nstop-all.sh\n```\n\n> 这里是作业要截图的地方\n\n![image-20250306192423176](../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/6598318c96d7150998b697814614cbe5697559838-1743071004580-177-1746692007776-398-1747299497350-23-1747900721328-23-1749470495095-24.png)\n\njps命令用来查看进程是否启动，以上是hadoop正常启动的进程，总共有6个\n\n### 访问hadoop网页\n\n看看你的ip\n\n```\nip a\n```\n\n![image-20250306192632197](../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/5bdaab2f886644715fb131d56b9cc239697559838-1743071004580-178-1746692007776-399-1747299497350-24-1747900721328-24-1749470495095-25.png)\n\n如果你这里没有ip说明你没有开启dhcp服务，自行回到最开始，找开启dhcp的方法，关机开启dhcp，然后开机就会有ip了\n\n> 这里是作业要截图的地方\n\nhttp://ip:9870\n\n```\nhttp://192.168.48.132:9870/\n```\n\n![image-20250306192915923](../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/4dfc296f2ec13a6dfafc20a8f5891d1d697559838-1743071004580-179-1746692007776-400-1747299497350-25-1747900721328-25-1749470495095-27.png)\n\nhttp://ip:8088\n\n![image-20250306193032219](../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/19c347205dca343973b7ee126ce96a6b697559838-1743071004580-180-1746692007777-401-1747299497350-26-1747900721328-26-1749470495095-26.png)\n\n### 关机步骤\n\n这时候关闭hadoop集群\n\n```\nstop-all.sh\n```\n\n然后关机打快照，命名伪分布\n\n```\nsudo poweroff\n```\n\n然后在这里打个快照，命名为伪分布安装成功，等你哪天机子坏了，你就可以恢复快照\n\n![image-20250318173513618](../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/2da7a916c9744aa69041f71f45d21ddc697559838-1743071004580-181-1746692007777-402-1747299497350-27-1747900721328-27-1749470495095-28.png)\n\n> 严肃告知，别说我没提醒你，不要直接关机，也不要挂起虚拟机，否则你的虚拟机和hadoop坏了，你就重装吧\n>\n> ![image-20250318173348088](../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/7327d43e46ac634be9f37da89e6d4241697559838-1743071004580-182-1746692007777-403-1747299497350-28-1747900721328-28-1749470495095-29.png)\n\n## 第一次实验\n\n### 熟悉常用的Linux操作\n\n1）cd命令：切换目录\n\n（1） 切换到目录“/usr/local”\n\n```\ncd /usr/local\n```\n\n（2） 切换到当前目录的上一级目录\n\n```\ncd ..\n```\n\n（3） 切换到当前登录Linux系统的用户的自己的主文件夹\n\n```\ncd ~\n```\n\n![image-20250313143132503](../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/c7feb6b1c838be089bc0415e2fee14aa697559838-1743071004581-183-1746692007777-404-1747299497350-29-1747900721328-29-1749470495095-30.png)\n\n2）ls命令：查看文件与目录\n\n查看目录“/usr”下的所有文件和目录\n\n```\ncd /usr\nls -al\n```\n\n![image-20250313143140661](../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/207e580ee326e3c1ac36d020bb5f9107697559838-1743071004581-184-1746692007777-405-1747299497350-30-1747900721328-30-1749470495095-31.png)\n\n3）mkdir命令：新建目录\n\n（1）进入“/tmp”目录，创建一个名为“a”的目录，并查看“/tmp”目录下已经存在哪些目录\n\n```\ncd /tmp\nmkdir a\nls -al\n```\n\n![image-20250313143206832](../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/2c3bd5c36f9ab9cef9fd9d0757b816ca697559838-1743071004581-185-1746692007777-406-1747299497350-31-1747900721328-31-1749470495095-32.png)\n\n（2）进入“/tmp”目录，创建目录“a1/a2/a3/a4” \n\n```\ncd /tmp\nmkdir -p a1/a2/a3/a4\n```\n\n![image-20250313143217857](../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/620d448824dba651c9bd4949647ee72a697559838-1743071004581-186-1746692007777-407-1747299497350-32-1747900721328-32-1749470495095-33.png)\n\n4）rmdir命令：删除空的目录\n\n（1）将上面创建的目录a（在“/tmp”目录下面）删除\n\n（2）删除上面创建的目录“a1/a2/a3/a4” （在“/tmp”目录下面），然后查看“/tmp”目录下面存在哪些目录\n\n```\ncd /tmp\nrmdir a\ncd /tmp\nrmdir -p a1/a2/a3/a4\nls -al\n```\n\n![image-20250313150519301](../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/d02274363f08a488d8901ebe00e25cca697559838-1743071004581-187-1746692007777-408-1747299497350-33-1747900721328-34-1749470495095-34.png)\n\n5）cp命令：复制文件或目录\n\n（1）将当前用户的主文件夹下的文件.bashrc复制到目录“/usr”下，并重命名为bashrc1\n\n```\nsudo cp ~/.bashrc /usr/bashrc1\n```\n\n![image-20250313150547907](../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/97f3fb32f45eb9fc11150ca1cd003f07697559838-1743071004581-188-1746692007777-409-1747299497350-34-1747900721328-33-1749470495095-35.png)\n\n（2）在目录“/tmp”下新建目录test，再把这个目录复制到“/usr”目录下\n\n```\ncd /tmp\nmkdir test\nsudo cp -r /tmp/test /usr\n```\n\n![image-20250313150608722](../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/315577abf317204a01afe6ded7293d3c697559838-1743071004581-189-1746692007777-410-1747299497350-35-1747900721328-35-1749470495095-36.png)\n\n6）mv命令：移动文件与目录，或更名\n\n（1）将“/usr”目录下的文件bashrc1移动到“/usr/test”目录下\n\n```\nsudo mv /usr/bashrc1 /usr/test\n```\n\n（2）将“/usr”目录下的test目录重命名为test2\n\n```\nsudo mv /usr/test /usr/test2\n```\n\n![image-20250313150650543](../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/b8275a3ec6d53feebd7380e0248c75f0697559838-1743071004581-190-1746692007777-411-1747299497350-36-1747900721328-36-1749470495095-38.png)\n\n7）rm命令：移除文件或目录\n\n（1）将“/usr/test2”目录下的bashrc1文件删除\n\n```\nsudo rm /usr/test2/bashrc1\n```\n\n（2）将“/usr”目录下的test2目录删除\n\n```\nsudo rm -r /usr/test2\n```\n\n![image-20250313150701498](../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/b447cf3a45829d5e43aaf9a5a59ec0db697559838-1743071004581-191-1746692007777-412-1747299497350-37-1747900721328-37-1749470495095-37.png)\n\n8）cat命令：查看文件内容\n\n查看当前用户主文件夹下的.bashrc文件内容\n\n```\ncat ~/.bashrc\n```\n\n![image-20250313150717805](../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/a4d6640a8ea734665621d6d9e566704c697559838-1743071004581-192-1746692007777-413-1747299497350-38-1747900721328-38-1749470495095-40.png)\n\n9）tac命令：反向查看文件内容\n\n反向查看当前用户主文件夹下的.bashrc文件的内容\n\n```\ntac ~/.bashrc\n```\n\n![image-20250313150727016](../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/b6dc096b152e74428be417550aebca41697559838-1743071004581-193-1746692007777-414-1747299497350-39-1747900721329-39-1749470495095-39.png)\n\n10）more命令：一页一页翻动查看\n\n翻页查看当前用户主文件夹下的.bashrc文件的内容\n\n```\nmore ~/.bashrc\n```\n\n![image-20250313150745391](../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/2b4378e6085504a1a609dab7af2fc4a9697559838-1743071004581-194-1746692007777-415-1747299497350-41-1747900721329-40-1749470495095-41.png)\n\n11）head命令：取出前面几行\n\n（1）查看当前用户主文件夹下.bashrc文件内容前20行\n\n```\nhead -n 20 ~/.bashrc\n```\n\n（2）查看当前用户主文件夹下.bashrc文件内容，后面50行不显示，只显示前面几行\n\n```\nhead -n -50 ~/.bashrc\n```\n\n![image-20250313150813349](../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/b8ff8645a0dc3e3577aa7b11982f22c5697559838-1743071004581-195-1746692007777-416-1747299497350-42-1747900721329-41-1749470495095-42.png)\n\n12）tail命令：取出后面几行\n\n（1）查看当前用户主文件夹下.bashrc文件内容最后20行\n\n```\ntail -n 20 ~/.bashrc\n```\n\n（2）查看当前用户主文件夹下.bashrc文件内容，并且只列出50行以后的数据\n\n```\ntail -n +50 ~/.bashrc\n```\n\n![image-20250313150837188](../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/c641803b61a67b7b189d1e43dc559178697559838-1743071004581-196-1746692007777-417-1747299497350-40-1747900721329-42-1749470495095-45.png)\n\n13）touch命令：修改文件时间或创建新文件\n\n（1）在“/tmp”目录下创建一个空文件hello，并查看文件时间\n\n```\ncd /tmp\ntouch hello\nls -l hello\n```\n\n![image-20250313150847348](../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/fd031b0f26eb4125f30a4c76b01693fb697559838-1743071004581-197-1746692007777-418-1747299497350-43-1747900721329-43-1749470495095-43.png)\n\n（2）修改hello文件，将文件时间整为5天前\n\n```\ntouch -d \"5 days ago\" hello\n```\n\n![image-20250313150952003](../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/c894c82b4795e434fece04c38b09ecc1697559838-1743071004581-198-1746692007777-419-1747299497350-44-1747900721329-44-1749470495095-44.png)\n\n14）chown命令：修改文件所有者权限\n\n将hello文件所有者改为root帐号，并查看属性\n\n```\nsudo chown root /tmp/hello\nls -l /tmp/hello\n```\n\n![image-20250313151030899](../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/c200b410e0e05a4003ed9d47529f27f8697559838-1743071004581-199-1746692007777-420-1747299497350-47-1747900721329-46-1749470495095-46.png)\n\n15）find命令：文件查找\n\n找出主文件夹下文件名为.bashrc的文件\n\n```\n find ~ -name .bashrc\n```\n\n![image-20250313151052617](../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/243db7fb68b2a78a621793f52cf33633697559838-1743071004581-200-1746692007777-421-1747299497350-45-1747900721329-45-1749470495095-48.png)\n\n16）tar命令：压缩命令\n\n（1）在根目录“/”下新建文件夹test，然后在根目录“/”下打包成test.tar.gz\n\n```\nsudo mkdir /test\nsudo tar -zcv -f /test.tar.gz test\n```\n\n（2）把上面的test.tar.gz压缩包，解压缩到“/tmp”目录\n\n```\nsudo tar -zxv -f /test.tar.gz -C /tmp\n```\n\n![image-20250313151121057](../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/9a20e406ed55d0e2c113cba8d4e81b5f697559838-1743071004581-201-1746692007778-422-1747299497350-46-1747900721329-47-1749470495095-47.png)\n\n17）grep命令：查找字符串\n\n从“～/.bashrc”文件中查找字符串'examples'\n\n```\n grep -n 'examples' ~/.bashrc\n```\n\n![image-20250313151133044](../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/b4e5f49fa570987ddb3a1a6e32876c11697559838-1743071004581-202-1746692007778-423-1747299497350-48-1747900721329-48-1749470495095-49.png)\n\n18）配置环境变量\n\n（1）请在“～/.bashrc”中设置，配置Java环境变量\n\n```\necho \"export JAVA_HOME=/usr/lib/jvm/jdk1.8.0_162\" >> ~/.bashrc\necho \"export PATH=\\$JAVA_HOME/bin:\\$PATH\" >> ~/.bashrc\nsource ~/.bashrc\njava -version\n```\n\n（2）查看JAVA_HOME变量的值\n\n```\necho $JAVA_HOME\n```\n\n![image-20250313143109134](../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/deef51d65ab888223594404f2c673de1697559838-1743071004581-203-1746692007778-424-1747299497350-49-1747900721329-49-1749470495095-50.png)\n\n### 熟悉常用的Hadoop操作\n\n（1）使用hadoop用户登录Linux系统，启动Hadoop（Hadoop的安装目录为“/usr/local/hadoop”），为hadoop用户在HDFS中创建用户目录“/user/hadoop”\n\n```\nstart-dfs.sh\nhdfs dfs -mkdir -p /user/hadoop \n```\n\n![image-20250313151220243](../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/eb9da7727cc112475cfc9c45fb585741697559838-1743071004581-204-1746692007778-425-1747299497350-51-1747900721329-50-1749470495095-51.png)\n\n（2）接着在HDFS的目录“/user/hadoop”下，创建test文件夹，并查看文件列表\n\n```\nhdfs dfs -mkdir test\nhdfs dfs -ls .\n```\n\n![image-20250313151235040](../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/5b6ce4bdc15610c9f4039ef8f7dbfc91697559838-1743071004581-205-1746692007778-426-1747299497350-50-1747900721329-51-1749470495095-52.png)\n\n（3）将Linux系统本地的“～/.bashrc”文件上传到HDFS的test文件夹中，并查看test\n\n```\nhdfs dfs -put ~/.bashrc test\nhdfs dfs -ls test\n```\n\n![image-20250313151248871](../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/e501c2993fa20ae4dfefc77cbf50a513697559838-1743071004581-206-1746692007778-427-1747299497350-53-1747900721329-52-1749470495095-54.png)\n\n（4）将HDFS文件夹test复制到Linux系统本地文件系统的“/usr/local/hadoop”目录下\n\n```\nhdfs dfs -get test ./\n```\n\n![image-20250313151433060](../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/33754f23d00e296f81fd3c3eae2b70f1697559838-1743071004581-207-1746692007778-428-1747299497350-52-1747900721329-53-1749470495095-53.png)\n\n## （3.7.3）实验\n\n### 安装eclipse\n\n为了提高程序编写和调试效率，本教程采用Eclipse工具编写Java程序。\n现在要执行的任务是：假设在目录`hdfs://localhost:9000/user/hadoop`下面有几个文件，分别是file1.txt、file2.txt、file3.txt、file4.abc和file5.abc，这里需要从该目录中过滤出所有后缀名不为`.abc`的文件，对过滤之后的文件进行读取，并将这些文件的内容合并到文件`hdfs://localhost:9000/user/hadoop/merge.txt`中。\n\n要确保HDFS的`/user/hadoop`目录下已经存在file1.txt、file2.txt、file3.txt、file4.abc和file5.abc，每个文件里面有内容。这里，假设文件内容如下：\nfile1.txt的内容是： this is file1.txt\nfile2.txt的内容是： this is file2.txt\nfile3.txt的内容是： this is file3.txt\nfile4.abc的内容是： this is file4.abc\nfile5.abc的内容是： this is file5.abc\n\n> 后面我会给命令，上面的内容就先看看\n\n\n\n登入`hadoop用户`不多说了，启动hadoop集群\n\n```\nstart-all.sh\n```\n\n下载eclipse安装包到ubuntu的下载目录,然后在空白处右键打开终端\n\n![image-20250318155038350](../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/60c162a765d08e3803ca119480baef99697559838-1743071004582-208-1746692007778-429-1747299497350-54-1747900721329-54-1749470495095-55.png)\n\n```\nsudo ls\n```\n\n```bash\nsudo tar -zxvf eclipse-4.7.0-linux.gtk.x86_64.tar.gz -C /usr/local \nsudo chown -R hadoop /usr/local/eclipse\necho \"export ECLIPSE_HOME=/usr/local/eclipse\" >> ~/.bashrc\necho \"export PATH=\\$ECLIPSE_HOME/:\\$PATH\" >> ~/.bashrc\nsource ~/.bashrc\n```\n\n启动eclipse\n\n```\neclipse\n```\n\n### 在Eclipse中创建项目\n\n启动Eclipse。当Eclipse启动以后，会弹出如下图所示界面，提示设置工作空间（workspace）。\n\n![image-20250318160051796](../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/87b70fbcc1e51f170156e90437e1c0ec697559838-1743071004582-209-1746692007778-430-1747299497350-55-1747900721329-55-1749470495095-56.png)\n\n![image-20250318160340954](../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/065dc77c668bee8eb9fa31623a0bee83697559838-1743071004582-210-1746692007778-431-1747299497350-56-1747900721329-56-1749470495096-57.png)\n\n选择`File-->New-->Java Project`菜单，开始创建一个Java工程，会弹出如下图所示界面。在`Project name`后面输入工程名称`HDFSExample`，选中`Use default location`，让这个Java工程的所有文件都保存到`/home/hadoop/workspace/HDFSExample`目录下。在`JRE`这个选项卡中，可以选择当前的Linux系统中已经安装好的JDK，比如jdk1.8.0_162。然后，点击界面底部的`Next>`按钮，进入下一步的设置。\n\n![image-20250318160434807](../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/8c4984aa63dd56f996b36b84bc95eabf697559838-1743071004582-211-1746692007778-432-1747299497350-57-1747900721329-57-1749470495096-58.png)\n\n### 为项目添加需要用到的JAR包\n\n为了能够运行程序，我们有`四个目录`的`jar包`要添加到工程去\n\n> (1)`/usr/local/hadoop/share/hadoop/common`目录下的所有JAR包，包括\n>\n> `hadoop-common-3.1.3.jar`、`hadoop-kms-3.1.3.jar`\n> `hadoop-common-3.1.3-tests.jar`、`hadoop-nfs-3.1.3.jar`\n>\n> 注意，不包括目录jdiff、lib、sources和webapps；\n>\n> ---\n>\n> (2)`/usr/local/hadoop/share/hadoop/common/lib`目录下的所有JAR包；\n> (3)`/usr/local/hadoop/share/hadoop/hdfs`目录下的所有JAR包，注意，不包括目录jdiff、lib、sources和webapps；\n> (4)`/usr/local/hadoop/share/hadoop/hdfs/lib`目录下的所有JAR包。\n\n---\n\n`以下我只演示第一种和第二种!!!!!!!!!`\n\n`以下我只演示第一种和第二种!!!!!!!!!`\n\n``以下我只演示第一种和第二种!!!!!!!!!``\n\n`以下我只演示第一种和第二种!!!!!!!!!`\n\n---\n\n`第一种`\n\n`/usr/local/hadoop/share/hadoop/common`目录下的所有JAR包\n\n点击`Add External JARs…`按钮，点击其他位置，自己看这个路径定位到这`/usr/local/hadoop/share/hadoop/common`,选择下面的四个包，然后点击ok\n\n![image-20250318161304973](../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/2472a090934284d0ff7605267cb1e469697559838-1743071004582-212-1746692007778-433-1747299497350-58-1747900721329-58-1749470495096-59.png)\n\n\n\n`第二种`\n\n`/usr/local/hadoop/share/hadoop/common/lib`目录下的所有JAR包；\n\n![image-20250318170347078](../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/279304c9eac49aaeaeb836fec1d1b792697559838-1743071004582-213-1746692007778-434-1747299497350-59-1747900721329-59-1749470495096-60.png)\n\n\n\n> 以下两个目录，我就不演示了，如果有文件夹被全选中，你就按住ctrl然后点击文件夹，就可以取消选中了，我们只添加所有后缀名为`.jar`的包\n>\n> (3)`/usr/local/hadoop/share/hadoop/hdfs`目录下的所有JAR包，注意，不包括目录jdiff、lib、sources和webapps；\n> (4)`/usr/local/hadoop/share/hadoop/hdfs/lib`目录下的所有JAR包。\n\n\n\n最后是这样的\n\n![image-20250318170435251](../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/6d79a5d1e0a3158a375e0dced25a97bb697559838-1743071004582-214-1746692007778-435-1747299497350-60-1747900721329-60-1749470495096-61.png)\n\n![image-20250318161735778](../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/ea01a0f0daf799e542dd562b75bdbb9c697559838-1743071004582-215-1746692007778-436-1747299497350-61-1747900721329-61-1749470495096-62.png)\n\n### 编写Java应用程序\n\n![image-20250318162034984](../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/569602ed23795682d3d79612712be1d3697559838-1743071004582-216-1746692007778-437-1747299497350-62-1747900721329-62-1749470495096-63.png)\n\n在该界面中，只需要在`Name`后面输入新建的Java类文件的名称，这里采用称`MergeFile`，其他都可以采用默认设置，然后，点击界面右下角`Finish`按钮。\n\n![image-20250318162134278](../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/4168e9160a7c8a3163955e0234b253f1697559838-1743071004582-217-1746692007778-438-1747299497350-63-1747900721329-63-1749470495096-64.png)\n\n![image-20250318162458949](../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/0f62d55c83b9297b9ca10da5e0b8a411697559838-1743071004582-218-1746692007778-439-1747299497350-64-1747900721329-64-1749470495096-65.png)\n\n\n\n把下面的代码直接写到MergeFile.java,`全选复制粘贴`，这就不多说了，然后记得`Ctrl+S保存`\n\n```java\nimport java.io.IOException;\nimport java.io.PrintStream;\nimport java.net.URI;\nimport org.apache.hadoop.conf.Configuration;\nimport org.apache.hadoop.fs.*;\n/**\n * 过滤掉文件名满足特定条件的文件 \n */\nclass MyPathFilter implements PathFilter {\n     String reg = null; \n     MyPathFilter(String reg) {\n          this.reg = reg;\n     }\n     public boolean accept(Path path) {\n        if (!(path.toString().matches(reg)))\n            return true;\n        return false;\n    }\n}\n/***\n * 利用FSDataOutputStream和FSDataInputStream合并HDFS中的文件\n */\npublic class MergeFile {\n    Path inputPath = null; //待合并的文件所在的目录的路径\n    Path outputPath = null; //输出文件的路径\n    public MergeFile(String input, String output) {\n        this.inputPath = new Path(input);\n        this.outputPath = new Path(output);\n    }\n    public void doMerge() throws IOException {\n        Configuration conf = new Configuration();\n        conf.set(\"fs.defaultFS\",\"hdfs://localhost:9000\");\n          conf.set(\"fs.hdfs.impl\",\"org.apache.hadoop.hdfs.DistributedFileSystem\");\n        FileSystem fsSource = FileSystem.get(URI.create(inputPath.toString()), conf);\n        FileSystem fsDst = FileSystem.get(URI.create(outputPath.toString()), conf);\n                //下面过滤掉输入目录中后缀为.abc的文件\n        FileStatus[] sourceStatus = fsSource.listStatus(inputPath,\n                new MyPathFilter(\".*\\\\.abc\")); \n        FSDataOutputStream fsdos = fsDst.create(outputPath);\n        PrintStream ps = new PrintStream(System.out);\n        //下面分别读取过滤之后的每个文件的内容，并输出到同一个文件中\n        for (FileStatus sta : sourceStatus) {\n            //下面打印后缀不为.abc的文件的路径、文件大小\n            System.out.print(\"路径：\" + sta.getPath() + \"    文件大小：\" + sta.getLen()\n                    + \"   权限：\" + sta.getPermission() + \"   内容：\");\n            FSDataInputStream fsdis = fsSource.open(sta.getPath());\n            byte[] data = new byte[1024];\n            int read = -1;\n            while ((read = fsdis.read(data)) > 0) {\n                ps.write(data, 0, read);\n                fsdos.write(data, 0, read);\n            }\n            fsdis.close();\n        }\n        ps.close();\n        fsdos.close();\n    }\n    public static void main(String[] args) throws IOException {\n        MergeFile merge = new MergeFile(\n                \"hdfs://localhost:9000/user/hadoop/\",\n                \"hdfs://localhost:9000/user/hadoop/merge.txt\");\n        merge.doMerge();\n    }\n}\n```\n\n### 编译运行程序\n\n在这里`强调一下`，如果你没启动hadoop自行启动，我早已在7.1告知启动了\n\n编写测试文件\n\n```bash\necho \"this is file1.txt\" > file1.txt\necho \"this is file2.txt\" > file2.txt\necho \"this is file3.txt\" > file3.txt\necho \"this is file4.abc\" > file4.abc\necho \"this is file5.abc\" > file5.abc\nhdfs dfs -mkdir -p /user/hadoop\nhdfs dfs -put file1.txt /user/hadoop/\nhdfs dfs -put file2.txt /user/hadoop/\nhdfs dfs -put file3.txt /user/hadoop/\nhdfs dfs -put file4.abc /user/hadoop/\nhdfs dfs -put file5.abc /user/hadoop/\nhdfs dfs -ls /user/hadoop\n```\n\n![image-20250318163431895](../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/0acb5d22e3cf68f2eacbdb853adfe764697559838-1743071004582-219-1746692007778-440-1747299497350-65-1747900721329-65-1749470495096-67.png)\n\n![image-20250318163620255](../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/2cb7b57a21bf6cd3bab2afc16a205a93697559838-1743071004582-220-1746692007778-441-1747299497350-66-1747900721329-66-1749470495096-66.png)\n\n![image-20250318163921782](../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/1182eb47d5e3c245b7df9084abc2895e697559838-1743071004582-221-1746692007778-442-1747299497350-67-1747900721329-67-1749470495096-68.png)\n\n![image-20250318171657423](../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/e3d397b4d237e9a0dfec9cd2640d508d697559838-1743071004582-222-1746692007778-443-1747299497350-68-1747900721329-68-1749470495096-69.png)\n\n最后验证是否成功\n\n```\nhdfs dfs -cat /user/hadoop/merge.txt\n```\n\n![image-20250318171722425](../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/3e1303434798e633dcc66a8275b770ab697559838-1743071004582-223-1746692007778-444-1747299497350-69-1747900721329-69-1749470495096-70.png)\n\n### 应用程序的部署\n\n因为前面只是在eclipse运行java项目才会生成merge.txt，我们的目的是通过hadoop去执行这个java项目，所以我们要对工程打包\n\n#### 创建myapp目录\n\n目的：用来存放hadoop应用程序目录\n\n```\nmkdir /usr/local/hadoop/myapp\n```\n\n#### 开始打包程序\n\n![image-20250318172258928](../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/6d30b10a743fb22c9d0e7afd672e8659697559838-1743071004582-224-1746692007778-445-1747299497350-70-1747900721329-70-1749470495096-71.png)\n\n`Launch configuration`下拉选择`MergeFile-HDFSExample`\n\n`Export destination`填写 `/usr/local/hadoop/myapp/HDFSExample.jar`\n\n![image-20250318172440560](../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/129b3ca17345b0a0ecf4ab263615f4a0697559838-1743071004582-225-1746692007778-446-1747299497350-71-1747900721329-71-1749470495096-72.png)\n\n![image-20250318172512532](../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/3df4894053094c4a47afb06635f77dd8697559838-1743071004582-226-1746692007779-447-1747299497350-72-1747900721329-72-1749470495096-73.png)\n\n![image-20250318172626710](../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/0d99df2fda8b868a9e76ed3af1bd857b697559838-1743071004582-227-1746692007779-448-1747299497350-73-1747900721329-73-1749470495096-75.png)\n\n#### 查看是否生成\n\n```\nls /usr/local/hadoop/myapp\n```\n\n![image-20250318172709040](../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/1e58d1e9952a02b14a00561e3e864bce697559838-1743071004582-228-1746692007779-449-1747299497350-74-1747900721329-74-1749470495096-74.png)\n\n#### 重新验证项目的运行\n\n由于我们在eclipse测试过了项目，之前就在hdfs目录生成了`/user/hadoop/merge.txt`，为了验证刚刚打包的项目，我们要删掉这个`/user/hadoop/merge.txt`，等等重新运行项目\n\n```bash\nhdfs dfs -rm /user/hadoop/merge.txt\nhadoop jar /usr/local/hadoop/myapp/HDFSExample.jar\nhdfs dfs -cat /user/hadoop/merge.txt\n```\n\n![image-20250318173057716](../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/656a8305fac65693562adc40133628e3697559838-1743071004582-229-1746692007779-450-1747299497350-76-1747900721329-75-1749470495096-76.png)\n\n![image-20250318173128692](../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/4af0f6cf14aa25ff8f53493639441fda697559838-1743071004582-230-1746692007779-451-1747299497350-75-1747900721329-76-1749470495096-77.png)\n\n如果你没事了，要关机了就回到这里[5.6 关机步骤](#关机步骤),去执行关机\n\n顺便把`eclipse`的窗口关掉\n\n> 严肃告知，别说我没提醒你，不要直接关机，也不要挂起虚拟机，否则你的虚拟机和你的hadoop坏了，你就重装，如果你坏了你也可以恢复快照到`伪分布安装成功`，但是你只是要重新做这周的实验\n>\n> ![image-20250318173348088](../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/7327d43e46ac634be9f37da89e6d4241697559838-1743071004580-182-1746692007777-403-1747299497350-28-1747900721328-28-1749470495095-29.png)\n\n### 练习文件\n\n写入文件\n\n```\n        import org.apache.hadoop.conf.Configuration;  \n        import org.apache.hadoop.fs.FileSystem;\n        import org.apache.hadoop.fs.FSDataOutputStream;\n        import org.apache.hadoop.fs.Path;\n \n        public class write {    \n                public static void main(String[] args) { \n                        try {\n                                Configuration conf = new Configuration();  \n                                conf.set(\"fs.defaultFS\",\"hdfs://localhost:9000\");\n                                conf.set(\"fs.hdfs.impl\",\"org.apache.hadoop.hdfs.DistributedFileSystem\");\n                                FileSystem fs = FileSystem.get(conf);\n                                byte[] buff = \"Hello world\".getBytes(); // 要写入的内容\n                                String filename = \"gcc-test\"; //要写入的文件名\n                                FSDataOutputStream os = fs.create(new Path(filename));\n                                os.write(buff,0,buff.length);\n                                System.out.println(\"Create:\"+ filename);\n                                os.close();\n                                fs.close();\n                        } catch (Exception e) {  \n                                e.printStackTrace();  \n                        }  \n                }  \n        }\n```\n\n![image-20250327152823953](../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/f81d8f19db69bf635b50027d05f3589a697559838-1743071004582-231-1746692007779-452-1747299497350-77-1747900721329-77-1749470495096-78.png)\n\n```\nhdfs dfs -ls /user/hadoop\nhdfs dfs -cat /user/hadoop/gcc-test\n```\n\n![image-20250327153115107](../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/f70dd011c699b1830f5b92f1229327a0697559838-1746692007779-453-1747299497350-78-1747900721329-78-1749470495096-79.png)\n\n判断文件是否存在\n\n```\n        import org.apache.hadoop.conf.Configuration;\n        import org.apache.hadoop.fs.FileSystem;\n        import org.apache.hadoop.fs.Path;\n \n        public class panduan {\n                public static void main(String[] args) {\n                            try {\n                                    String filename = \"gcc-test\";\n \n                                    Configuration conf = new Configuration();\n                                    conf.set(\"fs.defaultFS\",\"hdfs://localhost:9000\");\n                                    conf.set(\"fs.hdfs.impl\",\"org.apache.hadoop.hdfs.DistributedFileSystem\");\n                                    FileSystem fs = FileSystem.get(conf);\n                                    if(fs.exists(new Path(filename))){\n                                            System.out.println(\"文件存在\");\n                                    }else{\n                                            System.out.println(\"文件不存在\");\n                                    }\n                                    fs.close();\n                        } catch (Exception e) {\n                                e.printStackTrace();\n                        }\n                }\n        } \n```\n\n![image-20250327153328234](../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/8d1bc9f2d385b1e188e920816c1bb7f3697559838-1746692007779-454-1747299497350-79-1747900721329-79-1749470495096-80.png)\n\n\n\n读取文件\n\n```\n        import java.io.BufferedReader;\n        import java.io.InputStreamReader;\n \n        import org.apache.hadoop.conf.Configuration;\n        import org.apache.hadoop.fs.FileSystem;\n        import org.apache.hadoop.fs.Path;\n        import org.apache.hadoop.fs.FSDataInputStream;\n \n        public class read {\n                public static void main(String[] args) {\n                        try {\n                                Configuration conf = new Configuration();\n                                conf.set(\"fs.defaultFS\",\"hdfs://localhost:9000\");\n                                conf.set(\"fs.hdfs.impl\",\"org.apache.hadoop.hdfs.DistributedFileSystem\");\n                                FileSystem fs = FileSystem.get(conf);\n                                Path file = new Path(\"gcc-test\"); \n                                FSDataInputStream getIt = fs.open(file);\n                                BufferedReader d = new BufferedReader(new InputStreamReader(getIt));\n                                String content = d.readLine(); //读取文件一行\n                                System.out.println(content);\n                                d.close(); //关闭文件\n                                fs.close(); //关闭hdfs\n                        } catch (Exception e) {\n                                e.printStackTrace();\n                        }\n                }\n        }\n```\n\n![image-20250327153426275](../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/30c4144922fa2e7c0d12ecce042a9174697559838-1746692007779-455-1747299497350-80-1747900721329-80-1749470495096-81.png)\n\n## 第二次实验\n\n编程实现以下指定功能，并利用Hadoop提供的Shell命令完成相同的任务。\n\n`① 向HDFS中上传任意文本文件，如果指定的文件在HDFS中已经存在，由用户指定是追加到原有文件末尾还是覆盖原有的文件。`\n\n==shell==\n\n检查文件是否存在，可以使用如下命令:  \n\n```bash\necho \"gcc-text\" > /home/hadoop/text.txt\nhdfs dfs -put /home/hadoop/text.txt /user/hadoop/text.txt\nhdfs dfs -test -e text.txt\necho $?\n```\n\n![image-20250327163611055](../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/732a232a618c74f52551daf4d3d15857697559838-1746692007779-456-1747299497350-81-1747900721329-81-1749470495096-82.png)\n\n返回 `0` 表示文件存在。\n\n返回 `1` 表示文件不存在。\n\n 如果结果显示文件已经存在，则用户可以选择追加到原来文件末尾或者覆盖原来文件，具体命令如下：\n\n```bash\necho \"gcc-local\" > /home/hadoop/local.txt\n```\n\n**`local.txt`** 是本地文件的路径。\n\n**`/text.txt`** 是 HDFS 中的文件路径。\n\n```bash\n#追加到原文件末尾\nhdfs dfs -appendToFile local.txt text.txt\nhdfs dfs -cat text.txt\n#覆盖原来文件，第一种命令形式\nhdfs dfs -copyFromLocal -f  local.txt text.txt\nhdfs dfs -cat text.txt\n#覆盖原来文件，第二种命令形式\nhdfs dfs -cp -f  file:///home/hadoop/local.txt text.txt\nhdfs dfs -cat text.txt\n```\n\n![image-20250327163724735](../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/206dd11b8882e95f80f28b4e5b01e072697559838-1746692007779-457-1747299497350-82-1747900721329-82-1749470495096-83.png)\n\n![image-20250327163755158](../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/bd4b3da872ab219749c41ad650c87c4c697559838-1746692007779-458-1747299497350-83-1747900721329-83-1749470495096-84.png)\n\n![image-20250327163824318](../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/abb97e6170286bca4dc7942d1e5327b1697559838-1746692007779-459-1747299497350-84-1747900721329-84-1749470495096-85.png)\n\n 实际上，也可以不用上述方式，而是采用**如下命令**来实现：\n\n```bash\nhdfs dfs -rm text.txt\nhdfs dfs -put text.txt \nhdfs dfs -cat text.txt\nif $(hdfs dfs -test -e text.txt);\nthen $(hdfs dfs -appendToFile local.txt text.txt);\nelse $(hdfs dfs -copyFromLocal -f local.txt text.txt);\nfi\nhdfs dfs -cat text.txt\n```\n\n![image-20250327163953466](../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/967e82c7f298e509d654c5a019137183697559838-1746692007779-460-1747299497350-86-1747900721329-85-1749470495096-87.png)\n\n==Java==\n\n> `我这里只说一次，自己创建好HDFSApi.java后面的每个实验，都会覆盖前面一个实验的代码`\n>\n> `你就不要手欠，去创建别的，你要是自己会也行`\n>\n> `后面就不会再说了`\n>\n> ![image-20250327173112868](../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/b526634908c47bc47e94463cb3eaf0fa697559838-1746692007779-461-1747299497350-85-1747900721329-86-1749470495096-86.png)\n\n\n\n```java\nimport  org.apache.hadoop.conf.Configuration;\nimport  org.apache.hadoop.fs.*;\nimport java.io.*;\npublic class HDFSApi {\n    /**\n     * 判断路径是否存在\n     */\n    public static boolean test(Configuration  conf, String path) throws IOException {\n        FileSystem fs = FileSystem.get(conf);\n        return fs.exists(new Path(path));\n    }\n    /**\n     * 复制文件到指定路径\n     * 若路径已存在，则进行覆盖\n     */\n    public static void  copyFromLocalFile(Configuration conf, String localFilePath, String  remoteFilePath) throws IOException {\n        FileSystem fs = FileSystem.get(conf);\n        Path localPath = new  Path(localFilePath);\n        Path remotePath = new  Path(remoteFilePath);\n        /* fs.copyFromLocalFile 第一个参数表示是否删除源文件，第二个参数表示是否覆盖 */\n        fs.copyFromLocalFile(false, true,  localPath, remotePath);\n        fs.close();\n    }\n    /**\n     * 追加文件内容\n     */\n    public static void  appendToFile(Configuration conf, String localFilePath, String remoteFilePath)  throws IOException {\n        FileSystem fs = FileSystem.get(conf);\n        Path remotePath = new  Path(remoteFilePath);\n        /* 创建一个文件读入流 */\n        FileInputStream in = new  FileInputStream(localFilePath);\n        /* 创建一个文件输出流，输出的内容将追加到文件末尾 */\n        FSDataOutputStream out =  fs.append(remotePath);\n        /* 读写文件内容 */\n        byte[] data = new byte[1024];\n        int read = -1;\n        while ( (read = in.read(data)) > 0  ) {\n            out.write(data,  0, read);\n        }\n        out.close();\n        in.close();\n        fs.close();\n    }\n    /**\n     * 主函数\n     */\n    public static void main(String[] args)  {\n        Configuration conf = new  Configuration();\n        conf.set(\"fs.default.name\",\"hdfs://localhost:9000\");\n        String localFilePath =  \"/home/hadoop/text.txt\";     // 本地路径\n        String remoteFilePath =  \"/user/hadoop/text.txt\";     // HDFS路径\n        String choice =  \"append\";    // 若文件存在则追加到文件末尾\n//            String choice =  \"overwrite\";    // 若文件存在则覆盖\n        try {\n            /* 判断文件是否存在 */\n            Boolean fileExists =  false;\n            if (HDFSApi.test(conf,  remoteFilePath)) {\n                fileExists = true;\n                System.out.println(remoteFilePath  + \" 已存在.\");\n            } else {\n                System.out.println(remoteFilePath  + \" 不存在.\");\n            }\n            /* 进行处理 */\n            if ( !fileExists) { // 文件不存在，则上传\n                HDFSApi.copyFromLocalFile(conf,  localFilePath, remoteFilePath);\n                System.out.println(localFilePath  + \" 已上传至 \" + remoteFilePath);\n            } else if (  choice.equals(\"overwrite\") ) {     // 选择覆盖\n                HDFSApi.copyFromLocalFile(conf,  localFilePath, remoteFilePath);\n                System.out.println(localFilePath  + \" 已覆盖 \" + remoteFilePath);\n            } else if (  choice.equals(\"append\") ) {    // 选择追加\n                HDFSApi.appendToFile(conf,  localFilePath, remoteFilePath);\n                System.out.println(localFilePath  + \" 已追加至 \" + remoteFilePath);\n            }\n        } catch (Exception e) {\n            e.printStackTrace();\n        }\n    }\n}\n```\n\n![image-20250327160802735](../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/31ec101590ca24d894bca6f0f11f6d42697559838-1746692007779-462-1747299497350-87-1747900721329-88-1749470495096-88.png)\n\n验证\n\n```\nhdfs dfs -cat text.txt\n```\n\n![image-20250327173741220](../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/9574b088a46b592d385e083bc26be07e697559838-1746692007779-463-1747299497350-88-1747900721329-87-1749470495096-89.png)\n\n\n\n\n\n`② 从HDFS中下载指定文件，如果本地文件与要下载的文件名称相同，则自动对下载的文件重命名。`\n\n==shell==\n\n```bash\nls | grep text\nif $(hdfs dfs -test -e  file:///home/hadoop/text.txt);\nthen $(hdfs dfs -copyToLocal text.txt ./text2.txt); \nelse $(hdfs dfs -copyToLocal text.txt ./text.txt); \nfi\nls | grep text\n```\n\n![image-20250327161545345](../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/eade1ac0f8ce42ebc36ce74160f7f708697559838-1746692007779-464-1747299497350-89-1747900721329-89-1749470495096-91.png)\n\n==Java==\n\n```java\nimport  org.apache.hadoop.conf.Configuration;\nimport  org.apache.hadoop.fs.*;\nimport java.io.*;\npublic class HDFSApi {\n    /**\n     * 下载文件到本地\n     * 判断本地路径是否已存在，若已存在，则自动进行重命名\n     */\n    public static void  copyToLocal(Configuration conf, String remoteFilePath, String localFilePath)  throws IOException {\n        FileSystem fs = FileSystem.get(conf);\n        Path remotePath = new  Path(remoteFilePath);\n        File f = new File(localFilePath);\n        /* 如果文件名存在，自动重命名(在文件名后面加上 _0, _1  ...) */\n        if (f.exists()) {\n               System.out.println(localFilePath  + \" 已存在.\");\n               Integer  i = 0;\n               while  (true) {\n                      f  = new File(localFilePath + \"_\" + i.toString());\n                      if  (!f.exists()) {\n                             localFilePath  = localFilePath + \"_\" + i.toString();\n                             break;\n                      }\n               }\n               System.out.println(\"将重新命名为: \" +  localFilePath);\n        }\n        // 下载文件到本地\n       Path localPath = new  Path(localFilePath);\n       fs.copyToLocalFile(remotePath,  localPath);\n       fs.close();\n    }\n       /**\n        * 主函数\n        */\n       public static void main(String[] args)  {\n              Configuration conf = new  Configuration();\n    conf.set(\"fs.default.name\",\"hdfs://localhost:9000\");\n              String localFilePath =  \"/home/hadoop/text.txt\";     // 本地路径\n              String remoteFilePath =  \"/user/hadoop/text.txt\";     // HDFS路径\n              try {\n                     HDFSApi.copyToLocal(conf,  remoteFilePath, localFilePath);\n                     System.out.println(\"下载完成\");\n              } catch (Exception e) {\n                     e.printStackTrace();\n              }\n       }\n}\n\n```\n\n![image-20250327173448075](../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/d0d2c5b5dd466df087017b7f20645a78697559838-1746692007779-465-1747299497350-90-1747900721329-90-1749470495096-92.png)\n\n验证：\n\n```bash\nls | grep text\n```\n\n![image-20250327162206125](../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/5fe0e7c436df931dbaac91c05446504c697559838-1746692007779-466-1747299497351-91-1747900721329-91-1749470495096-90.png)\n\n`③ 将HDFS中指定文件的内容输出到终端。`\n\n==shell==\n\n```bash\nhdfs dfs -cat text.txt\n```\n\n![image-20250327173824043](../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/73e2b739dcc8316d62aa83730edf0503697559838-1746692007779-467-1747299497351-92-1747900721329-92-1749470495096-93.png)\n\n==Java==\n\n```java\nimport  org.apache.hadoop.conf.Configuration;\nimport  org.apache.hadoop.fs.*;\nimport java.io.*;\npublic class HDFSApi {\n    /**\n     * 读取文件内容\n     */\n    public static void cat(Configuration  conf, String remoteFilePath) throws IOException {\n        FileSystem fs = FileSystem.get(conf);\n        Path remotePath = new  Path(remoteFilePath);\n        FSDataInputStream in =  fs.open(remotePath);\n        BufferedReader d = new  BufferedReader(new InputStreamReader(in));\n        String line = null;\n        while ( (line = d.readLine()) != null  ) {\n              System.out.println(line);\n        }\n       d.close();\n       in.close();\n       fs.close();\n    }\n       /**\n        * 主函数\n        */\n       public static void main(String[] args)  {\n              Configuration conf = new  Configuration();\n    conf.set(\"fs.default.name\",\"hdfs://localhost:9000\");\n              String remoteFilePath =  \"/user/hadoop/text.txt\";     // HDFS路径 \n              try {\n                     System.out.println(\"读取文件: \" +  remoteFilePath);\n                     HDFSApi.cat(conf,  remoteFilePath);\n                     System.out.println(\"\\n读取完成\");\n              } catch (Exception e) {\n                     e.printStackTrace();\n              }\n       }\n}\n\n```\n\n![image-20250327173919281](../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/ff9dc32429797c7ca63268995b6f23d9697559838-1746692007779-468-1747299497351-93-1747900721329-93-1749470495096-94.png)\n\n④ 显示HDFS中指定的文件读写权限、大小、创建时间、路径等信息。\n\n==shell==\n\n```\nhdfs dfs -ls -h text.txt\n```\n\n![image-20250327174107993](../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/378b994b1f5bc5db0e9634c4de77d316697559838-1746692007779-469-1747299497351-94-1747900721329-94-1749470495096-95.png)\n\n==Java==\n\n```java\nimport  org.apache.hadoop.conf.Configuration;\nimport  org.apache.hadoop.fs.*;\nimport java.io.*;\nimport  java.text.SimpleDateFormat;\npublic class HDFSApi {\n    /**\n     * 显示指定文件的信息\n     */\n    public static void ls(Configuration conf,  String remoteFilePath) throws IOException {\n        FileSystem fs = FileSystem.get(conf);\n        Path remotePath = new  Path(remoteFilePath);\n        FileStatus[] fileStatuses =  fs.listStatus(remotePath);\n        for (FileStatus s : fileStatuses) {\n               System.out.println(\"路径: \" +  s.getPath().toString());\n               System.out.println(\"权限: \" +  s.getPermission().toString());\n               System.out.println(\"大小: \" +  s.getLen());\n               /*  返回的是时间戳,转化为时间日期格式 */\n               Long  timeStamp = s.getModificationTime();\n               SimpleDateFormat  format =  new  SimpleDateFormat(\"yyyy-MM-dd HH:mm:ss\");\n               String  date = format.format(timeStamp);  \n               System.out.println(\"时间: \" +  date);\n        }\n        fs.close();\n    }\n       /**\n        * 主函数\n        */\n       public static void main(String[] args)  {\n              Configuration conf = new  Configuration();\n    conf.set(\"fs.default.name\",\"hdfs://localhost:9000\");\n              String remoteFilePath =  \"/user/hadoop/text.txt\";     // HDFS路径\n              try {\n                     System.out.println(\"读取文件信息: \" +  remoteFilePath);\n                     HDFSApi.ls(conf,  remoteFilePath);\n                     System.out.println(\"\\n读取完成\");\n              } catch (Exception e) {\n                     e.printStackTrace();\n              }\n       }\n}\n\n```\n\n![image-20250327174122828](../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/6e738a4c04440e31fd73f64e1e292fb4697559838-1746692007779-470-1747299497351-95-1747900721329-95-1749470495096-96.png)\n\n⑤ 给定HDFS中某一个目录，输出该目录下的所有文件的读写权限、大小、创建时间、路径等信息，如果该文件是目录，则递归输出该目录下所有文件相关信息。\n\n==shell==\n\n```\nhdfs dfs -ls -R -h /user/hadoop\n```\n\n![image-20250327174252672](../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/a01e0de8bc2984748005fa2d1735be70697559838-1746692007779-471-1747299497351-96-1747900721329-96-1749470495097-97.png)\n\n`别管我这里有什么文件，你能显示出来就行`\n\n==Java==\n\n```java\nimport  org.apache.hadoop.conf.Configuration;\nimport  org.apache.hadoop.fs.*;\nimport java.io.*;\nimport  java.text.SimpleDateFormat;\npublic class HDFSApi {\n    /**\n     * 显示指定文件夹下所有文件的信息（递归）\n     */\n    public static void lsDir(Configuration  conf, String remoteDir) throws IOException {\n        FileSystem fs = FileSystem.get(conf);\n        Path dirPath = new Path(remoteDir);\n        /* 递归获取目录下的所有文件 */\n         RemoteIterator<LocatedFileStatus> remoteIterator =  fs.listFiles(dirPath, true);\n        /* 输出每个文件的信息 */\n        while (remoteIterator.hasNext()) {\n               FileStatus  s = remoteIterator.next();\n            System.out.println(\"路径: \" +  s.getPath().toString());\n            System.out.println(\"权限: \" +  s.getPermission().toString());\n            System.out.println(\"大小: \" +  s.getLen());\n               /*  返回的是时间戳,转化为时间日期格式 */\n               Long  timeStamp = s.getModificationTime();\n               SimpleDateFormat  format =  new  SimpleDateFormat(\"yyyy-MM-dd HH:mm:ss\");\n               String  date = format.format(timeStamp);  \n               System.out.println(\"时间: \" +  date);\n               System.out.println();\n        }\n        fs.close();\n    }     \n       /**\n        * 主函数\n        */\n       public static void main(String[] args)  {\n              Configuration conf = new  Configuration();\n    conf.set(\"fs.default.name\",\"hdfs://localhost:9000\");\n              String remoteDir =  \"/user/hadoop\";    // HDFS路径\n              try {\n                     System.out.println(\"(递归)读取目录下所有文件的信息: \" +  remoteDir);\n                     HDFSApi.lsDir(conf,  remoteDir);\n                     System.out.println(\"读取完成\");\n              } catch (Exception e) {\n                     e.printStackTrace();\n              }\n       }\n}\n\n```\n\n![image-20250327174420260](../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/64970cdb69adf4ff023608eca537ba91697559838-1746692007780-472-1747299497351-97-1747900721329-97-1749470495097-98.png)\n\n⑥ 提供一个HDFS中的文件的路径，对该文件进行创建和删除操作。如果文件所在目录不存在，则自动创建目录。\n\n==shell==\n\n```bash\nif $(hdfs dfs -test -d dir1/dir2);\nthen $(hdfs dfs -touchz  dir1/dir2/filename);\nelse $(hdfs dfs -mkdir -p dir1/dir2  && hdfs dfs -touchz dir1/dir2/filename); \nfi\nhdfs dfs -rm dir1/dir2/filename\n```\n\n![image-20250327175606597](../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/f80ef99809ede779b9cb3f1af2335b64697559838-1746692007780-473-1747299497351-98-1747900721329-98-1749470495097-100.png)\n\n==Java==\n\n```java\nimport  org.apache.hadoop.conf.Configuration;\nimport  org.apache.hadoop.fs.*;\nimport java.io.*;\npublic class HDFSApi {\n    /**\n     * 判断路径是否存在\n     */\n    public static boolean test(Configuration  conf, String path) throws IOException {\n        FileSystem fs = FileSystem.get(conf);\n        return fs.exists(new Path(path));\n    }\n    /**\n     * 创建目录\n     */\n    public static boolean mkdir(Configuration  conf, String remoteDir) throws IOException {\n        FileSystem fs = FileSystem.get(conf);\n        Path dirPath = new Path(remoteDir);\n        boolean result = fs.mkdirs(dirPath);\n        fs.close();\n        return result;\n    }\n    /**\n     * 创建文件\n     */\n    public static void touchz(Configuration  conf, String remoteFilePath) throws IOException {\n        FileSystem fs = FileSystem.get(conf);\n        Path remotePath = new  Path(remoteFilePath);\n        FSDataOutputStream outputStream =  fs.create(remotePath);\n        outputStream.close();\n        fs.close();\n    }\n    /**\n     * 删除文件\n     */\n    public static boolean rm(Configuration  conf, String remoteFilePath) throws IOException {\n        FileSystem fs = FileSystem.get(conf);\n        Path remotePath = new  Path(remoteFilePath);\n        boolean result =  fs.delete(remotePath, false);\n        fs.close();\n        return result;\n    }\n       /**\n        * 主函数\n        */\n       public static void main(String[] args)  {\n              Configuration conf = new  Configuration();\n    conf.set(\"fs.default.name\",\"hdfs://localhost:9000\");\n              String remoteFilePath =  \"/user/hadoop/input/text.txt\";     // HDFS路径\n              String remoteDir =  \"/user/hadoop/input\";    //  HDFS路径对应的目录           \n              try {\n                     /* 判断路径是否存在，存在则删除，否则进行创建 */\n                     if ( HDFSApi.test(conf,  remoteFilePath) ) {\n                            HDFSApi.rm(conf,  remoteFilePath); // 删除\n                            System.out.println(\"删除路径: \" +  remoteFilePath);\n                     } else {\n                            if (  !HDFSApi.test(conf, remoteDir) ) { // 若目录不存在，则进行创建\n                                   HDFSApi.mkdir(conf,  remoteDir);\n                                   System.out.println(\"创建文件夹: \" +  remoteDir);\n                            }\n                            HDFSApi.touchz(conf,  remoteFilePath);\n                            System.out.println(\"创建路径: \" +  remoteFilePath);\n                     }\n              } catch (Exception e) {\n                     e.printStackTrace();\n              }\n       }\n}\n\n```\n\n![image-20250327175819965](../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/a9509597a505b1052be048905290387d697559838-1746692007780-474-1747299497351-99-1747900721329-99-1749470495097-99.png)\n\n\n\n⑦ 提供一个HDFS的目录的路径，对该目录进行创建和删除操作。创建目录时，如果目录文件所在目录不存在则自动创建相应目录；删除目录时，由用户指定当该目录不为空时是否还删除该目录。\n\n==shell==\n\n```bash\nhdfs dfs -mkdir -p dir1/dir2\nhdfs dfs -rmdir dir1/dir2\n#上述命令执行以后，如果目录非空，则会提示not empty，删除操作不会执行。如果要强制删除目录，可以使用如下命令：\nhdfs dfs -rm -R dir1/dir2\n```\n\n![image-20250327175958011](../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/image-20250327175958011-1746692007780-475-1747299497351-100-1747900721330-100-1749470495097-102.png)\n\n==Java==\n\n```java\nimport  org.apache.hadoop.conf.Configuration;\nimport  org.apache.hadoop.fs.*;\nimport java.io.*;\npublic class HDFSApi {\n    /**\n     * 判断路径是否存在\n     */\n    public static boolean test(Configuration  conf, String path) throws IOException {\n        FileSystem fs = FileSystem.get(conf);\n        return fs.exists(new Path(path));\n    }\n    /**\n     * 判断目录是否为空\n     * true: 空，false: 非空\n     */\n    public static boolean  isDirEmpty(Configuration conf, String remoteDir) throws IOException {\n        FileSystem fs = FileSystem.get(conf);\n        Path dirPath = new Path(remoteDir);\n         RemoteIterator<LocatedFileStatus> remoteIterator =  fs.listFiles(dirPath, true);\n        return !remoteIterator.hasNext();\n    }      \n    /**\n     * 创建目录\n     */\n    public static boolean mkdir(Configuration  conf, String remoteDir) throws IOException {\n        FileSystem fs = FileSystem.get(conf);\n        Path dirPath = new Path(remoteDir);\n        boolean result = fs.mkdirs(dirPath);\n        fs.close();\n        return result;\n    }\n    /**\n     * 删除目录\n     */\n    public static boolean rmDir(Configuration  conf, String remoteDir) throws IOException {\n        FileSystem fs = FileSystem.get(conf);\n        Path dirPath = new Path(remoteDir);\n        /* 第二个参数表示是否递归删除所有文件 */\n        boolean result = fs.delete(dirPath,  true);\n        fs.close();\n        return result;\n    }\n       /**\n        * 主函数\n        */\n       public static void main(String[] args)  {\n              Configuration conf = new  Configuration();\n    conf.set(\"fs.default.name\",\"hdfs://localhost:9000\");\n              String remoteDir =  \"/user/hadoop/input\";    //  HDFS目录\n              Boolean forceDelete =  false;  // 是否强制删除\n              try {\n                     /* 判断目录是否存在，不存在则创建，存在则删除 */\n                     if ( !HDFSApi.test(conf,  remoteDir) ) {\n                            HDFSApi.mkdir(conf,  remoteDir); // 创建目录\n                            System.out.println(\"创建目录: \" +  remoteDir);\n                     } else {\n                            if (  HDFSApi.isDirEmpty(conf, remoteDir) || forceDelete ) { // 目录为空或强制删除\n                                   HDFSApi.rmDir(conf,  remoteDir);\n                                   System.out.println(\"删除目录: \" +  remoteDir);\n                            } else  { // 目录不为空\n                                   System.out.println(\"目录不为空，不删除: \" +  remoteDir);\n                            }\n                     }\n              } catch (Exception e) {\n                     e.printStackTrace();\n              }\n       }\n}\n\n```\n\n![image-20250327180216959](../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/aa3dca52f3b01284a8ad8ba28db79349697559838-1746692007780-476-1747299497351-101-1747900721330-101-1749470495097-101.png)\n\n⑧ 向HDFS中指定的文件追加内容，由用户指定将内容追加到原有文件的开头或结尾。\n\n==shell==\n\n```\nrm -rf text.txt\nhdfs dfs -appendToFile local.txt text.txt\nhdfs dfs -get text.txt\ncat text.txt >> local.txt\nhdfs dfs -copyFromLocal -f text.txt text.txt\nhdfs dfs -cat text.txt\n```\n\n![image-20250327180622881](../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/7cdd5e339904c6b2048dec92da1dfc73697559838-1746692007780-477-1747299497351-102-1747900721330-102-1749470495097-103.png)\n\n==Java==\n\n```java\nimport  org.apache.hadoop.conf.Configuration;\nimport  org.apache.hadoop.fs.*;\nimport java.io.*;\npublic class HDFSApi {\n    /**\n     * 判断路径是否存在\n     */\n    public static boolean test(Configuration  conf, String path) throws IOException {\n        FileSystem fs = FileSystem.get(conf);\n        return fs.exists(new Path(path));\n    }\n    /**\n     * 追加文本内容\n     */\n    public static void  appendContentToFile(Configuration conf, String content, String  remoteFilePath) throws IOException {\n        FileSystem fs = FileSystem.get(conf);\n        Path remotePath = new  Path(remoteFilePath);\n        /* 创建一个文件输出流，输出的内容将追加到文件末尾 */\n        FSDataOutputStream out =  fs.append(remotePath);\n        out.write(content.getBytes());\n        out.close();\n        fs.close();\n}\n    /**\n     * 追加文件内容\n     */\n    public static void  appendToFile(Configuration conf, String localFilePath, String remoteFilePath)  throws IOException {\n        FileSystem fs = FileSystem.get(conf);\n        Path remotePath = new  Path(remoteFilePath);\n        /* 创建一个文件读入流 */\n        FileInputStream in = new  FileInputStream(localFilePath);\n        /* 创建一个文件输出流，输出的内容将追加到文件末尾 */\n        FSDataOutputStream out =  fs.append(remotePath);\n        /* 读写文件内容 */\n        byte[] data = new byte[1024];\n        int read = -1;\n        while ( (read = in.read(data)) > 0  ) {\n               out.write(data,  0, read);\n        }\n        out.close();\n        in.close();\n        fs.close();\n    }\n    /**\n     * 移动文件到本地\n     * 移动后，删除源文件\n     */\n    public static void  moveToLocalFile(Configuration conf, String remoteFilePath, String  localFilePath) throws IOException {\n        FileSystem fs = FileSystem.get(conf);\n        Path remotePath = new  Path(remoteFilePath);\n        Path localPath = new  Path(localFilePath);\n        fs.moveToLocalFile(remotePath,  localPath);\n    }\n    /**\n     * 创建文件\n     */\n    public static void touchz(Configuration  conf, String remoteFilePath) throws IOException {\n        FileSystem fs = FileSystem.get(conf);\n        Path remotePath = new  Path(remoteFilePath);\n        FSDataOutputStream outputStream =  fs.create(remotePath);\n        outputStream.close();\n        fs.close();\n    }\n       /**\n        * 主函数\n        */\n       public static void main(String[] args)  {\n              Configuration conf = new  Configuration();\n    conf.set(\"fs.default.name\",\"hdfs://localhost:9000\");\n              String remoteFilePath =  \"/user/hadoop/text.txt\";     // HDFS文件\n              String content = \"新追加的内容\\n\";\n              String choice =  \"after\";         //追加到文件末尾\n//            String choice =  \"before\";    // 追加到文件开头\n              try {\n                     /* 判断文件是否存在 */\n                     if ( !HDFSApi.test(conf,  remoteFilePath) ) {\n                            System.out.println(\"文件不存在: \" +  remoteFilePath);\n                     } else {\n                            if (  choice.equals(\"after\") ) { // 追加在文件末尾\n                                   HDFSApi.appendContentToFile(conf,  content, remoteFilePath);\n                                   System.out.println(\"已追加内容到文件末尾\" +  remoteFilePath);\n                            } else if (  choice.equals(\"before\") )  {  // 追加到文件开头\n                                   /* 没有相应的api可以直接操作，因此先把文件移动到本地*/\n/*创建一个新的HDFS，再按顺序追加内容 */\n                                   String  localTmpPath = \"/user/hadoop/tmp.txt\";\n                                   // 移动到本地\nHDFSApi.moveToLocalFile(conf, remoteFilePath,  localTmpPath);\n   // 创建一个新文件\n                          HDFSApi.touchz(conf,  remoteFilePath); \n                    // 先写入新内容\n                          HDFSApi.appendContentToFile(conf,  content, remoteFilePath);\n                    // 再写入原来内容\n                           HDFSApi.appendToFile(conf,  localTmpPath, remoteFilePath); \n                           System.out.println(\"已追加内容到文件开头: \" +  remoteFilePath);\n                            }\n                     }\n              } catch (Exception e) {\n                     e.printStackTrace();\n              }\n       }\n}\n\n```\n\n![image-20250327180721307](../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/710a090fa1c394fe6e2808329cda4dc2697559838-1746692007780-478-1747299497351-103-1747900721330-103-1749470495097-105.png)\n\n```\nhdfs dfs -cat text.txt\n```\n\n![image-20250327180742432](../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/9f8d75e4b88732f54a55451338533fe6697559838-1746692007780-479-1747299497351-104-1747900721330-104-1749470495097-104.png)\n\n\n\n⑨ 删除HDFS中指定的文件。\n\n==shell==\n\n```\nrm text.txt\nhdfs dfs -get text.txt\nhdfs dfs -rm text.txt\n```\n\n![image-20250327180918344](../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/0a49740aa72800dd9f780cd6e02db10d697559838-1746692007780-480-1747299497351-105-1747900721330-105-1749470495097-106.png)\n\n```\nhdfs dfs -put text.txt\n```\n\n\n\n==Java==\n\n```java\nimport  org.apache.hadoop.conf.Configuration;\nimport  org.apache.hadoop.fs.*;\nimport java.io.*;\npublic class HDFSApi {\n    /**\n     * 删除文件\n     */\n    public static boolean rm(Configuration  conf, String remoteFilePath) throws IOException {\n        FileSystem fs = FileSystem.get(conf);\n        Path remotePath = new  Path(remoteFilePath);\n        boolean result =  fs.delete(remotePath, false);\n        fs.close();\n        return result;\n    }\n       /**\n        * 主函数\n        */\n       public static void main(String[] args)  {\n              Configuration conf = new  Configuration();\n    conf.set(\"fs.default.name\",\"hdfs://localhost:9000\");\n              String remoteFilePath =  \"/user/hadoop/text.txt\";     // HDFS文件         \n              try {\n                     if ( HDFSApi.rm(conf,  remoteFilePath) ) {\n                            System.out.println(\"文件删除: \" +  remoteFilePath);\n                     } else {\n                            System.out.println(\"操作失败（文件不存在或删除失败）\");\n                     }\n              } catch (Exception e) {\n                     e.printStackTrace();\n              }\n       }\n}\n\n```\n\n![image-20250327181030978](../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/08a6b2fb485de0b4a274d3ec647ad025697559838-1746692007780-481-1747299497351-106-1747900721330-106-1749470495097-107.png)\n\n⑩ 在HDFS中将文件从源路径移动到目的路径。\n\n==shell==\n\n```\nhdfs dfs -put text.txt\nhdfs dfs -mv text.txt text2.txt\nhdfs dfs -ls\n```\n\n![image-20250327181119936](../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/78098652ed313c1aaf03bc4ad865abb0697559838-1746692007780-482-1747299497351-107-1747900721330-107-1749470495097-108.png)\n\n```\nhdfs dfs -put text.txt\n```\n\n\n\n==Java==\n\n```java\nimport  org.apache.hadoop.conf.Configuration;\nimport org.apache.hadoop.fs.*;\nimport java.io.*;\npublic class HDFSApi {\n    /**\n     * 移动文件\n     */\n    public static boolean mv(Configuration  conf, String remoteFilePath, String remoteToFilePath) throws IOException {\n        FileSystem fs = FileSystem.get(conf);\n        Path srcPath = new  Path(remoteFilePath);\n        Path dstPath = new  Path(remoteToFilePath);\n        boolean result = fs.rename(srcPath,  dstPath);\n        fs.close();\n        return result;\n    }\n       /**\n        * 主函数\n        */\n       public static void main(String[] args) {\n              Configuration conf = new Configuration();\n    conf.set(\"fs.default.name\",\"hdfs://localhost:9000\");\n              String remoteFilePath =  \"hdfs:///user/hadoop/text.txt\";     // 源文件HDFS路径\n              String remoteToFilePath =  \"hdfs:///user/hadoop/new.txt\";     // 目的HDFS路径\n              try {\n                     if ( HDFSApi.mv(conf, remoteFilePath,  remoteToFilePath) ) {\n                            System.out.println(\"将文件 \" +  remoteFilePath + \" 移动到 \" + remoteToFilePath);\n                     } else {\n                                   System.out.println(\"操作失败(源文件不存在或移动失败)\");\n                     }\n              } catch (Exception e) {\n                     e.printStackTrace();\n              }\n       }\n}\n\n```\n\n![image-20250327181230298](../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/3ef11dae7bf3e355fb37a037de122b87697559838-1746692007780-483-1747299497351-108-1747900721330-108-1749470495097-109.png)\n\n```\nhdfs dfs -ls | grep new\n```\n\n![image-20250327181334769](../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/e943e8ea612d9c03d72de2eb33a9270f697559838-1746692007780-484-1747299497351-109-1747900721330-109-1749470495097-110.png)\n\n\n\n（2）编程实现一个类“MyFSDataInputStream”，该类继承“org.apache.hadoop.fs.FSDataInput Stream”，要求如下： 实现按行读取HDFS中指定文件的方法“readLine()”，如果读到文件末尾，则返回空，否则返回文件一行的文本。\n\n==shell==\n\n```\nhdfs dfs -put text.txt\n```\n\n==Java==\n\n> `自己创建好MyFSDataInputStream.java`\n\n```java\nimport  org.apache.hadoop.conf.Configuration;\nimport  org.apache.hadoop.fs.FSDataInputStream;\nimport  org.apache.hadoop.fs.FileSystem;\nimport  org.apache.hadoop.fs.Path;\nimport  java.io.*;\npublic  class MyFSDataInputStream extends FSDataInputStream {\n       public MyFSDataInputStream(InputStream  in) {\n              super(in);\n       }\n       /**\n     * 实现按行读取\n     * 每次读入一个字符，遇到\"\\n\"结束，返回一行内容\n     */\n       public static String  readline(BufferedReader br) throws IOException {\n              char[] data = new char[1024];\n              int read = -1;\n              int off = 0; \n// 循环执行时，br 每次会从上一次读取结束的位置继续读取\n//因此该函数里，off 每次都从0开始\n              while ( (read = br.read(data,  off, 1)) != -1 ) {\n                     if  (String.valueOf(data[off].equals(\"\\n\") ) {\n                            off += 1;\n                            break;\n                     }\n                     off += 1;\n              }          \n              if (off > 0) {\n                     return  String.valueOf(data);\n              } else {\n                     return null;\n              }\n       }\n       /**\n     * 读取文件内容\n     */\n    public static void cat(Configuration  conf, String remoteFilePath) throws IOException {\n        FileSystem fs = FileSystem.get(conf);\n        Path remotePath = new  Path(remoteFilePath);\n        FSDataInputStream in =  fs.open(remotePath);\n        BufferedReader br = new  BufferedReader(new InputStreamReader(in));\n        String line = null;\n        while ( (line =  MyFSDataInputStream.readline(br)) != null ) {\n               System.out.println(line);\n        }\n        br.close();\n        in.close();\n        fs.close();\n    }   \n       /**\n        * 主函数\n        */\n       public static void main(String[] args)  {\n              Configuration conf = new  Configuration();\n    conf.set(\"fs.default.name\",\"hdfs://localhost:9000\");\n              String remoteFilePath =  \"/user/hadoop/text.txt\";     // HDFS路径\n              try {\n                     MyFSDataInputStream.cat(conf,  remoteFilePath);\n              } catch (Exception e) {\n                     e.printStackTrace();\n              }\n       }\n}\n\n```\n\n![image-20250327181734199](../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/4d9c8b1a54195c6a3ce4f8a9d1162065697559838-1746692007780-485-1747299497351-110-1747900721330-110-1749470495097-111.png)\n\n（3）查看Java帮助手册或其他资料，用“java.net.URL”和“org.apache.hadoop.fs.FsURLStream HandlerFactory”编程来输出HDFS中指定文件的文本到终端中。\n\n==Java==\n\n用回`HDFSApi`\n\n```java\nimport org.apache.hadoop.fs.*;\nimport org.apache.hadoop.io.IOUtils;\nimport java.io.*;\nimport java.net.URL;\n\npublic class HDFSApi {\n    static {\n        URL.setURLStreamHandlerFactory(new FsUrlStreamHandlerFactory());\n    }\n\n    /**\n     * 主函数\n     */\n    public static void main(String[] args) throws Exception {\n        // HDFS文件路径，需包含主机名和端口号\n        String remoteFilePath = \"hdfs://localhost:9000/user/hadoop/text.txt\"; // 修改为正确的HDFS URI\n        InputStream in = null;\n\n        try {\n            /* 通过URL对象打开数据流，从中读取数据 */\n            in = new URL(remoteFilePath).openStream();\n            IOUtils.copyBytes(in, System.out, 4096, false); // 将数据输出到控制台\n        } finally {\n            IOUtils.closeStream(in); // 关闭输入流\n        }\n    }\n}\n```\n\n![image-20250327182240291](../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/224356211e87ed627058fbdf9d557f92697559838-1746692007780-486-1747299497351-111-1747900721330-111-1749470495097-113.png)\n\n## Hbase安装(4.6.1)\n\n这里有两个题，就是要交两个截图，我会注明\n\n`进hadoop用户`\n\n![image-20250408162058097](../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/21494f461a2bcfa10ef3533188e26bff55933597-1746692007780-487-1747299497351-112-1747900721330-112-1749470495097-112.png)\n\n`自行启动hadoop`\n\n### 安装hbase\n\n```\nsudo ls\n```\n\n![image-20250408162139854](../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/76c9277a9bea6c8f5f60a0bce8b5de3a55933597-1746692007780-488-1747299497351-113-1747900721330-113-1749470495097-114.png)\n\n```bash\nsudo tar -xf hbase-2.5.4-bin.tar.gz -C /usr/local/\nsudo mv /usr/local/hbase-2.5.4 /usr/local/hbase\nsudo chown -R hadoop:hadoop /usr/local/hbase\necho \"export HBASE_HOME=/usr/local/hbase\" >> ~/.bashrc\necho \"export PATH=\\$PATH:\\$HBASE_HOME/bin\" >> ~/.bashrc\nsource ~/.bashrc\nsudo sed -i \"s/CLASSPATH=\\${CLASSPATH}:\\$JAVA_HOME\\/lib\\/tools.jar/CLASSPATH=\\${CLASSPATH}:\\$JAVA_HOME\\/lib\\/tools.jar:\\/usr\\/local\\/hbase\\/lib\\/*/g\" /usr/local/hbase/bin/hbase\n\necho \"export JAVA_HOME=/usr/lib/jvm/jdk1.8.0_162\" >> $HBASE_HOME/conf/hbase-env.sh\necho \"export HBASE_CLASSPATH=/usr/local/hbase/conf\" >> $HBASE_HOME/conf/hbase-env.sh\necho \"export HBASE_MANAGES_ZK=true\" >> $HBASE_HOME/conf/hbase-env.sh\necho \"export HBASE_DISABLE_HADOOP_CLASSPATH_LOOKUP=true\" >> $HBASE_HOME/conf/hbase-env.sh\n\ncat >$HBASE_HOME/conf/hbase-site.xml<<\"EOF\"\n<configuration>\n        <property>\n                <name>hbase.rootdir</name>\n                <value>hdfs://localhost:9000/hbase</value>\n        </property>\n        <property>\n                <name>hbase.cluster.distributed</name>\n                <value>true</value>\n        </property>\n        <property>\n                <name>hbase.unsafe.stream.capability.enforce</name>\n                <value>false</value>\n        </property>\n</configuration>\nEOF\nhbase version\n```\n\n> `这个截图交到4.6.1开头第一个作业`\n\n![image-20250408162305665](../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/91151a2feff536bb833551d46297998855933597-1746692007780-489-1747299497351-114-1747900721330-114-1749470495097-115.png)\n\n### 启动hbase\n\n`开机顺序：一定是先启动hadoop（大）在启动hbase（小）`\n\n`开机顺序：一定是先启动hadoop（大）在启动hbase（小）`\n\n`开机顺序：一定是先启动hadoop（大）在启动hbase（小）`\n\n```\nstart-all.sh\nstart-hbase.sh\n```\n\n然后输入jps,有以下三个个就安装成功\n\n> `这是4.6.1里最下面的第二个作业截图`\n\n![image-20250408162520533](../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/eac0cd31a5b01c64eef55ab24e277f8555933597-1746692007780-490-1747299497351-115-1747900721330-115-1749470495097-116.png)\n\n测试hbase\n\n```\nhbase shell\nlist\n```\n\n![image-20250408162546768](../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/c8239e3d81e133e56e4209d0e451523755933597-1746692007780-491-1747299497351-116-1747900721330-116-1749470495097-117.png)\n\n能运行没报错就行\n\n退出hbase数据库用`exit`\n\n![image-20250401165245612](../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/66ed6e4c766ea1fc194a4657f260987d55933597-1746692007780-492-1747299497351-117-1747900721330-117-1749470495097-118.png)\n\n访问hbase网页\n\nhttp://ip:16010/\n\n![image-20250408162639789](../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/fba67e9070ac30030461dd890b011fa955933597-1746692007780-493-1747299497351-118-1747900721330-118-1749470495097-119.png)\n\n### 关闭hbase\n\n`关机顺序：先关habse(小)再关hadoop（大）`\n\n`关机顺序：先关habse(小)再关hadoop（大）`\n\n`关机顺序：先关habse(小)再关hadoop（大）`\n\n`关机顺序：先关habse(小)再关hadoop（大）`\n\n不按操作来，机器坏了，自己重装吧\n\n```\nstop-hbase.sh\nstop-all.sh\nsudo poweroff\n```\n\n`关机后自己打个habse的快照`\n\n## （4.6.2）实验\n\n### 启动eclipse\n\n```\neclipse\n```\n\n![image-20250408164622803](../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/1923b4c74871006064488c96e58ca45855933597-1746692007780-494-1747299497351-120-1747900721330-119-1749470495097-120.png)\n\n![image-20250408164638364](../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/9a4ecb36e968a02b73e7623a8fda4f8a55933597-1746692007780-495-1747299497351-119-1747900721330-120-1749470495097-121.png)\n\n### 新建项目\n\n名为`HBaseExample`\n\n![image-20250408164919609](../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/636129eb6dee23242d4e2d6c8081873f55933597-1746692007781-496-1747299497351-121-1747900721330-121-1749470495097-122.png)\n\n![image-20250408164950280](../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/6e3bb9833a72d6546944cbae664a474455933597-1746692007781-497-1747299497351-122-1747900721330-122-1749470495097-123.png)\n\n`现在有几个目录要添加注意了！！！`\n\n`现在有几个目录要添加注意了！！！`\n\n`现在有几个目录要添加注意了！！！`\n\n`现在有几个目录要添加注意了！！！`\n\n> `/usr/local/hbase/lib`下所有的jar包\n>\n> `/usr/local/hbase/lib/client-facing-thirdparty`下所有的jar包\n\n![image-20250408165300706](../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/2b2dbcc5dcd4b9bead17749b9df213fa55933597-1746692007781-498-1747299497351-123-1747900721330-123-1749470495097-124.png)\n\n![image-20250408165316864](../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/a3fc6310f34a3ef1daa99b09452f0a7455933597-1746692007781-499-1747299497351-124-1747900721330-124-1749470495097-125.png)\n\n![image-20250408165342189](../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/4c79bcd883e1303d5997906eef903d0155933597-1746692007781-500-1747299497351-125-1747900721330-125-1749470495097-126.png)\n\n最后直接点击finish完成创建\n\n\n\n### 新建class\n\n![image-20250408165715828](../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/f6137b4051dab5c88e26d29ce588847e55933597-1746692007781-501-1747299497351-126-1747900721330-126-1749470495097-127.png)\n\n然后在你创建的这个java文件输入，别运行\n\n```java\nimport org.apache.hadoop.conf.Configuration;\nimport org.apache.hadoop.hbase.*;\nimport org.apache.hadoop.hbase.client.*;\nimport org.apache.hadoop.hbase.util.Bytes;\n \nimport java.io.IOException;\npublic class ExampleForHBase {\n    public static Configuration configuration;\n    public static Connection connection;\n    public static Admin admin;\n    public static void main(String[] args)throws IOException{\n        init();\n        createTable(\"student\",new String[]{\"score\"});\n        insertData(\"student\",\"zhangsan\",\"score\",\"English\",\"69\");\n        insertData(\"student\",\"zhangsan\",\"score\",\"Math\",\"86\");\n        insertData(\"student\",\"zhangsan\",\"score\",\"Computer\",\"77\");\n        getData(\"student\", \"zhangsan\", \"score\",\"English\");\n        close();\n    }\n \n    public static void init(){\n        configuration  = HBaseConfiguration.create();\n        configuration.set(\"hbase.rootdir\",\"hdfs://localhost:9000/hbase\");\n        try{\n            connection = ConnectionFactory.createConnection(configuration);\n            admin = connection.getAdmin();\n        }catch (IOException e){\n            e.printStackTrace();\n        }\n    }\n \n    public static void close(){\n        try{\n            if(admin != null){\n                admin.close();\n            }\n            if(null != connection){\n                connection.close();\n            }\n        }catch (IOException e){\n            e.printStackTrace();\n        }\n    }\n \n    public static void createTable(String myTableName,String[] colFamily) throws IOException {\n        TableName tableName = TableName.valueOf(myTableName);\n        if(admin.tableExists(tableName)){\n            System.out.println(\"talbe is exists!\");\n        }else {\n            TableDescriptorBuilder tableDescriptor = TableDescriptorBuilder.newBuilder(tableName);\n            for(String str:colFamily){\n                ColumnFamilyDescriptor family = \nColumnFamilyDescriptorBuilder.newBuilder(Bytes.toBytes(str)).build();\n                tableDescriptor.setColumnFamily(family);\n            }\n            admin.createTable(tableDescriptor.build());\n        } \n    }\n \n    public static void insertData(String tableName,String rowKey,String colFamily,String col,String val) throws IOException { \n        Table table = connection.getTable(TableName.valueOf(tableName));\n        Put put = new Put(rowKey.getBytes());\n        put.addColumn(colFamily.getBytes(),col.getBytes(), val.getBytes());\n        table.put(put);\n        table.close(); \n    }\n \n    public static void getData(String tableName,String rowKey,String colFamily, String col)throws  IOException{ \n        Table table = connection.getTable(TableName.valueOf(tableName));\n        Get get = new Get(rowKey.getBytes());\n        get.addColumn(colFamily.getBytes(),col.getBytes());\n        Result result = table.get(get);\n        System.out.println(new String(result.getValue(colFamily.getBytes(),col==null?null:col.getBytes())));\n        table.close(); \n    }\n}\n```\n\n自行启动hadoop和hbase，不记得了回去翻记录，我有写启动顺序，别搞错了，`搞错了就恢复快照吧`，下面是关闭和启动的顺序\n\n[9.2 启动hbase](#启动hbase)\n\n[9.3 关闭hbase](#关闭hbase)\n\n`没启动就不要做下面的内容！！！`\n\n`没启动就不要做下面的内容！！！`\n\n`没启动就不要做下面的内容！！！`\n\n`没启动就不要做下面的内容！！！`\n\n运行代码\n\n![image-20250408170354469](../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/617bb420d0196e81f2eb7cd73664bc9455933597-1746692007781-502-1747299497351-127-1747900721330-127-1749470495097-128.png)\n\n就会出现这样的结果\n\n> `4.6.2实验要交的截图1`\n\n![image-20250408170422533](../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/8fb2b2bdc0962691f05c04c233375a1c55933597-1746692007781-503-1747299497351-128-1747900721330-128-1749470495097-129.png)\n\n这时候进入hbase数据库查看有没有student表\n\n```\nhbase shell\n```\n\n`这是进入hbase数据库的命令，我前面也有写后面不会再说了，记不住就自己找办法`\n\n```\nlist\nscan 'student'\n```\n\n> `4.6.2实验要交的截图2`\n\n![image-20250408170549890](../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/ffffe943d8c41a3fe1565a88efe89ae755933597-1746692007781-504-1747299497351-130-1747900721330-129-1749470495097-131.png)\n\n## (4.8实验3)\n\n`如果这里你输入第一条和第二条命令就报错，自己找找原因，我不想说了`\n\n---\n\n### 第一题\n\n`（1）编程实现以下指定功能，并用Hadoop提供的HBaseShell命令完成相同的任务。`\n\n  ①列出HBase所有表的相关信息，如表名、创建时间等。\n\n==shell==\n\n```\nhbase shell\nlist\n```\n\n![image-20250408172837610](../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/d7c69d7997f40d717b95e140a09c8cd855933597-1746692007781-505-1747299497351-129-1747900721330-130-1749470495097-130.png)\n\n==java==\n\n自己创建一个`test.java`,要在`HBaseExample`的项目下,后面一直都会用这个java\n\n```java\nimport org.apache.hadoop.conf.Configuration;\nimport org.apache.hadoop.hbase.*;\nimport org.apache.hadoop.hbase.client.*;\nimport org.apache.hadoop.hbase.util.Bytes;\nimport java.util.List;\nimport java.io.IOException;\npublic class test {\n    public static Configuration configuration;\n    public static Connection connection;\n    public static Admin admin;\n    public static void main(String[] args)throws IOException{\n        init();\n        List<TableDescriptor>  tableDescriptors = admin.listTableDescriptors();\n        for(TableDescriptor tableDescriptor :  tableDescriptors){ \n        TableName tableName =  tableDescriptor.getTableName(); \n        System.out.println(\"Table:\" + tableName);\n        }\n        close();\n    }\n\n    public static void init() {\n        configuration = HBaseConfiguration.create();\n        configuration.set(\"hbase.rootdir\", \"hbase://localhost:9000/hbase\");\n        try {\n            connection = ConnectionFactory.createConnection(configuration);\n            if (connection == null) {\n                System.err.println(\"Failed to create HBase connection.\");\n            } else {\n                System.out.println(\"HBase connection created successfully.\");\n            }\n            admin = connection.getAdmin();\n            if (admin == null) {\n                System.err.println(\"Failed to get HBase Admin.\");\n            } else {\n                System.out.println(\"HBase Admin initialized successfully.\");\n            }\n        } catch (IOException e) {\n            e.printStackTrace();\n        }\n    }\n \n    public static void close(){\n        try{\n            if(admin != null){\n                admin.close();\n            }\n            if(null != connection){\n                connection.close();\n            }\n        }catch (IOException e){\n            e.printStackTrace();\n        }\n    }\n \n    public static void createTable(String myTableName,String[] colFamily) throws IOException {\n        TableName tableName = TableName.valueOf(myTableName);\n        if(admin.tableExists(tableName)){\n            System.out.println(\"talbe is exists!\");\n        }else {\n            TableDescriptorBuilder tableDescriptor = TableDescriptorBuilder.newBuilder(tableName);\n            for(String str:colFamily){\n                ColumnFamilyDescriptor family = \nColumnFamilyDescriptorBuilder.newBuilder(Bytes.toBytes(str)).build();\n                tableDescriptor.setColumnFamily(family);\n            }\n            admin.createTable(tableDescriptor.build());\n        } \n    }\n \n    public static void insertData(String tableName,String rowKey,String colFamily,String col,String val) throws IOException { \n        Table table = connection.getTable(TableName.valueOf(tableName));\n        Put put = new Put(rowKey.getBytes());\n        put.addColumn(colFamily.getBytes(),col.getBytes(), val.getBytes());\n        table.put(put);\n        table.close(); \n    }\n \n    public static void getData(String tableName,String rowKey,String colFamily, String col)throws  IOException{ \n        Table table = connection.getTable(TableName.valueOf(tableName));\n        Get get = new Get(rowKey.getBytes());\n        get.addColumn(colFamily.getBytes(),col.getBytes());\n        Result result = table.get(get);\n        System.out.println(new String(result.getValue(colFamily.getBytes(),col==null?null:col.getBytes())));\n        table.close(); \n    }\n}\n```\n\n![image-20250408180910551](../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/661b8bf5388c32a8028982d7495d41eb55933597-1746692007781-506-1747299497351-131-1747900721330-131-1749470495097-133.png)\n\n\n\n\n\n  ②在终端输出指定表的所有记录数据。\n\n==shell==\n\n```\nscan 'student'\n```\n\n![image-20250408175605631](../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/a9bf5f6896beb92e8720ba6cb643bfcd55933597-1746692007781-507-1747299497351-132-1747900721330-133-1749470495097-134.png)\n\n==java==\n\n```java\nimport org.apache.hadoop.conf.Configuration;\nimport org.apache.hadoop.hbase.*;\nimport org.apache.hadoop.hbase.client.*;\nimport org.apache.hadoop.hbase.util.Bytes;\nimport java.util.List;\nimport java.io.IOException;\npublic class test {\n    public static Configuration configuration;\n    public static Connection connection;\n    public static Admin admin;\n    public static void main(String[] args) throws IOException {\n    \t  // 指定表名 \"student\" 并获取所有记录\n    \t  String tableName = \"student\";\n    \t  getData(tableName);\n    \t }\n    \t // 在终端打印出指定表的所有记录数据\n    \t public static void getData(String tableName) throws IOException {\n    \t  init(); // 初始化连接\n    \t  Table table = connection.getTable(TableName.valueOf(tableName)); // 获取表对象\n    \t  Scan scan = new Scan(); // 创建扫描器\n    \t  ResultScanner scanner = table.getScanner(scan); // 获取扫描结果\n    \t  System.out.println(\"表 \" + tableName + \" 的所有记录如下：\");\n    \t  for (Result result : scanner) { // 遍历每一行数据\n    \tprintRecoder(result); // 打印每条记录的详情\n    \t  }\n    \t  close(); // 关闭连接\n    \t }\n    \t // 打印一条记录的详情\n    \t public static void printRecoder(Result result) throws IOException {\n    \t  for (Cell cell : result.rawCells()) { // 遍历每个单元格\n    \tSystem.out.print(\"行键: \" + new String(Bytes.toString(cell.getRowArray(), cell.getRowOffset(), cell.getRowLength())));\n    \tSystem.out.print(\" 列簇: \" + new String(Bytes.toString(cell.getFamilyArray(), cell.getFamilyOffset(), cell.getFamilyLength())));\n    \tSystem.out.print(\" 列: \" + new String(Bytes.toString(cell.getQualifierArray(), cell.getQualifierOffset(), cell.getQualifierLength())));\n    \tSystem.out.print(\" 值: \" + new String(Bytes.toString(cell.getValueArray(), cell.getValueOffset(), cell.getValueLength())));\n    \tSystem.out.println(\" 时间戳: \" + cell.getTimestamp());\n    \t  }\n    \t }\n\n\n    public static void init() {\n        configuration = HBaseConfiguration.create();\n        configuration.set(\"hbase.rootdir\", \"hbase://localhost:9000/hbase\");\n        try {\n            connection = ConnectionFactory.createConnection(configuration);\n            if (connection == null) {\n                System.err.println(\"Failed to create HBase connection.\");\n            } else {\n                System.out.println(\"HBase connection created successfully.\");\n            }\n            admin = connection.getAdmin();\n            if (admin == null) {\n                System.err.println(\"Failed to get HBase Admin.\");\n            } else {\n                System.out.println(\"HBase Admin initialized successfully.\");\n            }\n        } catch (IOException e) {\n            e.printStackTrace();\n        }\n    }\n \n    public static void close(){\n        try{\n            if(admin != null){\n                admin.close();\n            }\n            if(null != connection){\n                connection.close();\n            }\n        }catch (IOException e){\n            e.printStackTrace();\n        }\n    }\n \n    public static void createTable(String myTableName,String[] colFamily) throws IOException {\n        TableName tableName = TableName.valueOf(myTableName);\n        if(admin.tableExists(tableName)){\n            System.out.println(\"talbe is exists!\");\n        }else {\n            TableDescriptorBuilder tableDescriptor = TableDescriptorBuilder.newBuilder(tableName);\n            for(String str:colFamily){\n                ColumnFamilyDescriptor family = \nColumnFamilyDescriptorBuilder.newBuilder(Bytes.toBytes(str)).build();\n                tableDescriptor.setColumnFamily(family);\n            }\n            admin.createTable(tableDescriptor.build());\n        } \n    }\n \n    public static void insertData(String tableName,String rowKey,String colFamily,String col,String val) throws IOException { \n        Table table = connection.getTable(TableName.valueOf(tableName));\n        Put put = new Put(rowKey.getBytes());\n        put.addColumn(colFamily.getBytes(),col.getBytes(), val.getBytes());\n        table.put(put);\n        table.close(); \n    }\n \n    public static void getData(String tableName,String rowKey,String colFamily, String col)throws  IOException{ \n        Table table = connection.getTable(TableName.valueOf(tableName));\n        Get get = new Get(rowKey.getBytes());\n        get.addColumn(colFamily.getBytes(),col.getBytes());\n        Result result = table.get(get);\n        System.out.println(new String(result.getValue(colFamily.getBytes(),col==null?null:col.getBytes())));\n        table.close(); \n    }\n}\n```\n\n运行结果如下\n\n![image-20250408180840552](../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/f5f936356529f42ce9823d1a641abb3e55933597-1746692007781-508-1747299497351-133-1747900721330-132-1749470495097-132.png)\n\n  ③向已经创建好的表添加和删除指定的列族或列。\n\n==shell==\n\n```\ncreate 's1','score'\nput 's1','zhangsan','score:Math','69'\ndelete 's1','zhangsan','score:Math'\n```\n\n![image-20250408175944024](../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/2e51321547d302cea1a9024b5bb2f1ad55933597-1746692007781-509-1747299497351-134-1747900721330-134-1749470495098-135.png)\n\n==JAVA==\n\n```java\nimport org.apache.hadoop.conf.Configuration;\nimport org.apache.hadoop.hbase.*;\nimport org.apache.hadoop.hbase.client.*;\nimport org.apache.hadoop.hbase.util.Bytes;\n\nimport java.io.IOException;\n\npublic class test {\n    public static Configuration configuration;\n    public static Connection connection;\n    public static Admin admin;\n\n    public static void main(String[] args) throws IOException {\n        init(); // 初始化连接\n\n        String tableName = \"s1\"; // 表名\n        String[] columnFamilies = {\"score\"}; // 列簇\n        String rowKey = \"zhangsan\"; // 行键\n        String colFamily = \"score\"; // 列簇\n        String col = \"Math\"; // 列名\n        String val = \"69\"; // 值\n\n        // 创建表\n        System.out.println(\"开始创建表...\");\n        createTable(tableName, columnFamilies);\n\n        // 插入数据\n        System.out.println(\"开始插入数据...\");\n        insertRow(tableName, rowKey, colFamily, col, val);\n\n        // 查询数据\n        System.out.println(\"验证插入的数据...\");\n        getData(tableName, rowKey, colFamily, col);\n\n        // 删除数据\n        System.out.println(\"开始删除数据...\");\n        deleteRow(tableName, rowKey, colFamily, col);\n\n        // 验证删除\n        System.out.println(\"验证删除后的数据...\");\n        getData(tableName, rowKey, colFamily, col);\n\n        close(); // 关闭连接\n    }\n\n    public static void init() {\n        configuration = HBaseConfiguration.create();\n        configuration.set(\"hbase.rootdir\", \"hdfs://localhost:9000/hbase\"); // 注意这里用的是 hdfs\n        configuration.set(\"hbase.zookeeper.quorum\", \"localhost\"); // 指定 zookeeper 地址\n        try {\n            connection = ConnectionFactory.createConnection(configuration);\n            admin = connection.getAdmin();\n            System.out.println(\"HBase connection and Admin initialized successfully.\");\n        } catch (IOException e) {\n            e.printStackTrace();\n        }\n    }\n\n    public static void close() {\n        try {\n            if (admin != null) {\n                admin.close();\n            }\n            if (connection != null) {\n                connection.close();\n            }\n        } catch (IOException e) {\n            e.printStackTrace();\n        }\n    }\n\n    public static void createTable(String myTableName, String[] colFamilies) throws IOException {\n        TableName tableName = TableName.valueOf(myTableName);\n        if (admin.tableExists(tableName)) {\n            System.out.println(\"表已存在！\");\n        } else {\n            TableDescriptorBuilder tableDescriptor = TableDescriptorBuilder.newBuilder(tableName);\n            for (String cf : colFamilies) {\n                ColumnFamilyDescriptor family =\n                        ColumnFamilyDescriptorBuilder.newBuilder(Bytes.toBytes(cf)).build();\n                tableDescriptor.setColumnFamily(family);\n            }\n            admin.createTable(tableDescriptor.build());\n            System.out.println(\"表 \" + myTableName + \" 创建成功！\");\n        }\n    }\n\n    public static void insertRow(String tableName, String rowKey, String colFamily, String col, String val) throws IOException {\n        Table table = connection.getTable(TableName.valueOf(tableName));\n        Put put = new Put(Bytes.toBytes(rowKey));\n        put.addColumn(Bytes.toBytes(colFamily), Bytes.toBytes(col), Bytes.toBytes(val));\n        table.put(put);\n        table.close();\n        System.out.println(\"数据插入成功！\");\n    }\n\n    public static void getData(String tableName, String rowKey, String colFamily, String col) throws IOException {\n        Table table = connection.getTable(TableName.valueOf(tableName));\n        Get get = new Get(Bytes.toBytes(rowKey));\n        get.addColumn(Bytes.toBytes(colFamily), Bytes.toBytes(col));\n        Result result = table.get(get);\n        byte[] value = result.getValue(Bytes.toBytes(colFamily), Bytes.toBytes(col));\n        if (value != null) {\n            System.out.println(\"获取到数据: \" + new String(value));\n        } else {\n            System.out.println(\"未找到数据。\");\n        }\n        table.close();\n    }\n\n    public static void deleteRow(String tableName, String rowKey, String colFamily, String col) throws IOException {\n        Table table = connection.getTable(TableName.valueOf(tableName));\n        Delete delete = new Delete(Bytes.toBytes(rowKey));\n        delete.addColumn(Bytes.toBytes(colFamily), Bytes.toBytes(col));\n        table.delete(delete);\n        table.close();\n        System.out.println(\"数据删除成功！\");\n    }\n}\n\n```\n\n![image-20250408181938555](../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/4952ac8d1d540a6e277b0582297fbf2055933597-1746692007781-510-1747299497351-136-1747900721330-135-1749470495098-136.png)\n\n---\n\n④清空指定表的所有记录数据。\n\n==shell==\n\n```\ncreate 's1','score'\nput 's1','zhangsan','score:Math','69'\ntruncate 's1'\nscan 's1'\n```\n\n![image-20250408182046843](../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/7afb99cf0df777c1ef237f2b838b508a55933597-1746692007781-511-1747299497351-135-1747900721330-136-1749470495098-137.png)\n\n```\nput 's1','zhangsan','score:Math','69'\n```\n\n==java==\n\n教材中的代码\n\n`clearRows()` 方法缺了一个 **关键点**：\n\n> 在删除表之后重新创建时，需要重新添加原来的列簇（否则建出来的表是空结构）。\n\n所以我用新的\n\n```java\nimport org.apache.hadoop.conf.Configuration;\nimport org.apache.hadoop.hbase.HBaseConfiguration;\nimport org.apache.hadoop.hbase.TableName;\nimport org.apache.hadoop.hbase.client.*;\nimport org.apache.hadoop.hbase.util.Bytes;\nimport java.io.IOException;\npublic class test {\n    public static Configuration configuration;\n    public static Connection connection;\n    public static Admin admin;\n    public static void main(String[] args) throws IOException {\n        String tableName = \"s1\"; // 你要清空的表名\n        clearRows(tableName);\n    }\n    // 初始化 HBase 连接\n    public static void init() throws IOException {\n        configuration = HBaseConfiguration.create();\n        configuration.set(\"hbase.rootdir\", \"hdfs://localhost:9000/hbase\");\n        configuration.set(\"hbase.zookeeper.quorum\", \"localhost\");\n        connection = ConnectionFactory.createConnection(configuration);\n        admin = connection.getAdmin();\n    }\n    // 关闭 HBase 连接\n    public static void close() throws IOException {\n        if (admin != null) admin.close();\n        if (connection != null) connection.close();\n    }\n    // 清空指定表的所有数据，保留列簇结构\n    public static void clearRows(String tableNameStr) throws IOException {\n        init(); // 初始化连接\n        TableName tableName = TableName.valueOf(tableNameStr);\n        if (!admin.tableExists(tableName)) {\n            System.out.println(\"表不存在，无法清空！\");\n            close();\n            return;\n        }\n        // 获取原始表结构\n        TableDescriptor descriptor = admin.getDescriptor(tableName);\n        // 禁用表\n        if (!admin.isTableDisabled(tableName)) {\n            admin.disableTable(tableName);\n        }\n        // 删除表\n        admin.deleteTable(tableName);\n        // 重新创建表（使用原结构）\n        admin.createTable(descriptor);\n        System.out.println(\"表 [\" + tableNameStr + \"] 已清空（保留列簇结构）\");\n        close(); // 关闭连接\n    }\n}\n\n```\n\n![image-20250408182815289](../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/073c2af343c85961acffe8bcfe440c1855933597-1746692007781-512-1747299497351-137-1747900721330-137-1749470495098-138.png)\n\n这时候再去查表\n\n![image-20250408182848140](../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/af59211330068025067a668b71a2da5b55933597-1746692007781-513-1747299497351-138-1747900721330-138-1749470495098-139.png)\n\n---\n\n⑤统计表的行数。\n\n==shell==\n\n```\nput 's1','zhangsan','score:Math','69'\ncount  's1'\n```\n\n![image-20250408182937568](../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/981c0e0a9e8be7f01f8de72ca3ddb26555933597-1746692007781-514-1747299497351-139-1747900721330-139-1749470495098-140.png)\n\n==java==\n\n```\nimport org.apache.hadoop.conf.Configuration;\nimport org.apache.hadoop.hbase.HBaseConfiguration;\nimport org.apache.hadoop.hbase.TableName;\nimport org.apache.hadoop.hbase.client.*;\n\nimport java.io.IOException;\n\npublic class test {\n    public static Configuration configuration;\n    public static Connection connection;\n    public static Admin admin;\n\n    public static void main(String[] args) throws IOException {\n        String tableName = \"s1\"; // 你要统计的表名\n        countRows(tableName);\n    }\n\n    // 初始化 HBase 连接\n    public static void init() throws IOException {\n        configuration = HBaseConfiguration.create();\n        configuration.set(\"hbase.rootdir\", \"hdfs://localhost:9000/hbase\");\n        configuration.set(\"hbase.zookeeper.quorum\", \"localhost\");\n        connection = ConnectionFactory.createConnection(configuration);\n        admin = connection.getAdmin();\n    }\n\n    // 关闭 HBase 连接\n    public static void close() throws IOException {\n        if (admin != null) admin.close();\n        if (connection != null) connection.close();\n    }\n\n    // 统计表的行数\n    public static void countRows(String tableName) throws IOException {\n        init(); // 初始化连接\n\n        Table table = connection.getTable(TableName.valueOf(tableName));\n        Scan scan = new Scan();\n        scan.setCaching(500); // 可选优化，加快扫描速度\n\n        ResultScanner scanner = table.getScanner(scan);\n\n        int num = 0;\n        for (Result result = scanner.next(); result != null; result = scanner.next()) {\n            num++;\n        }\n\n        System.out.println(\"表 [\" + tableName + \"] 的总行数为: \" + num);\n\n        scanner.close();\n        table.close(); // 关闭 Table 对象\n        close();       // 关闭连接\n    }\n}\n\n```\n\n![image-20250408183057896](../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/6a04692ff70305b199bc63ac2b63d60b55933597-1746692007781-515-1747299497351-140-1747900721330-140-1749470495098-141.png)\n\n### 第二题\n\n （2）现有以下关系数据库中的表（见表4-21、表4-22和表4-23），要求将其转换为适合HBase存储的表并插入数据。\n\n表4-21 学生（Student）表      \n\n| 学号（S_No） | 姓名（S_Name） | 性别（S_Sex） | 年龄（S_Age） |\n| ------------ | -------------- | ------------- | ------------- |\n| 2015001      | Zhangsan       | male          | 23            |\n| 2015002      | Mary           | female        | 22            |\n| 2015003      | Lisi           | male          | 24            |\n\n表4-22 课程（Course）表         \n\n| 课程号（C_No） | 课程名（C_Name） | 学分（C_Credit） |\n| -------------- | ---------------- | ---------------- |\n| 123001         | Math             | 2.0              |\n| 123002         | Computer Science | 5.0              |\n| 123003         | English          | 3.0              |\n\n表4-23  选课（SC）表                  \n\n| 学号（SC_Sno） | 课程号（SC_Cno） | 成绩（SC_Score） |\n| -------------- | ---------------- | ---------------- |\n| 2015001        | 123001           | 86               |\n| 2015001        | 123003           | 69               |\n| 2015002        | 123002           | 77               |\n| 2015002        | 123003           | 99               |\n| 2015003        | 123001           | 98               |\n| 2015003        | 123002           | 95               |\n\n==shell==\n\n```\ndisable 'student'\ndrop 'student'\n```\n\n创建学生 student表\n\n```\ncreate 'Student','S_No','S_Name','S_Sex','S_Age'\nput 'Student','s001','S_No','2015001'\nput 'Student','s001','S_Name','Zhangsan'\nput 'Student','s001','S_Sex','male'\nput 'Student','s001','S_Age','23'\nput 'Student','s002','S_No','2015002'\nput 'Student','s002','S_Name','Mary'\nput 'Student','s002','S_Sex','female'\nput 'Student','s002','S_Age','22'\nput 'Student','s003','S_No','2015003'\nput 'Student','s003','S_Name','Lisi'\nput 'Student','s003','S_Sex','male'\nput 'Student','s003','S_Age','24'\n\n```\n\n![image-20250408183744904](../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/5e31a2708e11baa119c76ecde299ab6355933597-1746692007781-516-1747299497351-141-1747900721330-141-1749470495098-142.png)\n\n创建课程 Course 表\n\n```\ncreate 'Course','C_No','C_Name','C_Credit'\nput 'Course','c001','C_No','123001'\nput 'Course','c001','C_Name','Math'\nput 'Course','c001','C_Credit','2.0'\nput 'Course','c002','C_No','123002'\nput 'Course','c002','C_Name','Computer'\nput 'Course','c002','C_Credit','5.0'\nput 'Course','c003','C_No','123003'\nput 'Course','c003','C_Name','English'\nput 'Course','c003','C_Credit','3.0'\n```\n\n![image-20250408183801194](../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/b90f6dce4ae75d8d6aae1ff094bbddb455933597-1746692007781-517-1747299497351-142-1747900721330-142-1749470495098-144.png)\n\n创建选课 SC 表\n\n```\ncreate 'SC','SC_Sno','SC_Cno','SC_Score'\nput 'SC','sc001','SC_Sno','2015001'\nput 'SC','sc001','SC_Cno','123001'\nput 'SC','sc001','SC_Score','86'\nput 'SC','sc002','SC_Sno','2015001'\nput 'SC','sc002','SC_Cno','123003'\nput 'SC','sc002','SC_Score','69'\nput 'SC','sc003','SC_Sno','2015002'\nput 'SC','sc003','SC_Cno','123002'\nput 'SC','sc003','SC_Score','77'\nput 'SC','sc004','SC_Sno','2015002'\nput 'SC','sc004','SC_Cno','123003'\nput 'SC','sc004','SC_Score','99'\nput 'SC','sc005','SC_Sno','2015003'\nput 'SC','sc005','SC_Cno','123001'\nput 'SC','sc005','SC_Score','98'\nput 'SC','sc006','SC_Sno','2015003'\nput 'SC','sc006','SC_Cno','123002'\nput 'SC','sc006','SC_Score','95'\n```\n\n![image-20250408183820490](../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/5c7e6e07073a4fc9aaab422f5d7ea6ff55933597-1746692007781-518-1747299497351-144-1747900721330-143-1749470495098-143.png)\n\n验证\n\n```\nscan 'Student'\nscan 'Course'\nscan 'SC'\n```\n\n![image-20250408184041557](../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/32917960477379ca6d005534185fbfd555933597-1746692007781-519-1747299497351-143-1747900721330-144-1749470495098-145.png)\n\n```\ndisable 'Student'\ndrop 'Student'\ndisable 'Course'\ndrop 'Course'\ndisable 'SC'\ndrop 'SC'\n```\n\n\n\n==java==\n\n① createTable(String tableName, String[] fields)。\n\n② addRecord(String tableName, String row, String[] fields, String[]values)。\n\n③ scanColumn(String tableName, String column)。\n\n④ modifyData(String tableName, String row, String column)。\n\n⑤ deleteRow(String tableName, String row)。\n\n```java\nimport java.io.IOException;\nimport org.apache.hadoop.conf.Configuration;\nimport org.apache.hadoop.hbase.*;\nimport org.apache.hadoop.hbase.client.*;\nimport org.apache.hadoop.hbase.util.Bytes;\n\npublic class test {\n    static Connection connection;\n    static Admin admin;\n\n    public static void init() throws IOException {\n        Configuration conf = HBaseConfiguration.create();\n        conf.set(\"hbase.zookeeper.quorum\", \"localhost\");\n        connection = ConnectionFactory.createConnection(conf);\n        admin = connection.getAdmin();\n    }\n\n    public static void close() throws IOException {\n        if (admin != null) admin.close();\n        if (connection != null) connection.close();\n    }\n\n    public static void createTable(String tableName, String[] fields) throws IOException {\n        init();\n        TableName tablename = TableName.valueOf(tableName);\n        if (admin.tableExists(tablename)) {\n            System.out.println(\"表 \" + tableName + \" 已存在，正在删除...\");\n            admin.disableTable(tablename);\n            admin.deleteTable(tablename);\n        }\n        TableDescriptorBuilder tableDescriptor = TableDescriptorBuilder.newBuilder(tablename);\n        for (String str : fields) {\n            tableDescriptor.setColumnFamily(ColumnFamilyDescriptorBuilder.newBuilder(Bytes.toBytes(str)).build());\n        }\n        admin.createTable(tableDescriptor.build());\n        System.out.println(\"表 \" + tableName + \" 创建成功\");\n        close();\n    }\n\n    public static void addRecord(String tableName, String row, String[] fields, String[] values) throws IOException {\n        init();\n        Table table = connection.getTable(TableName.valueOf(tableName));\n        Put put = new Put(Bytes.toBytes(row));\n        for (int i = 0; i < fields.length; i++) {\n            String[] parts = fields[i].split(\":\");\n            put.addColumn(Bytes.toBytes(parts[0], Bytes.toBytes(parts[1], Bytes.toBytes(values[i]);\n        }\n        table.put(put);\n        table.close();\n        close();\n    }\n\n    public static void scanColumn(String tableName, String column) throws IOException {\n        init();\n        Table table = connection.getTable(TableName.valueOf(tableName));\n        Scan scan = new Scan();\n        if (column.contains(\":\")) {\n            String[] parts = column.split(\":\");\n            scan.addColumn(Bytes.toBytes(parts[0], Bytes.toBytes(parts[1]);\n        } else {\n            scan.addFamily(Bytes.toBytes(column));\n        }\n        ResultScanner scanner = table.getScanner(scan);\n        for (Result result = scanner.next(); result != null; result = scanner.next()) {\n            showCell(result);\n        }\n        scanner.close();\n        table.close();\n        close();\n    }\n\n    public static void showCell(Result result) {\n        for (Cell cell : result.rawCells()) {\n            System.out.println(\"RowName: \" + Bytes.toString(CellUtil.cloneRow(cell)));\n            System.out.println(\"Timestamp: \" + cell.getTimestamp());\n            System.out.println(\"ColumnFamily: \" + Bytes.toString(CellUtil.cloneFamily(cell)));\n            System.out.println(\"Column: \" + Bytes.toString(CellUtil.cloneQualifier(cell)));\n            System.out.println(\"Value: \" + Bytes.toString(CellUtil.cloneValue(cell)));\n            System.out.println(\"----------------------------------------\");\n        }\n    }\n\n    public static void modifyData(String tableName, String row, String column, String val) throws IOException {\n        init();\n        Table table = connection.getTable(TableName.valueOf(tableName));\n        String[] parts = column.split(\":\");\n        Put put = new Put(Bytes.toBytes(row));\n        put.addColumn(Bytes.toBytes(parts[0], Bytes.toBytes(parts[1], Bytes.toBytes(val));\n        table.put(put);\n        System.out.println(\"修改表 \" + tableName + \" 中 \" + row + \" 行的列 \" + column + \" 为 \" + val);\n        table.close();\n        close();\n    }\n\n    public static void deleteRow(String tableName, String row) throws IOException {\n        init();\n        Table table = connection.getTable(TableName.valueOf(tableName));\n        Delete delete = new Delete(Bytes.toBytes(row));\n        table.delete(delete);\n        System.out.println(\"删除表 \" + tableName + \" 中的行 \" + row);\n        table.close();\n        close();\n    }\n\n    public static void main(String[] args) throws IOException {\n        // Student 表\n        createTable(\"Student\", new String[]{\"S_No\", \"S_Name\", \"S_Sex\", \"S_Age\"});\n        addRecord(\"Student\", \"s001\", new String[]{\"S_No:S_No\", \"S_Name:S_Name\", \"S_Sex:S_Sex\", \"S_Age:S_Age\"},\n                new String[]{\"2015001\", \"Zhangsan\", \"male\", \"23\"});\n        addRecord(\"Student\", \"s002\", new String[]{\"S_No:S_No\", \"S_Name:S_Name\", \"S_Sex:S_Sex\", \"S_Age:S_Age\"},\n                new String[]{\"2015002\", \"Mary\", \"female\", \"22\"});\n        addRecord(\"Student\", \"s003\", new String[]{\"S_No:S_No\", \"S_Name:S_Name\", \"S_Sex:S_Sex\", \"S_Age:S_Age\"},\n                new String[]{\"2015003\", \"Lisi\", \"male\", \"24\"});\n        System.out.println(\"Student 表插入数据成功\");\n\n        // Course 表\n        createTable(\"Course\", new String[]{\"C_No\", \"C_Name\", \"C_Credit\"});\n        addRecord(\"Course\", \"c001\", new String[]{\"C_No:C_No\", \"C_Name:C_Name\", \"C_Credit:C_Credit\"},\n                new String[]{\"123001\", \"Math\", \"2.0\"});\n        addRecord(\"Course\", \"c002\", new String[]{\"C_No:C_No\", \"C_Name:C_Name\", \"C_Credit:C_Credit\"},\n                new String[]{\"123002\", \"Computer\", \"5.0\"});\n        addRecord(\"Course\", \"c003\", new String[]{\"C_No:C_No\", \"C_Name:C_Name\", \"C_Credit:C_Credit\"},\n                new String[]{\"123003\", \"English\", \"3.0\"});\n        System.out.println(\"Course 表插入数据成功\");\n\n        // SC 表\n        createTable(\"SC\", new String[]{\"SC_Sno\", \"SC_Cno\", \"SC_Score\"});\n        addRecord(\"SC\", \"sc001\", new String[]{\"SC_Sno:SC_Sno\", \"SC_Cno:SC_Cno\", \"SC_Score:SC_Score\"},\n                new String[]{\"2015001\", \"123001\", \"86\"});\n        addRecord(\"SC\", \"sc002\", new String[]{\"SC_Sno:SC_Sno\", \"SC_Cno:SC_Cno\", \"SC_Score:SC_Score\"},\n                new String[]{\"2015001\", \"123003\", \"69\"});\n        addRecord(\"SC\", \"sc003\", new String[]{\"SC_Sno:SC_Sno\", \"SC_Cno:SC_Cno\", \"SC_Score:SC_Score\"},\n                new String[]{\"2015002\", \"123002\", \"77\"});\n        addRecord(\"SC\", \"sc004\", new String[]{\"SC_Sno:SC_Sno\", \"SC_Cno:SC_Cno\", \"SC_Score:SC_Score\"},\n                new String[]{\"2015002\", \"123003\", \"99\"});\n        addRecord(\"SC\", \"sc005\", new String[]{\"SC_Sno:SC_Sno\", \"SC_Cno:SC_Cno\", \"SC_Score:SC_Score\"},\n                new String[]{\"2015003\", \"123001\", \"98\"});\n        addRecord(\"SC\", \"sc006\", new String[]{\"SC_Sno:SC_Sno\", \"SC_Cno:SC_Cno\", \"SC_Score:SC_Score\"},\n                new String[]{\"2015003\", \"123002\", \"95\"});\n        System.out.println(\"SC 表插入数据成功\");\n\n        // 示例输出\n        System.out.println(\"===== 浏览 Student 表的全部 S_Name 列族 =====\");\n        scanColumn(\"Student\", \"S_Name\");\n\n        System.out.println(\"===== 修改 Student 表中 s002 的 S_Age 为 25 =====\");\n        modifyData(\"Student\", \"s002\", \"S_Age:S_Age\", \"25\");\n\n        System.out.println(\"===== 删除 Student 表中的 s003 =====\");\n        deleteRow(\"Student\", \"s003\");\n    }\n}\n\n```\n\n![image-20250408190024787](../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/6558a1532abdadb376905f6513ac10ce55933597-1746692007782-520-1747299497351-145-1747900721330-145-1749470495098-146.png)\n\n## （7.5.5）\n\n### 基础\n\n自行开启hadoop集群和hbase\n\n```\ncd\ncat > wordfile1.txt<<\"EOF\"\nI love Spark\nI love Hadoop\nEOF\ncat > wordfile2.txt<<\"EOF\"\nHadoop is good\nSpark is fast\nEOF\nhdfs dfs -rm -r input\nhdfs dfs -rm -r output\nhdfs dfs -mkdir input\nhdfs dfs -put wordfile1.txt input\nhdfs dfs -put wordfile2.txt input\n```\n\n![image-20250508151954700](../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/b7c6ae4b33cc17a2deb9057b404fe7a655933597-1746692007782-521-1747299497351-146-1747900721330-146-1749470495098-147.png)\n\n### 在eclipse创建项目\n\n启动eclipse\n\n```\neclipse\n```\n\n创建项目\n\nFile-new-project\n\n名字：`WordCount`\n\n![image-20250508152019222](../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/ee7d820cccc370c09b7e12965ac9f30655933597-1746692007782-522-1747299497351-147-1747900721330-147-1749470495098-149.png)\n\n为了编写一个MapReduce程序，一般需要向Java工程中添加以下JAR包：\n（1)`/usr/local/hadoop/share/hadoop/common`目录下的`hadoop-common-3.1.3.jar`和`haoop-nfs-3.1.3.jar`；\n（2)`/usr/local/hadoop/share/hadoop/common/lib`目录下的`所有JAR包`；\n（3)`/usr/local/hadoop/share/hadoop/mapreduce`目录下的`所有JAR包`，但是，`不包括jdiff、lib-examples和sources目录`.\n\n![image-20250508152028054](../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/6e5dba872fef1b72dcb96aa60032bcaa55933597-1746692007782-523-1747299497351-148-1747900721330-148-1749470495098-148.png)\n\n添加完成就finish就行\n\n### 编写Java应用程序\n\n创建`WordCount.java`,自己看好，以后不会再说了\n\n![image-20250508152037946](../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/d12d00e0e59333d347ab4f14c335af9d55933597-1746692007782-524-1747299497351-149-1747900721330-149-1749470495098-150.png)\n\n添加代码\n\n```java\nimport java.io.IOException;\nimport java.util.Iterator;\nimport java.util.StringTokenizer;\nimport org.apache.hadoop.conf.Configuration;\nimport org.apache.hadoop.fs.Path;\nimport org.apache.hadoop.io.IntWritable;\nimport org.apache.hadoop.io.Text;\nimport org.apache.hadoop.mapreduce.Job;\nimport org.apache.hadoop.mapreduce.Mapper;\nimport org.apache.hadoop.mapreduce.Reducer;\nimport org.apache.hadoop.mapreduce.lib.input.FileInputFormat;\nimport org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;\nimport org.apache.hadoop.util.GenericOptionsParser;\npublic class WordCount {\n    public WordCount() {\n    }\n     public static void main(String[] args) throws Exception {\n        Configuration conf = new Configuration();\n        String[] otherArgs = (new GenericOptionsParser(conf, args)).getRemainingArgs();\n        if(otherArgs.length < 2) {\n            System.err.println(\"Usage: wordcount <in> [<in>...] <out>\");\n            System.exit(2);\n        }\n        Job job = Job.getInstance(conf, \"word count\");\n        job.setJarByClass(WordCount.class);\n        job.setMapperClass(WordCount.TokenizerMapper.class);\n        job.setCombinerClass(WordCount.IntSumReducer.class);\n        job.setReducerClass(WordCount.IntSumReducer.class);\n        job.setOutputKeyClass(Text.class);\n        job.setOutputValueClass(IntWritable.class); \n        for(int i = 0; i < otherArgs.length - 1; ++i) {\n            FileInputFormat.addInputPath(job, new Path(otherArgs[i]);\n        }\n        FileOutputFormat.setOutputPath(job, new Path(otherArgs[otherArgs.length - 1]);\n        System.exit(job.waitForCompletion(true)?0:1);\n    }\n    public static class TokenizerMapper extends Mapper<Object, Text, Text, IntWritable> {\n        private static final IntWritable one = new IntWritable(1);\n        private Text word = new Text();\n        public TokenizerMapper() {\n        }\n        public void map(Object key, Text value, Mapper<Object, Text, Text, IntWritable>.Context context) throws IOException, InterruptedException {\n            StringTokenizer itr = new StringTokenizer(value.toString()); \n            while(itr.hasMoreTokens()) {\n                this.word.set(itr.nextToken());\n                context.write(this.word, one);\n            }\n        }\n    }\npublic static class IntSumReducer extends Reducer<Text, IntWritable, Text, IntWritable> {\n        private IntWritable result = new IntWritable();\n        public IntSumReducer() {\n        }\n        public void reduce(Text key, Iterable<IntWritable> values, Reducer<Text, IntWritable, Text, IntWritable>.Context context) throws IOException, InterruptedException {\n            int sum = 0;\n            IntWritable val;\n            for(Iterator i$ = values.iterator(); i$.hasNext(); sum += val.get()) {\n                val = (IntWritable)i$.next();\n            }\n            this.result.set(sum);\n            context.write(key, this.result);\n        }\n    }\n}\n```\n\n运行一下\n\n![image-20250508152047998](../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/ed5660e7f99bf786444e3ca5dc01aeca55933597-1746692007782-525-1747299497351-151-1747900721330-150-1749470495098-151.png)\n\n> 7.5.5截图1\n\n### 编译打包程序\n\n如果你没有myapp文件夹你就自己创建，我的是有的\n\n![image-20250508152056980](../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/61642003432b78f55cab6505fa1742ac55933597-1746692007782-526-1747299497351-150-1747900721330-151-1749470495098-152.png)\n\n![image-20250508152109370](../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/248cd9a79f38735b1cd8594baf84d9d555933597-1746692007782-527-1747299497351-152-1747900721330-153-1749470495098-153.png)\n\n\n\n![image-20250508152443407](../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/d5da5d88e74e5be4a0209559bbeefad455933597-1746692007782-528-1747299497351-153-1747900721330-152-1749470495098-155.png)\n\n选择`WordCount`项目\n\n填写路径`/usr/local/hadoop/myapp/WordCount.jar`\n\n然后`finish`\n\n这时候会有弹窗，一路`ok下来`就行了\n\n```\nll  /usr/local/hadoop/myapp\n```\n\n![image-20250508152129030](../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/c37f9d8706aaf5419770baf2a840253755933597-1746692007782-529-1747299497352-154-1747900721330-154-1749470495098-154.png)\n\n### 运行程序\n\n```\nhadoop jar /usr/local/hadoop/myapp/WordCount.jar input output\nhdfs dfs -cat output/*\n```\n\n![image-20250508152139398](../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/4136c00c46c5a26bf1daef363b79467455933597-1746692007782-530-1747299497352-155-1747900721330-155-1749470495098-156.png)\n\n![image-20250508152151659](../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/0e03c562f7b2919d9a19b3be3a0d176255933597-1746692007782-531-1747299497352-156-1747900721330-156-1749470495098-158.png)\n\n> 7.5.5 截图2和3\n\n\n\n## （7.3.4）\n\n==第四题==\n\n==shell==\n\n```\ncat > avg.txt <<\"EOF\"\nmath 80\nmath 90\nenglish 70\nenglish 100\nEOF\nhdfs dfs -rm -r input\nhdfs dfs -rm -r output\nhdfs dfs -mkdir input\nhdfs dfs -put avg.txt input\n```\n\n创建`AverageCalculator.java`\n\n```java\nimport org.apache.hadoop.conf.Configuration;\nimport org.apache.hadoop.fs.Path;\nimport org.apache.hadoop.io.IntWritable;\nimport org.apache.hadoop.io.LongWritable;\nimport org.apache.hadoop.io.Text;\nimport org.apache.hadoop.mapreduce.Job;\nimport org.apache.hadoop.mapreduce.Mapper;\nimport org.apache.hadoop.mapreduce.Reducer;\nimport org.apache.hadoop.mapreduce.lib.input.FileInputFormat;\nimport org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;\n\nimport java.io.IOException;\n\npublic class AverageCalculator {\n\n    public static class AvgMapper extends Mapper<LongWritable, Text, Text, IntWritable> {\n        private Text keyOut = new Text();\n        private IntWritable valOut = new IntWritable();\n\n        @Override\n        protected void map(LongWritable key, Text value, Context context)\n                throws IOException, InterruptedException {\n            String[] parts = value.toString().split(\"\\\\s+\");\n            if (parts.length == 2) {\n                keyOut.set(parts[0];\n                valOut.set(Integer.parseInt(parts[1]);\n                context.write(keyOut, valOut);\n            }\n        }\n    }\n\n    public static class AvgReducer extends Reducer<Text, IntWritable, Text, IntWritable> {\n        private IntWritable result = new IntWritable();\n\n        @Override\n        protected void reduce(Text key, Iterable<IntWritable> values, Context context)\n                throws IOException, InterruptedException {\n            int sum = 0;\n            int count = 0;\n            for (IntWritable val : values) {\n                sum += val.get();\n                count++;\n            }\n            if (count != 0) {\n                result.set(sum / count);\n                context.write(key, result);\n            }\n        }\n    }\n\n    public static void main(String[] args) throws Exception {\n        if (args.length != 2) {\n            System.err.println(\"Usage: AverageCalculator <input path> <output path>\");\n            System.exit(-1);\n        }\n\n        Configuration conf = new Configuration();\n        Job job = Job.getInstance(conf, \"Average Calculator\");\n        job.setJarByClass(AverageCalculator.class);\n\n        job.setMapperClass(AvgMapper.class);\n        job.setReducerClass(AvgReducer.class);\n\n        job.setOutputKeyClass(Text.class);\n        job.setOutputValueClass(IntWritable.class);\n\n        FileInputFormat.setInputPaths(job, new Path(args[0]);\n        FileOutputFormat.setOutputPath(job, new Path(args[1]);\n\n        System.exit(job.waitForCompletion(true) ? 0 : 1);\n    }\n}\n\n```\n\n自己运行一下，不然下面打包程序出现不了，运行报错别管，运行就对了，别问\n\n自己运行一下，不然下面打包程序出现不了，运行报错别管，运行就对了，别问\n\n自己运行一下，不然下面打包程序出现不了，运行报错别管，运行就对了，别问\n\n自己运行一下，不然下面打包程序出现不了，运行报错别管，运行就对了，别问\n\n==打包项目==\n\n这是打包java项目的路径教程，自己看，后面还会有各种java要打包，后面不会再说了\n\n![image-20250508152109370](../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/248cd9a79f38735b1cd8594baf84d9d555933597-1746692007782-527-1747299497351-152-1747900721330-153-1749470495098-153.png)\n\n![image-20250508144848815](../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/6097eb929713ca7dc7077f72409911b455933597-1746692007782-533-1747299497352-157-1747900721330-158-1749470495098-157.png)\n\n一路ok\n\n```\nhadoop jar /usr/local/hadoop/myapp/AverageCalculator.jar input output\nhadoop dfs -cat output/*\n```\n\n![image-20250508145036243](../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/88ceb627c2201a1dbb32a8372e649e6355933597-1746692007782-534-1747299497352-158-1747900721330-157-1749470495098-160.png)\n\n> 这个是第四题的图片\n\n\n\n\n\n==第八题和第九题==\n\n```\ncat > maxmin.txt <<\"EOF\"\n23\n45\n12\n67\n89\n34\n56\nEOF\nhdfs dfs -rm -r input\nhdfs dfs -rm -r output\nhdfs dfs -mkdir input\nhdfs dfs -put maxmin.txt input\n```\n\n创建`MaxMinValue.java`\n\n```java\nimport org.apache.hadoop.conf.Configuration;\nimport org.apache.hadoop.fs.Path;\nimport org.apache.hadoop.io.IntWritable;\nimport org.apache.hadoop.io.LongWritable;\nimport org.apache.hadoop.io.Text;\nimport org.apache.hadoop.mapreduce.Job;\nimport org.apache.hadoop.mapreduce.Mapper;\nimport org.apache.hadoop.mapreduce.Reducer;\nimport org.apache.hadoop.mapreduce.lib.input.FileInputFormat;\nimport org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;\n\nimport java.io.IOException;\n\npublic class MaxMinValue {\n\n    public static class MaxMinMapper extends Mapper<LongWritable, Text, Text, IntWritable> {\n        private IntWritable valueOut = new IntWritable();\n\n        @Override\n        protected void map(LongWritable key, Text value, Context context) throws IOException, InterruptedException {\n            int num = Integer.parseInt(value.toString());\n            valueOut.set(num);\n            context.write(new Text(\"max\"), valueOut);\n            context.write(new Text(\"min\"), valueOut);\n        }\n    }\n\n    public static class MaxMinReducer extends Reducer<Text, IntWritable, Text, IntWritable> {\n        private IntWritable result = new IntWritable();\n\n        @Override\n        protected void reduce(Text key, Iterable<IntWritable> values, Context context)\n                throws IOException, InterruptedException {\n            int finalValue = key.toString().equals(\"max\") ? Integer.MIN_VALUE : Integer.MAX_VALUE;\n\n            for (IntWritable val : values) {\n                if (key.toString().equals(\"max\")) {\n                    finalValue = Math.max(finalValue, val.get());\n                } else if (key.toString().equals(\"min\")) {\n                    finalValue = Math.min(finalValue, val.get());\n                }\n            }\n\n            result.set(finalValue);\n            context.write(key, result);\n        }\n    }\n\n    public static void main(String[] args) throws Exception {\n        Configuration conf = new Configuration();\n        Job job = Job.getInstance(conf, \"Max and Min Values\");\n\n        job.setJarByClass(MaxMinValue.class);\n        job.setMapperClass(MaxMinMapper.class);\n        job.setReducerClass(MaxMinReducer.class);\n\n        job.setOutputKeyClass(Text.class);\n        job.setOutputValueClass(IntWritable.class);\n\n        FileInputFormat.setInputPaths(job, new Path(args[0]);\n        FileOutputFormat.setOutputPath(job, new Path(args[1]);\n\n        System.exit(job.waitForCompletion(true) ? 0 : 1);\n    }\n}\n\n```\n\n然后自己`打包程序`，不会就去翻前面，前面有说\n\n![image-20250508150606591](../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/b790a45036594ee7a01ec92264eae17455933597-1746692007782-535-1747299497352-159-1747900721330-159-1749470495098-159.png)\n\n```\nhadoop jar /usr/local/hadoop/myapp/MaxMinValue.jar input output\nhadoop dfs -cat output/*\n```\n\n![image-20250508150707867](../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/e226581c924c43648f17a029be07dd7a55933597-1746692007782-536-1747299497352-160-1747900721330-160-1749470495098-161.png)\n\n> 这个是第八题和第九题的图片\n\n接下来的创建java打包程序不说了，自己翻前面的\n\n\n\n\n\n==第十题==\n\n```\ncat > SalesVolume.txt <<\"EOF\"\n2025-01-01 200\n2025-01-15 150\n2025-02-10 300\n2025-02-25 250\n2025-03-05 400\n2025-03-15 350\nEOF\nhdfs dfs -rm -r input\nhdfs dfs -rm -r output\nhdfs dfs -mkdir input\nhdfs dfs -put SalesVolume.txt input\n```\n\n创建`SalesByMonth.java`\n\n```java\nimport org.apache.hadoop.conf.Configuration;\nimport org.apache.hadoop.fs.Path;\nimport org.apache.hadoop.io.IntWritable;\nimport org.apache.hadoop.io.LongWritable;\nimport org.apache.hadoop.io.Text;\nimport org.apache.hadoop.mapreduce.Job;\nimport org.apache.hadoop.mapreduce.Mapper;\nimport org.apache.hadoop.mapreduce.Reducer;\nimport org.apache.hadoop.mapreduce.lib.input.FileInputFormat;\nimport org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;\n\nimport java.io.IOException;\n\npublic class SalesByMonth {\n\n    public static class SalesMapper extends Mapper<LongWritable, Text, Text, IntWritable> {\n        private Text month = new Text();\n        private IntWritable salesAmount = new IntWritable();\n\n        @Override\n        protected void map(LongWritable key, Text value, Context context) throws IOException, InterruptedException {\n            String[] parts = value.toString().split(\"\\\\s+\");\n            String date = parts[0];  // 日期格式为 YYYY-MM-DD\n            int amount = Integer.parseInt(parts[1];  // 销售金额\n\n            // 提取月份（格式为 YYYY-MM）\n            String yearMonth = date.substring(0, 7);\n            month.set(yearMonth);\n            salesAmount.set(amount);\n\n            context.write(month, salesAmount);\n        }\n    }\n\n    public static class SalesReducer extends Reducer<Text, IntWritable, Text, IntWritable> {\n        private IntWritable result = new IntWritable();\n\n        @Override\n        protected void reduce(Text key, Iterable<IntWritable> values, Context context)\n                throws IOException, InterruptedException {\n            int totalSales = 0;\n\n            for (IntWritable val : values) {\n                totalSales += val.get();\n            }\n\n            result.set(totalSales);\n            context.write(key, result);\n        }\n    }\n\n    public static void main(String[] args) throws Exception {\n        Configuration conf = new Configuration();\n        Job job = Job.getInstance(conf, \"Sales by Month\");\n\n        job.setJarByClass(SalesByMonth.class);\n        job.setMapperClass(SalesMapper.class);\n        job.setReducerClass(SalesReducer.class);\n\n        job.setOutputKeyClass(Text.class);\n        job.setOutputValueClass(IntWritable.class);\n\n        FileInputFormat.setInputPaths(job, new Path(args[0]);\n        FileOutputFormat.setOutputPath(job, new Path(args[1]);\n\n        System.exit(job.waitForCompletion(true) ? 0 : 1);\n    }\n}\n\n```\n\n自己打包程序，然后运行程序\n\n```\nhadoop jar /usr/local/hadoop/myapp/SalesByMonth.jar input output\nhadoop dfs -cat output/*\n```\n\n![image-20250508151430701](../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/b139c3b6ed2dd067a6205773a6886d8555933597-1746692007782-537-1747299497352-161-1747900721330-161-1749470495098-162.png)\n\n> 这是第十题的图片\n\n## 实验四\n\n### 第一题\n\n#### shell\n\n1．编程实现文件合并和去重操作\n\n==shell==\n\n对于两个输入文件，即文件A和文件B，请编写MapReduce程序，对两个文件进行合并，并剔除其中重复的内容，得到一个新的输出文件C。下面是输入文件和输出文件的一个样例，以供参考。\n\n```\ncat >a.txt<<\"EOF\"\n20150101    x\n20150102    y\n20150103    x\n20150104    y\n20150105    z\n20150106    x\nEOF\ncat >b.txt<<\"EOF\"\n20150101     y\n20150102     y\n20150103     x\n20150104     z\n20150105     y\nEOF\nhdfs dfs -rm -r input\nhdfs dfs -rm -r output\nhdfs dfs -mkdir input\nhdfs dfs -put a.txt input\nhdfs dfs -put b.txt input\n```\n\n![image-20250508155455652](../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/ae79fafc4e921a8b98dc0a3ca1b7a7e155933597-1747299497352-162-1747900721330-162-1749470495098-163.png)\n\n创建`Merge.java`\n\n```java\n\nimport java.io.IOException;\nimport java.util.StringTokenizer;\n\nimport org.apache.hadoop.conf.Configuration;\nimport org.apache.hadoop.fs.Path;\nimport org.apache.hadoop.io.Text;\nimport org.apache.hadoop.mapreduce.Job;\nimport org.apache.hadoop.mapreduce.Mapper;\nimport org.apache.hadoop.mapreduce.Reducer;\nimport org.apache.hadoop.mapreduce.lib.input.FileInputFormat;\nimport org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;\n\npublic class Merge {\n\n    /**\n     * 对A,B两个文件进行合并，并剔除其中重复的内容，得到一个新的输出文件C\n     */\n\n    // Mapper: 清理每行多余的空白，并作为 key 输出\n    public static class Map extends Mapper<Object, Text, Text, Text> {\n        private Text outKey = new Text();\n\n        public void map(Object key, Text value, Context context) throws IOException, InterruptedException {\n            String line = value.toString().trim(); // 去除首尾空格\n            StringTokenizer tokenizer = new StringTokenizer(line);\n            StringBuilder sb = new StringBuilder();\n            while (tokenizer.hasMoreTokens()) {\n                sb.append(tokenizer.nextToken()).append(\" \"); // 用单空格连接\n            }\n            if (sb.length() > 0) sb.setLength(sb.length() - 1); // 去掉最后一个空格\n            outKey.set(sb.toString());\n            context.write(outKey, new Text(\"\"));\n        }\n    }\n\n    // Reducer: 每个 key 写出一次，达到去重目的\n    public static class Reduce extends Reducer<Text, Text, Text, Text> {\n        public void reduce(Text key, Iterable<Text> values, Context context) throws IOException, InterruptedException {\n            context.write(key, new Text(\"\"));\n        }\n    }\n\n    public static void main(String[] args) throws Exception {\n        Configuration conf = new Configuration();\n        conf.set(\"fs.default.name\", \"hdfs://localhost:9000\");\n\n        String[] otherArgs = new String[]{\"input\", \"output\"};\n        if (otherArgs.length != 2) {\n            System.err.println(\"Usage: Merge <in> <out>\");\n            System.exit(2);\n        }\n\n        Job job = Job.getInstance(conf, \"Merge and Deduplicate\");\n        job.setJarByClass(Merge.class);\n        job.setMapperClass(Map.class);\n        job.setCombinerClass(Reduce.class);\n        job.setReducerClass(Reduce.class);\n\n        job.setOutputKeyClass(Text.class);\n        job.setOutputValueClass(Text.class);\n\n        FileInputFormat.addInputPath(job, new Path(otherArgs[0]);\n        FileOutputFormat.setOutputPath(job, new Path(otherArgs[1]);\n\n        // 强制使用一个 reducer，确保全局去重\n        job.setNumReduceTasks(1);\n\n        System.exit(job.waitForCompletion(true) ? 0 : 1);\n    }\n}\n```\n\n打包程序，然后运行\n\n```\nhadoop jar /usr/local/hadoop/myapp/Merge.jar input output\nhadoop dfs -cat output/*\n```\n\n![image-20250508160448250](../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/90c8bbd767dd5de11bd41dc9d22bd7bc55933597-1747299497352-163-1747900721330-163-1749470495098-165.png)\n\n#### java\n\n==java==\n\n导入hdfs包\n\n![image-20250515163900774](../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/image-20250515163900774-1747900721330-164-1749470495098-164.png)\n\n![image-20250515163913862](../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/image-20250515163913862-1747900721330-165-1749470495099-166.png)\n\n`/usr/local/hadoop/share/hadoop/yarn/lib`下的`所有jar包`\n\n`/usr/local/hadoop/share/hadoop/yarn`下的`所有jar包`\n\n`/usr/local/hadoop/share/hadoop/hdfs`下的这两个包也要添加\n\n![image-20250517182949447](../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/1265942a61b2a35512e94d2e86d7b6f7697559838-1747900721330-166-1749470495099-167.png)\n\n测试文件\n\n```\ncat >a.txt<<\"EOF\"\n20150101    x\n20150102    y\n20150103    x\n20150104    y\n20150105    z\n20150106    x\nEOF\ncat >b.txt<<\"EOF\"\n20150101     y\n20150102     y\n20150103     x\n20150104     z\n20150105     y\nEOF\nhdfs dfs -rm -r input\nhdfs dfs -rm -r output\nhdfs dfs -mkdir input\nhdfs dfs -put a.txt input\nhdfs dfs -put b.txt input\n```\n\n更新`Merge.java`代码\n\n```java\nimport java.io.IOException;\nimport java.util.StringTokenizer;\n\nimport org.apache.hadoop.conf.Configuration;\nimport org.apache.hadoop.fs.Path;\nimport org.apache.hadoop.io.Text;\nimport org.apache.hadoop.mapreduce.Job;\nimport org.apache.hadoop.mapreduce.Mapper;\nimport org.apache.hadoop.mapreduce.Reducer;\nimport org.apache.hadoop.mapreduce.lib.input.FileInputFormat;\nimport org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;\n\npublic class Merge {\n\n    /**\n     * 对A,B两个文件进行合并，并剔除其中重复的内容，得到一个新的输出文件C\n     */\n\n    // Mapper: 清理每行多余的空白，并作为 key 输出\n    public static class Map extends Mapper<Object, Text, Text, Text> {\n        private Text outKey = new Text();\n\n        public void map(Object key, Text value, Context context) throws IOException, InterruptedException {\n            String line = value.toString().trim(); // 去除首尾空格\n            StringTokenizer tokenizer = new StringTokenizer(line);\n            StringBuilder sb = new StringBuilder();\n            while (tokenizer.hasMoreTokens()) {\n                sb.append(tokenizer.nextToken()).append(\" \"); // 用单空格连接\n            }\n            if (sb.length() > 0) sb.setLength(sb.length() - 1); // 去掉最后一个空格\n            outKey.set(sb.toString());\n            context.write(outKey, new Text(\"\"));\n        }\n    }\n\n    // Reducer: 每个 key 写出一次，达到去重目的\n    public static class Reduce extends Reducer<Text, Text, Text, Text> {\n        public void reduce(Text key, Iterable<Text> values, Context context) throws IOException, InterruptedException {\n            context.write(key, new Text(\"\"));\n        }\n    }\n\n    public static void main(String[] args) throws Exception {\n        Configuration conf = new Configuration();\n        conf.set(\"fs.default.name\", \"hdfs://localhost:9000\");\n\n        // 写死输入输出路径\n        String inputPath = \"hdfs://localhost:9000/user/hadoop/input\";\n        String outputPath = \"hdfs://localhost:9000/user/hadoop/output\";\n\n        Job job = Job.getInstance(conf, \"Merge and Deduplicate\");\n        job.setJarByClass(Merge.class);\n        job.setMapperClass(Map.class);\n        job.setCombinerClass(Reduce.class);\n        job.setReducerClass(Reduce.class);\n\n        job.setOutputKeyClass(Text.class);\n        job.setOutputValueClass(Text.class);\n\n        FileInputFormat.addInputPath(job, new Path(inputPath));\n        FileOutputFormat.setOutputPath(job, new Path(outputPath));\n\n        // 强制使用一个 reducer，确保全局去重\n        job.setNumReduceTasks(1);\n\n        System.exit(job.waitForCompletion(true) ? 0 : 1);\n    }\n}\n```\n\n![image-20250515164951693](../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/image-20250515164951693-1747900721330-167-1749470495099-168.png)\n\n查看结果\n\n```\nhadoop dfs -cat output/*\n```\n\n![image-20250515165032947](../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/image-20250515165032947-1747900721330-168-1749470495099-169.png)\n\n### 第二题\n\n#### shell\n\n2．编程实现对输入文件的排序\n\n现在有多个输入文件，每个文件中的每行内容均为一个整数。要求读取所有文件中的整数，进行升序排列后，将其输出到一个新的文件中，输出的数据格式为每行两个整数，第一个整数为第二个整数的排序位次，第二个整数为原待排列的整数。下面是输入文件和输出文件的一个样例，以供参考。\n\n==shell==\n\n```\ncat >a.txt<<\"EOF\"\n33\n37\n12\n40\nEOF\ncat >b.txt<<\"EOF\"\n4\n16\n39\n5\nEOF\ncat >c.txt<<\"EOF\"\n1\n45\n25\nEOF\nhdfs dfs -rm -r input\nhdfs dfs -rm -r output\nhdfs dfs -mkdir input\nhdfs dfs -put a.txt input\nhdfs dfs -put b.txt input\nhdfs dfs -put c.txt input\n```\n\n创建`MergeSort.java`\n\n```java\nimport java.io.IOException;\nimport org.apache.hadoop.conf.Configuration;\nimport org.apache.hadoop.fs.Path;\nimport org.apache.hadoop.io.IntWritable;\nimport org.apache.hadoop.io.Text;\nimport org.apache.hadoop.mapreduce.Job;\nimport org.apache.hadoop.mapreduce.Mapper;\nimport org.apache.hadoop.mapreduce.Partitioner;\nimport org.apache.hadoop.mapreduce.Reducer;\nimport org.apache.hadoop.mapreduce.lib.input.FileInputFormat;\nimport org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;\nimport org.apache.hadoop.util.GenericOptionsParser;\npublic class MergeSort {\n    /**\n     * @param args\n     * 输入多个文件，每个文件中的每行内容均为一个整数\n     * 输出到一个新的文件中，输出的数据格式为每行两个整数，第一个数字为第二个整数的排序位次，第二个整数为原待排列的整数\n     */\n    //map函数读取输入中的value，将其转化成IntWritable类型，最后作为输出key\n    public static class Map extends Mapper<Object, Text, IntWritable, IntWritable>{\n        private static IntWritable data = new IntWritable();\n        public void map(Object key, Text value, Context context) throws IOException,InterruptedException{\n            String text = value.toString();\n            data.set(Integer.parseInt(text));\n            context.write(data, new IntWritable(1));\n        }\n    }\n    //reduce函数将map输入的key复制到输出的value上，然后根据输入的value-list中元素的个数决定key的输出次数,定义一个全局变量line_num来代表key的位次\n    public static class Reduce extends Reducer<IntWritable, IntWritable, IntWritable,  IntWritable>{\n        private static IntWritable line_num = new IntWritable(1);       \n        public void reduce(IntWritable key, Iterable<IntWritable> values, Context  context) throws IOException,InterruptedException{\n            for(IntWritable val : values){ \n                context.write(line_num, key);\n                line_num = new IntWritable(line_num.get() + 1);\n            }\n        }\n    }\n    //自定义Partition函数，此函数根据输入数据的最大值和MapReduce框架中Partition的数量获取将输入数据按照大小分块的边界，然后根据输入数值和边界的关系返回对应的Partiton ID\n    public static class Partition extends Partitioner<IntWritable, IntWritable>{\n        public int getPartition(IntWritable key, IntWritable value, int num_Partition){\n            int Maxnumber = 65223;//int型的最大数值\n            int bound = Maxnumber/num_Partition+1;\n            int keynumber = key.get();\n            for (int i = 0; i<num_Partition; i++){\n                if(keynumber<bound * (i+1) && keynumber>=bound * i){ \n                   return i;\n                }\n            }\n            return -1;\n        }\n    }\n    public static  void main(String[] args) throws Exception{ \n        // TODO  Auto-generated method stub\n        Configuration  conf = new Configuration();\n               conf.set(\"fs.default.name\",\"hdfs://localhost:9000\");\n        String[] otherArgs = new String[]{\"input\",\"output\"}; /* 直接设置输入参数 */\n        if (otherArgs.length != 2) {\n            System.err.println(\"Usage: wordcount <in><out>\");\n            System.exit(2);\n            }\n               Job job = Job.getInstance(conf,\"Merge and sort\");\n        job.setJarByClass(MergeSort.class);\n        job.setMapperClass(Map.class); \n        job.setReducerClass(Reduce.class);\n        job.setPartitionerClass(Partition.class);\n        job.setOutputKeyClass(IntWritable.class); \n        job.setOutputValueClass(IntWritable.class); \n        FileInputFormat.addInputPath(job, new Path(otherArgs[0]);\n        FileOutputFormat.setOutputPath(job, new Path(otherArgs[1]);\n        System.exit(job.waitForCompletion(true) ? 0 : 1);\n    }\n}\n\n```\n\n自己打包项目\n\n```\nhadoop jar /usr/local/hadoop/myapp/MergeSort.jar input output\nhadoop dfs -cat output/*\n```\n\n![image-20250508160625143](../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/7564f49802db8df0e5e5de4a1c96222c55933597-1747299497352-164-1747900721330-169-1749470495099-171.png)\n\n#### java\n\n==java==\n\n写入测试文件\n\n```\ncat >a.txt<<\"EOF\"\n33\n37\n12\n40\nEOF\ncat >b.txt<<\"EOF\"\n4\n16\n39\n5\nEOF\ncat >c.txt<<\"EOF\"\n1\n45\n25\nEOF\nhdfs dfs -rm -r input\nhdfs dfs -rm -r output\nhdfs dfs -mkdir input\nhdfs dfs -put a.txt input\nhdfs dfs -put b.txt input\nhdfs dfs -put c.txt input\n```\n\n更新代码\n\n`MergeSort.java`\n\n```java\nimport java.io.IOException;\n\nimport org.apache.hadoop.conf.Configuration;\nimport org.apache.hadoop.fs.Path;\nimport org.apache.hadoop.io.IntWritable;\nimport org.apache.hadoop.io.Text;\nimport org.apache.hadoop.mapreduce.Job;\nimport org.apache.hadoop.mapreduce.Mapper;\nimport org.apache.hadoop.mapreduce.Partitioner;\nimport org.apache.hadoop.mapreduce.Reducer;\nimport org.apache.hadoop.mapreduce.lib.input.FileInputFormat;\nimport org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;\n\npublic class MergeSort {\n\n    /**\n     * @param args\n     * 输入多个文件，每个文件中的每行内容均为一个整数\n     * 输出到一个新的文件中，输出的数据格式为每行两个整数，\n     * 第一个数字为第二个整数的排序位次（从1开始），第二个整数为原待排列的整数\n     */\n\n    // Mapper：读取每行整数，作为 key 输出\n    public static class Map extends Mapper<Object, Text, IntWritable, IntWritable> {\n        private static final IntWritable data = new IntWritable();\n\n        public void map(Object key, Text value, Context context) throws IOException, InterruptedException {\n            String text = value.toString().trim();\n            if (!text.isEmpty()) {\n                data.set(Integer.parseInt(text));\n                context.write(data, new IntWritable(1));\n            }\n        }\n    }\n\n    // Reducer：根据 key 的顺序输出排名和对应的整数\n    public static class Reduce extends Reducer<IntWritable, IntWritable, IntWritable, IntWritable> {\n        private static IntWritable line_num = new IntWritable(1);\n\n        public void reduce(IntWritable key, Iterable<IntWritable> values, Context context)\n                throws IOException, InterruptedException {\n            for (IntWritable val : values) {\n                context.write(line_num, key);\n                line_num = new IntWritable(line_num.get() + 1);\n            }\n        }\n    }\n\n    // 自定义 Partitioner：按数值大小分块，提升并行效率\n    public static class Partition extends Partitioner<IntWritable, IntWritable> {\n        public int getPartition(IntWritable key, IntWritable value, int num_Partition) {\n            int Maxnumber = 65223; // 可以根据数据范围调整\n            int bound = Maxnumber / num_Partition + 1;\n            int keynumber = key.get();\n            for (int i = 0; i < num_Partition; i++) {\n                if (keynumber < bound * (i + 1) && keynumber >= bound * i) {\n                    return i;\n                }\n            }\n            return -1;\n        }\n    }\n\n    public static void main(String[] args) throws Exception {\n        Configuration conf = new Configuration();\n\n        // 设置新的 fs.defaultFS，并设置本地执行模式\n        conf.set(\"fs.defaultFS\", \"hdfs://localhost:9000\");\n        conf.set(\"mapreduce.framework.name\", \"local\");\n        conf.set(\"mapreduce.jobtracker.address\", \"local\");\n\n        // 写死输入输出路径\n        String inputPath = \"hdfs://localhost:9000/user/hadoop/input\";\n        String outputPath = \"hdfs://localhost:9000/user/hadoop/output\";\n\n        Job job = Job.getInstance(conf, \"Merge and Sort\");\n        job.setJarByClass(MergeSort.class);\n        job.setMapperClass(Map.class);\n        job.setReducerClass(Reduce.class);\n        job.setPartitionerClass(Partition.class);\n\n        job.setOutputKeyClass(IntWritable.class);\n        job.setOutputValueClass(IntWritable.class);\n\n        FileInputFormat.addInputPath(job, new Path(inputPath));\n        FileOutputFormat.setOutputPath(job, new Path(outputPath));\n\n        System.exit(job.waitForCompletion(true) ? 0 : 1);\n    }\n}\n```\n\n![image-20250515165402525](../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/image-20250515165402525-1747900721330-170-1749470495099-170.png)\n\n```\nhadoop dfs -cat output/*\n```\n\n![image-20250515165432143](../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/image-20250515165432143-1747900721330-171-1749470495099-172.png)\n\n### 第三题\n\n#### shell\n\n3．对给定的表格进行信息挖掘\n\n下面给出一个child-parent的表格，要求挖掘其中的父子关系，给出祖孙关系的表格。\n\n```\ncat >a.txt<<\"EOF\"\nchild parent\nSteven Lucy\nSteven Jack\nJone Lucy\nJone Jack\nLucy Mary\nLucy Frank\nJack Alice\nJack Jesse\nDavid Alice\nDavid Jesse\nPhilip David\nPhilip Alma\nMark David\nMark Alma\nEOF\nhdfs dfs -rm -r input\nhdfs dfs -rm -r output\nhdfs dfs -mkdir input\nhdfs dfs -put a.txt input\n```\n\n创建`simple_data_mining.java`\n\n```java\nimport java.io.IOException;\nimport java.util.*;\nimport org.apache.hadoop.conf.Configuration;\nimport org.apache.hadoop.fs.Path;\nimport org.apache.hadoop.io.IntWritable;\nimport org.apache.hadoop.io.Text;\nimport org.apache.hadoop.mapreduce.Job;\nimport org.apache.hadoop.mapreduce.Mapper;\nimport org.apache.hadoop.mapreduce.Reducer;\nimport org.apache.hadoop.mapreduce.lib.input.FileInputFormat;\nimport org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;\nimport org.apache.hadoop.util.GenericOptionsParser;\npublic class simple_data_mining { \n    public static int time = 0;\n    /**\n     * @param args \n     * 输入一个child-parent的表格\n     * 输出一个体现grandchild-grandparent关系的表格\n     */\n    //Map将输入文件按照空格分割成child和parent，然后正序输出一次作为右表，反序输出一次作为左表，需要注意的是在输出的value中必须加上左右表区别标志\n    public static class Map extends Mapper<Object, Text, Text, Text>{\n        public void map(Object key, Text value, Context context) throws IOException,InterruptedException{\n            String child_name = new String();\n            String parent_name = new String();\n            String relation_type = new String();\n            String line = value.toString();\n            int i = 0;\n            while(line.charAt(i)!= ' '){\n                i++;\n            }\n            String[] values = {line.substring(0,i),line.substring(i+1)}; \n            if(values[0].compareTo(\"child\")!= 0){\n                child_name = values[0];\n                parent_name = values[1];\n                relation_type = \"1\";//左右表区分标志\n                context.write(new Text(values[1], new Text(relation_type+\"+\"+child_name+\"+\"+parent_name));\n                //左表\n                relation_type = \"2\";\n                context.write(new Text(values[0], new Text(relation_type+\"+\"+child_name+\"+\"+parent_name));\n                //右表\n            }\n        }\n    }\n    public static class Reduce extends Reducer<Text, Text, Text, Text>{\n        public void reduce(Text key, Iterable<Text> values,Context context) throws IOException,InterruptedException{\n            if(time == 0){   //输出表头\n                context.write(new Text(\"grand_child\"), new Text(\"grand_parent\"));\n                time++;\n            }\n            int grand_child_num = 0; \n            String grand_child[] = new String[10];\n            int grand_parent_num = 0;\n            String grand_parent[]= new String[10];\n            Iterator ite = values.iterator();\n            while(ite.hasNext()){\n                String record = ite.next().toString();\n                int len = record.length();\n                int i = 2;\n                if(len == 0) continue;\n                char relation_type = record.charAt(0);\n                String child_name = new String();\n                String parent_name = new String();\n                //获取value-list中value的child\n                while(record.charAt(i)!= '+'){\n                   child_name = child_name + record.charAt(i);\n                   i++;\n                }\n                i=i+1;\n                //获取value-list中value的parent\n                while(i<len){\n                   parent_name = parent_name+record.charAt(i);\n                   i++;\n                } \n                //左表，取出child放入grand_child\n                if(relation_type  == '1'){\n                   grand_child[grand_child_num]  = child_name; \n                   grand_child_num++;\n                }\n                else{//右表，取出parent放入grand_parent\n                   grand_parent[grand_parent_num]  = parent_name;\n                   grand_parent_num++;\n                }\n            } \n            if(grand_parent_num != 0 && grand_child_num != 0 ){\n                for(int m = 0;m<grand_child_num;m++){\n                  for(int n=0;n<grand_parent_num;n++){\n                                                                        context.write(new  Text(grand_child[m], new Text(grand_parent[n]);\n                       //输出结果\n                   }\n                } \n            }\n        } \n    }\n    public static void main(String[] args) throws Exception{\n        //  TODO Auto-generated method stub \n        Configuration conf = new Configuration();\n               conf.set(\"fs.default.name\",\"hdfs://localhost:9000\");\n        String[] otherArgs = new String[]{\"input\",\"output\"}; /* 直接设置输入参数 */\n        if (otherArgs.length != 2) {\n            System.err.println(\"Usage: wordcount <in><out>\");\n            System.exit(2);\n            }\n               Job job =  Job.getInstance(conf,\"Single table join\");\n        job.setJarByClass(simple_data_mining.class);\n        job.setMapperClass(Map.class); \n        job.setReducerClass(Reduce.class); \n        job.setOutputKeyClass(Text.class);\n        job.setOutputValueClass(Text.class);\n        FileInputFormat.addInputPath(job, new Path(otherArgs[0]);\n        FileOutputFormat.setOutputPath(job, new Path(otherArgs[1]);\n        System.exit(job.waitForCompletion(true) ? 0 : 1);\n    }\n}\n\n```\n\n自己打包文件\n\n```\nhadoop jar /usr/local/hadoop/myapp/simple_data_mining.jar input output\nhadoop dfs -cat output/*\n```\n\n![image-20250508160923581](../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/a1126764960165978203787b9ae638c355933597-1747299497352-165-1747900721330-172-1749470495099-173.png)\n\n#### java\n\n==java==\n\n更新测试文件\n\n```\ncat >a.txt<<\"EOF\"\nchild parent\nSteven Lucy\nSteven Jack\nJone Lucy\nJone Jack\nLucy Mary\nLucy Frank\nJack Alice\nJack Jesse\nDavid Alice\nDavid Jesse\nPhilip David\nPhilip Alma\nMark David\nMark Alma\nEOF\nhdfs dfs -rm -r input\nhdfs dfs -rm -r output\nhdfs dfs -mkdir input\nhdfs dfs -put a.txt input\n```\n\n更新`simple_data_mining.java`\n\n```java\nimport java.io.IOException;\nimport java.util.*;\n\nimport org.apache.hadoop.conf.Configuration;\nimport org.apache.hadoop.fs.Path;\nimport org.apache.hadoop.io.Text;\nimport org.apache.hadoop.mapreduce.Job;\nimport org.apache.hadoop.mapreduce.Mapper;\nimport org.apache.hadoop.mapreduce.Reducer;\nimport org.apache.hadoop.mapreduce.lib.input.FileInputFormat;\nimport org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;\n\npublic class simple_data_mining {\n\n    public static int time = 0; // 控制表头只输出一次\n\n    /**\n     * 输入：每行两个字段 child parent\n     * 输出：grand_child grand_parent\n     */\n\n    // Mapper：将每条记录正序和逆序分别输出，标识左表和右表\n    public static class Map extends Mapper<Object, Text, Text, Text> {\n        public void map(Object key, Text value, Context context) throws IOException, InterruptedException {\n            String line = value.toString().trim();\n            if (line.isEmpty() || line.startsWith(\"child\")) return;\n\n            String[] parts = line.split(\"\\\\s+\");\n            if (parts.length < 2) return;\n\n            String child = parts[0];\n            String parent = parts[1];\n\n            // 左表输出：parent -> left+child+parent\n            context.write(new Text(parent), new Text(\"1+\" + child + \"+\" + parent));\n            // 右表输出：child -> right+child+parent\n            context.write(new Text(child), new Text(\"2+\" + child + \"+\" + parent));\n        }\n    }\n\n    // Reducer：将同一key下的左右表数据组合，找出所有祖孙关系\n    public static class Reduce extends Reducer<Text, Text, Text, Text> {\n        public void reduce(Text key, Iterable<Text> values, Context context)\n                throws IOException, InterruptedException {\n\n            List<String> leftList = new ArrayList<>();\n            List<String> rightList = new ArrayList<>();\n\n            for (Text val : values) {\n                String record = val.toString();\n                if (record.isEmpty()) continue;\n\n                char relationType = record.charAt(0);\n                String[] fields = record.substring(2).split(\"\\\\+\");\n                if (fields.length < 2) continue;\n\n                String child = fields[0];\n                String parent = fields[1];\n\n                if (relationType == '1') {\n                    leftList.add(child); // 左表：child 是孙子\n                } else {\n                    rightList.add(parent); // 右表：parent 是祖父\n                }\n            }\n\n            // 输出所有可能的祖孙组合\n            if (time == 0) {\n                context.write(new Text(\"grand_child\"), new Text(\"grand_parent\"));\n                time++;\n            }\n\n            for (String lc : leftList) {\n                for (String rp : rightList) {\n                    context.write(new Text(lc), new Text(rp));\n                }\n            }\n        }\n    }\n\n    public static void main(String[] args) throws Exception {\n        Configuration conf = new Configuration();\n\n        // 设置新的 fs.defaultFS，并设置本地执行模式\n        conf.set(\"fs.defaultFS\", \"hdfs://localhost:9000\");\n        conf.set(\"mapreduce.framework.name\", \"local\");\n        conf.set(\"mapreduce.jobtracker.address\", \"local\");\n\n        // 写死输入输出路径\n        String inputPath = \"hdfs://localhost:9000/user/hadoop/input\";\n        String outputPath = \"hdfs://localhost:9000/user/hadoop/output\";\n\n        Job job = Job.getInstance(conf, \"Simple Data Mining - Grandchild to Grandparent\");\n        job.setJarByClass(simple_data_mining.class);\n\n        job.setMapperClass(Map.class);\n        job.setReducerClass(Reduce.class);\n\n        job.setOutputKeyClass(Text.class);\n        job.setOutputValueClass(Text.class);\n\n        FileInputFormat.addInputPath(job, new Path(inputPath));\n        FileOutputFormat.setOutputPath(job, new Path(outputPath));\n\n        System.exit(job.waitForCompletion(true) ? 0 : 1);\n    }\n}\n```\n\n![image-20250515165610418](../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/image-20250515165610418-1747900721330-173-1749470495099-174.png)\n\n```\nhadoop dfs -cat output/*\n```\n\n![image-20250515165632038](../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/image-20250515165632038-1747900721330-174-1749470495099-175.png)\n\n\n\n## Hive\n\n![image-20250522140819106](../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/image-20250522140819106-1749470495099-176.png)\n\n就在下载页面空白处，右键打开终端\n\n```\nsudo ls\n```\n\n![image-20250522141330178](../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/image-20250522141330178-1749470495099-177.png)\n\n```bash\nsudo tar -xf apache-hive-3.1.3-bin.tar.gz\nsudo mv apache-hive-3.1.3-bin /usr/local/hive\necho \"export HIVE_HOME=/usr/local/hive\" >> ~/.bashrc\necho \"export PATH=\\$HIVE_HOME/bin:\\$PATH\" >> ~/.bashrc\nsource ~/.bashrc\nsudo tee /usr/local/hive/conf/hive-site.xml > /dev/null <<'EOF'\n<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n<?xml-stylesheet type=\"text/xsl\" href=\"configuration.xsl\"?>\n<configuration>\n  <property>\n    <name>javax.jdo.option.ConnectionURL</name>\n    <value>jdbc:mysql://localhost:3306/hive?createDatabaseIfNotExist=true&amp;useSSL=false</value>\n    <description>JDBC connect string for a JDBC metastore</description>\n  </property>\n  <property>\n    <name>javax.jdo.option.ConnectionDriverName</name>\n    <value>com.mysql.jdbc.Driver</value>\n    <description>Driver class name for a JDBC metastore</description>\n  </property>\n  <property>\n    <name>javax.jdo.option.ConnectionUserName</name>\n    <value>hive</value>\n    <description>username to use against metastore database</description>\n  </property>\n  <property>\n    <name>javax.jdo.option.ConnectionPassword</name>\n    <value>hive</value>\n    <description>password to use against metastore database</description>\n  </property>\n  <property>\n    <name>hive.exec.mode.local.auto</name>\n    <value>true</value>\n  </property>\n</configuration>\nEOF\nsudo mv mysql-connector-java-5.1.46.tar{\\(2\\).gz,.gz}\nsudo tar -xf mysql-connector-java-5.1.46*.tar.gz\n\nsudo mv mysql-connector-java-5.1.46/mysql-connector-java-5.1.46.jar /usr/local/hive/lib/\nsudo chown hadoop:hadoop /usr/local/hive/lib/mysql-connector-java-5.1.46.jar\nsudo chmod 644 /usr/local/hive/lib/mysql-connector-java-5.1.46.jar\n```\n\n安装mysql\n\n```bash\nsudo apt remove mariadb* -y\n#上面报错不用管\nsudo apt install -y net-tools wget mysql-server\nsudo systemctl enable --now mysql\n```\n\n进入mysql初始化\n\n```\nsudo mysql_secure_installation\n```\n\n下面开始要手动输入了，输入yes或no\n\n下面开始要手动输入了，输入yes或no\n\n下面开始要手动输入了，输入yes或no\n\n下面开始要手动输入了，输入yes或no\n\n```bash\n1. Press y|Y for Yes, any other key for No:   no\nPlease set the password for root here.\n\nNew password:                 输入密码123456\nRe-enter new password:        输入密码123456\n....\n\n2. Remove anonymous users?  :   yes\n....\n3.Disallow root login remotely?  : no\n....\n4.Remove test database and access to it?: yes\n ....\n5.Reload privilege tables now? : yes\n```\n\n登入数据库床创建用户\n\n```\ncd\nsudo mysql -uroot -p123456\nUNINSTALL PLUGIN validate_password;\ncreate database hive;\ngrant all on *.* to hive@localhost identified by 'hive';\nflush privileges; \nexit\nsudo sed -i 's/^bind-address\\s*=\\s*127.0.0.1/bind-address = 0.0.0.0/' /etc/mysql/mysql.conf.d/mysqld.cnf\nsudo sed -i 's/^mysqlx-bind-address\\s*=\\s*127.0.0.1/mysqlx-bind-address = 0.0.0.0/' /etc/mysql/mysql.conf.d/mysqld.cnf\nsudo systemctl restart mysql\n\n```\n\n![image-20250522144324814](../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/image-20250522144324814-1749470495099-178.png)\n\n\n\n升级元数据\n\n```\nsudo rm -rf /usr/local/hive/lib/guava*.jar\nsudo cp /usr/local/hadoop/share/hadoop/common/lib/guava-*.jar /usr/local/hive/lib/\nsudo cp /home/hadoop/下载/mysql-connector-java-5.1.46.tar* /usr/local/hive/lib/\nsudo cp /home/hadoop/Downloads/mysql-connector-java-5.1.46.tar* /usr/local/hive/lib/\nstart-all.sh\n\n\n#hive初始化，这个命令只需要运行一次\nschematool -dbType mysql -initSchema\n```\n\n![image-20250522150929161](../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/image-20250522150929161-1749470495099-180.png)\n\n这个是成功的意思\n\n启动hive，要启动hadoop\n\n```\nhive\nshow databases;\nexit;\n```\n\n![image-20250522151212300](../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/image-20250522151212300-1749470495099-179.png)\n\n这个图片交到9.9去\n\n## 实验五\n\n![image-20250522152320297](../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/image-20250522152320297-1749470495099-181.png)\n\n自己启动hadoop，在下载文件夹空白处右键\n\n```\nsudo mv data ../\ncd\nls | grep data\n```\n\n![image-20250522152519618](../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/image-20250522152519618-1749470495099-182.png)\n\n启动hive\n\n```\nhive\n```\n\n（1）创建内部表 `stocks`\n\n表A-6 stocks表结构\n\n| col_name        | data_type |\n| --------------- | --------- |\n| exchange        | string    |\n| symbol          | string    |\n| ymd             | string    |\n| price_open      | float     |\n| price_high      | float     |\n| price_low       | float     |\n| price_close     | float     |\n| volume          | int       |\n| price_adj_close | float     |\n\n\n\n```\ncreate table if not exists stocks\n(\n`exchange` string,\n`symbol` string,\n`ymd` string,\n`price_open` float,\n`price_high` float,\n`price_low` float,\n`price_close` float,\n`volume` int,\n`price_adj_close` float\n)\nrow format delimited fields terminated by ',';\n```\n\n![image-20250522152934167](../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/image-20250522152934167-1749470495099-183.png)\n\n（2）创建一个外部分区表dividends（分区字段为exchange和symbol）\n\n 表A-7 dividends表结构\n\n| col_name | data_type |\n| -------- | --------- |\n| ymd      | string    |\n| dividend | float     |\n| exchange | string    |\n| symbol   | string    |\n\n```\ncreate external table if not exists dividends\n(\n`ymd` string,\n`dividend` float\n)\npartitioned by(`exchange` string ,`symbol` string)\nrow format delimited fields terminated by ',';\n```\n\n![image-20250522153028622](../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/image-20250522153028622-1749470495099-184.png)\n\n（3）从stocks.csv文件向stocks表中导入数据。\n\n```\nload data local inpath '/home/hadoop/data/stocks/stocks.csv' overwrite into table stocks;\n```\n\n![image-20250522153255569](../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/image-20250522153255569-1749470495099-185.png)\n\n（4） 创建一个未分区的外部表dividends_unpartitioned，并从dividends.csv向其中导入数据，表结构如表A-8所示。\n\n​    表A-8 dividends_unpartitioned表结构\n\n| col_name | data_type |\n| -------- | --------- |\n| ymd      | string    |\n| dividend | float     |\n| exchange | string    |\n| symbol   | string    |\n\n```\ncreate external table if not exists dividends_unpartitioned\n(\n`exchange` string ,\n`symbol` string,\n`ymd` string,\n`dividend` float\n)\nrow format delimited fields terminated by ',';\nload data local inpath '/home/hadoop/data/dividends/dividends.csv' overwrite into table dividends_unpartitioned;\n```\n\n![image-20250522153350030](../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/image-20250522153350030-1749470495099-186.png)\n\n（5）通过对dividends_unpartitioned的查询语句，利用Hive自动分区特性向分区表dividends各个分区中插入对应数据。\n\n```\nset hive.exec.dynamic.partition=true;\nset hive.exec.dynamic.partition.mode=nonstrict;\nset hive.exec.max.dynamic.partitions.pernode=1000;\ninsert overwrite table dividends partition(`exchange`,`symbol`) select `ymd`,`dividend`,`exchange`,`symbol` from dividends_unpartitioned;\n```\n\n运行一分钟，有点慢\n\n![image-20250522153604286](../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/image-20250522153604286-1749470495099-187.png)\n\n（6）查询IBM公司(symbol=IBM)从2000年起所有支付股息的交易日(dividends表中有对应记录)的收盘价(price_close)。\n\n```\nselect s.ymd,s.symbol,s.price_close\nfrom stocks s \nLEFT SEMI JOIN \ndividends d\nON s.ymd=d.ymd and s.symbol=d.symbol\nwhere s.symbol='IBM' and year(ymd)>=2000;\n```\n\n![image-20250522153702090](../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/image-20250522153702090-1749470495099-188.png)\n\n（7）查询苹果公司(symbol=AAPL)2008年10月每个交易日的涨跌情况，涨显示rise，跌显示fall,不变显示unchange。\n\n```\nselect ymd,\ncase\n    when price_close-price_open>0 then 'rise'\n    when price_close-price_open<0 then 'fall'\n    else 'unchanged'\nend as situation\nfrom stocks\nwhere symbol='AAPL' and substring(ymd,0,7)='2008-10';\n```\n\n![image-20250522153845775](../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/image-20250522153845775-1749470495099-189.png)\n\n（8）查询stocks表中收盘价(price_close)比开盘价(price_open)高得最多的那条记录的交易所(exchange)、股票代码(symbol)、日期(ymd)、收盘价、开盘价及二者差价。\n\n```\nselect `exchange`,symbol,ymd,price_close-price_open as `diff`\nfrom\n(\n    select *\n    from stocks\n    order by price_close-price_open desc\n    limit 1\n)t;\n```\n\n![image-20250522153914410](../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/image-20250522153914410-1749470495099-190.png)\n\n（9）从stocks表中查询苹果公司（symbol=AAPL）年平均调整后收盘价(price_adj_close) 大于50美元的年份及年平均调整后收盘价。\n\n```\nselect\n    year(ymd) as `year`,\n    avg(price_adj_close) as avg_price from stocks\nwhere `exchange`='NASDAQ' and symbol='AAPL'\ngroup by year(ymd)\nhaving avg_price > 50;\n```\n\n![image-20250522154025370](../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/image-20250522154025370-1749470495099-191.png)\n\n（10）查询每年年平均调整后收盘价(price_adj_close)前三名的公司的股票代码及年平均调整后收盘价。\n\n```\nSET mapreduce.job.reduces=2;\nselect t2.year, t2.symbol, t2.avg_price\nfrom (\n    select *,\n           row_number() over (partition by year order by avg_price desc) as rn\n    from (\n        select\n            year(ymd) as year,\n            symbol,\n            avg(price_adj_close) as avg_price\n        from stocks\n        group by year(ymd), symbol\n    ) t1\n) t2\nwhere t2.rn <= 3;\n```\n\n![image-20250522161403513](../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/image-20250522161403513-1749470495099-192.png)\n\n## (9.9.3)\n\n1.利用mapreduce实现词频统计\n\n```\nsudo ls && start-all.sh\n```\n\n```bash\ncd\nhdfs dfs -rm -r input\nhdfs dfs -rm -r output\nhdfs dfs -mkdir input\nrm -rf input\nmkdir input\necho \"hello world\" > input/file1.txt\necho \"hello hadoop\" > input/file2.txt\nhdfs dfs -put input/* input/\nhadoop jar $HADOOP_HOME/share/hadoop/mapreduce/hadoop-mapreduce-examples-3.1.3.jar wordcount input output\nhdfs dfs -cat output/*\n```\n\n![image-20250609195315190](../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/image-20250609195315190.png)\n\n2.利用hive实现词频统计\n\n```\nhive\n```\n\n```sql\ncreate table docs(line string);\nload data inpath 'file:///home/hadoop/input' overwrite into table docs;\ncreate table word_count as \nselect word, count(1) as count from\n(select explode(split(line,' '))as word from docs) w\ngroup by word\norder by word;\n```\n\n对文本进行“分词 + 炸裂”，得到所有单词列表\n\n```sql\nSELECT explode(split(line, ' ')) AS word FROM docs;\n```\n\n![image-20250609195635791](../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/image-20250609195635791.png)\n\n对单词进行分组并计数\n\n```sql\nSELECT word, COUNT(*) AS count\nFROM (\n  SELECT explode(split(line, ' ')) AS word FROM docs\n) w\nGROUP BY word;\n```\n\n![image-20250609195734111](../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/image-20250609195734111.png)\n\n\n\n> `三张图片都交到9.9.3`\n"},{"title":"ZeroTier免费远控工具","url":"/posts/a735afbd/","content":"\n<meta name=\"referrer\" content=\"no-referrer\"/>\n\n# ZeroTier免费远控工具\n\n[ZeroTier](https://www.zerotier.com/)，分分钟异地实现组网的远控工具，这个工具有免费计划的\n\n免费计划里有3个网络和10个设备。\n\n例子：在ZeroTier网页后台添加一个网络，就是在两个设备下载ZeroTier客户端，两个设备都加入到网络，就形成了一个局域网，最后在网页后台进行设备加入的授权加入，就会形成一个ip，只需要输入这个ip就可以实现远控了。\n\n这个网络，相当于一个巨型的局域网，在免费计划里可以加入10个设备。\n\n![image-20250227100506316](../img/ZeroTier%E5%85%8D%E8%B4%B9%E8%BF%9C%E6%8E%A7%E5%B7%A5%E5%85%B7/5982fd2823f00f4099c8de6c52dcfba155933597.png)\n\n## 注册ZeroTier\n\n在[Sign in to ZeroTier](https://accounts.zerotier.com/realms/zerotier/protocol/openid-connect/auth?client_id=zt-central&redirect_uri=https%3A%2F%2Fmy.zerotier.com%2Fauth%2Fcallback&response_type=code&scope=openid+profile+email+offline_access&state=a3c0bc038dac41e0a0c8e32f298a1e6f&code_challenge=1Y9O_eh9aN4HK6anc1W22JgfiFil_uv-aJM_qhWIm1w&code_challenge_method=S256&response_mode=query)注册一个账号，有很多方式，自己选一个就行了\n![image-20250227091906232](../img/ZeroTier%E5%85%8D%E8%B4%B9%E8%BF%9C%E6%8E%A7%E5%B7%A5%E5%85%B7/2fbef4b369295cc784ec2cf1dd9b2e9955933597.png)\n\n## 创建网络\n\n点击创建网络，下面就会有一个网络id，这个id是所有设备加入网络需要的输入的id\n\n![image-20250227092054437](../img/ZeroTier%E5%85%8D%E8%B4%B9%E8%BF%9C%E6%8E%A7%E5%B7%A5%E5%85%B7/46a731bc8b11ac8e53aad0fbf2bd3de555933597.png)\n\n## 各个设备下载客户端\n\n在你需要远控的==各个==设备，下载客户端[Download - ZeroTier](https://www.zerotier.com/download/)\n\n你的设备是什么系统，你就下载对应系统的软件\n\n![image-20250227093209263](../img/ZeroTier%E5%85%8D%E8%B4%B9%E8%BF%9C%E6%8E%A7%E5%B7%A5%E5%85%B7/9a0b675a61f723646c57fd7c12e80e7355933597.png)\n\n我这里双方都是windows，linux有教程，你可以自己看看\n\nwindows安装之后是没有桌面图标的，你要在开始菜单里才能看见\n\n![image-20250227095049175](../img/ZeroTier%E5%85%8D%E8%B4%B9%E8%BF%9C%E6%8E%A7%E5%B7%A5%E5%85%B7/bcd2a8644d6fd55b399b1b65e09cbf8055933597.png)        ![image-20250227095115621](../img/ZeroTier%E5%85%8D%E8%B4%B9%E8%BF%9C%E6%8E%A7%E5%B7%A5%E5%85%B7/9a6bad75cc80e55dc9425cc6c7140ba155933597.png)    \n\n打开之后再小托盘里就可以看见了\n\n## 客户端加入网络\n\n复制这个网络id，然后在小托盘右键ZeroTier，点击Join New Network输入网络id就可以成功加入网络，各个需要远控的设备都要安装ZeroTier和输入网络id，才能成功加入这个网络\n\n![image-20250227095220088](../img/ZeroTier%E5%85%8D%E8%B4%B9%E8%BF%9C%E6%8E%A7%E5%B7%A5%E5%85%B7/56a336a5ba60fd5a6e7d19f0dd44566255933597.png)\n\n![image-20250227095257254](../img/ZeroTier%E5%85%8D%E8%B4%B9%E8%BF%9C%E6%8E%A7%E5%B7%A5%E5%85%B7/8b77ff2da2d1a651d164e2bfe81f3b4355933597.png)\n\n![image-20250227095303750](../img/ZeroTier%E5%85%8D%E8%B4%B9%E8%BF%9C%E6%8E%A7%E5%B7%A5%E5%85%B7/afaef8b899a41d4afd9955a2aea5a85055933597.png)\n\n## 授权设备\n\n![](../img/ZeroTier%E5%85%8D%E8%B4%B9%E8%BF%9C%E6%8E%A7%E5%B7%A5%E5%85%B7/88496a5df443cc0f031ca96be8d6286d55933597.png)\n\n## 进行远控\n\n按win+r输入mstsc\n\n![image-20250227095724804](../img/ZeroTier%E5%85%8D%E8%B4%B9%E8%BF%9C%E6%8E%A7%E5%B7%A5%E5%85%B7/52a07de2fcbff7b19f25541276867a4255933597.png)\n\n然后输入你要控制对方的托管ip即可远控\n\n![image-20250227095945162](../img/ZeroTier%E5%85%8D%E8%B4%B9%E8%BF%9C%E6%8E%A7%E5%B7%A5%E5%85%B7/6400eb59d5203331dcd6382f58edcc8e55933597.png)\n\n登入一下就可以了\n\n<div class=\"tbsm\" style=\"margin-top:54px;\">\n<div class=\"tbsm-top\"><span><svg t=\"1674654360507\" class=\"icon\" viewBox=\"0 0 1024 1024\" version=\"1.1\" xmlns=\"http://www.w3.org/2000/svg\" p-id=\"987\" data-spm-anchor-id=\"a313x.7781069.0.i0\" width=\"35\" height=\"35\"><path d=\"M410.49 97.74H155.08a56.74 56.74 0 0 0-56.84 56.73V410a56.84 56.84 0 0 0 56.84 56.84h255.41A56.83 56.83 0 0 0 467.32 410V154.58a56.83 56.83 0 0 0-56.83-56.84zM410.49 558.74H155.08a56.74 56.74 0 0 0-56.84 56.73V871a56.84 56.84 0 0 0 56.84 56.84h255.41A56.83 56.83 0 0 0 467.32 871V615.58a56.83 56.83 0 0 0-56.83-56.84zM871.49 558.74H616.08a56.74 56.74 0 0 0-56.84 56.73V871a56.84 56.84 0 0 0 56.84 56.84h255.41A56.83 56.83 0 0 0 928.32 871V615.58a56.83 56.83 0 0 0-56.83-56.84z\" fill=\"#66EEFF\" p-id=\"988\"></path><path d=\"M410.49 558.74h-4.14A475 475 0 0 0 299.52 859.6a481.16 481.16 0 0 0 4.84 68.22h106.13A56.83 56.83 0 0 0 467.32 871V615.58a56.83 56.83 0 0 0-56.83-56.84zM871.49 558.74H616.08a56.74 56.74 0 0 0-56.84 56.73V871a56.84 56.84 0 0 0 56.84 56.84h255.41A56.83 56.83 0 0 0 928.32 871V615.58a56.83 56.83 0 0 0-56.83-56.84z\" fill=\"#C2F8FF\" p-id=\"989\"></path></svg></span><span style=\"font-size:30px;\"> 特别声明</span></div>\n<div class=\"tbsm-wz\">千屹博客旗下的所有文章，是通过本人课堂学习和课外自学所精心整理的知识巨著<br/>难免会有出错的地方<br/>如果细心的你发现了小失误，可以在下方评论区告诉我，或者私信我！<br />非常感谢大家的热烈支持！</div>\n</div>","categories":["组网"]},{"title":"Hadoop 3.3.5部署","url":"/posts/cbb23bdb/","content":"\n<meta name=\"referrer\" content=\"no-referrer\"/>\n\n# Hadoop 3.3.5部署\n\n## 前情提要\n\n本次实验采用Ubuntu 24.04LTS，自行安装\n\n[Ubuntu 24.04.02 LTS 初始化安装 | 严千屹博客](https://blog.qianyios.top/posts/14363/)\n\n\n\n本笔记分`伪分布`和`分布式`两大块，但建议从头开始观看\n\n文章所需资源可[点击这里](https://www.alipan.com/s/wtajKBGvPuh)下载\n\n1. 伪分布主机拓扑\n\n|  主机名  |   ip（NAT）    | 内存 | 硬盘 |\n| :------: | :------------: | :--: | :--: |\n| qianyios | 192.168.48.128 |  7G  | 100G |\n\n2. 分布式主机拓扑\n\n|  机名  |   ip（NAT）    | 内存 | 硬盘 |\n| :----: | :------------: | :--: | :--: |\n| master | 192.168.48.128 |  6G  | 100G |\n| slave  | 192.168.48.129 |  6G  | 100G |\n\n## 基础初始化\n\n简单部署一个单节点的hadoop，然后打快照，后续给伪分布和分布式做基础底座\n\n由于本系统在[Ubuntu 24.04.02 LTS 初始化安装 | 严千屹博客](https://blog.qianyios.top/posts/14363/)已经进行了设置阿里源和关闭防火墙，这里就不再赘述了\n\n`切换root用户`\n\n```\nqianyios@qianyios:~$ su -  root\n密码：\nroot@qianyios:~#\n```\n\n`基础配置`\n\n```shell\ncat >init.sh<<\"EOF\"\n#!/bin/bash\nsed -i 's/^#*PermitRootLogin.*/PermitRootLogin yes/' /etc/ssh/sshd_config\nsed -i 's/^#*PasswordAuthentication.*/PasswordAuthentication yes/' /etc/ssh/sshd_config\nsystemctl restart ssh\n# 添加 hosts\necho \"192.168.48.128 qianyios\" >> /etc/hosts\necho \"已添加 hosts 条目。\"\n\n# 设置主机名\nhostnamectl set-hostname qianyios\necho \"主机名已设置为 qianyios。\"\n\n# 安装 sshpass\napt install -y sshpass || { echo \"安装 sshpass 失败\"; exit 1; }\necho \"sshpass 安装完成。\"\n\n# 目标主机列表\nhosts=(\"qianyios\")\n# 密码\npassword=\"123456\"\n\n# 生成 SSH 密钥对\nssh-keygen -t rsa -N \"\" -f ~/.ssh/id_rsa\necho \"SSH 密钥对已生成。\"\n\n# 循环遍历目标主机\nfor host in \"${hosts[@]}\"\ndo\n    echo \"正在为 $host 配置免密登录...\"\n    sshpass -p \"$password\" ssh-copy-id -o StrictHostKeyChecking=no \"$host\" || { echo \"复制公钥到 $host 失败\"; exit 1; }\n    sshpass -p \"$password\" ssh -o StrictHostKeyChecking=no \"$host\" \"echo '免密登录成功'\" || { echo \"验证免密登录失败\"; exit 1; }\ndone\nreboot\nEOF\nbash init.sh\n```\n\n测试免密登入\n\n```\nroot@qianyios:~# ssh qianyios\nWelcome to Ubuntu 24.04.2 LTS (GNU/Linux 6.11.0-17-generic x86_64)\n\n......\n\nLast login: Tue Feb 25 00:02:32 2025 from 127.0.0.1\nroot@qianyios:~#\n```\n\n\n\n下载[所需资源](https://www.alipan.com/s/wtajKBGvPuh)并解压到/root/hadoop/下，如下图\n\n![image-20250225001010678](../img/Hadoop%203.3.5%E9%83%A8%E7%BD%B2/f38ec4a925111c05a235fe8dd79f402f55933597-1741134057016-7.png)\n\n`安装java环境和hadoop`\n\n```bash\ncd /root/hadoop\nmkdir /usr/lib/jvm\n#安装java8\ntar -xf /root/hadoop/jdk-8u371-linux-x64.tar.gz  -C /usr/lib/jvm\necho \"export JAVA_HOME=/usr/lib/jvm/jdk1.8.0_371\" >> /etc/profile\necho \"export PATH=\\$JAVA_HOME/bin:\\$PATH\" >> /etc/profile\nsource /etc/profile\njava -version\n\n#安装hadoop3.3.5\ntar -zxf hadoop-3.3.5.tar.gz -C /usr/local\nmv /usr/local/hadoop-3.3.5/ /usr/local/hadoop\necho \"export HADOOP_HOME=/usr/local/hadoop\" >> /etc/profile\necho \"export PATH=\\$HADOOP_HOME/bin/:\\$HADOOP_HOME/sbin/:\\$PATH\" >> /etc/profile\nsource /etc/profile\nhadoop version\n```\n\n成功图\n\n![image-20250225001421609](../img/Hadoop%203.3.5%E9%83%A8%E7%BD%B2/95f74daa7de0699880c670c1a060a69855933597-1741134057016-8.png)\n\n这时候关机\n\n```\npoweroff\n```\n\n`打个快照，方便做分布式部署,如果你要做分布式的直接跳到`[4.分布式](#分布式)\n\n![image-20250225001553286](../img/Hadoop%203.3.5%E9%83%A8%E7%BD%B2/3d9ba6fb30ae5bcc47e82a27598e96e355933597-1741134057016-9.png)\n\n## 伪分布\n\n开机吧！\n\n### 编写配置文件\n\n#### 编写cort-site.yaml文件\n\n修改下面hdfs://qianyios:9000中的qianyios为你的主机名\n\n```bash\ncat > /usr/local/hadoop/etc/hadoop/core-site.xml<< \"EOF\"\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<?xml-stylesheet type=\"text/xsl\" href=\"configuration.xsl\"?>\n<configuration>\n    <property>\n        <name>hadoop.tmp.dir</name>\n        <value>file:/usr/local/hadoop/tmp</value>\n        <description>Abase for other temporary directories.</description>\n    </property>\n    <property>\n        <name>fs.defaultFS</name>\n        <value>hdfs://qianyios:9000</value>\n    </property>\n</configuration>\n\nEOF\n```\n\n#### 编写hdfs-site.xml\n\n```bash\ncat >/usr/local/hadoop/etc/hadoop/hdfs-site.xml<<\"EOF\"\n<configuration>\n    <property>\n        <name>dfs.replication</name>\n        <value>1</value>\n    </property>\n    <property>\n        <name>dfs.namenode.name.dir</name>\n        <value>file:/usr/local/hadoop/tmp/dfs/name</value>\n    </property>\n    <property>\n        <name>dfs.datanode.data.dir</name>\n        <value>file:/usr/local/hadoop/tmp/dfs/data</value>\n    </property>\n</configuration>\nEOF\n```\n\n### 启动hdfs服务\n\nhadoop初始化\n\n```\nhdfs namenode -format\n```\n\n`这条命令只需要运行一次，以后都不要再运行了！！！！！！`\n\n`这条命令只需要运行一次，以后都不要再运行了！！！！！！`\n\n`这条命令只需要运行一次，以后都不要再运行了！！！！！！`\n\n![image-20250225002137864](../img/Hadoop%203.3.5%E9%83%A8%E7%BD%B2/01a33f64e78e68f25feafd136cc8ee1355933597-1741134057016-10.png)\n\n### 添加环境变量\n\n```bash\necho \"export HDFS_NAMENODE_USER=root\" >> /etc/profile\necho \"export HDFS_DATANODE_USER=root\" >> /etc/profile\necho \"export HDFS_SECONDARYNAMENODE_USER=root\" >> /etc/profile\necho \"export YARN_RESOURCEMANAGER_USER=root\" >> /etc/profile\necho \"export YARN_NODEMANAGER_USER=root\" >> /etc/profile\nsource /etc/profile\n```\n\n### 修改hadoop配置文件\n\n```bash\necho \"export JAVA_HOME=/usr/lib/jvm/jdk1.8.0_371\" >> /usr/local/hadoop/etc/hadoop/hadoop-env.sh\n```\n\n### 启动hadoop\n\n```bash\n#启动服务\nstart-all.sh\n```\n\n```bash\n#关闭服务\nstop-all.sh\n```\n\n![image-20250225002639543](../img/Hadoop%203.3.5%E9%83%A8%E7%BD%B2/8109ed6221eb8f3800d456ddfd600f6455933597-1741134057016-11.png)\n\n\n\n> `localhost: Warning: Permanently added 'localhost' (ED25519) to the list of known hosts.`\n>\n> - 这是一个 SSH 的警告信息，表明 SSH 客户端首次连接到 `localhost` 时，将 `localhost` 的主机密钥（使用 ED25519 算法生成）添加到了 `known_hosts` 文件中。\n> - 这是 SSH 的正常行为，用于防止中间人攻击。每次 SSH 客户端连接到一个新主机时，都会将主机的密钥记录下来。\n\n### 启动historyserver服务\n\n```bash\n#启动hadoop\nstart-all.sh\nmapred --daemon start historyserver\n```\n\n关闭用\n\n```\nmapred --daemon stop historyserver\n```\n\n正常启动hadoop你会看到如下服务\n\n```\nroot@qianyios:~# jps\n14050 NodeManager\n10245 JobHistoryServer\n13894 ResourceManager\n13255 NameNode\n13449 DataNode\n13673 SecondaryNameNode\n14606 Jps\n```\n\n### 访问网页ip:9870查看hdfs\n\n![image-20250225003504886](../img/Hadoop%203.3.5%E9%83%A8%E7%BD%B2/ca5e881a499f56ea8a2f0ed7ea8dd51955933597-1741134057016-12.png)\n\n#### 访问网页ip:8088查看hadoop\n\n![image-20250225003534036](../img/Hadoop%203.3.5%E9%83%A8%E7%BD%B2/3fc9b78167b7990fb02a5d0922ec21f055933597-1741134057016-13.png)\n\n至此伪分布hadoop就搞定了，这时候你要在你这里打上一个伪分布的快照\n\n## 分布式\n\n### 前情提要\n\n|  机名  |   ip（NAT）    | 内存 | 硬盘 |\n| :----: | :------------: | :--: | :--: |\n| master | 192.168.48.128 |  6G  | 100G |\n| slave  | 192.168.48.129 |  6G  | 100G |\n\n由于前面不是做了一个hadoop的一个基础快照吗，这时候你就对那个基础快照进行完整克隆两个出来，分别命名为master和slave\n\n![image-20250225114203260](../img/Hadoop%203.3.5%E9%83%A8%E7%BD%B2/a7b2efe8888a00a01f7cc90caa3eefbe55933597-1741134057016-14.png)\n\n![image-20250225114415054](../img/Hadoop%203.3.5%E9%83%A8%E7%BD%B2/a72ba0ad11eb21ca08c4f57fa1cd700c55933597-1741134057016-15.png)\n\n这时候先开slave，master不要开\n\n```\nvim /etc/netplan/01-network-manager-all.yaml\n```\n\nip改成192.168.48.129\n\n```\n# Let NetworkManager manage all devices on this system\nnetwork:\n  ethernets:\n    ens33:\n      addresses: [192.168.48.129/24]\n      dhcp4: false\n      nameservers:\n          addresses: [192.168.48.2, 114.114.114.114]\n      routes:\n        - to: default\n          via: 192.168.48.2\n  version: 2\n  renderer: NetworkManager\n```\n\n重启网卡\n\n```\nnetplan apply\n```\n\n这时候再把master开机，接着就可以进行基础操作了\n\n### 基础操作\n\n以下我会提前告诉你哪些是哪个节点要操作的命令\n\n操作节点：===master和slave===\n\n```shell\ncat >fbsnit.sh <<\"EOF\"\n#!/bin/bash\nif [ $# -eq 1 ];then\n  echo \"设置主机名为：$1\"\nelse\n  echo  \"使用方法：sh $0 主机名\"\n  exit 2\nfi\nsudo sed -i '/qianyios/d' /etc/hosts\n#这里你要改成你的ip\ngrep -q \"^192\\.168\\.48\\.128\\s\\+master\" /etc/hosts || echo \"192.168.48.128 master\" >> /etc/hosts\ngrep -q \"^192\\.168\\.48\\.129\\s\\+slave\" /etc/hosts || echo \"192.168.48.129 slave\" >> /etc/hosts\nhostnamectl set-hostname $1\n#设置免密\napt install -y sshpass || { echo \"安装 sshpass 失败\"; exit 1; }\necho \"sshpass 安装完成。\"\n\n# 目标主机列表\nhosts=(\"master\" \"slave\")\n# 密码\npassword=\"123456\"\n\n# 生成 SSH 密钥对\nssh-keygen -t rsa -N \"\" -f ~/.ssh/id_rsa\necho \"SSH 密钥对已生成。\"\n\n# 循环遍历目标主机\nfor host in \"${hosts[@]}\"\ndo\n    echo \"正在为 $host 配置免密登录...\"\n    sshpass -p \"$password\" ssh-copy-id -o StrictHostKeyChecking=no \"$host\" || { echo \"复制公钥到 $host 失败\"; exit 1; }\n    sshpass -p \"$password\" ssh -o StrictHostKeyChecking=no \"$host\" \"echo '免密登录成功'\" || { echo \"验证免密登录失败\"; exit 1; }\ndone\nreboot\nEOF\n```\n\n```shell\n#master执行这个\nbash fbsnit.sh master\n```\n\n```bash\n#slave执行这个\nbash fbsnit.sh slave\n```\n\n### 修改配置文件\n\n操作节点：==master==\n\n1.修改workers文件\n\n在Hadoop集群中，`workers`文件是一个非常重要的配置文件，它用于指定Hadoop集群中所有**从节点（DataNode和TaskTracker/NodeManager）的主机名或IP地址**\n\n将slave修改成你自己的从节点的主机名\n\n```shell\ncat> /usr/local/hadoop/etc/hadoop/workers <<\"EOF\"\nslave\nEOF\n```\n\n2.修改core-site.xml\n\n操作节点：==master==\n\n将master修改成你自己的主节点的主机名\n\n> - **作用**：配置Hadoop的核心参数，主要涉及文件系统的访问和临时目录的设置。\n>   - **`fs.defaultFS`**：指定HDFS的默认访问路径，格式为`hdfs://<namenode-host>:<port>`。这是Hadoop客户端访问HDFS的入口。\n>   - **`hadoop.tmp.dir`**：指定Hadoop的临时目录，用于存储运行时的临时文件。\n\n```bash\ncat> /usr/local/hadoop/etc/hadoop/core-site.xml<<\"EOF\"\n<configuration>\n        <property>\n                <name>fs.defaultFS</name>\n                <value>hdfs://master:9000</value>\n        </property>\n        <property>\n                <name>hadoop.tmp.dir</name>\n                <value>file:/usr/local/hadoop/tmp</value>\n                <description>Abase for other temporary directories.</description>\n        </property>\n</configuration>\nEOF\n```\n\n3.修改hdfs-site.xml\n\n操作节点：==master==\n\n将master修改成你自己的主节点的主机名\n\n> - **作用**：配置HDFS（Hadoop Distributed File System）的高级参数。\n>   - **`dfs.namenode.secondary.http-address`**：指定Secondary NameNode的HTTP地址。\n>   - **`dfs.replication`**：设置HDFS数据块的副本数量，默认为3，这里设置为1（适合单节点测试环境）。\n>   - **`dfs.namenode.name.dir`**：指定NameNode存储元数据的目录。\n>   - **`dfs.datanode.data.dir`**：指定DataNode存储数据块的目录。\n\n```\ncat> /usr/local/hadoop/etc/hadoop/hdfs-site.xml<<\"EOF\"\n<configuration>\n        <property>\n                <name>dfs.namenode.secondary.http-address</name>\n                <value>master:50090</value>\n        </property>\n        <property>\n                <name>dfs.replication</name>\n                <value>1</value>\n        </property>\n        <property>\n                <name>dfs.namenode.name.dir</name>\n                <value>file:/usr/local/hadoop/tmp/dfs/name</value>\n        </property>\n        <property>\n                <name>dfs.datanode.data.dir</name>\n                <value>file:/usr/local/hadoop/tmp/dfs/data</value>\n        </property>\n</configuration>\n\nEOF\n```\n\n4.修改mapred-site.xml配置文件\n\n操作节点：==master==\n\n将master修改成你自己的主节点的主机名\n\n> - **作用**：配置MapReduce作业的运行参数。\n>   - **`mapreduce.framework.name`**：指定MapReduce作业运行的框架（这里是YARN）。\n>   - **`mapreduce.jobhistory.address`** 和 **`mapreduce.jobhistory.webapp.address`**：指定MapReduce作业历史服务器的地址和Web界面地址。\n>   - **环境变量配置**：设置MapReduce作业运行时的环境变量，例如`HADOOP_MAPRED_HOME`。\n\n```bash\ncat> /usr/local/hadoop/etc/hadoop/mapred-site.xml<<\"EOF\"\n<configuration>\n        <property>\n                <name>mapreduce.framework.name</name>\n                <value>yarn</value>\n        </property>\n        <property>\n                <name>mapreduce.jobhistory.address</name>\n                <value>master:10020</value>\n        </property>\n        <property>\n                <name>mapreduce.jobhistory.webapp.address</name>\n                <value>master:19888</value>\n        </property>\n        <property>\n<name>yarn.app.mapreduce.am.env</name>\n<value>HADOOP_MAPRED_HOME=/usr/local/hadoop</value>\n</property>\n<property>\n<name>mapreduce.map.env</name>\n<value>HADOOP_MAPRED_HOME=/usr/local/hadoop</value>\n</property>\n<property>\n<name>mapreduce.reduce.env</name>\n<value>HADOOP_MAPRED_HOME=/usr/local/hadoop</value>\n</property>\n</configuration>\nEOF\n```\n\n5.修改yarn-site.xml文件\n\n操作节点：==master==\n\n将master修改成你自己的主节点的主机名\n\n> - **作用**：配置YARN（Yet Another Resource Negotiator）的参数。\n>   - **`yarn.resourcemanager.hostname`**：指定ResourceManager的主机名，用于资源管理和作业调度。\n>   - **`yarn.nodemanager.aux-services`**：启用MapReduce的Shuffle服务，这是MapReduce作业运行的必要配置。\n\n```bash\ncat> /usr/local/hadoop/etc/hadoop/yarn-site.xml<<\"EOF\"\n<configuration>\n        <property>\n                <name>yarn.resourcemanager.hostname</name>\n                <value>master</value>\n        </property>\n        <property>\n                <name>yarn.nodemanager.aux-services</name>\n                <value>mapreduce_shuffle</value>\n        </property>\n</configuration>\nEOF\n```\n\n### 将上述配置拷贝到slave\n\n操作节点：==master==\n\n```bash\ncd /usr/local/hadoop/etc/hadoop/\nscp core-site.xml slave:/usr/local/hadoop/etc/hadoop/\nscp hdfs-site.xml slave:/usr/local/hadoop/etc/hadoop/\nscp mapred-site.xml slave:/usr/local/hadoop/etc/hadoop/\nscp workers slave:/usr/local/hadoop/etc/hadoop/\nscp yarn-site.xml slave:/usr/local/hadoop/etc/hadoop/\ncd\n```\n\n这里是不用输入密码，如果提示你要输入密码，说明你前面4.2的ssh免密没做好\n\n### 修改环境变量拷贝到slave\n\n操作节点：==master==\n\n```\necho \"export HDFS_NAMENODE_USER=root\" >> /etc/profile\necho \"export HDFS_DATANODE_USER=root\" >> /etc/profile\necho \"export HDFS_SECONDARYNAMENODE_USER=root\" >> /etc/profile\necho \"export YARN_RESOURCEMANAGER_USER=root\" >> /etc/profile\necho \"export YARN_NODEMANAGER_USER=root\" >> /etc/profile\nsource /etc/profile\nscp /etc/profile slave:/etc/profile\nsource /etc/profile\n```\n\n### 修改hadoop环境配置文件\n\n操作节点：==master==\n\n并将配置文件拷贝到slave\n\n```bash\necho \"export JAVA_HOME=/usr/lib/jvm/jdk1.8.0_371\" >> /usr/local/hadoop/etc/hadoop/hadoop-env.sh\nscp /usr/local/hadoop/etc/hadoop/hadoop-env.sh slave:/usr/local/hadoop/etc/hadoop/hadoop-env.sh\n```\n\n### 集群启动\n\n操作节点：==master==\n\nmaster初始化\n\n```\nhdfs namenode -format\n```\n\n![image-20250225125251009](../img/Hadoop%203.3.5%E9%83%A8%E7%BD%B2/e8c49f492e15de26ce81ca9487713dbb55933597-1741134057016-16.png)\n\n### 启动hadoop\n\n操作节点：==master==\n\n```bash\n#启动hadoop\nstart-all.sh\n```\n\n```bash\n#关闭服务\nstop-all.sh\n```\n\n启动的时候如果有这些没关系\n\n![image-20250225125953364](../img/Hadoop%203.3.5%E9%83%A8%E7%BD%B2/8e557859aed91345e878f5e726d390ee55933597-1741134057016-17.png)\n\n### 启动historyserver\n\n操作节点：==master==\n\n```\nmapred --daemon start historyserver\n```\n\n关闭用\n\n```\nmapred --daemon stop historyserver\n```\n\n### 查看进程\n\n两个节点说运行的服务如下\n\n```\nroot@master:~# jps\n31364 ResourceManager\n31140 SecondaryNameNode\n30856 NameNode\n32282 Jps\n28046 JobHistoryServer\n\nroot@slave:~# jps\n6304 DataNode\n6444 NodeManager\n6605 Jps\n```\n\n访问hadoop页面\n\nhttp://192.168.48.128:8088/\n\n![image-20250225130356821](../img/Hadoop%203.3.5%E9%83%A8%E7%BD%B2/801acdadb2295edd013381fb66aaea4655933597-1741134057016-18.png)\n\nhttp://192.168.48.128:9870/\n\n![image-20250225130422951](../img/Hadoop%203.3.5%E9%83%A8%E7%BD%B2/c26d8e695f06b81ea7e275862eb8566f55933597-1741134057016-19.png)\n\n至此分布式hadoop集群构建成功\n\n这时候就你要给你这两台机，打上hadoop集群部署成功的快照，以便你后期做项目不报错可以恢复\n\n\n\n## HBase\n\n   HBase 是一个面向列式存储的分布式数据库，其设计思想来源于 Google 的 BigTable 论文。HBase 底层存储基于 HDFS 实现，集群的管理基于 ZooKeeper 实现。HBase 良好的分布式架构设计为海量数据的快速存储、随机访问提供了可能，基于数据副本机制和分区机制可以轻松实现在线扩容、缩容和数据容灾，是大数据领域中 Key-Value 数据结构存储最常用的数据库方案。\n\n本实验部署在伪分布机子上\n\n### 安装\n\n```bash\ntar -xf /root/hadoop/hbase-2.5.4-bin.tar.gz -C /usr/local/\nmv /usr/local/hbase-2.5.4 /usr/local/hbase\necho \"export HBASE_HOME=/usr/local/hbase\" >> /etc/profile\necho \"export PATH=\\$PATH:\\$HBASE_HOME/bin\" >> /etc/profile\nsource /etc/profile\nsed -i \"s/CLASSPATH=\\${CLASSPATH}:\\$JAVA_HOME\\/lib\\/tools.jar/CLASSPATH=\\${CLASSPATH}:\\$JAVA_HOME\\/lib\\/tools.jar:\\/usr\\/local\\/hbase\\/lib\\/*/g\" /usr/local/hbase/bin/hbase\nhbase version\n```\n\n![image-20250228150312197](../img/Hadoop%203.3.5%E9%83%A8%E7%BD%B2/0dfefd758a4032f713df8045df6fc03c55933597-1741134057016-20.png)\n\n### HBase配置\n\n文件里的qianyios要改成你的主机名,运行 HDFS NameNode 的主机名。\n\n`hbase.cluster.distributed`\n\n- 设置为 `true` 表示 HBase 以分布式模式运行。\n- 如果设置为 `false`，HBase 将以单机模式运行（通常用于测试）。\n\n==HBASE_MANAGES_ZK=true==\n\n- **`HBASE_MANAGES_ZK=true`** ：\n  - 表示 HBase 将启动并管理自己的嵌入式 ZooKeeper 实例。\n  - 这种模式通常用于单机环境或小型测试环境，简化了配置和管理。\n- **`HBASE_MANAGES_ZK=false`** ：\n  - 表示 HBase 不会启动自己的 ZooKeeper 实例，而是依赖外部独立的 ZooKeeper 集群。\n  - 这种模式适用于生产环境，推荐使用独立的 ZooKeeper 集群以提高稳定性和性能。\n\n```bash\necho \"export JAVA_HOME=/usr/lib/jvm/jdk1.8.0_371\" >> $HBASE_HOME/conf/hbase-env.sh\necho \"export HBASE_CLASSPATH=/usr/local/hbase/conf\" >> $HBASE_HOME/conf/hbase-env.sh\necho \"export HBASE_MANAGES_ZK=true\" >> $HBASE_HOME/conf/hbase-env.sh\necho \"export HBASE_DISABLE_HADOOP_CLASSPATH_LOOKUP=true\" >> $HBASE_HOME/conf/hbase-env.sh\n\ncat >$HBASE_HOME/conf/hbase-site.xml<<\"EOF\"\n<configuration>\n        <property>\n                <name>hbase.rootdir</name>\n                <value>hdfs://qianyios:9000/hbase</value>\n        </property>\n        <property>\n                <name>hbase.cluster.distributed</name>\n                <value>true</value>\n        </property>\n        <property>\n                <name>hbase.unsafe.stream.capability.enforce</name>\n                <value>false</value>\n        </property>\n</configuration>\nEOF\n```\n\n### 启动hbase\n\n```\nstart-all.sh \nstart-hbase.sh\n```\n\n然后输入jps,有以下三个个就安装成功\n\n![image-20250228160532991](../img/Hadoop%203.3.5%E9%83%A8%E7%BD%B2/c04c2e13c89c8eae6005dd6e22745bb755933597-1741134057017-21.png)\n\n\n\n测试hbase\n\n```\nhbase shell\nlist\n```\n\n能运行没报错就行\n\n![image-20250228163520364](../img/Hadoop%203.3.5%E9%83%A8%E7%BD%B2/4672fe19c429bef2f4168e3d93aec7a755933597-1741134057017-22.png)\n\n访问hbase网页\n\nhttp://192.168.48.128:16010/\n\n![image-20250228163637109](../img/Hadoop%203.3.5%E9%83%A8%E7%BD%B2/00cc2038142a72aa0874e4455578118e55933597-1741134057017-24.png)\n\n关机备份打快照\n\n关机顺序\n\n```\nstop-hbase.sh\nstop-all.sh\npoweroff\n```\n\n开机顺序\n\n```\nstart-all.sh\nstart-hbase.sh\n```\n\n\n\n### 实例测试1\n\n| 学号（S_No） | 姓名（S_Name） | 性别（S_Sex） | 年龄（S_Age） |\n| :----------: | :------------: | :-----------: | :-----------: |\n|   2015001    |    zhangsan    |     male      |      23       |\n|   2015002    |      Mary      |    female     |      22       |\n|   2015003    |      Lisi      |     male      |      24       |\n\n#### 创建学生表\n\n```bash\nhbase shell\ncreate 'student','no','name','sex','age'\n#查看表结构\ndescribe 'student'\n```\n\n![image-20250228164331731](../img/Hadoop%203.3.5%E9%83%A8%E7%BD%B2/6e83288fecfc08b2f279113720320c1655933597-1741134057017-23.png)\n\n#### 添加数据\n\ns001为行键,行键可以自定义,但是要注意区别,按照前面的学生表,输入第一行s001的学生信息,我这里就简单输入一些信息，做例子用\n\n```bash\n#查看表的信息\nscan 'student'\nput 'student','s001','no','2015001'\nput 'student','s001','name','zhangsan'\nscan 'student'\n```\n\n![image-20250228164715165](../img/Hadoop%203.3.5%E9%83%A8%E7%BD%B2/dd0085f6d72cad5865ce4b8bdcb9f4df55933597-1741134057017-25.png)\n\n#### 查看整行\n\n```\nget 'student','s001'\n```\n\n![image-20250228164802747](../img/Hadoop%203.3.5%E9%83%A8%E7%BD%B2/a8025f688a510221d5ecdf2bd7b8893e55933597-1741134057017-26.png)\n\n#### 查看单元格\n\n```\nget 'student','s001','name'\n```\n\n![image-20250228164900943](../img/Hadoop%203.3.5%E9%83%A8%E7%BD%B2/7a69cf09647e40bb019fb4d60df91a2055933597-1741134057017-27.png)\n\n### 实例测试2\n\n这是一个订单表\n\n![image-20250228165126371](../img/Hadoop%203.3.5%E9%83%A8%E7%BD%B2/badb58d81d015ee7018a5b064a0f479455933597-1741134057017-28.png)\n\n#### 创建order表\n\n创建一个order表，出现两列族==userinfo,orderinfo==\n\n你看这次的行是1就和上个实例的s001，是不一样，都是可以自定义的\n\n然后在列族下创建列==userinfo:name，userinfo:age，orderinfo:id，orderinfo:money==\n\n在创建列的同时附带值\n\n```\ncreate 'order','userinfo','orderinfo'\nlist\nput 'order','1','userinfo:name','sw'\nput 'order','1','userinfo:age','24'\nput 'order','1','orderinfo:id','23333'\nput 'order','1','orderinfo:money','30'\nscan 'order'\n```\n\n![image-20250228165243544](../img/Hadoop%203.3.5%E9%83%A8%E7%BD%B2/62c035ec5ebac17f0447343741ae78d955933597-1741134057017-30.png)\n\n#### 修改数据\n\n```\nput 'order','1','userinfo:name','zhangxiaosan'\nget 'order','1','userinfo:name'\nscan 'order'\n```\n\n![image-20250228170258943](../img/Hadoop%203.3.5%E9%83%A8%E7%BD%B2/6669ad4bc556d790e2d969f8b120630a55933597-1741134057017-29.png)\n\n#### 时间戳\n\n数据添加到HBase的时候都会被记录一个`时间戳`，这个时间戳被我们当做一个版本。\n\n当修改某一条的时候，本质上是往里边新增一条数据，记录的版本加一。\n\n![image-20250228170428084](../img/Hadoop%203.3.5%E9%83%A8%E7%BD%B2/060968af7f2b968e0e4d854cd0b9573455933597-1741134057017-31.png)\n\n现在要把这条记录的值改为40，实际上就是多添加一条记录，在读的时候按照时间戳读最新的记录\n\n![image-20250228170509622](../img/Hadoop%203.3.5%E9%83%A8%E7%BD%B2/52de916bf5cca1f325f94acc901d6e4355933597-1741134057017-32.png)\n\n```\nget 'order','1','orderinfo:money'\nput 'order','1','orderinfo:money','40'\nget 'order','1','orderinfo:money'\n```\n\n![image-20250228170922948](../img/Hadoop%203.3.5%E9%83%A8%E7%BD%B2/f497d628fd03b1287fdb9e46d1e1f20d55933597-1741134057017-33.png)\n\n#### 删除数据\n\nname后一定要加个`:`\n\n```\nscan 'student'\ndelete 'student','s001','name:'\nget 'student','s001','name'\n```\n\n![image-20250228171143117](../img/Hadoop%203.3.5%E9%83%A8%E7%BD%B2/35ff5d39e108ce3201e476b35bceb36855933597-1741134057017-34.png)\n\n#### 删除表\n\n```\ndisable 'student'\ndescribe 'student'\ndrop 'student'\n```\n\n![image-20250228171228570](../img/Hadoop%203.3.5%E9%83%A8%E7%BD%B2/edef5233300dc9dc8be699628ed9ce8355933597-1741134057017-35.png)\n\n## Hive\n\nhive 是一种底层封装了Hadoop 的数据仓库处理工具，使用类SQL 的hiveSQL 语言实现数据查询，所有hive 的数据都存储在Hadoop 兼容的文件系统、(例如，[Amazon S3](https://baike.baidu.com/item/Amazon S3/10809744)、HDFS)中。hive 在加载数据过程中不会对数据进行任何的修改，只是将数据移动到HDFS 中hive 设定的目录下，因此，hive 不支持对数据的改写和添加，所有的数据都是在加载的时候确定的。\n\n**用户接口Client**\n\n用户接口主要有三个：CLI，Client 和 WUI。其中最常用的是 Cli，Cli启动的时候，会同时启动一个 hive 副本。Client 是 hive 的客户端，用户连接至 hive Server。在启动 Client 模式的时候，需要指出 hive Server 所在节点，并且在该节点启动 hive Server。 WUI 是通过浏览器访问 hive。\n\n**元数据存储 Metastore**\n\nhive 将元数据存储在数据库中，如 mysql、derby。hive 中的元数据包括表的名字，表的列和分区及其属性，表的属性（是否为外部表等），表的数据所在目录等。\n\n**驱动器：Driver 解释器、编译器、优化器、执行器**\n\n解释器、编译器、优化器完成 HQL 查询语句从词法分析、语法分析、编译、优化以及查询计划的生成。生成的查询计划存储在 HDFS 中，并在随后由 MapReduce 调用执行。\n\n**Hadoop**\n\nhive 的数据存储在 HDFS 中，大部分的查询由 MapReduce 完成（不包含 * 的查询，比如 select * from tbl 不会生成 MapReduce 任务）。\n\n![image-20250304164524876](../img/Hadoop%203.3.5%E9%83%A8%E7%BD%B2/4f81535914ee466bb896c99825fc8a5455933597.png)\n\n![image-20250304164530902](../img/Hadoop%203.3.5%E9%83%A8%E7%BD%B2/e70302cba6a69ea06f90990acefe1fa655933597.png)\n\n### 安装hive\n\n`qianyios:3306`这里要改成你的主机名\n\n`root`是数据库的root用户\n\n`qianyios666`是数据库密码\n\n```bash\ntar -xf /root/hadoop/apache-hive-3.1.3-bin.tar.gz\nmv apache-hive-3.1.3-bin /usr/local/hive\necho \"export HIVE_HOME=/usr/local/hive\" >> /etc/profile\necho \"export PATH=\\$HIVE_HOME/bin:\\$PATH\" >> /etc/profile\nsource /etc/profile\ncat >/usr/local/hive/conf/hive-site.xml<<\"EOF\"\n<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n<?xml-stylesheet type=\"text/xsl\" href=\"configuration.xsl\"?>\n<configuration>\n  <property>\n    <name>javax.jdo.option.ConnectionURL</name>\n    <value>jdbc:mysql://qianyios:3306/hive?createDatabaseIfNotExist=true&amp;useSSL=false</value>\n    <description>JDBC connect string for a JDBC metastore</description>\n  </property>\n  <property>\n    <name>javax.jdo.option.ConnectionDriverName</name>\n    <value>com.mysql.cj.jdbc.Driver</value>\n    <description>Driver class name for a JDBC metastore</description>\n  </property>\n  <property>\n    <name>javax.jdo.option.ConnectionUserName</name>\n    <value>root</value>\n    <description>username to use against metastore database</description>\n  </property>\n  <property>\n    <name>javax.jdo.option.ConnectionPassword</name>\n    <value>qianyios666</value>\n    <description>password to use against metastore database</description>\n  </property>\n \t<property>\n    <name>hive.exec.mode.local.auto</name>\n    <value>true</value>\n  </property>\n</configuration>\nEOF\n```\n\n### 安装mysql\n\n```bash\napt remove mariadb* -y\napt install -y net-tools wget mysql-server\nsystemctl enable --now mysql\n#mysql初始化\nmysql_secure_installation\n```\n\n```bash\n#输入no\nPress y|Y for Yes, any other key for No: no\nRemove anonymous users?: yes\nDisallow root login remotely?: no\nRemove test database and access to it?: yes\nReload privilege tables now?: yes\n```\n\n```bash\nmysql -uroot\n#创建用户 'root'@'localhost'\nCREATE USER IF NOT EXISTS 'root'@'localhost' IDENTIFIED BY 'qianyios666';\nGRANT ALL PRIVILEGES ON *.* TO 'root'@'localhost' WITH GRANT OPTION;\n#将 'root'@'localhost' 的认证插件切换为 mysql_native_password\nALTER USER 'root'@'localhost' IDENTIFIED WITH mysql_native_password BY 'qianyios666';\n#创建用户 'root'@'qianyios'\nCREATE USER IF NOT EXISTS 'root'@'qianyios' IDENTIFIED BY 'qianyios666';\nGRANT ALL PRIVILEGES ON *.* TO 'root'@'qianyios' WITH GRANT OPTION;\nFLUSH PRIVILEGES;\ncreate database hive;\nexit\nsudo sed -i 's/^bind-address\\s*=\\s*127.0.0.1/bind-address = 0.0.0.0/' /etc/mysql/mysql.conf.d/mysqld.cnf\nsudo sed -i 's/^mysqlx-bind-address\\s*=\\s*127.0.0.1/mysqlx-bind-address = 0.0.0.0/' /etc/mysql/mysql.conf.d/mysqld.cnf\nsystemctl restart mysql\n```\n\n### 启动hive\n\n```bash\ncd\nwget -P /root/hadoop/ https://downloads.mysql.com/archives/get/p/3/file/mysql-connector-java-8.0.11.tar.gz\ntar -xf /root/hadoop/mysql-connector-java-8.0.11.tar.gz\ncp mysql-connector-java-8.0.11/mysql-connector-java-8.0.11.jar /usr/local/hive/lib/\nmv /usr/local/hive/lib/guava-19.0.jar{,.bak}\ncp /usr/local/hadoop/share/hadoop/common/lib/guava-27.0-jre.jar  /usr/local/hive/lib\nstart-all.sh \n#hive初始化，这个命令只需要运行一次\nschematool -dbType mysql -initSchema\n#启动hive\nhive\n```\n\nhive初始化有这个说明成功初始化如果失败，检查一下配置文件或者数据库\n\n![image-20250304193132330](../img/Hadoop%203.3.5%E9%83%A8%E7%BD%B2/f4659243f9cf16b7b00f826f5273851b55933597.png)\n\n![image-20250304193255320](../img/Hadoop%203.3.5%E9%83%A8%E7%BD%B2/8461b4121e001687243685b5b4d9382c55933597.png)\n\n要退出就按两下ctrl+C\n\n### Hive数据类型\n\n|          类型          |                 描述                  |     示例     |\n| :--------------------: | :-----------------------------------: | :----------: |\n|   TINYINT（tinyint）   | 一个字节（8位）有符号整数，  -128~127 |      1       |\n|  SMALLINT（smallint）  | 2字节（16位）有符号整数，-32768~32767 |      1       |\n|       INT（int）       |        4字节（32位）有符号整数        |      1       |\n|    BIGINT（bigint）    |        8字节（64位）有符号整数        |      1       |\n|     FLOAT（float）     |       4字节（32位）单精度浮点数       |      1       |\n|    DOUBLE（double）    |       8字节（64位）双精度浮点数       |      1       |\n|    DECIMAL(decimal)    |         任意精度的带符号小数          |      1       |\n|   BOOLEAN（boolean）   |              true/false               |  true/false  |\n|    STRING（string）    |             字符串，变长              | ‘a’,‘b’,‘1’  |\n|   VARCHAR（varchar）   |              变长字符串               |     ‘a’      |\n|      CHAR（char）      |            固定长度字符串             |     ‘a’      |\n|    BINANY（binany）    |               字节数组                |   无法表示   |\n| TIMESTAMP（timestamp） |           时间戳，纳秒精度            | 1.22327E+11  |\n|      DATE（date）      |                 日期                  | ‘2016-03-29’ |\n\n### hive的集合数据类型\n\n|  类型  |                             描述                             |       示例        |\n| :----: | :----------------------------------------------------------: | :---------------: |\n| ARRAY  |                 有序数组，字段的类型必须相同                 |   Array（1，2）   |\n|  MAP   | 一组无序的键值对，键的类型必须是原始数据类型，他的值可以是任何类型，同一个映射的键的类型必须相同，值得类型也必须相同 |   Map（‘a’,1）    |\n| STRUCT |               一组命名的字段,字段类型可以不同                | Struct（‘a’,1,2.0 |\n| UNION  | UNION则类似于C语言中的UNION结构，在给定的任何一个时间点，UNION类型可以保存指定数据类型中的任意一种 |                   |\n\n### 基本命令\n\n以下在hive数据仓库了运行,输入以下命令进入，可能启动有点慢\n\n```\nhive\n```\n\n\n\n#### 创建数据库和表\n\n```\ncreate database hive;\nuse hive;\ncreate table usr(id int,name string,age int);\n```\n\n#### 查看和描述数据库和表\n\n```\nshow databases;\nshow tables;\nUSE hive;\ndescribe database hive;\ndescribe hive.usr;\n```\n\n![image-20250304195510092](../img/Hadoop%203.3.5%E9%83%A8%E7%BD%B2/523e2a71150e1d8d4964e4a3a0dcffc455933597.png)\n\n#### 向表中装载数据\n\n```bash\ninsert into usr values(1,'sina',20);\n\n#从linux读取数据\n[root@qianyios555 ~]# echo \"2,zhangsan,22\" >> /opt/data\n#从hive导入数据\nhive> use hive;\ncreate table usr1(id int,name string,age int) row format delimited fields terminated by \",\";\nload data local inpath '/opt/data' overwrite into table usr1;\n```\n\n#### 从hdfs中读取数据\n\n```\n#从linux读取数据\necho \"3,lisi,25\" > /opt/test.txt\nhdfs dfs -put /opt/test.txt /\nhive\nuse hive;\nload data inpath 'hdfs://qianyios:9000/test.txt' overwrite into table usr1;\n```\n\n#### 从别的表中读取数据\n\n```\nhive> select * from usr;\nOK\n1       sina    20\n\nhive> select * from usr1;\nOK\n3       lisi    25\n#读取usr1的id=3的数据到usr\ninsert overwrite table usr select * from usr1 where id=3;\n\nhive> select * from usr;\nOK\n3       lisi    25\n```\n\n#### 查询表中数据\n\n```\nselect * from usr1;\n```\n\n### Hive实验：词频统计\n\n#### 在linux上创建输入目录：/opt/input；\n\n```\nmkdir /opt/input\n```\n\n#### 在以上输入目录中添加多个文本文件，其中文件中包含单词：姓名学号，例如：qianyios555；\n\n```\necho \"hello1 qianyios555\" > /opt/input/text1.txt\necho \"hello2 qianyios555\" > /opt/input/text2.txt\necho \"hello3 qianyios555\" > /opt/input/text3.txt\n```\n\n#### 在Hive中创建表“docs”，并把输入目录的文件数据加载到该表中；\n\n```\nhive\nuse hive;\ncreate table docs(line string);\nload data local inpath '/opt/input' overwrite into table docs;\nselect * from docs;\n```\n\n#### 编写HiveQL语句对输入目录的文本进行词频统计，统计单词“姓名学号”出现的次数。\n\n```\ncreate table word_count as\nselect word,count(1) as count from\n(select explode(split(line,' ')) as word from docs) w\ngroup by word\norder by word;\n\nselect * from word_count;\ndescribe word_count;\n```\n\n![image-20250304200653584](../img/Hadoop%203.3.5%E9%83%A8%E7%BD%B2/ad87efeb56e56016026c6c3ac559b93755933597.png)\n\n<div class=\"tbsm\" style=\"margin-top:54px;\">\n<div class=\"tbsm-top\"><span><svg t=\"1674654360507\" class=\"icon\" viewBox=\"0 0 1024 1024\" version=\"1.1\" xmlns=\"http://www.w3.org/2000/svg\" p-id=\"987\" data-spm-anchor-id=\"a313x.7781069.0.i0\" width=\"35\" height=\"35\"><path d=\"M410.49 97.74H155.08a56.74 56.74 0 0 0-56.84 56.73V410a56.84 56.84 0 0 0 56.84 56.84h255.41A56.83 56.83 0 0 0 467.32 410V154.58a56.83 56.83 0 0 0-56.83-56.84zM410.49 558.74H155.08a56.74 56.74 0 0 0-56.84 56.73V871a56.84 56.84 0 0 0 56.84 56.84h255.41A56.83 56.83 0 0 0 467.32 871V615.58a56.83 56.83 0 0 0-56.83-56.84zM871.49 558.74H616.08a56.74 56.74 0 0 0-56.84 56.73V871a56.84 56.84 0 0 0 56.84 56.84h255.41A56.83 56.83 0 0 0 928.32 871V615.58a56.83 56.83 0 0 0-56.83-56.84z\" fill=\"#66EEFF\" p-id=\"988\"></path><path d=\"M410.49 558.74h-4.14A475 475 0 0 0 299.52 859.6a481.16 481.16 0 0 0 4.84 68.22h106.13A56.83 56.83 0 0 0 467.32 871V615.58a56.83 56.83 0 0 0-56.83-56.84zM871.49 558.74H616.08a56.74 56.74 0 0 0-56.84 56.73V871a56.84 56.84 0 0 0 56.84 56.84h255.41A56.83 56.83 0 0 0 928.32 871V615.58a56.83 56.83 0 0 0-56.83-56.84z\" fill=\"#C2F8FF\" p-id=\"989\"></path></svg></span><span style=\"font-size:30px;\"> 特别声明</span></div>\n<div class=\"tbsm-wz\">千屹博客旗下的所有文章，是通过本人课堂学习和课外自学所精心整理的知识巨著<br/>难免会有出错的地方<br/>如果细心的你发现了小失误，可以在下方评论区告诉我，或者私信我！<br />非常感谢大家的热烈支持！</div>\n</div>\n","tags":["Ubuntu","Hadoop"],"categories":["运维"]},{"title":"计算机网络技术课程综合实验","url":"/posts/f5e08620/","content":"\n<meta name=\"referrer\" content=\"no-referrer\"/>\n\n# 计算机网络技术课程综合实验\n\n空拓扑下载：[空拓扑](https://resource.qianyios.top/%E7%BD%91%E7%BB%9C/%E7%BB%BC%E5%90%88%E5%AE%9E%E9%AA%8C%28%E7%A9%BA%E6%8B%93%E6%89%91%EF%BC%89.zip)\n\n## 前情提要\n\n自行安装ensp软件，结合教程来安装\n\n[华为ensp模拟器安装教程 | 严千屹博客](https://blog.qianyios.top/posts/f8bb3dfe/)\n\n\n\n打开显示端口\n\n![image-20250224122453035](../img/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E6%8A%80%E6%9C%AF%E8%AF%BE%E7%A8%8B%E7%BB%BC%E5%90%88%E5%AE%9E%E9%AA%8C/1718e9303bc216f086f248ec3d5bd5db55933597-1748227909929-1.png)\n\n\n\n简单说一下一些常识\n\n1.用户视图`<Huawei>`： - 这是登录后的初始界面，在这里可以执行一些基本信息查看和简单的命令。\n2.系统视图：`[Huawei]` - 输入`system-view`或者`sys`进入此模式，用于全局性的设备配置。\n3.接口视图：`[Huawei-GigabitEthernet0/0/1]` - 使用`interface`或`int`命令进入特定接口进行配置。\n4.协议视图：`[Huawei-ospf-1]` - 对应于路由协议等高级功能的配置。\n\n\n\n> 以后的每一步实验都会从`<Huawei>`开始，如果你是系统视图，自行输入q退回用户试图\n\n## 基础配置\n\n`要求：`\n\n1、给6个路由器AR1到AR6，6个交换机LSW1到LSW6全部改好设备名字，设备名称修改为自己名字首字母缩写+设备名。比如最左边的AR1路由器，学生名字为张三，则设备名称改为 yjxAR1\n\n![image-20250224123713290](../img/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E6%8A%80%E6%9C%AF%E8%AF%BE%E7%A8%8B%E7%BB%BC%E5%90%88%E5%AE%9E%E9%AA%8C/f7fdb0de23e0278c1b01ca3ff187836255933597-1748227909930-2.png)\n\n2、给第一行的AR1、AR2、AR3、AR4、AR5共5个路由器的接口，配置好IP地址。在网络拓扑图明确给出来的，按图示的配置。没有明确给出来的，则统一默认规则：左右并排连接的，左边接口最后1个字节配1，右边接口配2； 上下连接的，下边接口配1，上边接口配2.\n\n![image-20250224124132783](../img/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E6%8A%80%E6%9C%AF%E8%AF%BE%E7%A8%8B%E7%BB%BC%E5%90%88%E5%AE%9E%E9%AA%8C/9f934a357f640fec95736ec78e1d17db55933597-1748227909930-3.png)\n\n\n\n如果刚开始是`<Huawei>`也叫用户视图就可以直接输入下面的指令，如果是`[Huawei]`也叫系统视图，要输入一个`quit`或`q`进行退出。这样是为了方便统一大家的输入，我们全部退回到用户视图，这样就可以全部输入指令了\n\n![image-20250224123518605](../img/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E6%8A%80%E6%9C%AF%E8%AF%BE%E7%A8%8B%E7%BB%BC%E5%90%88%E5%AE%9E%E9%AA%8C/5b10c95c98cf4999fd454d59e7e156d055933597-1748227909930-4.png)\n\n以下简写的命令，回到[前情提要](#前情提要)自己看\n\n### 路由器配置\n\n> 主机位没有明确给出来的，则统一默认规则：左右并排连接的，左边接口最后1个字节配1，右边接口配2； 上下连接的，下边接口配1，上边接口配2.\n\n`yjxAR1`\n\n```\nsys\nsysname yjxAR1\nint g0/0/2\nip address 10.1.3.2 30\nq\nint g0/0/1\nip address 10.1.1.2 30\nq\nint g0/0/0\nip address 10.1.2.2 30\nq\nint g4/0/0\nip address 10.12.100.10 24\nq\nq\n\n```\n\n复制全部，粘贴全部一步到位\n\n![image-20250224125827919](../img/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E6%8A%80%E6%9C%AF%E8%AF%BE%E7%A8%8B%E7%BB%BC%E5%90%88%E5%AE%9E%E9%AA%8C/10753fea0befbf3b2745d5276541e1fa55933597-1748227909930-5.png)\n\n\n\n`yjxAR2`\n\n```\nsys\nsysname yjxAR2\nint g0/0/0\nip address 10.12.100.20 24\nq\nint s4/0/0\nip address 23.1.1.1 24\nq\nq\n\n```\n\n![image-20250224125845081](../img/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E6%8A%80%E6%9C%AF%E8%AF%BE%E7%A8%8B%E7%BB%BC%E5%90%88%E5%AE%9E%E9%AA%8C/5b34d4c9820d0a3b3d50358ea2b57afa55933597-1748227909930-6.png)\n\n\n\n`yjxAR3`\n\n```\nsys\nsysname yjxAR3\nint s4/0/0\nip address 23.1.1.2 24\nq\nint g0/0/0\nip address 34.1.1.1 30\nq\nq\n\n```\n\n![image-20250224125908801](../img/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E6%8A%80%E6%9C%AF%E8%AF%BE%E7%A8%8B%E7%BB%BC%E5%90%88%E5%AE%9E%E9%AA%8C/73f1d9e264bfe1f6638d58709f807bf255933597-1748227909930-7.png)\n\n\n\n`yjxAR4`\n\n```\nsys\nsysname yjxAR4\nint g0/0/0\nip address 34.1.1.2 30\nq\nint g0/0/1\nip address 45.1.1.1 30\nq\nq\n\n```\n\n![image-20250224130105066](../img/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E6%8A%80%E6%9C%AF%E8%AF%BE%E7%A8%8B%E7%BB%BC%E5%90%88%E5%AE%9E%E9%AA%8C/8c430ea28f8ef87e89f680950c0ec76655933597-1748227909930-8.png)\n\n\n\n`yjxAR5`\n\n```\nun te mo\nsys\nsysname yjxAR5\nint g0/0/0\nip address 45.1.1.2 30\nq\n\n```\n\n![image-20250224142354111](../img/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E6%8A%80%E6%9C%AF%E8%AF%BE%E7%A8%8B%E7%BB%BC%E5%90%88%E5%AE%9E%E9%AA%8C/89b46c60d80f7307b736096a82c3144f55933597-1748227909930-9.png)\n\n\n\n3、重要提醒：所有网络设备的配置，记得最后用save命令保存。否则软件关闭后将不保留。\n\n![image-20250224142529913](../img/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E6%8A%80%E6%9C%AF%E8%AF%BE%E7%A8%8B%E7%BB%BC%E5%90%88%E5%AE%9E%E9%AA%8C/9be01986830f8d0539d350518d5ebfe255933597-1748227909930-10.png)\n\n### pc配置静态ip\n\n4、给网络拓扑图最底下的PC，按图配置好静态IP地址。\n\n![image-20250224142725509](../img/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E6%8A%80%E6%9C%AF%E8%AF%BE%E7%A8%8B%E7%BB%BC%E5%90%88%E5%AE%9E%E9%AA%8C/6f7915a7f301266a9b9d781e8e686ef055933597-1748227909930-11.png)\n\n![image-20250224143251395](../img/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E6%8A%80%E6%9C%AF%E8%AF%BE%E7%A8%8B%E7%BB%BC%E5%90%88%E5%AE%9E%E9%AA%8C/b8888eb23ea01f87a44e45e73a854ef555933597-1748227909930-12.png)\n\n![image-20250224144907420](../img/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E6%8A%80%E6%9C%AF%E8%AF%BE%E7%A8%8B%E7%BB%BC%E5%90%88%E5%AE%9E%E9%AA%8C/4488aa1240c8b280ef748987e07024dd55933597-1748227909930-13.png)\n\n![image-20250224144935595](../img/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E6%8A%80%E6%9C%AF%E8%AF%BE%E7%A8%8B%E7%BB%BC%E5%90%88%E5%AE%9E%E9%AA%8C/246c8a59b4599db4ff3e948d643f65c455933597-1748227909930-14.png)\n\n![image-20250224144952698](../img/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E6%8A%80%E6%9C%AF%E8%AF%BE%E7%A8%8B%E7%BB%BC%E5%90%88%E5%AE%9E%E9%AA%8C/1afebce5e4f6f7cd14600a992bca012a55933597-1748227909930-15.png)\n\n![image-20250224145236193](../img/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E6%8A%80%E6%9C%AF%E8%AF%BE%E7%A8%8B%E7%BB%BC%E5%90%88%E5%AE%9E%E9%AA%8C/b778665ff793aaeed3716740802e980355933597-1748227909930-16.png)\n\n![image-20250226121259570](../img/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E6%8A%80%E6%9C%AF%E8%AF%BE%E7%A8%8B%E7%BB%BC%E5%90%88%E5%AE%9E%E9%AA%8C/04a1b74208276139418875b04dec413e55933597-1748227909930-18.png)\n\n![image-20250226121328616](../img/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E6%8A%80%E6%9C%AF%E8%AF%BE%E7%A8%8B%E7%BB%BC%E5%90%88%E5%AE%9E%E9%AA%8C/d31d5b7242f80df2ba08e7585b8ac0da55933597-1748227909930-17.png)\n\n![image-20250224145315321](../img/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E6%8A%80%E6%9C%AF%E8%AF%BE%E7%A8%8B%E7%BB%BC%E5%90%88%E5%AE%9E%E9%AA%8C/97be91a109d7e8f94162d318f6e128a455933597-1748227909930-19.png)\n\n![image-20250224145344081](../img/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E6%8A%80%E6%9C%AF%E8%AF%BE%E7%A8%8B%E7%BB%BC%E5%90%88%E5%AE%9E%E9%AA%8C/b56545ab02e861e492a5cfdfd013697c55933597-1748227909930-20.png)\n\n\n\n### AR路由表展示\n\n![image-20250226125730431](../img/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E6%8A%80%E6%9C%AF%E8%AF%BE%E7%A8%8B%E7%BB%BC%E5%90%88%E5%AE%9E%E9%AA%8C/757c033c0e73430b05812873c6505a5c55933597-1748227909930-21.png)\n\n![image-20250226130016385](../img/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E6%8A%80%E6%9C%AF%E8%AF%BE%E7%A8%8B%E7%BB%BC%E5%90%88%E5%AE%9E%E9%AA%8C/f301994aa24b62948ad2d4706992593755933597-1748227909930-22.png)\n\n![image-20250226122050939](../img/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E6%8A%80%E6%9C%AF%E8%AF%BE%E7%A8%8B%E7%BB%BC%E5%90%88%E5%AE%9E%E9%AA%8C/82ee192e32b93ed85009f89cd216ae9a55933597-1748227909930-23.png)\n\n![image-20250226122224080](../img/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E6%8A%80%E6%9C%AF%E8%AF%BE%E7%A8%8B%E7%BB%BC%E5%90%88%E5%AE%9E%E9%AA%8C/c2d838f32ee8720bda779c6cdecfd35b55933597-1748227909930-24.png)\n\n![image-20250226122250938](../img/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E6%8A%80%E6%9C%AF%E8%AF%BE%E7%A8%8B%E7%BB%BC%E5%90%88%E5%AE%9E%E9%AA%8C/7c8f88c9d8bc3a471473f3a04229bbee55933597-1748227909930-26.png)\n\n## 第二周\n\n### 配置vlan\n\n开启LSW1、LSW3、LSW4，关闭LSW2避免形成环路，配置VLAN库，配置交换机端口属性，配置交换机端口归属哪些VLAN\n\n`yjxLSW3`\n\n```\nsys\nsysname yjxLSW3\n#配置VLAN库\nvlan batch 10 20\n#配置交换机端口属性\nint g0/0/1\nport link-type access\nint g0/0/2\nport link-type access\nint g0/0/5\nport link-type access\nint g0/0/3\nport link-type trunk\n#配置交换机端口归属哪些VLAN或哪些VLAN能通过\nint g0/0/1\nport default vlan 10\nint g0/0/2\nport default vlan 20\nint g0/0/5\nport default vlan 10\nint g0/0/3\nport trunk allow-pass vlan 10 20 \n#查看配置信息\ndisplay vlan\n```\n\n![image-20250303102338703](../img/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E6%8A%80%E6%9C%AF%E8%AF%BE%E7%A8%8B%E7%BB%BC%E5%90%88%E5%AE%9E%E9%AA%8C/bce9e60b19478316a16fe0bf497c0bcd55933597-1748227909930-25.png)\n\n`yjxLSW4`\n\n```\nun te mo\nsys\nsysname yjxLSW4\nvlan batch 10 20\nint g0/0/1\nport link-type access\nint g0/0/2\nport link-type access\nint g0/0/3\nport link-type trunk\nint g0/0/1\nport default vlan 10\nint g0/0/2\nport default vlan 20\nint g0/0/3\nport trunk allow-pass vlan 10 20\ndisplay vlan\n```\n\n![image-20250303102746287](../img/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E6%8A%80%E6%9C%AF%E8%AF%BE%E7%A8%8B%E7%BB%BC%E5%90%88%E5%AE%9E%E9%AA%8C/6ce0aa8f70b427dd28f65216c9718d0655933597-1748227909930-27.png)\n\n### 配置网关\n\n在LSW1交换机上，配置VLAN的虚拟接口SVI，配置SVI的IP地址，从而实现各VLAN的连通。一般配置VLAN接口，是在核心交换机上，本拓扑图即为LSW1。PC1到PC4补充上对应的网关，即SVI的IP地址\n\n在`yjxLSW1`配置网关\n\n`yjxLSW1`\n\n```\nun te mo\nsys\nsysname yjxLSW1\nvlan batch 10 20\nint vlan 10\nip address 192.168.1.254 24\nint vlan 20\nip address 192.168.2.254 24\ndis ip int br\n```\n\n![image-20250303103425485](../img/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E6%8A%80%E6%9C%AF%E8%AF%BE%E7%A8%8B%E7%BB%BC%E5%90%88%E5%AE%9E%E9%AA%8C/bf638dda0a427599b7facbeafef84f1d55933597-1748227909930-28.png)\n\n\n\n最后LSW1,3,4全部退回到用户视图，保存\n\n```\nsave\n```\n\n\n\n### 给pc1-pc4配置网关\n\n![image-20250303103611183](../img/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E6%8A%80%E6%9C%AF%E8%AF%BE%E7%A8%8B%E7%BB%BC%E5%90%88%E5%AE%9E%E9%AA%8C/6f0f66b5e080e4081007e5b622467be455933597-1748227909930-30.png)\n\n## 第三周\n\n开启这两台机\n\n![image-20250310103803318](../img/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E6%8A%80%E6%9C%AF%E8%AF%BE%E7%A8%8B%E7%BB%BC%E5%90%88%E5%AE%9E%E9%AA%8C/6c69495e42ae2701c2136512119c754255933597-1748227909930-31.png)\n\n配置链路聚合\n\n==yjxLSW1==\n\n```\nun te mo\nsys\nsysname yjxLSW1\nint Eth-Trunk 1\nport link-type trunk\nport trunk allow-pass vlan 10 20\nint Eth-Trunk 1\nmode lacp-static\nmax active-linknumber 2\ntrunkport g0/0/3\ntrunkport g0/0/4\ntrunkport g0/0/6\n```\n\n==yjxLSW2==\n\n```\nun te mo\nsys\nsysname yjxLSW2\nint Eth-Trunk 1\nport link-type trunk\nport trunk allow-pass vlan 10 20\nint Eth-Trunk 1\nmode lacp-static\nmax active-linknumber 2\ntrunkport g0/0/3\ntrunkport g0/0/4\ntrunkport g0/0/6\n```\n\n两个交换机一起打\n\n```\ndis eth-trunk\n```\n\n![image-20250310104555440](../img/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E6%8A%80%E6%9C%AF%E8%AF%BE%E7%A8%8B%E7%BB%BC%E5%90%88%E5%AE%9E%E9%AA%8C/bc704ac9cc58aec6dce362f34840875355933597-1748227909930-29.png)\n\n\n\n当连接GE0/0/3的线路出现问题时，会自动切换到使用GE0/0/4和GE0/0/6端口的线路。\n\n在此实验中，手工将GE0/0/3的线路删除，再显示链路聚合的状态信息\n\n`右键线路删除，注意如果3口还在说明你删错了，连回来`\n\n<video src='https://blog.qianyios.top/video/1.mov ' type='video/mp4' controls='controls'  width='100%' height='100%'>\n</video>\n\n你测试完记得加回来\n\n![image-20250310110704741](../img/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E6%8A%80%E6%9C%AF%E8%AF%BE%E7%A8%8B%E7%BB%BC%E5%90%88%E5%AE%9E%E9%AA%8C/98a5e41d80168d04ae163c297dc1b50955933597-1748227909930-32.png)\n\n然后保存关机\n\n![image-20250310110857985](../img/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E6%8A%80%E6%9C%AF%E8%AF%BE%E7%A8%8B%E7%BB%BC%E5%90%88%E5%AE%9E%E9%AA%8C/1e54448afa4040e50d14e3b2420f20bf55933597-1748227909930-33.png)\n\n## 第四周\n\n本实验通过配置动态路由RIP协议，实现内网全网互通。\n\n删除三条链路聚合的线，并且开起圈内的机子\n\n![image-20250317102313698](../img/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E6%8A%80%E6%9C%AF%E8%AF%BE%E7%A8%8B%E7%BB%BC%E5%90%88%E5%AE%9E%E9%AA%8C/199e1ddf3594a387342b2665bd8f998d697559838-1748227909930-34.png)\n\n开启内网的所有设备：R1、LSW1、LSW2、LSW3、LSW4，Serve1及内网PC。为避免环路影响，本次实验将连接LSW1与LSW2的聚合链路（即心跳线）先删除断开。\n\n### 任务1 \n\n 配置LSW1、LSW2、LSW3、LSW4的VLAN库，端口属性，端口归属。其中\n`yjxLSW1`的VLAN库有VLAN 10，VLAN 20，VLAN 110\n\n```\nun te mo\nsys\nvlan 110\ndis vlan\n```\n\n![image-20250317103437160](../img/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E6%8A%80%E6%9C%AF%E8%AF%BE%E7%A8%8B%E7%BB%BC%E5%90%88%E5%AE%9E%E9%AA%8C/13af7aeb9df6c4d47710e89177640318697559838-1748227909930-35.png)\n\n`yjxLSW2`的VLAN库有VLAN 10，VLAN 20，VLAN 120\n\n```\nun te mo\nsys\nvlan 120\ndis vlan\n```\n\n![image-20250317103545921](../img/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E6%8A%80%E6%9C%AF%E8%AF%BE%E7%A8%8B%E7%BB%BC%E5%90%88%E5%AE%9E%E9%AA%8C/1ad09c4c23dfc6ab63a267e9460ed349697559838-1748227909930-36.png)\n\n`yjxLSW3`的VLAN库有VLAN 10，VLAN 20 （之前已配置）\n\n![image-20250317103613515](../img/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E6%8A%80%E6%9C%AF%E8%AF%BE%E7%A8%8B%E7%BB%BC%E5%90%88%E5%AE%9E%E9%AA%8C/3bdf78890a9e3d96b5e50831fc952176697559838-1748227909930-37.png)\n\n`yjxLSW4`的VLAN库有VLAN 10，VLAN 20 （之前已配置）\n\n![image-20250317103646879](../img/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E6%8A%80%E6%9C%AF%E8%AF%BE%E7%A8%8B%E7%BB%BC%E5%90%88%E5%AE%9E%E9%AA%8C/fa904e9f3edc24644d9313c5579ea1a8697559838-1748227909930-38.png)\n\n`yjxLSW1`中，GE0/0/1口和GE0/0/2口为Trunk口，允许VLAN 10和VLAN 20通过\n         GE0/0/5口为Access口，归属VLAN 110\n         Eth-Trunk1为Trunk口，允许VLAN 10和VLAN 20通过（之前已配置）\n\n```\nun te mo\nsys\nvlan batch 10 20\nint g0/0/1\nport link-type trunk\nport trunk allow-pass vlan 10 20\nint g0/0/2\nport link-type trunk\nport trunk allow-pass vlan 10 20\nint g0/0/5\nport link-type access\nport default vlan 110\ndis vlan\n```\n\n![image-20250317104212732](../img/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E6%8A%80%E6%9C%AF%E8%AF%BE%E7%A8%8B%E7%BB%BC%E5%90%88%E5%AE%9E%E9%AA%8C/0bab0c3793163cea4ed239b3ddc9ce57697559838-1748227909930-39.png)\n\n`yjxLSW2`中，GE0/0/1口和GE0/0/2口为Trunk口，允许VLAN 10和VLAN 20通过\n         GE0/0/5口为Access口，归属VLAN 120\n         Eth-Trunk1为Trunk口，允许VLAN 10和VLAN 20通过\n\n```\nun te mo\nsys\nvlan batch 10 20\nint g0/0/1\nport link-type trunk\nport trunk allow-pass vlan 10 20\nint g0/0/2\nport link-type trunk\nport trunk allow-pass vlan 10 20\nint g0/0/5\nport link-type access\nport default vlan 120\ndis vlan\n```\n\n![image-20250317104415034](../img/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E6%8A%80%E6%9C%AF%E8%AF%BE%E7%A8%8B%E7%BB%BC%E5%90%88%E5%AE%9E%E9%AA%8C/312ef1450dccb3a950c8ac0a0102ce54697559838-1748227909930-40.png)\n\n`yjxLSW3`中，GE0/0/3口和GE0/0/4口为Trunk口，允许VLAN 10和VLAN 20通过（3口之前已配置）\n         GE0/0/1口和GE0/0/5口为Access口，归属VLAN 10（之前已配置）\n         GE0/0/2口为Access口，归属VLAN 20（之前已配置）\n\n```\nun te mo\nsys\nint g0/0/4\nport link-type trunk\nport trunk allow-pass vlan 10 20\ndis vlan\n```\n\n![image-20250317104629802](../img/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E6%8A%80%E6%9C%AF%E8%AF%BE%E7%A8%8B%E7%BB%BC%E5%90%88%E5%AE%9E%E9%AA%8C/43db48908c9fce2b2f0050f3f310541b697559838-1748227909930-41.png)\n\n`yjxLSW4`中，GE0/0/3口和GE0/0/4口为Trunk口，允许VLAN 10和VLAN 20通过（3口之前已配置）\n         GE0/0/1口为Access口，归属VLAN 10（之前已配置）\n         GE0/0/2口为Access口，归属VLAN 20（之前已配置）\n\n```\nun te mo\nsys\nint g0/0/4\nport link-type trunk\nport trunk allow-pass vlan 10 20\ndis vlan\n```\n\n![image-20250317104723213](../img/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E6%8A%80%E6%9C%AF%E8%AF%BE%E7%A8%8B%E7%BB%BC%E5%90%88%E5%AE%9E%E9%AA%8C/e67b5ae75a921f30bac119318015fea5697559838-1748227909930-42.png)\n\n### 任务2\n\n给AR1路由器的4个端口配置IP地址；给LSW1的VLAN10、VLAN20、VLAN110配置IP地址；给LSW2的VLAN10、VLAN、VLAN120配置IP地址。遵行未明确指示的情况下，IP地址最后一个字节：左边为1，右边为2；下面为1，上面为2。\n\n`yjxAR1`\n\n```\nun te mo\nsys\nsysname yjxAR1\nint g0/0/2\nip address 10.1.3.2 30\nint g0/0/1\nip address 10.1.1.2 30\nint g0/0/0\nip address 10.1.2.2 30\nint g4/0/0\nip address 10.12.100.10 24\ndis ip in br\n```\n\n![image-20250317110002377](../img/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E6%8A%80%E6%9C%AF%E8%AF%BE%E7%A8%8B%E7%BB%BC%E5%90%88%E5%AE%9E%E9%AA%8C/e52ea8b0d1fff544edcfc8e48e6cadb6697559838-1748227909930-43.png)\n\n`yjxLSW1`\n\n```\nun te mo\nsys\nint vlan 10\nip address 192.168.1.253 24\nint vlan 20\nip address 192.168.2.253 24\nint vlan 110\nip address 10.1.1.1 30\ndis ip in br\n```\n\n![image-20250317110135608](../img/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E6%8A%80%E6%9C%AF%E8%AF%BE%E7%A8%8B%E7%BB%BC%E5%90%88%E5%AE%9E%E9%AA%8C/cc84ec15f041f03a7c2feb6c48e7ff63697559838-1748227909930-44.png)\n\n`yjxLSW2`\n\n```\nun te mo\nsys\nint vlan 10\nip address 192.168.1.252 24\nint vlan 20\nip address 192.168.2.252 24\nint vlan 120\nip address 10.1.2.1 30\ndis ip in br\n```\n\n![image-20250317110421476](../img/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E6%8A%80%E6%9C%AF%E8%AF%BE%E7%A8%8B%E7%BB%BC%E5%90%88%E5%AE%9E%E9%AA%8C/a33c55496075f7ff29d9bbfb6d8af6e4697559838-1748227909930-45.png)\n\n### 任务3\n\n给AR1、LSW1、LSW2配置使用动态路由协议RIPv2，\n\nserver1配置IP地址10.1.3.1  网关10.1.3.2\n\n处于VLAN 10的PC手动切换网关为 1.253或者1.252\n\n处于VLAN 20的PC手动切换网关为 2.253或者2.252\n\n配置完成后，内网全网互相能Ping通，通过显示路由表信息确定结果。\n\n![image-20250317110843239](../img/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E6%8A%80%E6%9C%AF%E8%AF%BE%E7%A8%8B%E7%BB%BC%E5%90%88%E5%AE%9E%E9%AA%8C/c22b2b11bf3dcfc102f44b9b9282cb6f697559838-1748227909930-46.png)\n\n![image-20250317111117963](../img/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E6%8A%80%E6%9C%AF%E8%AF%BE%E7%A8%8B%E7%BB%BC%E5%90%88%E5%AE%9E%E9%AA%8C/a58004bc5bb3ca6cfd2814dbaf6a1f9c697559838-1748227909930-47.png)\n\n要点保存哈\n\n![image-20250317111255584](../img/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E6%8A%80%E6%9C%AF%E8%AF%BE%E7%A8%8B%E7%BB%BC%E5%90%88%E5%AE%9E%E9%AA%8C/334cfe7f15a68519abb00b38abcddef3697559838-1748227909930-49.png)\n\n配置rip协议\n\n`yjxAR1`\n\n配置AR1路由器使用RIP协议，如果直接按照拓扑图给的网络地址配置，如此命令[yjxAR1-rip-1]network 10.1.1.0将会提示出错\n\n原因是Error: The network address is invalid, and the specified address must be major-net address without any subnets.  \n\n错误：网络地址无效，指定的地址必须是主网地址，不能包含任何子网。\n\n```\nsys\nrip 1\nversion 2\nnetwork 10.0.0.0\n```\n\n`yjxLSW1`\n\n```\nsys\nrip 1\nversion 2\nnetwork 10.0.0.0\nnetwork 192.168.1.0\nnetwork 192.168.2.0\n```\n\n`yjxLSW2`\n\n```\nsys\nrip 1\nversion 2\nnetwork 10.0.0.0\nnetwork 192.168.1.0\nnetwork 192.168.2.0\n```\n\n\n\n`yjxAR1`\n\n```\ndis ip rou\n```\n\n![image-20250317111850525](../img/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E6%8A%80%E6%9C%AF%E8%AF%BE%E7%A8%8B%E7%BB%BC%E5%90%88%E5%AE%9E%E9%AA%8C/7142e9524bb82c8b5a526e211107c8a0697559838-1748227909930-48.png)\n\n`yjxLSW1`\n\n```\ndis ip rou\n```\n\n![image-20250317112027035](../img/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E6%8A%80%E6%9C%AF%E8%AF%BE%E7%A8%8B%E7%BB%BC%E5%90%88%E5%AE%9E%E9%AA%8C/ab21cd00346ece309bea350c734a0537697559838-1748227909930-51.png)\n\n`yjxLSW2`\n\n```\ndis ip rou\n```\n\n![image-20250317112233934](../img/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E6%8A%80%E6%9C%AF%E8%AF%BE%E7%A8%8B%E7%BB%BC%E5%90%88%E5%AE%9E%E9%AA%8C/e4d61fcff663719063e949ff82c079d6697559838-1748227909930-50.png)\n\n### 测试互通\n\npc1 ping pc3和pc4\n\n![image-20250317112619242](../img/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E6%8A%80%E6%9C%AF%E8%AF%BE%E7%A8%8B%E7%BB%BC%E5%90%88%E5%AE%9E%E9%AA%8C/89ea3a8cf4c69db7dbe5b3c2bbe8ba0c697559838-1748227909930-52.png)\n\npc1 ping client1和pc2\n\n![image-20250317112707434](../img/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E6%8A%80%E6%9C%AF%E8%AF%BE%E7%A8%8B%E7%BB%BC%E5%90%88%E5%AE%9E%E9%AA%8C/076261b7976e1a3ced0ee4545019cf06697559838-1748227909930-53.png)\n\npc1 ping `yjxAR1`和server\n\n![image-20250317112818902](../img/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E6%8A%80%E6%9C%AF%E8%AF%BE%E7%A8%8B%E7%BB%BC%E5%90%88%E5%AE%9E%E9%AA%8C/b648c5fdc74797c5c46fec89099e6869697559838-1748227909930-54.png)\n\npc2 ping `yjxAR1`和server\n\n![image-20250317112900397](../img/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E6%8A%80%E6%9C%AF%E8%AF%BE%E7%A8%8B%E7%BB%BC%E5%90%88%E5%AE%9E%E9%AA%8C/d09fe38558bd7918d34d3fd820b9aa9d697559838-1748227909930-55.png)\n\npc3 ping `yjxAR1`和server\n\n![image-20250317112934357](../img/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E6%8A%80%E6%9C%AF%E8%AF%BE%E7%A8%8B%E7%BB%BC%E5%90%88%E5%AE%9E%E9%AA%8C/611b3c80f83600476fbc6f7800c4fac3697559838-1748227909930-56.png)\n\npc4 ping `yjxAR1`和server\n\n![image-20250317113014981](../img/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E6%8A%80%E6%9C%AF%E8%AF%BE%E7%A8%8B%E7%BB%BC%E5%90%88%E5%AE%9E%E9%AA%8C/64c90e343dfe2b5509014d5618bd92cc697559838-1748227909930-57.png)\n\n配置保存，给你所有的交换机路由器输入save，这里就不多说了\n\n## 第五周\n\n开这几台\n\n![image-20250324114250347](../img/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E6%8A%80%E6%9C%AF%E8%AF%BE%E7%A8%8B%E7%BB%BC%E5%90%88%E5%AE%9E%E9%AA%8C/6c0319418d8dcd3eade76e9a03347d65697559838-1748227909930-58.png)\n\n\n\n目的：给LSW1和LSW2配置VRRP，给VLAN 10和VLAN 20配置不同的虚拟路由备份组，既有主备备份功能，又有负载分担功能。\n\n![image-20250324114656727](../img/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E6%8A%80%E6%9C%AF%E8%AF%BE%E7%A8%8B%E7%BB%BC%E5%90%88%E5%AE%9E%E9%AA%8C/227efaaa2be816d1cbacf2c413e31952697559838-1748227909930-59.png)\n\n可以还很清晰的看出，两个区域的pc走的是各自的网关\n\n`yjxLSW1`\n\n```\nsys\nun in en\nint vlan 10\nvrrp vrid 10 virtual-ip 192.168.1.254\nvrrp vrid 10 priority 120\nvrrp vrid 10 preempt-mode time delay 20\nint vlan 20\nvrrp vrid 20 virtual-ip 192.168.2.254\nvrrp vrid 20 preempt-mode time delay 20\n```\n\n`yjxLSW2`\n\n```\nsys\nun in en\nint vlan 10\nvrrp vrid 10 virtual-ip 192.168.1.254\nvrrp vrid 10 preempt-mode time delay 20\nint vlan 20\nvrrp vrid 20 virtual-ip 192.168.2.254\nvrrp vrid 20 priority 120\nvrrp vrid 20 preempt-mode time delay 20\n```\n\n\n\n`yjxLSW1`\n\n```\ndisplay vrrp interface Vlanif 10\ndisplay vrrp interface Vlanif 20\n```\n\n![image-20250324115420322](../img/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E6%8A%80%E6%9C%AF%E8%AF%BE%E7%A8%8B%E7%BB%BC%E5%90%88%E5%AE%9E%E9%AA%8C/ac098a8faf3cd39e3e4a5113834e671e697559838-1748227909930-60.png)\n\n`yjxLSW2`\n\n```\ndisplay vrrp interface Vlanif 10\ndisplay vrrp interface Vlanif 20\n```\n\n![image-20250324115448980](../img/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E6%8A%80%E6%9C%AF%E8%AF%BE%E7%A8%8B%E7%BB%BC%E5%90%88%E5%AE%9E%E9%AA%8C/577d9161784eac9d970f75abdd672d2c697559838-1748227909930-61.png)\n\n所有PC修改网关，记得点击`应用和保存`\n\n![image-20250324115802110](../img/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E6%8A%80%E6%9C%AF%E8%AF%BE%E7%A8%8B%E7%BB%BC%E5%90%88%E5%AE%9E%E9%AA%8C/c4255a301b81e38c189a206a6a8b208a697559838-1748227909930-62.png)\n\n验证pc\n\n![image-20250324120346164](../img/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E6%8A%80%E6%9C%AF%E8%AF%BE%E7%A8%8B%E7%BB%BC%E5%90%88%E5%AE%9E%E9%AA%8C/bb6437d87baf30e3cfd173ad093e0548697559838-1748227909930-63.png)\n\n实验可知通过配置vrrp实现`yjxLSW1`和`yjxLSW2`之间构建虚拟ip，也就是虚拟网关，然后pc设置这个虚拟网关，达到负载均衡，且有主备-备份功能。就是原本有两个网关的，192.168.1.253和192.168.2.252,如果`yjxLSW1`和`yjxLSW2`之间一台挂了，就没办法与服务器通信了，这时候通过vrrp构建虚拟ip192.168.1.254和192.168.2.254实现了主备容灾\n\n\n\n然后给`yjxLSW1`和`yjxLSW2`进行save保存\n\n## 第六周\n\n![image-20250331100556696](../img/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E6%8A%80%E6%9C%AF%E8%AF%BE%E7%A8%8B%E7%BB%BC%E5%90%88%E5%AE%9E%E9%AA%8C/0bc526d53bcd4b037ce3ce144536658b55933597-1748227909930-64.png)\n\n开这几台\n\n==任务1==：使用display stp brief 命令查看LSW1、LSW2、LSW3、LSW4交换机各端口在生成树中的角色。画出处于工作状态的生成树的结构图，提示：保留根端口和指定端口即可得到。\n\n==任务2==：给LSW1与LSW2的3根连线（心跳线）接上，再使用display stp brief 命令查看LSW1、LSW2、LSW3、LSW4交换机各端口在生成树中的角色。画出处于工作状态的生成树的结构图，提示：保留根端口和指定端口即可得到。\n\n```\ndis stp br\n```\n\n![image-20250331110550315](../img/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E6%8A%80%E6%9C%AF%E8%AF%BE%E7%A8%8B%E7%BB%BC%E5%90%88%E5%AE%9E%E9%AA%8C/3851243db001df69c80dee646e88b9ef55933597-1748227909930-65.png)\n\n==任务3==：配置多生成树协议(MSTP)。实例1的根桥为LSW1，备份根桥为LSW2；实例2的根桥为LSW2，备份根桥为LSW1。将VLAN 10映射到实例1；将VLAN 20映射到实例2。最后查看实例0、实例1、实例2各自工作状态中构成的生成树。方法：查看各交换机各实例各端口的角色，保留根端口和指定端口即可得到。\n\n\n\n![image-20250331110647682](../img/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E6%8A%80%E6%9C%AF%E8%AF%BE%E7%A8%8B%E7%BB%BC%E5%90%88%E5%AE%9E%E9%AA%8C/d9cf06474ee52145d1bc6102b456a5dc55933597-1748227909930-66.png)\n\n`yjxLSW1`\n\n`region-name yanjiaxi`改成你的名字\n\n```\nsys\nun in en\nstp mode mstp\nstp region-configuration\nregion-name yanjiaxi\ninstance 1 vlan 10\ninstance 2 vlan 20\nactive region-configuration\nstp instance 1 root primary\nstp instance 2 root secondary\n```\n\n`yjxLSW2`\n\n`region-name yanjiaxi`改成你的名字\n\n```\nsys\nun in en\nstp region-configuration\nregion-name yanjiaxi\ninstance 1 vlan 10\ninstance 2 vlan 20\nactive region-configuration\nstp instance 1 root secondary\nstp instance 2 root primary\n```\n\n`yjxLSW3`\n\n`region-name yanjiaxi`改成你的名字\n\n```\nsys\nun in en\nstp region-configuration\nregion-name yanjiaxi\ninstance 1 vlan 10\ninstance 2 vlan 20\nactive region-configuration\n```\n\n`yjxLSW4`\n\n`region-name yanjiaxi`改成你的名字\n\n```\nsys\nun in en\nstp region-configuration\nregion-name yanjiaxi\ninstance 1 vlan 10\ninstance 2 vlan 20\nactive region-configuration\n```\n\n`yjxLSW1`\n\n```\ndisplay stp region-configuration\n```\n\n![image-20250331111445105](../img/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E6%8A%80%E6%9C%AF%E8%AF%BE%E7%A8%8B%E7%BB%BC%E5%90%88%E5%AE%9E%E9%AA%8C/58529292e4ca556b132bc3dca22b4fe455933597-1748227909930-67.png)\n\n```\ndis stp br\n```\n\n![image-20250331111904934](../img/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E6%8A%80%E6%9C%AF%E8%AF%BE%E7%A8%8B%E7%BB%BC%E5%90%88%E5%AE%9E%E9%AA%8C/dc73c6294bdb9b96453bdfc1cff9920055933597-1748227909930-68.png)\n\n四个交换机保存配置\n\n## 第七周\n\n开这几台\n\n![image-20250407103733464](../img/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E6%8A%80%E6%9C%AF%E8%AF%BE%E7%A8%8B%E7%BB%BC%E5%90%88%E5%AE%9E%E9%AA%8C/38f262d0c2921ed04155f0cf1fbafee755933597-1748227909930-69.png)\n\n`任务1：网络拓扑图中，AR2为出口路由器，AR1与AR2之间的网络属于内网。配置AR2使用RIP协议公告与AR1相连的网段，注意不要公告外网。`\n\n`yjxAR2`\n\n```\nsys\nun in en\nrip 1\nversion 2\nnetwork 10.0.0.0\n```\n\npc1  ping 10.12.100.20\n\n![image-20250407103152119](../img/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E6%8A%80%E6%9C%AF%E8%AF%BE%E7%A8%8B%E7%BB%BC%E5%90%88%E5%AE%9E%E9%AA%8C/d9a53e47a3c3e02401c3d6cd3bcfefee55933597-1748227909931-70.png)\n\n`任务2：AR2上配置SSH服务端，AR1上配置SSH客户端`\n\n`说明：AAA为3A认证，即：认证(Authentication)；授权(Authorization)；计帐(Accounting)。`\n\n`yjxAR2`\n\n```\n#生成本地密钥对，SSH需要使用密钥对进行加密通信\nsys\nun in en\nrsa local-key-pair create\n\n```\n\n![image-20250407103357952](../img/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E6%8A%80%E6%9C%AF%E8%AF%BE%E7%A8%8B%E7%BB%BC%E5%90%88%E5%AE%9E%E9%AA%8C/ad32c5d84133d18ebc988e0edc7b3be555933597-1748227909931-71.png)\n\n`ssh040`是我的学号，自己改\n\n```\nstelnet server enable\naaa\nlocal-user ssh040 password cipher 123456\nlocal-user ssh040 privilege level 15\nlocal-user ssh040 service-type ssh\n#这里用all和password可以，用其他两种不可以。因为如果使用密钥验证，需要在PC机上生成密钥对，并将公钥拷贝至网络设备。\nssh user ssh040 authentication-type password   \n#配置VTY接口，VTY接口用于管理远程登录。配置VTY接口支持SSH协议：\nuser-interface vty 0 4\nauthentication-mode aaa\nprotocol inbound ssh\n```\n\n`yjxAR1`\n\n```\nsys\nun in en\nssh client first-time enable \nstelnet 10.12.100.20\n#输入用户名，然后按两次y，然后输入密码\n```\n\n![image-20250414183853166](../img/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E6%8A%80%E6%9C%AF%E8%AF%BE%E7%A8%8B%E7%BB%BC%E5%90%88%E5%AE%9E%E9%AA%8C/d94a5feda7347f5ed51033e9dd64d85455933597-1748227909931-72.png)\n\n在AR1登入之后变成AR2就行\n\n\n\n最后两个路由器保存配置\n\n\n\n## 第八周\n\n开这几台\n\n![image-20250414103345248](../img/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E6%8A%80%E6%9C%AF%E8%AF%BE%E7%A8%8B%E7%BB%BC%E5%90%88%E5%AE%9E%E9%AA%8C/37c0f9851b3c01a4163f399ab4075cc555933597-1748227909931-73.png)\n\n==任务1==： 在LSW1与LSW2分别配置默认路由指向AR1,AR1配置默认路由指向AR2,AR2配置默认路由指向AR3。\n\n`yjxAR1`\n\n```\nsys\nun in en\nip route-static 0.0.0.0 0 10.12.100.20\n```\n\n`yjxLSW1`\n\n```\nsys\nun in en\nip route-static 0.0.0.0 0 10.1.1.2\n```\n\n`yjxLSW2`\n\n```\nsys\nun in en\nip route-static 0.0.0.0 0 10.1.2.2\n```\n\n`yjxAR2`\n\n```\nsys\nun in en\nip route-static 0.0.0.0 0 23.1.1.2\n```\n\n\n\n\n\n==任务2==：在AR2配置静态NAT,把服务器Server1 10.1.3.1映射为公网的23.1.1.5，用于公网能访问。\n\n未配置前先测试，AR1路由器、Server1都无法Ping通外网\n\n![image-20250414101431253](../img/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E6%8A%80%E6%9C%AF%E8%AF%BE%E7%A8%8B%E7%BB%BC%E5%90%88%E5%AE%9E%E9%AA%8C/edc583974c8b4db839232ff53f627e5955933597-1748227909931-74.png)\n\n同理 Server1不能Ping通23.1.1.2\n\n\n\n`yjxAR2`\n\n配置静态NAT映射：将内网IP地址映射到外网IP地址\n\n```\nsys\nun in en\nnat static global 23.1.1.5 inside 10.1.3.1\ninterface Serial 4/0/0\nnat static enable \n```\n\n配置后再测试，AR1路由器与外网是不通的，但是Server1能Ping通外网\n\n<yjxAR1>ping 23.1.1.2\n\n<yjxAR3>ping 23.1.1.5\n\n![image-20250414101859678](../img/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E6%8A%80%E6%9C%AF%E8%AF%BE%E7%A8%8B%E7%BB%BC%E5%90%88%E5%AE%9E%E9%AA%8C/e187118cd657a55c044e1a1c5aa2cc6a55933597-1748227909931-76.png)\n\n```\nsys\nun in en\ndisplay nat static \n```\n\n![image-20250414101928655](../img/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E6%8A%80%E6%9C%AF%E8%AF%BE%E7%A8%8B%E7%BB%BC%E5%90%88%E5%AE%9E%E9%AA%8C/3d787accfcd680a59d99b745d0d177e355933597-1748227909931-75.png)\n\n==任务3==：配置PAT把内网IP映射到端口S4/0/0，实现内网能够访问外网。\n\n未配置前，先测试\n\n<yjxAR1>ping 23.1.1.2\n\n![image-20250414102011547](../img/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E6%8A%80%E6%9C%AF%E8%AF%BE%E7%A8%8B%E7%BB%BC%E5%90%88%E5%AE%9E%E9%AA%8C/9305d5d2365a01c247d319c57dd05aca55933597-1748227909931-77.png)\n\n同理 PC1不能Ping通23.1.1.2\n\n\n\n配置ACL\n\n`yjxAR2`\n\n```\nsys\nun in en\nacl number 2000\nrule 0 permit source 192.168.1.0 0.0.0.255\nrule 1 permit source 192.168.2.0 0.0.0.255\n```\n\n配置NAT Outbound\n\n`yjxAR2`\n\n在外网接口上应用ACL，并启用NAT Outbound功能。\n\n```\ninterface Serial 4/0/0\nnat outbound 2000\n```\n\n\n\n配置后，AR1路由器是不能访问外网的，表明内网与外网是分隔开的。但是PC机已经能访问外网，表明NAT配置成功。\n\n<yjxAR1>ping 23.1.1.2\n\n![image-20250414102208876](../img/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E6%8A%80%E6%9C%AF%E8%AF%BE%E7%A8%8B%E7%BB%BC%E5%90%88%E5%AE%9E%E9%AA%8C/1663d5a1656c84cac8eb783c99511b9d55933597-1748227909931-78.png)\n\n但是： PC1能Ping通23.1.1.2\n\n![image-20250414102242346](../img/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E6%8A%80%E6%9C%AF%E8%AF%BE%E7%A8%8B%E7%BB%BC%E5%90%88%E5%AE%9E%E9%AA%8C/4026746463c770655de27416a2933aa855933597-1748227909931-79.png)\n\n\n\n`yjxAR2`\n\n```\ndisplay acl 2000\ndisplay nat outbound\n```\n\n![image-20250414102335893](../img/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E6%8A%80%E6%9C%AF%E8%AF%BE%E7%A8%8B%E7%BB%BC%E5%90%88%E5%AE%9E%E9%AA%8C/42a43afce15b74266e4f73bf91e4d9d955933597-1748227909931-80.png)\n\n\n\n==任务4==：用Server1对AR3的Serial4/0/0口进行Ping测试，抓包査看NAT地址是否转换成功？\n\n在AR2的Serial4/0/0口上抓取的Ping包如下：\n\n![image-20250414102417955](../img/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E6%8A%80%E6%9C%AF%E8%AF%BE%E7%A8%8B%E7%BB%BC%E5%90%88%E5%AE%9E%E9%AA%8C/bc727a4ba8b9c4577019e514ad8b7c8a55933597-1748227909931-82.png)\n\n![image-20250414102721815](../img/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E6%8A%80%E6%9C%AF%E8%AF%BE%E7%A8%8B%E7%BB%BC%E5%90%88%E5%AE%9E%E9%AA%8C/ad21d63e84f00e71a6ad681bde3eb6ac55933597-1748227909931-81.png)\n\n![image-20250414102655443](../img/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E6%8A%80%E6%9C%AF%E8%AF%BE%E7%A8%8B%E7%BB%BC%E5%90%88%E5%AE%9E%E9%AA%8C/8366964d05e63a3f667f43e74b6a491955933597-1748227909931-83.png)\n\nAR3  ping 23.1.1.5\n\n\n\n\n\n在AR1的GE4/0/0口或者AR2的GE0/0/0口，抓取的Ping包如下：\n\n两个接口二选一，然后抓包，不会打开就去看前面............\n\nAR3  ping 23.1.1.5\n\n![image-20250414103205695](../img/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E6%8A%80%E6%9C%AF%E8%AF%BE%E7%A8%8B%E7%BB%BC%E5%90%88%E5%AE%9E%E9%AA%8C/efff7ceba08d8882b2685a8b724ae94d55933597-1748227909931-84.png)\n\n\n\n最后所有配置过的交换机路由器保存\n\n## 第九周\n\n![image-20250421102200269](../img/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E6%8A%80%E6%9C%AF%E8%AF%BE%E7%A8%8B%E7%BB%BC%E5%90%88%E5%AE%9E%E9%AA%8C/63b6113642ad6df3203a4c31b31b5c8055933597-1748227909931-85.png)\n\n==任务0==：掌握单臂路由的原理，配置方法以及应用场合。配置前：测试不同VLAN的连通情况，例如PC7与PC8的连通情况。\n\n![image-20250421102219871](../img/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E6%8A%80%E6%9C%AF%E8%AF%BE%E7%A8%8B%E7%BB%BC%E5%90%88%E5%AE%9E%E9%AA%8C/713ea5804f461930b64247f00eb4885055933597-1748227909931-86.png)\n\n==任务1==：在交换机LSW6上配置VLAN，VLAN库有VLAN50与VLAN60。GE0/0/1口为Trunk口，GE0/0/2与GE0/0/3为Access口。\n\n`yjxLSW6`\n\n```\nsys\nsysname yjxLSW6\nun in en\nvlan batch 50 60\ninterface GigabitEthernet 0/0/1\nport link-type trunk \nport trunk allow-pass vlan 50 60\ninterface GigabitEthernet 0/0/2\nport link-type access \nport default vlan 50\ninterface GigabitEthernet 0/0/3\nport link-type access \nport default vlan 60\n```\n\n==任务2==：在路由器AR5上配置子接口，子接口通过使用802.1q协议与对应的VLAN进行识别绑定，给子接口配置IP地址。此地址作为对应VLAN网段的网关。\n\n`yjxAR5`\n\n```\nsys\nun in en\nint g0/0/2.5\ndot1q termination vid 50\nip add 192.168.8.1 24\narp broadcast enable\nint g0/0/2.6\ndot1q termination vid 60\nip add 192.168.9.1 24\narp broadcast enable\n```\n\n![image-20250421102649709](../img/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E6%8A%80%E6%9C%AF%E8%AF%BE%E7%A8%8B%E7%BB%BC%E5%90%88%E5%AE%9E%E9%AA%8C/f2ee1855fe464bb889f5834e1712624255933597-1748227909931-87.png)\n\n\n\n自己保存配置\n\n## 第十周\n\n![image-20250421102200269](../img/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E6%8A%80%E6%9C%AF%E8%AF%BE%E7%A8%8B%E7%BB%BC%E5%90%88%E5%AE%9E%E9%AA%8C/63b6113642ad6df3203a4c31b31b5c8055933597-1748227909931-85.png)\n\n==任务1==：参考上一周的单臂路由实验，在交换机LSW5一侧的网络，配置单臂路由。\n\n1）在交换机LSW5上配置VLAN，VLAN库有VLAN30与VLAN40。GE0/0/1口为Trunk口，GE0/0/2、GE0/0/3与GE0/0/5为Access口。同时配置端口加入到相应的VLAN中。\n\n`yjxLSW5`\n\n```\nsys\nsysname yjxLSW5\nun in en\nvlan batch 30 40\ninterface GigabitEthernet 0/0/1\nport link-type trunk \nport trunk allow-pass vlan 30 40\ninterface GigabitEthernet 0/0/2\t\nport link-type access \nport default vlan 30\ninterface GigabitEthernet 0/0/3\nport link-type access \nport default vlan 40\ninterface GigabitEthernet 0/0/5\t\nport link-type access \nport default vlan 40\n```\n\n2）在AR5上配置单臂路由，在路由器AR5上配置子接口，子接口通过使用802.1q协议与对应的VLAN进行识别绑定，给子接口配置IP地址。此地址作为对应VLAN网段的网关。\n\n`yjxAR5`\n\n```\nsys\nun in en\ninterface GigabitEthernet 0/0/1.30\ndot1q termination vid 30\nip address 172.16.1.254 24\narp broadcast enable \ninterface GigabitEthernet 0/0/1.40\ndot1q termination vid 40\nip address 172.16.2.254 24\narp broadcast enable \n```\n\n\n\n==任务2==：在AR5路由器上配置DHCP服务。\n\n`AR5`\n\n1. 启用 DHCP 功能 ，全局启用 DHCP 服务：\n\n```\nsys\ndhcp enable \n```\n\n2. 配置 DHCP 地址池，为每个 VLAN 创建 DHCP 地址池，配置网关、DNS 和 IP 地址范围\n   配置 VLAN30 的 DHCP 地址池\n\n```\nip pool vlan30\nnetwork 172.16.1.0 mask 24 \ngateway-list 172.16.1.254\ndns-list 8.8.8.8 \nip pool vlan40\nnetwork 172.16.2.0 mask 255.255.255.0\ngateway-list 172.16.2.254\ndns-list 8.8.8.8\nexcluded-ip-address 172.16.2.2\n```\n\n#excluded-ip-address 172.16.2.2   //此处排除的IP，是留给终端Client2\n\n3. 在子接口上启用 DHCP 服务，在每个子接口上启用 DHCP 服务，选择使用全局地址池\n\n```\ninterface GigabitEthernet 0/0/1.30\ndhcp select global\ninterface GigabitEthernet 0/0/1.40\ndhcp select global \n```\n\n\n\n==任务3==： 在LSW5交换机上配置DHCP Snooping功能      // snoop v. 监听、监控\n\n`yjxLSW5`\n\n1）在LSW5交换机上开启全局DHCP 以及DHCP Snooping\n\n```\nsys\ndhcp enable\ndhcp snooping enable\n```\n\n![image-20250427102650308](../img/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E6%8A%80%E6%9C%AF%E8%AF%BE%E7%A8%8B%E7%BB%BC%E5%90%88%E5%AE%9E%E9%AA%8C/6d4bfe11fcb054b7ac3b5a6225998af855933597-1748227909931-88.png)\n\n2）LSW5交换机GE0/0/1、GE0/0/2、GE0/0/3接口开启 dhcp snooping，此时默认情况下接口为非信任接口，只能发送DHCP请求包，无法接收DHCP应答包\n\n```\ninterface GigabitEthernet 0/0/1\ndhcp snooping enable \ninterface GigabitEthernet 0/0/2\ndhcp snooping enable \ninterface GigabitEthernet 0/0/3\ndhcp snooping enable\n```\n\nPC 先执行PC>ipconfig /release，再执行PC>ipconfig /renew发现无法获取到IP地址。\n\n![image-20250427102822305](../img/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E6%8A%80%E6%9C%AF%E8%AF%BE%E7%A8%8B%E7%BB%BC%E5%90%88%E5%AE%9E%E9%AA%8C/add194f389af8566cbe231ded1b6e7ba55933597-1748227909931-89.png)\n\n![image-20250427102858111](../img/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E6%8A%80%E6%9C%AF%E8%AF%BE%E7%A8%8B%E7%BB%BC%E5%90%88%E5%AE%9E%E9%AA%8C/9de3ff00b9bdf131d48152afcb3b657355933597-1748227909931-90.png)\n\n![image-20250427103528337](../img/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E6%8A%80%E6%9C%AF%E8%AF%BE%E7%A8%8B%E7%BB%BC%E5%90%88%E5%AE%9E%E9%AA%8C/84ea0d61deab47db75837fcf824ac44455933597-1748227909931-91.png)\n\n![image-20250427103013064](../img/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E6%8A%80%E6%9C%AF%E8%AF%BE%E7%A8%8B%E7%BB%BC%E5%90%88%E5%AE%9E%E9%AA%8C/5dcdfb53206487e103d71b142eaa0ec755933597-1748227909931-92.png)\n\n3）配置交换机GE0/0/1口为信任接口\n\n```\ninterface GigabitEthernet 0/0/1\ndhcp snooping trusted \n```\n\n![image-20250427103043056](../img/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E6%8A%80%E6%9C%AF%E8%AF%BE%E7%A8%8B%E7%BB%BC%E5%90%88%E5%AE%9E%E9%AA%8C/9d989beb946c73400534bd0360d7930455933597-1748227909931-93.png)\n\nPC5   执行PC>ipconfig /renew发现现在可以获取到IP地址。\n\n![image-20250427103102411](../img/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E6%8A%80%E6%9C%AF%E8%AF%BE%E7%A8%8B%E7%BB%BC%E5%90%88%E5%AE%9E%E9%AA%8C/b2b4c4f730a00c3d44d745f46e9a731455933597-1748227909931-94.png)\n\n![image-20250427103230620](../img/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E6%8A%80%E6%9C%AF%E8%AF%BE%E7%A8%8B%E7%BB%BC%E5%90%88%E5%AE%9E%E9%AA%8C/c75df24325f4c418697322a59204e48355933597-1748227909931-95.png)\n\n4）查看确认dhcp snooping的配置\n\n`yjxLSW5`\n\n```\ndisplay dhcp snooping configuration \n```\n\n![image-20250427103309370](../img/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E6%8A%80%E6%9C%AF%E8%AF%BE%E7%A8%8B%E7%BB%BC%E5%90%88%E5%AE%9E%E9%AA%8C/0c8fcaf5489a912da4b169991628804655933597-1748227909931-96.png)\n\n测试pc5  ping 其他机子\n\n![image-20250427103738557](../img/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E6%8A%80%E6%9C%AF%E8%AF%BE%E7%A8%8B%E7%BB%BC%E5%90%88%E5%AE%9E%E9%AA%8C/a2af960ecdffbd25a58101580bc06e3855933597-1748227909931-97.png)\n\n然后交换机，路由器保存配置\n\n## 第十一周\n\n开AR3和AR2就行\n\n### 任务一\n\n==任务1==：在AR3路由器上配置PPP认证，AR3为认证方，AR2为被认证方。\n\n`yjxAR3`\n\n1. 在AR3路由器的Serial 4/0/0口配置PPP认证的方式为PAP\n\n```\nsys\nun in en\ninterface Serial 4/0/0\nppp authentication-mode pap\nq\n```\n\n2. 在AR3路由器的aaa视图下，创建用户R2，服务类型为ppp。\n\n```\naaa\nlocal-user R2 password cipher 123456\nlocal-user R2 service-type ppp\nq\n```\n\n3. 检查AR2路由器的接口状态，特别留意Serial4/0/0口的物理状态和协议状态。\n\n`yjxAR2`\n\n```\ndisplay ip interface brief\n```\n\n![image-20250428101132391](../img/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E6%8A%80%E6%9C%AF%E8%AF%BE%E7%A8%8B%E7%BB%BC%E5%90%88%E5%AE%9E%E9%AA%8C/ab5af551e88ae5f314835e92fef1d3b055933597-1748227909931-98.png)\n\n4. 在AR3路由器上，重启Serial4/0/0口。\n\n`yjxAR3`\n\n```\nsys\nun in en\ninterface Serial 4/0/0\nshutdown\nundo shutdown\n```\n\n5. 再次检查AR2路由器的接口状态，特别留意Serial4/0/0口的物理状态和协议状态。\n\n`yjxAR2`\n\n```\ndisplay ip interface brief\n```\n\n![image-20250428101229218](../img/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E6%8A%80%E6%9C%AF%E8%AF%BE%E7%A8%8B%E7%BB%BC%E5%90%88%E5%AE%9E%E9%AA%8C/b60622f21dd8b05fd2b4e8649fcef14255933597-1748227909931-99.png)\n\n**观察结果** ：AR2与AR3无法正常通信，链路物理状态正常，但链路层协议状态不正常，Ping命令无法通过。这是因为PPP链路上的PAP认证未通过，需要在被认证方AR2上配置相关PAP认证参数。\n\n\n\n6. 在AR2上的S4/0/0接口下，使用PPP pap local-user命令配置本端被对端以PAP方式验证时本地发送的PAP用户名和密码。\n\n`yjxAR2`\n\n```\nsys\nun in en\ninterface Serial 4/0/0\nppp pap local-user R2 password cipher 123456\n```\n\n7. 配置完成后，等待`20秒以上`，再次查看链路状态并测试连通性。特别留意Serial4/0/0口的物理状态和协议状态。\n\n`yjxAR2`\n\n```\ndisplay ip interface brief\n```\n\n输出示例：\n\n![image-20250428101908555](../img/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E6%8A%80%E6%9C%AF%E8%AF%BE%E7%A8%8B%E7%BB%BC%E5%90%88%E5%AE%9E%E9%AA%8C/d510f3e962c3f661dca8f551e744a21855933597-1748227909931-100.png)\n\n### 任务二\n\n任务2：网络管理员发现网络频繁遭受攻击，因为PAP认证的密码为明文的，密码经常被盗用，遂将PPP认证的方式由PAP改为CHAP。\n\n1）首先，删除原有的PAP认证配置\n\n`yjxAR3`\n\n```\ninterface Serial 4/0/0\nundo ppp authentication-mode\n```\n\n\n\n`yjxAR2`\n\n```\ninterface Serial 4/0/0\nundo ppp pap local-user\n```\n\n2）再重新配置CHAP认证配置\n\n`yjxAR3`\n\n```\ninterface Serial 4/0/0\nppp authentication-mode chap\n```\n\n[保留继续使用任务1](../img/) 在aaa视图下配置的用户名R1与密码。此时可不用重复配置。\n\n \n\n3）在AR3路由器上，重启Serial4/0/0口。\n\n`yjxAR3`\n\n```\ninterface Serial 4/0/0\nshutdown\nundo shutdown\n```\n\n4）检查AR2路由器的接口状态，特别留意Serial4/0/0口的物理状态和协议状态。\n\n `yjxAR2`\n\n```\ndisplay ip interface brief\n```\n\n可以观察到，现在AR2与AR3无法正常通信，链路物理状态正常，但是链路层协议状态不正常，用Ping命令将无法Ping通。这是因为此时PPP链路上的CHAP认证未通过，现在仅仅配置了认证方设备AR3，还需要在被认证方AR2上配置相关CHAP认证参数。\n\n![image-20250428102011262](../img/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E6%8A%80%E6%9C%AF%E8%AF%BE%E7%A8%8B%E7%BB%BC%E5%90%88%E5%AE%9E%E9%AA%8C/1e3b1f43d0adfa2b60bd6eabdb17278c55933597-1748227909931-101.png)\n\n\n\n5)在AR2上的S4/0/0接口下，使用PPP chap 命令配置本端被对端以CHAP方式验证时本地发送的用户名和密码。\n\n`yjxAR2`\n\n```\ninterface Serial 4/0/0\nppp chap user R2\nppp chap password cipher 123456\n```\n\n配置完成后，等待20秒以上\n\n6)再次查看链路状态并测试连通性。特别留意Serial4/0/0口的物理状态和协议状态。\n\n`yjxAR2`\n\n```\ndisplay ip interface brief\n```\n\n![image-20250428102159442](../img/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E6%8A%80%E6%9C%AF%E8%AF%BE%E7%A8%8B%E7%BB%BC%E5%90%88%E5%AE%9E%E9%AA%8C/d47dcb807cd1a9982fd296c2d37d711555933597-1748227909931-102.png)\n\n 两个路由器保存配置\n\n## 第十二周\n\n全开\n\n任务1：对网段 AR2-AR3、AR3-AR4、AR4-AR5 配置 OSPF 路由协议实现互通\n`yjxAR2 配置`\n\n出口路由器需要配置默认路由指向互联网\n\n```\nsys\nun in en\nip route-static 0.0.0.0 0.0.0.0 23.1.1.2\n```\n\n`yjxAR3 配置`\n\n```\nsys\nun in en\nospf 1\narea 0\nnetwork 23.1.1.0 0.0.0.255\nnetwork 34.1.1.0 0.0.0.3\n```\n\n`yjxAR4 配置`\n\n```\nsys\nun in en\nospf 1\narea 0\nnetwork 34.1.1.0 0.0.0.3\nnetwork 45.1.1.0 0.0.0.3\n```\n\n`yjxAR5 配置`\n\n```\nsys\nun in en\nospf 1\narea 0\nnetwork 45.1.1.0 0.0.0.3\n```\n\n检查`各路由器`配置\n\n```\nsys\nun in en\ndis ip rou\n```\n\n![image-20250512164824056](../img/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E6%8A%80%E6%9C%AF%E8%AF%BE%E7%A8%8B%E7%BB%BC%E5%90%88%E5%AE%9E%E9%AA%8C/14ff46ce283aaf3e1319151b271f7b8855933597-1747040057649-109-1748227909931-103.png)\n\n![image-20250512164845058](../img/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E6%8A%80%E6%9C%AF%E8%AF%BE%E7%A8%8B%E7%BB%BC%E5%90%88%E5%AE%9E%E9%AA%8C/5ea16826f96ebadfffdab74ea8e0148255933597-1747040057649-110-1748227909931-104.png)\n\n![image-20250512164908759](../img/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E6%8A%80%E6%9C%AF%E8%AF%BE%E7%A8%8B%E7%BB%BC%E5%90%88%E5%AE%9E%E9%AA%8C/efb652fb44d7aea10338c878f5a67c3655933597-1747040057649-111-1748227909931-105.png)\n\n任务2：对网段 AR3-AR6 配置 OSPF 路由协议进行通告网段，并划分到区域 1\n`yjxAR3 配置`\n\n```\nsys\nun in en\ninterface GigabitEthernet 0/0/1\nip address 36.1.1.2 30\n\nospf 1\narea 1\nnetwork 36.1.1.0 0.0.0.3\n```\n\n`yjxAR6 配置`\n\n```\nsys\nun in en\nsysname yjxAR6\ninterface GigabitEthernet 0/0/0\nip address 36.1.1.1 30\n\ninterface GigabitEthernet 0/0/1\nip address 10.10.2.2 30\n\nospf 1\narea 1\nnetwork 36.1.1.0 0.0.0.3\n```\n\n检查`AR5`能否学习到area1的路由\n\n```\nsys\nun in en\ndis ip rou\n```\n\n![image-20250512164926169](../img/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E6%8A%80%E6%9C%AF%E8%AF%BE%E7%A8%8B%E7%BB%BC%E5%90%88%E5%AE%9E%E9%AA%8C/d8451f011e397106446f84f0565a689b55933597-1747040057649-112-1748227909931-106.png)\n\n\n\n任务3：AR3 与 AR6 之间配置 OSPF 认证\n\n在 AR3、AR6 之间配置 OSPF的接口认证，认证模式为 MD5 认证。测试认证前后网络的连通性。AR3 和 AR6 的配置完全一样。同一网段的接口认证模式和口令必须相同，不同网段可以不同。缺省情况下，OSPF接口没有配置认证方式。建议配置认证方式，否则系统可能不安全。\n\n`yjxAR3 配置`\n\n```\nsys\nun in en\ninterface GigabitEthernet 0/0/1\nospf authentication-mode md5 1 cipher jwk\nshutdown\nundo shutdown\n```\n\n`yjxAR6 配置`\n\n```\nsys\nun in en\ninterface GigabitEthernet 0/0/0\nospf authentication-mode md5 1 cipher jwk\n```\n\n\n\n测试与外网互通\n\n`AR6`和`pc1`  ping   AR5\n\n```\nping 45.1.1.2\n```\n\n![image-20250512165005600](../img/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E6%8A%80%E6%9C%AF%E8%AF%BE%E7%A8%8B%E7%BB%BC%E5%90%88%E5%AE%9E%E9%AA%8C/dfd1ae7d984f9fac529039dcf63cfb1255933597-1747040057649-113-1748227909931-107.png)\n\n![image-20250512165024885](../img/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E6%8A%80%E6%9C%AF%E8%AF%BE%E7%A8%8B%E7%BB%BC%E5%90%88%E5%AE%9E%E9%AA%8C/59b1fa49d189894b5d548e45b34f1b5955933597-1747040057649-114-1748227909931-108.png)\n\n保存配置，涉及啥路由器自己保存\n\n\n\n## 第十三周\n\n全开\n\n\n\n`任务 0`: 理解 NAT 配置相关知识(`不用做`)\n\n- **nat outbound** —— 配置源 NAT (SNAT)，用于内网用户访问外网（通常结合 ACL 或地址池使用）。\n- **nat server** —— 配置目的 NAT（端口映射），允许外网访问内网服务器（如 Web、FTP 等）。\n- **nat static** —— 配置静态 NAT（一对一映射），将公网 IP 直接映射到内网 IP，双向可达。\n\n```plaintext\n[zsAR6-GigabitEthernet0/0/0]nat ?\n    outbound      Specify net address translation\n    server        Specify NAT server\n    static        Specify static NAT\n```\n\n注意事项\n接口类型:nat outbound 和natserver 需配置在连接公网的接口。\n\nACL 控制:建议用 ACL限制 natserver 的访问来源，避免暴露内网服务。\n\nALG 兼容性:FTP、SIP 等协议依赖 ALG，若异常可尝试 nat alg ftp disable 关闭调试\n\n优先级:nat static>na tserver>nat outbound，冲突时按优先级生效。\n\n\n\n`任务 1: 配置路由器端口与服务器的 IP 地址`\n\n- AR6 路由器补齐全端口 IP 地址 GE0/0/1 的 IP 地址为 10.10.2.2\n\n`yjxAR6`\n\n```\nint g0/0/1\nip address 10.10.2.2 30\n```\n\n- Server2 配上 IP 地址：10.10.2.1 255.255.255.252 关联对端路由器端口地址 10.10.2.2\n\n`Server2`\n\n![image-20250519100213703](../img/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E6%8A%80%E6%9C%AF%E8%AF%BE%E7%A8%8B%E7%BB%BC%E5%90%88%E5%AE%9E%E9%AA%8C/image-20250519100213703-1748227909931-109.png)\n\n\n\n`任务 2: 在 AR5 和 AR6 配置 PAT 把内网 IP 映射到路由器的外网端口 GE0/0/0，实现内网能够访问外网。`\n\n1) 配置访问控制列表（ACL）\n\n`yjxAR6`\n\n```\nsys\nun in en\nacl 2000\nrule 0 permit source 10.10.20.0 0.0.0.3\n```\n\n2) 启用 NAT Outbound 功能，并关联相应的 ACL\n\n`yjxAR6`\n\n```\nint g0/0/0\nnat outbound 2000\n```\n\n3) 配置模块 2 的出口路由器 AR5\n\n`yjxAR5`\n\n```\nsys\nun in en\nacl 2000\nrule 0 permit source 192.168.8.0 0.0.0.255\nrule 2 permit source 192.168.9.0 0.0.0.255\nrule 3 permit source 172.16.1.0 0.0.0.255\nrule 4 permit source 172.16.2.0 0.0.0.255\nint g0/0/0\nnat outbound 2000\n```\n\npc5  ping  （pc8 ，AR2，ar6）\n\n![image-20250519102747669](../img/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E6%8A%80%E6%9C%AF%E8%AF%BE%E7%A8%8B%E7%BB%BC%E5%90%88%E5%AE%9E%E9%AA%8C/image-20250519102747669-1748227909931-111.png)\n\n`任务 3: Server2 开启 HTTP、FTP 服务。模块二的客户端可以获取到 Server2 的共享文件。`\n1.配置端口映射\n\n`yjxAR6`\n\n```\nint g0/0/0\nnat server protocol tcp global current-interface ftp inside 10.10.2.1 ftp\n输入y\nnat server protocol tcp global current-interface www inside 10.10.2.1 www\n输入y\n```\n\n2.启用 FTP 协议依赖的 NAT ALG\n\n`yjxAR6`\n\n```\nq\nnat alg ftp enable\n```\n\n在服务器 Server2 上将 HttpServer和 FtpServer 启动，目录文件夹放入文件。 然后在模块 2中，用客户端进行 HTTP 和 FTP 的访问测试。\n\n在你电脑找个位置创建一个文件夹和测试文件\n\n![image-20250519101727675](../img/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E6%8A%80%E6%9C%AF%E8%AF%BE%E7%A8%8B%E7%BB%BC%E5%90%88%E5%AE%9E%E9%AA%8C/image-20250519101727675-1748227909931-110.png)\n\n在server2开启两个服务\n\n![image-20250519101755684](../img/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E6%8A%80%E6%9C%AF%E8%AF%BE%E7%A8%8B%E7%BB%BC%E5%90%88%E5%AE%9E%E9%AA%8C/image-20250519101755684-1748227909931-112.png)\n\n![image-20250519101815459](../img/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E6%8A%80%E6%9C%AF%E8%AF%BE%E7%A8%8B%E7%BB%BC%E5%90%88%E5%AE%9E%E9%AA%8C/image-20250519101815459-1748227909931-113.png)\n\n在client2进行测试\n\n![image-20250519102958121](../img/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E6%8A%80%E6%9C%AF%E8%AF%BE%E7%A8%8B%E7%BB%BC%E5%90%88%E5%AE%9E%E9%AA%8C/image-20250519102958121-1748227909931-114.png)\n\n![image-20250519103024881](../img/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E6%8A%80%E6%9C%AF%E8%AF%BE%E7%A8%8B%E7%BB%BC%E5%90%88%E5%AE%9E%E9%AA%8C/image-20250519103024881-1748227909931-115.png)\n\nar5和ar6进行保存\n\n## 第十四周\n\n任务 1:配置访问控制列表ACL，只允许client2可以访问服务器server 2，拒绝其它网络访问\n\n1)在路由器 AR6 配置 ACL,只允许来自网段 45.1.1.0,也就是 AR4-AR5 网段的数据流量通过应用在GE0/0/0口，在这里是作为流量人口inbound方向，在这里注意，应用在路由器不同的接口(端口)，需要根据数据流量的流动方向，来判断此接口的流量方向是流入inbound还是流出 outbound.\n\n`yjxAR6`\n\n```\nsys\nun in en\nacl number 3000\nrule 5 permit tcp source 45.1.1.0 0.0.0.3 destination 36.1.1.0 0.0.0.3\nrule 10 deny tcp\nrule 15 permit ip\ninterface GigabitEthernet 0/0/0\ntraffic-filter inbound acl 3000\n```\n\n2)在路由器 AR5配置 ACL,只允许源IP为 172.16.2.2的终端访问目标IP为36.1.1.1的终端\n\n`yjxAR5`\n\n```\nsys\nun in en\nacl number 3000\nrule 5 permit tcp source 172.16.2.2 0 destination 36.1.1.1 0\nrule 10 deny tcp destination 36.1.1.1 0\nrule 15 permit ip\ninterface GigabitEthernet 0/0/1\ntraffic-filter inbound acl 3000\ninterface GigabitEthernet 0/0/2\ntraffic-filter inbound acl 3000\n```\n\n\n\n测试client2可以访问server2\n\n自己开启server2的服务\n\n![image-20250526102622981](../img/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E6%8A%80%E6%9C%AF%E8%AF%BE%E7%A8%8B%E7%BB%BC%E5%90%88%E5%AE%9E%E9%AA%8C/image-20250526102622981.png)\n\n![image-20250526102830610](../img/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E6%8A%80%E6%9C%AF%E8%AF%BE%E7%A8%8B%E7%BB%BC%E5%90%88%E5%AE%9E%E9%AA%8C/image-20250526102830610.png)\n\n测试client1访问\n\n![image-20250526102848298](../img/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E6%8A%80%E6%9C%AF%E8%AF%BE%E7%A8%8B%E7%BB%BC%E5%90%88%E5%AE%9E%E9%AA%8C/image-20250526102848298.png)\n\n![image-20250526103300144](../img/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E6%8A%80%E6%9C%AF%E8%AF%BE%E7%A8%8B%E7%BB%BC%E5%90%88%E5%AE%9E%E9%AA%8C/image-20250526103300144.png)\n\n测试更改pc7为client3，看看是否可访问server2\n\n把pc7删除更换为clien3，然后配置好ip地址，然后pc8进行ping  client3\n\n![image-20250526104644555](../img/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E6%8A%80%E6%9C%AF%E8%AF%BE%E7%A8%8B%E7%BB%BC%E5%90%88%E5%AE%9E%E9%AA%8C/image-20250526104644555.png)\n\n测试clent3能否访问server2\n\n![image-20250526105018859](../img/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E6%8A%80%E6%9C%AF%E8%AF%BE%E7%A8%8B%E7%BB%BC%E5%90%88%E5%AE%9E%E9%AA%8C/image-20250526105018859.png)\n\n![image-20250526104747783](../img/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E6%8A%80%E6%9C%AF%E8%AF%BE%E7%A8%8B%E7%BB%BC%E5%90%88%E5%AE%9E%E9%AA%8C/image-20250526104747783.png)\n\nar6和ar5  save\n\n<div class=\"tbsm\" style=\"margin-top:54px;\">\n<div class=\"tbsm-top\"><span><svg t=\"1674654360507\" class=\"icon\" viewBox=\"0 0 1024 1024\" version=\"1.1\" xmlns=\"http://www.w3.org/2000/svg\" p-id=\"987\" data-spm-anchor-id=\"a313x.7781069.0.i0\" width=\"35\" height=\"35\"><path d=\"M410.49 97.74H155.08a56.74 56.74 0 0 0-56.84 56.73V410a56.84 56.84 0 0 0 56.84 56.84h255.41A56.83 56.83 0 0 0 467.32 410V154.58a56.83 56.83 0 0 0-56.83-56.84zM410.49 558.74H155.08a56.74 56.74 0 0 0-56.84 56.73V871a56.84 56.84 0 0 0 56.84 56.84h255.41A56.83 56.83 0 0 0 467.32 871V615.58a56.83 56.83 0 0 0-56.83-56.84zM871.49 558.74H616.08a56.74 56.74 0 0 0-56.84 56.73V871a56.84 56.84 0 0 0 56.84 56.84h255.41A56.83 56.83 0 0 0 928.32 871V615.58a56.83 56.83 0 0 0-56.83-56.84z\" fill=\"#66EEFF\" p-id=\"988\"></path><path d=\"M410.49 558.74h-4.14A475 475 0 0 0 299.52 859.6a481.16 481.16 0 0 0 4.84 68.22h106.13A56.83 56.83 0 0 0 467.32 871V615.58a56.83 56.83 0 0 0-56.83-56.84zM871.49 558.74H616.08a56.74 56.74 0 0 0-56.84 56.73V871a56.84 56.84 0 0 0 56.84 56.84h255.41A56.83 56.83 0 0 0 928.32 871V615.58a56.83 56.83 0 0 0-56.83-56.84z\" fill=\"#C2F8FF\" p-id=\"989\"></path></svg></span><span style=\"font-size:30px;\"> 特别声明</span></div>\n<div class=\"tbsm-wz\">千屹博客旗下的所有文章，是通过本人课堂学习和课外自学所精心整理的知识巨著<br/>难免会有出错的地方<br/>如果细心的你发现了小失误，可以在下方评论区告诉我，或者私信我！<br />非常感谢大家的热烈支持！</div>\n","tags":["ensp"],"categories":["网络"]},{"title":"Ubuntu 24.04.02 LTS 初始化安装","url":"/posts/14363/","content":"\n<meta name=\"referrer\" content=\"no-referrer\"/>\n\n# Ubuntu 24.04.02 LTS 初始化安装\n\n镜像下载\n\n桌面版：[ubuntu-24.04.2-desktop-amd64.iso](https://mirrors.aliyun.com/ubuntu-releases/24.04/ubuntu-24.04.2-desktop-amd64.iso)\n\n本次实验选用的是桌面版\n\n使用的虚拟化软件 VMware Workstation\n\n## 创建虚拟机\n\n![image-20250216234621886](../img/Ubuntu%2024.04%20LTS%20%E5%88%9D%E5%A7%8B%E5%8C%96%E5%AE%89%E8%A3%85/dadbab8c4c0cd3456b6c645fb4c1833555933597.png)\n\n![image-20250216235038829](../img/Ubuntu%2024.04%20LTS%20%E5%88%9D%E5%A7%8B%E5%8C%96%E5%AE%89%E8%A3%85/d367806b668c6e5502c83fd4ce3067b555933597.png)\n\n![image-20250216235127444](../img/Ubuntu%2024.04%20LTS%20%E5%88%9D%E5%A7%8B%E5%8C%96%E5%AE%89%E8%A3%85/454ecb479c2bd7f4e8740b076a0d50a855933597.png)\n\n## 加装镜像\n\n![image-20250224102123784](../img/Ubuntu%2024.04%20LTS%20%E5%88%9D%E5%A7%8B%E5%8C%96%E5%AE%89%E8%A3%85/a74d2ce5dd1c6ac9f5abffd2fbc9c1d255933597.png)\n\n先别启动，接下来设置网络\n\n## 配置NAT网卡\n\n![image-20250216235854241](../img/Ubuntu%2024.04%20LTS%20%E5%88%9D%E5%A7%8B%E5%8C%96%E5%AE%89%E8%A3%85/fc8a5b8aeacd7411d89b44e8a2ee1e0155933597.png)\n\n## 开启虚拟机安装系统\n\n启动之后，会有一个黑色界面有一个选项是`Try or install ubuntu`默认是第一个，直接回车就行了\n\n![image-20250224102809642](../img/Ubuntu%2024.04%20LTS%20%E5%88%9D%E5%A7%8B%E5%8C%96%E5%AE%89%E8%A3%85/94c3fe8b5e49032453ea0563dc70b1de55933597.png)\n\n![image-20250224103157744](../img/Ubuntu%2024.04%20LTS%20%E5%88%9D%E5%A7%8B%E5%8C%96%E5%AE%89%E8%A3%85/75b18d3749fdd1d0c5d81327e5d9f8af55933597.png)\n\n![image-20250224103723948](../img/Ubuntu%2024.04%20LTS%20%E5%88%9D%E5%A7%8B%E5%8C%96%E5%AE%89%E8%A3%85/ff2ddeda14b36431a5cf6ee96638707a55933597.png)\n\n![image-20250224103729945](../img/Ubuntu%2024.04%20LTS%20%E5%88%9D%E5%A7%8B%E5%8C%96%E5%AE%89%E8%A3%85/73ec52b77cf17a109f5cee9b3e62ea6355933597.png)\n\n![image-20250224104437818](../img/Ubuntu%2024.04%20LTS%20%E5%88%9D%E5%A7%8B%E5%8C%96%E5%AE%89%E8%A3%85/f8bdf6930bcd44484020de13e5260cf255933597.png)\n\n![image-20250224104653496](../img/Ubuntu%2024.04%20LTS%20%E5%88%9D%E5%A7%8B%E5%8C%96%E5%AE%89%E8%A3%85/24b3172940a9f6704695ca7f2e2d342255933597.png)\n\n![image-20250224104755600](../img/Ubuntu%2024.04%20LTS%20%E5%88%9D%E5%A7%8B%E5%8C%96%E5%AE%89%E8%A3%85/75a21f681d88045ca885e0203596338355933597.png)\n\n这是一个终端工具，接下来我就不在这里运行了，我会给出代码，你照着在上面那张图运行就行了\n\n## 设置root用户密码\n\n![image-20250224111329361](../img/Ubuntu%2024.04%20LTS%20%E5%88%9D%E5%A7%8B%E5%8C%96%E5%AE%89%E8%A3%85/cff00927fb797792a6338ec46f2dca3155933597.png)\n\n## 配置静态ip\n\n直接去那个终端运行就行了，我不截图了\n\n安装必要工具\n\n```\nsudo apt-get install network-manager openssh-server vim inetutils-ping net-tools -y\n```\n\n\n\n查看需要配置的网卡，输入\n\n```\nip a\n```\n\n![image-20250224111556813](../img/Ubuntu%2024.04%20LTS%20%E5%88%9D%E5%A7%8B%E5%8C%96%E5%AE%89%E8%A3%85/59a6c999a44cc9d61bea086a707eac7055933597.png)\n\n```\nvim /etc/netplan/01-network-manager-all.yaml\n```\n\n```\n# Let NetworkManager manage all devices on this system\nnetwork:\n  ethernets:\n    ens33:\n      addresses: [192.168.48.128/24]\n      dhcp4: false\n      nameservers:\n          addresses: [192.168.48.2, 114.114.114.114]\n      routes:\n        - to: default\n          via: 192.168.48.2\n  version: 2\n  renderer: NetworkManager\n```\n\n![image-20250224111831503](../img/Ubuntu%2024.04%20LTS%20%E5%88%9D%E5%A7%8B%E5%8C%96%E5%AE%89%E8%A3%85/897d5841d95db60479d7cb123aa3bc9d55933597.png)\n\n这个ip`192.168.48.128`最后一位128你随意设置，192.168.48.这是网段对应前面[配置NAT网卡](#配置NAT网卡)你的网段，自行修改，网关（routes）也是\n\n最后按esc，然后按shift+冒号键，输入wq保存退出\n\n```\nnetplan apply\n```\n\n![image-20250224112149255](../img/Ubuntu%2024.04%20LTS%20%E5%88%9D%E5%A7%8B%E5%8C%96%E5%AE%89%E8%A3%85/7c086b072f20d76608e5d8582385efae55933597.png)\n\n静态ip已经配置好了\n\n## 关闭防火墙\n\n**1. 查看防火墙状态：**\n\n要查看 Ubuntu 中 `ufw` 防火墙的状态，可以执行以下命令：\n\n```\nsudo ufw status\n```\n\n这将显示当前防火墙规则的状态，包括是否启用和允许的规则。\n\n**2. 开启防火墙：**\n\n如果防火墙没有启用，可以使用以下命令来启用 `ufw` 防火墙：\n\n```\nsudo ufw enable\n```\n\n启用防火墙后，它将按照默认规则开始工作，通常会拒绝所有传入连接，但允许所有传出连接。\n\n**3. 关闭防火墙：**\n\n要关闭 `ufw` 防火墙，可以执行以下命令：\n\n```\nsudo ufw disable\n```\n\n[关闭防火墙](https://so.csdn.net/so/search?q=关闭防火墙&spm=1001.2101.3001.7020)后，所有传入和传出的连接将被允许，不再受到防火墙的限制。\n\n**4. 永久关闭防火墙：**\n\n如果想永久关闭 `ufw` 防火墙，可以执行以下步骤：\n\n- 停止 `ufw` 服务：\n\n  `sudo systemctl stop ufw`\n\n- 禁用 `ufw` 服务的自动启动：\n\n  `sudo systemctl disable ufw --now`\n\n- 重启系统，以确保防火墙不会在系统启动时重新启用。\n\n## 设置阿里源\n\n全部复制粘贴就行了\n\n```\ncat >/etc/apt/sources.list<<\"EOF\"\ndeb https://mirrors.aliyun.com/ubuntu/ noble main restricted universe multiverse\ndeb-src https://mirrors.aliyun.com/ubuntu/ noble main restricted universe multiverse\n\ndeb https://mirrors.aliyun.com/ubuntu/ noble-security main restricted universe multiverse\ndeb-src https://mirrors.aliyun.com/ubuntu/ noble-security main restricted universe multiverse\n\ndeb https://mirrors.aliyun.com/ubuntu/ noble-updates main restricted universe multiverse\ndeb-src https://mirrors.aliyun.com/ubuntu/ noble-updates main restricted universe multiverse\n\n# deb https://mirrors.aliyun.com/ubuntu/ noble-proposed main restricted universe multiverse\n# deb-src https://mirrors.aliyun.com/ubuntu/ noble-proposed main restricted universe multiverse\n\ndeb https://mirrors.aliyun.com/ubuntu/ noble-backports main restricted universe multiverse\ndeb-src https://mirrors.aliyun.com/ubuntu/ noble-backports main restricted universe multiverse\nEOF\nsudo apt-get update\n```\n\n## 设置模板\n\n进行关机\n\n```\nsudo poweroff\n```\n\n![image-20250224114254416](../img/Ubuntu%2024.04%20LTS%20%E5%88%9D%E5%A7%8B%E5%8C%96%E5%AE%89%E8%A3%85/858eff2f17599b734b0922a961a3099d55933597.png)\n\n<div class=\"tbsm\" style=\"margin-top:54px;\">\n<div class=\"tbsm-top\"><span><svg t=\"1674654360507\" class=\"icon\" viewBox=\"0 0 1024 1024\" version=\"1.1\" xmlns=\"http://www.w3.org/2000/svg\" p-id=\"987\" data-spm-anchor-id=\"a313x.7781069.0.i0\" width=\"35\" height=\"35\"><path d=\"M410.49 97.74H155.08a56.74 56.74 0 0 0-56.84 56.73V410a56.84 56.84 0 0 0 56.84 56.84h255.41A56.83 56.83 0 0 0 467.32 410V154.58a56.83 56.83 0 0 0-56.83-56.84zM410.49 558.74H155.08a56.74 56.74 0 0 0-56.84 56.73V871a56.84 56.84 0 0 0 56.84 56.84h255.41A56.83 56.83 0 0 0 467.32 871V615.58a56.83 56.83 0 0 0-56.83-56.84zM871.49 558.74H616.08a56.74 56.74 0 0 0-56.84 56.73V871a56.84 56.84 0 0 0 56.84 56.84h255.41A56.83 56.83 0 0 0 928.32 871V615.58a56.83 56.83 0 0 0-56.83-56.84z\" fill=\"#66EEFF\" p-id=\"988\"></path><path d=\"M410.49 558.74h-4.14A475 475 0 0 0 299.52 859.6a481.16 481.16 0 0 0 4.84 68.22h106.13A56.83 56.83 0 0 0 467.32 871V615.58a56.83 56.83 0 0 0-56.83-56.84zM871.49 558.74H616.08a56.74 56.74 0 0 0-56.84 56.73V871a56.84 56.84 0 0 0 56.84 56.84h255.41A56.83 56.83 0 0 0 928.32 871V615.58a56.83 56.83 0 0 0-56.83-56.84z\" fill=\"#C2F8FF\" p-id=\"989\"></path></svg></span><span style=\"font-size:30px;\"> 特别声明</span></div>\n<div class=\"tbsm-wz\">千屹博客旗下的所有文章，是通过本人课堂学习和课外自学所精心整理的知识巨著<br/>难免会有出错的地方<br/>如果细心的你发现了小失误，可以在下方评论区告诉我，或者私信我！<br />非常感谢大家的热烈支持！</div>\n\n","tags":["Ubuntu"],"categories":["运维"]},{"title":"从零开始搭建你的免费图床系统","url":"/posts/aaddb3d/","content":"\n<meta name=\"referrer\" content=\"no-referrer\"/>\n\n# 从零开始搭建你的免费图床系统（Cloudflare R2 + WebP Cloud + 图床工具）\n\n文章来源自：[从零开始搭建你的免费图床系统（Cloudflare R2 + WebP Cloud + PicGo） · Pseudoyu](https://www.pseudoyu.com/zh/2024/06/30/free_image_hosting_system_using_r2_webp_cloud_and_picgo/)\n\n## 背景\n\n陆陆续续两三年了，建立博客至今也有诸多文章了，有一个问题就是图片如果放在本地显示会很慢，特别是放在服务器，如果没有cdn的话，就没有如今的效果，我现在的模式就是hexo（github page+公益cdn），后话了，先回到这这里，由于图片一多，造成发送图片源位置移动的话，还要重新找，特别是我在hexo里static下的img文件夹，本身markdown显示的都是相对路径，管理起来很麻烦，如今我了解到图床的概念，不但可以统一进行管理，还能减少博客仓库的体积，提升网站速度，（虽然我现在依然保持着，源图和文档在一起，源图片直接上传到github，毕竟上传到别人服务器的数据，就怕突然有一天倒闭了，就没了，所以我依然有着备份原图片在本地的习惯），所以我接下来讲的，只是适用于，不那么重要的项目\n\n\n\n### 阿里云OSS+Picgo\n\n阿里云oss，我个人使用来说，很方便，速度很快，结合图床来使用也是很方便的，就是唯一的缺点就是大多都是按量付费，如果内容一多，对于本身就是非盈利性的我来说，就很不妥当，通过picgo或兰空图床进行上传图片到阿里云oss，访问速度也很快，针对国内用户的访问速度明显提升（`费用：存储加公网访问流量费用`）\n\n还有一个办法就是设置反向代理，你需要购买一台同区域的esc，保持和你存储桶是一个区域的，这样经过的流量就是内网流量，不会计费，但是会计算存储费用\n\n## 图床搭建说明\n\nCloudflare R2 + WebP Cloud + 图床工具 的方案尽管牵扯到了多个组件和平台，但所有操作都在 Free Plan 中，也是我最终选定的方案，下面将从零开始介绍如何搭建这个免费图床系统。\n\n### Cloudflare R2\n\nR2 是 Cloudflare 推出的免费对象存储服务，需要免费注册一个 [Cloudflare 账号](https://www.cloudflare.com/zh-cn/)才能使用，注册登录后，点击左侧边栏的 R2 访问服务，但需要注意的是开通 R2 服务需要绑定信用卡（国内外主流信用卡皆可），但并不会扣费，主要是为了验证用户身份使用。`但是我最近发现他有了paypal验证方式，有了paypal，可以直接绑定国内储蓄卡，就可以通过R2验证的银行卡验证了`\n\n![image-20250212151333273](https://images.qianyisky.cn/boke/从零开始搭建你的免费图床系统/20250212184252131.png)\n\n### 创建存储桶\n\n开通 R2 服务后，点击右上角「创建存储桶」按钮进行创建。\n\n![image-20250212151607908](https://images.qianyisky.cn/boke/从零开始搭建你的免费图床系统/20250212184252132.png)\n\n进入创建配置界面后，需要填写存储桶（Bucket）名称，建议有一些辨识度，后续在配置上传时会用到。\n\n位置则选择「自动」，但可以额外多配置一个位置提示，由于我后续还将使用「[WebP Cloud](https://webp.se/)」服务的美西机房进行图片代理优化，所以在此处选择的是「北美洲西部（WNAM）」，根据需求选其他区域也可以，但 Cloudflare 并不保证一定会分配到所指定的区域。\n\n![image-20250212151725856](https://images.qianyisky.cn/boke/从零开始搭建你的免费图床系统/20250212184252133.png)\n\n进入设置\n\n![image-20250212152030774](https://images.qianyisky.cn/boke/从零开始搭建你的免费图床系统/20250212184252134.png)\n\n首先我们需要打开「R2.dev 子域」，这是为了后续访问图片时需要的公网地址，点击「允许访问」，并按照提示输入「allow」即可开启。\n\n![image-20250212152203901](https://images.qianyisky.cn/boke/从零开始搭建你的免费图床系统/20250212184252135.png)\n\n完成后会显示一个以 `r2.dev` 结尾的公网网址，即我们后续访问图片的网址。\n\n\n\n`自定义图床域名（可选）`\n\n但是分配的网址比较长，不易于记忆，我们可以通过「自定义域」来绑定我们的专属域名，点击「连接域」按钮，填入想要访问的域名\n\n![image-20250212152355336](https://images.qianyisky.cn/boke/从零开始搭建你的免费图床系统/20250212184252136.png)\n\n然后在你域名服务商那添加dns解析，由于我是将域名托管到了cloudflare，直接自动添加解析了\n\n![image-20250212152448801](https://images.qianyisky.cn/boke/从零开始搭建你的免费图床系统/20250212184252137.png)\n\n效果就是这样了\n\n![image-20250212152555125](https://images.qianyisky.cn/boke/从零开始搭建你的免费图床系统/20250212184252138.png)\n\n![image-20250212152616008](https://images.qianyisky.cn/boke/从零开始搭建你的免费图床系统/20250212184252139.png)\n\n### 配置存储桶访问api\n\n当我们回到对象页面，上传一张测试图片\n\n![image-20250212155704337](https://images.qianyisky.cn/boke/从零开始搭建你的免费图床系统/20250212184252140.png)\n\n就有链接可以进行访问了\n\n![image-20250212155745302](https://images.qianyisky.cn/boke/从零开始搭建你的免费图床系统/20250212184252141.png)\n\n但是如果每次都打开cloudflare手动上传图片的话都会很麻烦。R2 提供了 S3 兼容的 API，可以方便地使用一些客户端/命令行工具进行上传、删除等操作。\n\n![image-20250212160118209](https://images.qianyisky.cn/boke/从零开始搭建你的免费图床系统/20250212184252142.png)\n\n![image-20250212160150594](https://images.qianyisky.cn/boke/从零开始搭建你的免费图床系统/20250212184252143.png)\n\n![image-20250212160306528](https://images.qianyisky.cn/boke/从零开始搭建你的免费图床系统/20250212184252144.png)\n\n这时候就会有api令牌信息，这里的内容只会出现一次，可以记下来，但是不要给别人哦\n\n![image-20250212160435719](https://images.qianyisky.cn/boke/从零开始搭建你的免费图床系统/20250212184252145.png)\n\n至此，我们需要在 Cloudflare R2 上配置的部分就完成了，接下来我们需要配置图床工具吧。\n\n### PicGo（可选，无需服务器）\n\nPicGo 是一个用于快速上传并获取图片 URL 的工具软件，有着较为丰富的插件生态，支持多种图床服务，其 GitHub 仓库为「[GitHub - Molunerfinn/PicGo](https://github.com/Molunerfinn/PicGo)」，可以下载对应平台客户端使用。\n\n#### 配置 R2 图床\n\nPicGo 本体并不包括 S3 图床，但可以通过「[GitHub - wayjam/picgo-plugin-s3](https://github.com/wayjam/picgo-plugin-s3)」插件来支持。\n\nwindows下的稳定版2.3.1会出现搜索不到插件的情况,下载里面的beta版本就行了\n\n[Bug: 插件设置页无法搜索到插件 · Issue #1297 · Molunerfinn/PicGo](https://github.com/Molunerfinn/PicGo/issues/1297)\n\n我只能安装1.0.2的，第一个安装不了，无关紧要\n\n![image-20250212160806906](https://images.qianyisky.cn/boke/从零开始搭建你的免费图床系统/20250212184252146.png)\n\n然后填写信息\n\n![image-20250212161619415](https://images.qianyisky.cn/boke/从零开始搭建你的免费图床系统/20250212184252147.png)\n\n这里有几项配置需要尤其注意。\n\n- **应用密钥 ID**，填写 R2 API 中的 Access Key ID（访问密钥 ID）\n- **应用密钥**，填写 R2 API 中的 Secret Access Key（机密访问密钥）\n- **桶名**，填写 R2 中创建的 Bucket 名称，如我上文的 `blog-r2`\n- **文件路径**，上传到 R2 中的文件路径，我选择使用 `{fileName}.{extName}` 来保留原文件的文件名和扩展名。\n- **自定义节点**，填写 R2 API 中的「为 S3 客户端使用管辖权地特定的终结点」，即 `xxx.r2.cloudflarestorage.com` 格式的 S3 Endpoint\n- **自定义域名**，填写上文生成的 `xxx.r2.dev` 格式的域名或自定义域名，如我配置的 `image.qianyisky.cn`\n\n![image-20250212162350766](https://images.qianyisky.cn/boke/从零开始搭建你的免费图床系统/20250212184252148.png)\n\n其他配置保持默认即可，确认参数无误后点击「确定」与「设置为默认图床」即可。\n\n#### 图片上传\n\n![image-20250212162515699](https://images.qianyisky.cn/boke/从零开始搭建你的免费图床系统/20250212184252149.png)\n\n完成上述配置后，我们就可以在「上传区」直接拖入文件进行图片上传了，如上传后显示无误则为配置成功，生成的链接会自动在系统剪贴板中，直接在需要的地方粘贴即可。\n\n根据你想要的链接格式，我这里是markdown，就选择markdown格式，然后在相册里复制链接，在markdown文档看看\n\n![image-20250212162638990](https://images.qianyisky.cn/boke/从零开始搭建你的免费图床系统/20250212184252150.png)\n\n![image-20250212162708601](https://images.qianyisky.cn/boke/从零开始搭建你的免费图床系统/20250212184252151.png)\n\n### Lsky Pro图床（可选，需要服务器）\n\n官网：[Lsky Pro+ - 属于您自己的云上相册。](https://www.lsky.pro/)\n\n部署教程：[Lsky Pro图床 | 严千屹博客](https://blog.qianyios.top/posts/6726/?highlight=兰)\n\n我这里就展示自己搭建好lsky pro图床进行演示了\n\n#### 创建存储策略\n\n![image-20250212163327404](https://images.qianyisky.cn/boke/从零开始搭建你的免费图床系统/20250212184252152.png)\n\n![image-20250212163547700](https://images.qianyisky.cn/boke/从零开始搭建你的免费图床系统/20250212184252153.png)\n\n确认即可\n\n#### 图片上传\n\n设置上传图片的限制大小为10M\n\n![image-20250212164032388](https://images.qianyisky.cn/boke/从零开始搭建你的免费图床系统/20250212184252155.png)\n\n![image-20250212164200929](https://images.qianyisky.cn/boke/从零开始搭建你的免费图床系统/20250212184252156.png)\n\n点击保存即可\n\n![image-20250212164344718](https://images.qianyisky.cn/boke/从零开始搭建你的免费图床系统/20250212184252157.png)\n\n![image-20250212164600963](https://images.qianyisky.cn/boke/从零开始搭建你的免费图床系统/20250212184252158.png)\n\n### 两者路径修改位置\n\n![image-20250212164651932](https://images.qianyisky.cn/boke/从零开始搭建你的免费图床系统/20250212184252159.png)\n\n这就是统一管理的方便性\n\n`这是lsky pro设置上传路径的位置`\n\n![image-20250212164754562](https://images.qianyisky.cn/boke/从零开始搭建你的免费图床系统/20250212184252160.png)\n\n`这是PicGo设置上传路径的位置`\n\n![image-20250212165842910](https://images.qianyisky.cn/boke/从零开始搭建你的免费图床系统/20250212184252161.png)\n\n再去测试上传看看\n\n![image-20250212165247121](https://images.qianyisky.cn/boke/从零开始搭建你的免费图床系统/20250212184252162.png)\n\n效果\n\n![image-20250212170129233](https://images.qianyisky.cn/boke/从零开始搭建你的免费图床系统/20250212184252163.png)\n\n当然你可以在设置里选择这两个\n\n![image-20250212170221106](https://images.qianyisky.cn/boke/从零开始搭建你的免费图床系统/20250212184252164.png)\n\n![image-20250212170422951](https://images.qianyisky.cn/boke/从零开始搭建你的免费图床系统/20250212184252165.png)\n\n![image-20250212170625037](https://images.qianyisky.cn/boke/从零开始搭建你的免费图床系统/20250212184252166.png)\n\n## WebP Cloud 图片优化\n\n至此我们已经完成了整个图床的搭建、配置和上传，但通常我们本地截图或是相机拍摄的图片体积较大，对于访客来说加载时间会较长，并不直接适合互联网发布。\n\n根据[从零开始搭建你的免费图床系统（Cloudflare R2 + WebP Cloud + PicGo） · Pseudoyu](https://www.pseudoyu.com/zh/2024/06/30/free_image_hosting_system_using_r2_webp_cloud_and_picgo/)写到[WebP Cloud](https://webp.se/)的方法\n\n它可以实现图片的压缩，加快页面显示的速度\n\n![image-20250212171017681](https://images.qianyisky.cn/boke/从零开始搭建你的免费图床系统/20250212184252167.png)\n\n简单来说这是一个类 CDN 的图片代理 SaaS 服务，可以在几乎不改变画质的情况下大幅缩小图片体积，加快整体站点加载速度。发展到现在除了图片体积减少外，还提供了缓存、添加水印、图片滤镜等更多实用的功能，并提供了自定义 Header 等配置选项。\n\n### 配置webp cloud\n\n首先通过 GitHub 授权登录 [WebP Cloud](https://dashboard.webp.se/) 平台。\n\n![image-20250212171123527](https://images.qianyisky.cn/boke/从零开始搭建你的免费图床系统/20250212184252168.png)\n\n![image-20250212171355857](https://images.qianyisky.cn/boke/从零开始搭建你的免费图床系统/20250212184252169.png)\n\n回到主页，点击创建代理\n\n![image-20250212171450450](https://images.qianyisky.cn/boke/从零开始搭建你的免费图床系统/20250212184252170.png)\n\n- 为了优化国内访问，我「Proxy Region」选择的是美西「Hillsboro, OR」区域\n- 「Proxy Name」填写一个自定义名称即可\n- 「Proxy Origin URL」，比较重要，需要填写上文我们配置好的 R2 自定义域名，如我填写的是 `image.qianyisky.cn`，如果没配置自定义域名则填写 R2 提供的 `xxx.r2.dev` 格式的域名\n\n![image-20250212171624454](https://images.qianyisky.cn/boke/从零开始搭建你的免费图床系统/20250212184252171.png)\n\n之后点击你创建的代理，将代理地址更新到存储策略的配置里\n\n`PicGo配置`\n\n![image-20250212171949706](https://images.qianyisky.cn/boke/从零开始搭建你的免费图床系统/20250212184252172.png)\n\n`Lsky Pro配置`\n\n![image-20250212172255953](https://images.qianyisky.cn/boke/从零开始搭建你的免费图床系统/20250212184252173.png)\n\n再进行上传图片的测试\n\n![image-20250212172515404](https://images.qianyisky.cn/boke/从零开始搭建你的免费图床系统/20250212184252174.png)\n\n就是我们通过图床工具上传的图片上传了之后，就可以通过这个[**WebP Cloud Services**](https://webp.se/)提供的代理节点进行访问\n\n如果觉得默认代理地址不好看，可以进行设置自定义域名\n\n![image-20250212172818032](https://images.qianyisky.cn/boke/从零开始搭建你的免费图床系统/20250212184252175.png)\n\n![image-20250212172832000](https://images.qianyisky.cn/boke/从零开始搭建你的免费图床系统/20250212184252176.png)\n\n![image-20250212173135188](https://images.qianyisky.cn/boke/从零开始搭建你的免费图床系统/20250212184252177.png)\n\n最后确认，等待十分钟这样子，点击刷新按钮，就会更新代理地址了，然后点击启用\n\n![image-20250212173324239](https://images.qianyisky.cn/boke/从零开始搭建你的免费图床系统/20250212184252178.png)\n\n![image-20250212173345988](https://images.qianyisky.cn/boke/从零开始搭建你的免费图床系统/20250212184252179.png)\n\n这时候你就可以去修改之前的图床工具的代理地址了\n\nhttps://images.qianyisky.cn/PicGo/test.png\n\n### WebP Cloud 用量\n\n免费用户每天有 3000 Free Quota，即能够代理 3000 次图片访问请求，并提供 200M 的图片缓存，对于一般用户来说完全够用，如有一些流量较大的特定时期也可以购买额外 Quota，价格很便宜。\n\n如超过了 Quota，访问则会被 301 转发到源站图片地址，不经 WebP Cloud 服务压缩，但依然可用；超过 200M 的缓存则会按照 LRU 算法清理，所以依然能够保障一些高频请求的图片能够有较好的访问体验。\n\n## 总结\n\n以上就是[Pseudoyu](https://www.pseudoyu.com/zh/)的图床系统搭建方案，如果你的项目是在国内的服务器上，用这个方法勉强够用哦，基本都是免费订阅的\n\n\n\n\n\n那么接下来就要讲到安全这几块了\n\n以下内容来自[使用 WebP Cloud 与 Cloudflare WAF 为你的图床添加隐私和版权保护 · Pseudoyu](https://www.pseudoyu.com/zh/2024/07/02/protect_your_image_using_webp_and_cloudflare_waf/)\n\n可以看看作者的一个图片被盗用的经历，就可以知道隐私保护的重要性\n\n# 使用 WebP Cloud 与 Cloudflare WAF 为你的图床添加隐私和版权保护\n\n在使用 WebP Cloud 的过程中，Pseudoyu发现它还提供了自定义 Proxy User Agent、水印等功能，于是萌生了一个想法，是不是可以通过 WebP Cloud 对Pseudoyu的图床源站链接进行保护，使 WebP Cloud 的代理链接成为访问我所有图片的唯一入口，并统一添加Pseudoyu的专属版权水印。\n\n本文是对这一实践的记录，也算是图床搭建番外篇了。\n\n## 需求分析\n\n![image-20250212175038678](https://images.qianyisky.cn/boke/从零开始搭建你的免费图床系统/20250212184252180.png)\n\n理论上两个地址都可以进行访问到我图床里的图片，但是前者是代理后经过处理的图，后者是直接访问cloudflare R2的原图\n\n### 隐私保护\n\n事实上我们通过手机、数码相机等设备拍摄的照片都会携带 EXIF(EXchangeable Image File Format) 信息，通常会包含拍摄设备、时间和地点等敏感信息，我们可以通过一些技术方式手动去除这些元数据，但操作十分繁琐且容易遗漏。\n\nPseudoyu查阅了一下 WebP Cloud 的文档，发现它果然提供自动擦除 EXIF 信息的功能，无须额外配置操作，但其实访客依然可以可以通过 Cloudflare R2 暴露出的源站信息访问到原图，为了避免这一点，我们需要限制用户只能通过 WebP Cloud 代理链接进行请求，访问 Cloudflare R2 源站链接时获取不到任何有用信息。\n\n### 版权保护\n\n这是作者图片被盗用的经历\n\n![image-20250212180156079](https://images.qianyisky.cn/boke/从零开始搭建你的免费图床系统/20250212184252181.png)\n\n## 实现方案\n\n需求清晰了，其实主要分为两部分：\n\n1. 让用户只能通过 WebP Cloud 代理链接访问到我的图片，禁止直接访问原图链接\n2. 在 WebP Cloud 代理层面为所有的图片统一自动添加自己的版权水印，无须手动操作\n\n以下是我的实现方案与详细步骤。\n\n### WebP 自定义 User Agent + Cloudflare WAF\n\n#### WebP Cloud 配置\n\n当我们访问互联网上的网页或图片链接时，请求通常会包含一个 User Agent 字段，一般包含浏览器版本等信息，网站可针对不同的 User Agent 进行一些特定逻辑处理。\n\nWebP Cloud 默认会使用 `WebP Cloud Services/1.0` 作为值，也就是不论用户访问图片时使用的是什么终端设备和浏览器，请求到 Cloudflare R2 时都会被统一为 WebP Cloud 定义的 User Agent 值，而这个值又是用户可以自定义的。\n\n![image-20250212180323061](https://images.qianyisky.cn/boke/从零开始搭建你的免费图床系统/20250212184252182.png)\n\n因此，我们登录 WebP Cloud 的控制台，将「Proxy User Agent」字段设置为一个自定义值，如 `ABC.com/1.0`。\n\n随后更新代理\n\n#### Cloudflare WAF 配置\n\n[WAF（Web Application Firewall）](https://developers.cloudflare.com/waf) 是 Cloudflare 提供的一个防火墙服务，可以自定义规则来限制特定请求以保护网站安全，登录 Cloudflare 后在左侧边栏点击「网站」，点击进入需要保护的域名，选择侧边栏「安全性」 - 「WAF」即可免费使用（注：不是最外层的账户级 WAF），免费账户可设定五个自定义规则。\n\n![image-20250212180818002](https://images.qianyisky.cn/boke/从零开始搭建你的免费图床系统/20250212184252183.png)\n\n![image-20250212180925777](https://images.qianyisky.cn/boke/从零开始搭建你的免费图床系统/20250212184252184.png)\n\n点击右侧的「编辑表达式」，填入以下规则：\n\n```\n(http.user_agent ne \"ABC.com/1.0\") and (http.host eq \"image.qianyisky.cn\")\n```\n\n![image-20250212181107490](https://images.qianyisky.cn/boke/从零开始搭建你的免费图床系统/20250212184252185.png)\n\n其他默认，然后点击保存\n\n> 方便理解：\n>\n> 1.代理链接的User Agent会包含在网络请求里，也就是设置了`ABC.com/1.0`（`A钥匙`）\n>\n> 2.cloudflare WAF：设置了只有`A钥匙`才可以访问\n>\n> 3.一般用户浏览网页的User Agent是这样的\n>\n> ```perl6\n> User-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36\n> ```\n>\n> 也就是说没有A钥匙，是访问不了的\n>\n> 4.所以在代理链接设置了A钥匙，那么他会把访问原地址的流量请求加入A钥匙，达到访问的目的，如果没有A钥匙直接访问原地址就会出现如下图\n\n![image-20250212181942387](https://images.qianyisky.cn/boke/从零开始搭建你的免费图床系统/20250212184252186.png)\n\n所以完成配置后，当我们再次访问原地址image.qianyisky.cn的时候就会被拦截，例如：\n\n原地址：https://image.qianyisky.cn/PicGo/test.png\n\n代理地址：https://images.qianyisky.cn/PicGo/test.png\n\n完美实现了我们的需求。\n\n### 设置水印\n\n我这里就设置了一个灰色的水印\n\n![image-20250212182258376](https://images.qianyisky.cn/boke/从零开始搭建你的免费图床系统/20250212184252187.png)\n\n![image-20250212182308863](https://images.qianyisky.cn/boke/从零开始搭建你的免费图床系统/20250212184252188.png)\n\n设置好后保存\n\n![image-20250212182443427](https://images.qianyisky.cn/boke/从零开始搭建你的免费图床系统/20250212184252189.png)\n\n由于，刚设置，只会对新上传的图片添加水印，如果你要之前上传的图片都要打上水印，你就要清除缓存，最后重新访问图片就会有水印了\n\n![image-20250212182549468](https://images.qianyisky.cn/boke/从零开始搭建你的免费图床系统/20250212184252190.png)\n\n缓存的规则：`目前所有代理都会有 200.00 MiB 缓存，如果超出这个限制，我们将使用“最近最少使用”（LRU）算法进行驱逐，也就是说，最少请求的内容将从缓存中驱逐。`\n\n代理地址：https://images.qianyisky.cn/PicGo/test.png\n\n![image-20250212182812682](https://images.qianyisky.cn/boke/从零开始搭建你的免费图床系统/20250212184252191.png)\n\n<div class=\"tbsm\" style=\"margin-top:54px;\">\n<div class=\"tbsm-top\"><span><svg t=\"1674654360507\" class=\"icon\" viewBox=\"0 0 1024 1024\" version=\"1.1\" xmlns=\"http://www.w3.org/2000/svg\" p-id=\"987\" data-spm-anchor-id=\"a313x.7781069.0.i0\" width=\"35\" height=\"35\"><path d=\"M410.49 97.74H155.08a56.74 56.74 0 0 0-56.84 56.73V410a56.84 56.84 0 0 0 56.84 56.84h255.41A56.83 56.83 0 0 0 467.32 410V154.58a56.83 56.83 0 0 0-56.83-56.84zM410.49 558.74H155.08a56.74 56.74 0 0 0-56.84 56.73V871a56.84 56.84 0 0 0 56.84 56.84h255.41A56.83 56.83 0 0 0 467.32 871V615.58a56.83 56.83 0 0 0-56.83-56.84zM871.49 558.74H616.08a56.74 56.74 0 0 0-56.84 56.73V871a56.84 56.84 0 0 0 56.84 56.84h255.41A56.83 56.83 0 0 0 928.32 871V615.58a56.83 56.83 0 0 0-56.83-56.84z\" fill=\"#66EEFF\" p-id=\"988\"></path><path d=\"M410.49 558.74h-4.14A475 475 0 0 0 299.52 859.6a481.16 481.16 0 0 0 4.84 68.22h106.13A56.83 56.83 0 0 0 467.32 871V615.58a56.83 56.83 0 0 0-56.83-56.84zM871.49 558.74H616.08a56.74 56.74 0 0 0-56.84 56.73V871a56.84 56.84 0 0 0 56.84 56.84h255.41A56.83 56.83 0 0 0 928.32 871V615.58a56.83 56.83 0 0 0-56.83-56.84z\" fill=\"#C2F8FF\" p-id=\"989\"></path></svg></span><span style=\"font-size:30px;\"> 特别声明</span></div>\n<div class=\"tbsm-wz\">千屹博客旗下的所有文章，是通过本人课堂学习和课外自学所精心整理的知识巨著<br/>难免会有出错的地方<br/>如果细心的你发现了小失误，可以在下方评论区告诉我，或者私信我！<br />非常感谢大家的热烈支持！</div>\n</div>","categories":["杂项"]},{"title":"OpenStack Antelope","url":"/posts/8c5be7b9/","content":"\n<meta name=\"referrer\" content=\"no-referrer\"/>\n\n# OpenStack Antelope\n\n本文档是基于 openEuler 24.03 LTS 的 OpenStack 部署指南\n\n镜像下载： [openEuler 24.03 LTS](https://repo.openeuler.org/openEuler-24.03-LTS/ISO/)\n\n## 主机拓扑\n\n|   主机名   |       ip       | 硬盘1 | 硬盘2 | cpu  | 内存 |\n| :--------: | :------------: | ----- | :---: | :--: | :--: |\n| controller | 192.168.48.101 | 100G  |       |  4   |  7G  |\n|  compute   | 192.168.48.102 | 100G  |       |  4   |  4G  |\n|  storage   | 192.168.48.103 | 100G  | 100G  |  4   |  2G  |\n\n具体安装的服务如下：\n\n| 节点名称   | OpenStack 服务                                               |\n| ---------- | ------------------------------------------------------------ |\n| 控制节点   | MariaDB RabbitMQ Memcache Keystone Placement Glance Nova Neutron Cinder Horizon Heat |\n| 计算节点   | Nova Neutron                                                 |\n| 块存储节点 | Cinder Swift                                                 |\n\n## 前情提要\n\ncompute启动虚拟机硬件加速（x86_64）\n\n![image-20241209211221288](https://i0.hdslb.com/bfs/article/9a9672ea7201e5d7b4904110548a7e97697559838.png)\n\n所有节点的内存和硬盘芯片都要按照我的来\n\n![image-20241209211140929](https://i0.hdslb.com/bfs/article/d87c419047278445f660cd46aec74eac697559838.png)\n\n## 安全性\n\n### 物理节点关闭顺序\n\n给每台机都加上两个脚本\n\n```\ncat >> stop.sh << EOF\n#!/bin/bash\n# 关闭所有 OpenStack 节点\n# 依次关闭计算节点、网络节点、控制节点\nfor server in \\$(openstack server list -f value -c ID); do\n    openstack server stop \\$server\ndone\n# 关闭计算节点\necho \"Stopping compute services...\"\nsystemctl stop openstack-nova-compute.service\nsystemctl stop libvirtd.service\n# 关闭网络节点\necho \"Stopping network services...\"\nsystemctl stop openvswitch.service\nsystemctl stop neutron-server.service\nsystemctl stop neutron-linuxbridge-agent.service\nsystemctl stop neutron-dhcp-agent.service\nsystemctl stop neutron-metadata-agent.service\nsystemctl stop neutron-l3-agent.service\n# 关闭控制节点\necho \"Stopping control services...\"\nsystemctl stop mariadb.service\nsystemctl stop rabbitmq-server.service\nsystemctl stop memcached.service\nsystemctl stop httpd.service\nsystemctl stop openstack-glance-api.service\nsystemctl stop openstack-glance-registry.service\nsystemctl stop openstack-cinder-api.service\nsystemctl stop openstack-cinder-scheduler.service\nsystemctl stop openstack-cinder-volume.service\nsystemctl stop openstack-nova-api.service\nsystemctl stop openstack-nova-scheduler.service\nsystemctl stop openstack-nova-conductor.service\nsystemctl stop openstack-nova-novncproxy.service\nsystemctl stop openstack-nova-consoleauth.service\nsystemctl stop openstack-keystone.service\nsystemctl stop openstack-heat-api.service\nsystemctl stop openstack-heat-api-cfn.service\nsystemctl stop openstack-heat-engine.service\nsystemctl stop openstack-swift-proxy.service\nsystemctl stop openstack-swift-account.service\nsystemctl stop openstack-swift-container.service\nsystemctl stop openstack-swift-object.service\necho \"Stopping all services...\"\nsystemctl stop --all\n# 关闭电源\necho \"Shutting down the system...\"\npoweroff\nEOF\n\ncat >> start.sh << EOF\n#!/bin/bash\n# 重新启动 OpenStack 服务\n# 依次启动控制节点、网络节点、计算节点\n# 启动控制节点\necho \"Starting control services...\"\nsystemctl start mariadb.service\nsystemctl start rabbitmq-server.service\nsystemctl start memcached.service\nsystemctl start httpd.service\nsystemctl start openstack-glance-api.service\nsystemctl start openstack-glance-registry.service\nsystemctl start openstack-cinder-api.service\nsystemctl start openstack-cinder-scheduler.service\nsystemctl start openstack-cinder-volume.service\nsystemctl start openstack-nova-api.service\nsystemctl start openstack-nova-scheduler.service\nsystemctl start openstack-nova-conductor.service\nsystemctl start openstack-nova-novncproxy.service\nsystemctl start openstack-nova-consoleauth.service\nsystemctl start openstack-keystone.service\nsystemctl start openstack-heat-api.service\nsystemctl start openstack-heat-api-cfn.service\nsystemctl start openstack-heat-engine.service\nsystemctl start openstack-swift-proxy.service\nsystemctl start openstack-swift-account.service\nsystemctl start openstack-swift-container.service\nsystemctl start openstack-swift-object.service\n# 启动网络节点\necho \"Starting network services...\"\nsystemctl start openvswitch.service\nsystemctl start neutron-server.service\nsystemctl start neutron-linuxbridge-agent.service\nsystemctl start neutron-dhcp-agent.service\nsystemctl start neutron-metadata-agent.service\nsystemctl start neutron-l3-agent.service\n# 启动计算节点\necho \"Starting compute services...\"\nsystemctl start libvirtd.service\nsystemctl start openstack-nova-compute.service\nEOF\n```\n\n<font color='red'>（先给coompute和storage节点执行-最后等这两个节点完全关闭，再给控制节点执行）</font>\n\n```\n关闭物理机的时候运行\nsh stop.sh\n(运行的时候可能会提示你有些服务找不到，报错，这个没关系，但是要是告诉你有些服务起不来，要你自己去找报错了)一般情况下是没问题的\n```\n\n### 物理节点开启顺序\n\n> <font color='red'>先开controller再开剩下的计算节点</font>\n\n### 基本用户信息\n\nOpenStack 各组件都需要在控制节点数据库中注册专属账户以存放数据信息，故需要设置密码，强烈建议各组件的密码以及宿主机密码各不相同。\n\n|    OpenStack 组件     |         密码          |\n| :-------------------: | :-------------------: |\n|     控制节点 root     |       Lj201840.       |\n|     计算节点 root     |       Lj201840.       |\n|  Metadata 元数据密钥  |    METADATA_SECRET    |\n|   Mariadb root 账户   |     MARIADB_PASS      |\n|     RabbitMQ 服务     |      RABBIT_PASS      |\n|    OpenStack admin    |      ADMIN_PASS       |\n|    Placement 服务     |    PLACEMENT_PASS     |\n|    Keystone 数据库    |    KEYSTONE_DBPASS    |\n|      Glance 服务      |      GLANCE_PASS      |\n|     Glance 数据库     |     GLANCE_DBPASS     |\n|       Nova 服务       |       NOVA_PASS       |\n|      Nova 数据库      |      NOVA_DBPASS      |\n|     Neutron 服务      |     NEUTRON_PASS      |\n|    Neutron 数据库     |    NEUTRON_DBPASS     |\n|      Cinder 服务      |      CINDER_PASS      |\n|     Cinder 数据库     |     CINDER_DBPASS     |\n|    Horizon 数据库     |      DASH_DBPASS      |\n|       Swift服务       |      SWIFT_PASS       |\n|       Heat服务        |       HEAT_PASS       |\n|    Heat数据库服务     |      HEAT_DBPASS      |\n| heat_domain_admin用户 | HEAT_DOMAIN_USER_PASS |\n\n### 测试用户\n\n| 用户    | 密码   |\n| ------- | ------ |\n| admin   | 123456 |\n| use_dog | 123456 |\n\n## 基础配置\n\n操作节点：[所有节点]\n\n不要一股脑的复制，注意修改网卡的名字，我这里是`ens33`，修改成你的网卡名字，包括修改ip段，比如我的是`192.168.48.`你就要修改成你的`172.8.3.`最后那一个主机位就不用管，其他不变\n\n```\nvi init.sh\n```\n\n```bash\n#!/bin/bash\nif [ $# -eq 2 ];then\n  echo \"设置主机名为：$1\"\n  echo \"ens33设置IP地址为：192.168.48.$2\"\nelse\n  echo  \"使用方法：sh $0 主机名 主机位\"\n  exit 2\nfi\n\necho \"--------------------------------------\"\necho \"1.正在设置主机名：$1\"\nhostnamectl set-hostname $1\n\necho \"2.正在关闭firewalld、selinux\"\nsystemctl disable firewalld &> /dev/null\nsystemctl stop firewalld\nsed -i \"s#SELINUX=enforcing#SELINUX=disabled#g\" /etc/selinux/config\nsetenforce 0\n\n\necho \"3.正在设置ens33：192.168.48.$2\"\ncat > /etc/sysconfig/network-scripts/ifcfg-ens33 <<EOF\nTYPE=Ethernet\nPROXY_METHOD=none\nBROWSER_ONLY=no\nBOOTPROTO=static\nDEFROUTE=yes\nIPV4_FAILURE_FATAL=no\nIPV6INIT=yes\nIPV6_AUTOCONF=yes\nIPV6_DEFROUTE=yes\nIPV6_FAILURE_FATAL=no\nNAME=ens33\nUUID=53b402ff-5865-47dd-a853-7afcd6521738\nDEVICE=ens33\nONBOOT=yes\nIPADDR=192.168.48.$2\nGATEWAY=192.168.48.2\nPREFIX=24\nDNS1=192.168.48.2\nDNS2=114.114.114.114\nEOF\nnmcli c reload\nnmcli c up ens33\necho \"4.新增华为云源\"\nmkdir /etc/yum.repos.d/bak/\ncp /etc/yum.repos.d/* /etc/yum.repos.d/bak/\n#切换为华为云，下载速度更快\nsed -i 's/\\$basearch/x86_64/g' /etc/yum.repos.d/openEuler.repo\nsed -i 's/http\\:\\/\\/repo.openeuler.org/https\\:\\/\\/mirrors.huaweicloud.com\\/openeuler/g' /etc/yum.repos.d/openEuler.repo\n\necho \"5.更新yum源软件包缓存\"\nyum clean all && yum makecache\n\necho \"6.添加hosts解析\"\ncat > /etc/hosts <<EOF\n127.0.0.1   localhost localhost.localdomain localhost4 localhost4.localdomain4\n::1         localhost localhost.localdomain localhost6 localhost6.localdomain6\n192.168.48.101   controller\n192.168.48.102   compute\n192.168.48.103   storage\nEOF\n\necho \"7.安装chrony服务，并同步时间\"\nyum install chrony -y\nsystemctl enable chronyd --now\ntimedatectl set-timezone Asia/Shanghai\ntimedatectl set-local-rtc 1\ntimedatectl set-ntp yes\nchronyc -a makestep\nchronyc tracking\nchronyc sources\n\necho \"8.必备工具安装\"\nyum install wget psmisc vim net-tools telnet socat device-mapper-persistent-data lvm2 git -y\n\necho \"9.安装openstack\"\n#新装的系统，默认启用 EPOL ，若没有启动，自行启用 EPOL 软件仓以支持 OpenStack\nyum update -y\nyum install openstack-release-antelope -y\n\necho \"10.重启\"\nreboot\n```\n\n运行\n\n```\nsh system_init.sh 主机名  主机位\n\n[controller] sh init.sh controller 101\n\n[compute] sh init.sh compute 102\n\n[storage] sh init.sh storage 103\n```\n\nSSH免密\n\n```bash\n#各节点\nyum install -y sshpass \ncat > sshmianmi.sh << \"EOF\"\n#!/bin/bash\n# 目标主机列表\nhosts=(\"controller\" \"compute\" \"storage\")\n# 密码（注意修改）!!!!!!!!!!!!!!!!!!!!!!!\npassword=\"Lj201840.\"\n# SSH 配置文件\nssh_config=\"$HOME/.ssh/config\"\n\n# 生成 SSH 密钥对\nssh-keygen -t rsa -N \"\" -f ~/.ssh/id_rsa\n\n# 确保 SSH 配置文件存在\nmkdir -p \"$HOME/.ssh\"\ntouch \"$ssh_config\"\nchmod 600 \"$ssh_config\"\n\n# 添加 SSH 配置\n{\n    echo \"Host *\"\n    echo \"    StrictHostKeyChecking no\"\n    echo \"    UserKnownHostsFile /dev/null\"\n} >> \"$ssh_config\"\n\n# 循环遍历目标主机\nfor host in \"${hosts[@]}\"\ndo\n    # 复制公钥到目标主机\n    sshpass -p \"$password\" ssh-copy-id -o StrictHostKeyChecking=no \"$host\"\n    \n    # 验证免密登录\n    sshpass -p \"$password\" ssh -o StrictHostKeyChecking=no \"$host\" \"echo '免密登录成功'\"\ndone\nEOF\n\nsh sshmianmi.sh\n```\n\n## 依赖组件\n\n### 时间同步\n\n集群环境时刻要求每个节点的时间一致，一般由时钟同步软件保证。本文使用`chrony`软件\n\n由于前面基础配置已经安装chrony，这里就不再安装了\n\n操作节点：[controller]\n\n```bash\necho \"allow 192.168.48.0/24\" | sudo tee -a /etc/chrony.conf > /dev/null\nsystemctl restart chronyd\n```\n\n操作节点：[compute,storage]\n\n```bash\n# 192.168.48.101是controller IP，表示从这个机器获取时间，这里我们填192.168.48.101，或者在`/etc/hosts`里配置好的controller名字即可。\necho \"server 192.168.48.101 iburst\" | sudo tee -a /etc/chrony.conf > /dev/null\nsystemctl restart chronyd\n```\n\n配置完成后，检查一下结果，在其他非controller节点执行`chronyc sources`，返回结果类似如下内容，表示成功从controller同步时钟\n\n![image-20241208163055470](https://i0.hdslb.com/bfs/article/c135552306af01075d91d08c382bc31b697559838.png)\n\n![image-20241208163141045](https://i0.hdslb.com/bfs/article/90c9558b91a9a0e76a0727b19666bd51697559838.png)\n\n### 安装数据库\n\n操作节点:[controller]\n\n```bash\ndnf install mysql-config mariadb mariadb-server python3-PyMySQL -y\ncat > /etc/my.cnf.d/openstack.cnf << \"EOF\"\n[mysqld]\nbind-address = 192.168.48.101\ndefault-storage-engine = innodb\ninnodb_file_per_table = on\nmax_connections = 4096\ncollation-server = utf8_general_ci\ncharacter-set-server = utf8\nEOF\nsystemctl enable --now mariadb\n#初始化数据库\nmysql_secure_installation\nEnter current password for root (enter for none): 回车\nSwitch to unix_socket authentication [Y/n] n\nChange the root password? [Y/n] y\n# 将要求输入数据库 root 账户密码 MARIADB_PASS\nRemove anonymous users? [Y/n] y\nDisallow root login remotely? [Y/n] Y\nRemove test database and access to it? [Y/n] y\nReload privilege tables now? [Y/n] y\n# 验证\nmysql -u root -pMARIADB_PASS\n```\n\n### 安装消息队列\n\n操作节点:[controller]\n\n```bash\ndnf install rabbitmq-server -y\nsystemctl enable --now rabbitmq-server\nrabbitmqctl add_user openstack RABBIT_PASS\nrabbitmqctl set_permissions openstack \".*\" \".*\" \".*\"\n```\n\n### 安装缓存服务\n\n操作节点:[controller]\n\ncontroller是我的主机名，你要改成你的主机名\n\n```bash\ndnf install memcached python3-memcached -y\nsed -i \"s/OPTIONS=\\\"-l 127.0.0.1,::1\\\"/OPTIONS=\\\"-l 127.0.0.1,::1,controller\\\"/g\" /etc/sysconfig/memcached\nsystemctl enable memcached --now\n```\n\n## Keystone\n\nKeystone是OpenStack提供的鉴权服务，是整个OpenStack的入口，提供了租户隔离、用户认证、服务发现等功能，必须安装。\n\n建立一个脚本  (`后续我都不做解释了，自行添加脚本，然后运行，要注意脚本里的密码啥的，改成自己需要的`)\n\n```\nmkdir openstack-install\ncd openstack-install\nvim keystone.sh\n```\n\n添加以下内容\n\n```bash\n#!/bin/bash\n# 创建数据库并授权\n#替换 KEYSTONE_DBPASS，为 keystone 数据库设置密码\necho \"CREATE DATABASE keystone;\" | mysql -u root -pMARIADB_PASS\necho \"GRANT ALL PRIVILEGES ON keystone.* TO 'keystone'@'localhost' IDENTIFIED BY 'KEYSTONE_DBPASS';\" | mysql -u root -pMARIADB_PASS\necho \"GRANT ALL PRIVILEGES ON keystone.* TO 'keystone'@'%' IDENTIFIED BY 'KEYSTONE_DBPASS';\" | mysql -u root -pMARIADB_PASS\nmysql -u root -pMARIADB_PASS -e \"FLUSH PRIVILEGES;\"\nsleep 3\n# 安装OpenStack Keystone和相关依赖\ndnf install openstack-keystone httpd mod_wsgi -y\n\n# 备份并配置keystone配置文件\nmv /etc/keystone/keystone.conf{,.bak}\ncat > /etc/keystone/keystone.conf <<EOF\n[database]\nconnection = mysql+pymysql://keystone:KEYSTONE_DBPASS@controller/keystone\n[token]\nprovider = fernet\nEOF\n\n# 同步数据库\nsu -s /bin/sh -c \"keystone-manage db_sync\" keystone\necho \"use keystone; show tables;\" | mysql -u root -pMARIADB_PASS\n# 初始化Fernet密钥仓库和凭证\nkeystone-manage fernet_setup --keystone-user keystone --keystone-group keystone\nkeystone-manage credential_setup --keystone-user keystone --keystone-group keystone\n\n# 启动服务\nkeystone-manage bootstrap --bootstrap-password 123456 \\\n--bootstrap-admin-url http://controller:5000/v3/ \\\n--bootstrap-internal-url http://controller:5000/v3/ \\\n--bootstrap-public-url http://controller:5000/v3/ \\\n--bootstrap-region-id RegionOne\n\n# 配置Apache HTTP server\ncp /etc/httpd/conf/httpd.conf{,.bak}\nsed -i \"s/#ServerName www.example.com:80/ServerName controller/g\" /etc/httpd/conf/httpd.conf\nln -s /usr/share/keystone/wsgi-keystone.conf /etc/httpd/conf.d/\nsystemctl enable httpd --now\n\n# 创建管理员账户配置文件\ncat << EOF > /root/admin-openrc\nexport OS_PROJECT_DOMAIN_NAME=Default\nexport OS_USER_DOMAIN_NAME=Default\nexport OS_PROJECT_NAME=admin\nexport OS_USERNAME=admin\nexport OS_PASSWORD=123456\nexport OS_AUTH_URL=http://controller:5000/v3\nexport OS_IDENTITY_API_VERSION=3\nexport OS_IMAGE_API_VERSION=2\nEOF\n\n# 创建测试用户配置文件\ncat << EOF > /root/user_dog-openrc\nexport OS_USERNAME=user_dog\nexport OS_PASSWORD=123456\nexport OS_PROJECT_NAME=Demo\nexport OS_USER_DOMAIN_NAME=RegionOne\nexport OS_PROJECT_DOMAIN_NAME=RegionOne\nexport OS_AUTH_URL=http://controller:5000/v3\nexport OS_IDENTITY_API_VERSION=3\nexport OS_IMAGE_API_VERSION=2\nEOF\n\n# 安装python3-openstackclient\ndnf install python3-openstackclient -y\n\n# 依次创建domain, projects, users, roles\nsource /root/admin-openrc\nopenstack domain create --description \"An RegionOne Domain\" RegionOne\nopenstack project create --domain default --description \"Service Project\" service\n# 在 RegionOne 域中创建一个 Demo 项目\nopenstack project create --domain RegionOne --description \"Demo Project\" Demo\nopenstack user create --domain RegionOne --password 123456 user_dog\nopenstack role create user_dog_role\nopenstack role add --project Demo --user user_dog user_dog_role\n\n# 列举当前所有域名\nopenstack domain list\n```\n\n运行keystone脚本\n\n```\nsh keystone.sh\n```\n\n![image-20241208171053281](https://i0.hdslb.com/bfs/article/428afc30bba203734ca51ab85629d399697559838.png)\n\n## Glance\n\n```\ncd openstack-install\nvim glance.sh\n```\n\n```shell\n#!/bin/bash\n#替换 GLANCE_DBPASS，为 glance 数据库设置密码\necho \"CREATE DATABASE glance;\" | mysql -u root -pMARIADB_PASS\necho \"GRANT ALL PRIVILEGES ON glance.* TO 'glance'@'localhost' IDENTIFIED BY 'GLANCE_DBPASS';\" | mysql -u root -pMARIADB_PASS\necho \"GRANT ALL PRIVILEGES ON glance.* TO 'glance'@'%' IDENTIFIED BY 'GLANCE_DBPASS';\" | mysql -u root -pMARIADB_PASS\nmysql -u root -pMARIADB_PASS -e \"FLUSH PRIVILEGES;\"\nsource /root/admin-openrc\n#创建glance用户并设置密码\nopenstack user create --domain default --password GLANCE_PASS glance\n#添加glance用户到service project并指定admin角色\nopenstack role add --project service --user glance admin\n#创建glance服务实体\nopenstack service create --name glance --description \"OpenStack Image\" image\n#创建glance API服务\nopenstack endpoint create --region RegionOne image public http://controller:9292\nopenstack endpoint create --region RegionOne image internal http://controller:9292\nopenstack endpoint create --region RegionOne image admin http://controller:9292\n#安装软件包\ndnf install openstack-glance -y\n#修改配置文件\nmv /etc/glance/glance-api.conf{,.bak}\ncat >/etc/glance/glance-api.conf << \"EOF\"\n[database]\nconnection = mysql+pymysql://glance:GLANCE_DBPASS@controller/glance\n\n[keystone_authtoken]\nwww_authenticate_uri  = http://controller:5000\nauth_url = http://controller:5000\nmemcached_servers = controller:11211\nauth_type = password\nproject_domain_name = Default\nuser_domain_name = Default\nproject_name = service\nusername = glance\npassword = GLANCE_PASS\n\n[paste_deploy]\nflavor = keystone\n\n[glance_store]\nstores = file,http\ndefault_store = file\nfilesystem_store_datadir = /var/lib/glance/images/\nEOF\n#同步数据库\nsu -s /bin/sh -c \"glance-manage db_sync\" glance\n#启动服务\nsystemctl enable openstack-glance-api.service --now\nsource /root/admin-openrc\nmkdir /root/openstack-install/iso/\n#下载镜像\nwget -P /root/openstack-install/iso/ https://resource.qianyios.top/cloud/iso/cirros-0.4.0-x86_64-disk.img\n#向Image服务上传镜像\nsource /root/admin-openrc\nopenstack image create --disk-format qcow2 --container-format bare \\\n   --file /root/openstack-install/iso/cirros-0.4.0-x86_64-disk.img --public cirros\n#验证是否上传\nopenstack image list\n```\n\n```\nsh glance.sh\n```\n\n![image-20241208192109265](https://i0.hdslb.com/bfs/article/8a1a635b624d1796e0c129eb506f87fd697559838.png)\n\n## Placement\n\nPlacement是OpenStack提供的资源调度组件，一般不面向用户，由Nova等组件调用，安装在控制节点。\n\n安装、配置Placement服务前，需要先创建相应的数据库、服务凭证和API endpoints。\n\n操作节点[controller]\n\n```\ncd openstack-install\nvim placement.sh\n```\n\n```shell\n#!/bin/bash\n#创建数据库并授权\n#替换PLACEMENT_DBPASS为placement数据库访问密码。\necho \"CREATE DATABASE placement;\" | mysql -u root -pMARIADB_PASS\necho \"GRANT ALL PRIVILEGES ON placement.* TO 'placement'@'localhost' IDENTIFIED BY 'PLACEMENT_DBPASS';\" | mysql -u root -pMARIADB_PASS\necho \"GRANT ALL PRIVILEGES ON placement.* TO 'placement'@'%' IDENTIFIED BY 'PLACEMENT_DBPASS';\" | mysql -u root -pMARIADB_PASS\nmysql -u root -pMARIADB_PASS -e \"FLUSH PRIVILEGES;\"\n\nsource /root/admin-openrc\n#创建placement用户并设置密码\nopenstack user create --domain default --password PLACEMENT_PASS placement\n#添加placement用户到service project并指定admin角色\nopenstack role add --project service --user placement admin\n#创建placement服务实体\nopenstack service create --name placement \\\n  --description \"Placement API\" placement\n#创建Placement API服务endpoints\nopenstack endpoint create --region RegionOne \\\n  placement public http://controller:8778\nopenstack endpoint create --region RegionOne \\\n  placement internal http://controller:8778\nopenstack endpoint create --region RegionOne \\\n  placement admin http://controller:8778\n\n#安装placement\ndnf install openstack-placement-api -y\n#配置placement\nmv /etc/placement/placement.conf{,.bak}\n#PLACEMENT_DBPASS为placement服务的数据库账户密码\n#PLACEMENT_PASS为placement服务的密码\n#以下的placement.conf文件不要有任何的注释，不然后面会报错\ncat > /etc/placement/placement.conf << \"EOF\"\n[placement_database]\nconnection = mysql+pymysql://placement:PLACEMENT_DBPASS@controller/placement\n[api]\nauth_strategy = keystone\n[keystone_authtoken]\nauth_url = http://controller:5000/v3\nmemcached_servers = controller:11211\nauth_type = password\nproject_domain_name = Default\nuser_domain_name = Default\nproject_name = service\nusername = placement\npassword = PLACEMENT_PASS\nEOF\nsu -s /bin/sh -c \"placement-manage db sync\" placement\noslopolicy-convert-json-to-yaml  --namespace placement \\\n  --policy-file /etc/placement/policy.json \\\n  --output-file /etc/placement/policy.yaml\nmv /etc/placement/policy.json{,.bak}\nsystemctl restart httpd\ndnf install python3-osc-placement -y\nplacement-status upgrade check\n```\n\n```\nsh placement.sh\n```\n\n![image-20241208193522497](https://i0.hdslb.com/bfs/article/35c73ecebfb9526be12acd1316ce239f697559838.png)\n\n验证服务，列出可用的资源类别及特性\n\n```\nsource /root/admin-openrc\nopenstack --os-placement-api-version 1.2 resource class list --sort-column name\nopenstack --os-placement-api-version 1.6 trait list --sort-column name\n```\n\n![image-20241208202746969](https://i0.hdslb.com/bfs/article/a1ef3888e4f1a721cb8a928469fafd92697559838.png)\n\n![image-20241208202805822](https://i0.hdslb.com/bfs/article/d8e6c1cfa2c178d3a062a88c1d1ac97b697559838.png)\n\n## Nova\n\nNova是OpenStack的计算服务，负责虚拟机的创建、发放等功能。\n\n### controller\n\n操作节点[controller]\n\n```\ncd openstack-install\nvim nova-controller.sh\n```\n\n```shell\n#创建数据库并授权\n#创建nova_api、nova和nova_cell0数据库：\necho \"CREATE DATABASE nova_api;\" | mysql -u root -pMARIADB_PASS\necho \"CREATE DATABASE nova;\" | mysql -u root -pMARIADB_PASS\necho \"CREATE DATABASE nova_cell0;\" | mysql -u root -pMARIADB_PASS\n#授权\necho \"GRANT ALL PRIVILEGES ON nova_api.* TO 'nova'@'localhost' IDENTIFIED BY 'NOVA_DBPASS';\" | mysql -u root -pMARIADB_PASS\necho \"GRANT ALL PRIVILEGES ON nova_api.* TO 'nova'@'%' IDENTIFIED BY 'NOVA_DBPASS';\" | mysql -u root -pMARIADB_PASS\necho \"GRANT ALL PRIVILEGES ON nova.* TO 'nova'@'localhost' IDENTIFIED BY 'NOVA_DBPASS';\" | mysql -u root -pMARIADB_PASS\necho \"GRANT ALL PRIVILEGES ON nova.* TO 'nova'@'%' IDENTIFIED BY 'NOVA_DBPASS';\" | mysql -u root -pMARIADB_PASS\necho \"GRANT ALL PRIVILEGES ON nova_cell0.* TO 'nova'@'localhost' IDENTIFIED BY 'NOVA_DBPASS';\" | mysql -u root -pMARIADB_PASS\necho \"GRANT ALL PRIVILEGES ON nova_cell0.* TO 'nova'@'%' IDENTIFIED BY 'NOVA_DBPASS';\" | mysql -u root -pMARIADB_PASS\nmysql -u root -pMARIADB_PASS -e \"FLUSH PRIVILEGES;\"\n\nsource /root/admin-openrc\n#创建nova用户并设置用户密码\nopenstack user create --domain default --password NOVA_PASS nova\n#添加nova用户到service project并指定admin角色\nopenstack role add --project service --user nova admin\n#创建nova服务实体\nopenstack service create --name nova \\\n  --description \"OpenStack Compute\" compute\n#创建Nova API服务endpoints：\nopenstack endpoint create --region RegionOne \\\n  compute public http://controller:8774/v2.1\nopenstack endpoint create --region RegionOne \\\n  compute internal http://controller:8774/v2.1\nopenstack endpoint create --region RegionOne \\\n  compute admin http://controller:8774/v2.1\ndnf install openstack-nova-api openstack-nova-conductor \\\n  openstack-nova-novncproxy openstack-nova-scheduler -y\n\nmv /etc/nova/nova.conf{,.bak}\ncat > /etc/nova/nova.conf <<EOF\n[DEFAULT]\nenabled_apis = osapi_compute,metadata\ntransport_url = rabbit://openstack:RABBIT_PASS@controller:5672/\n# RABBIT_PASS为 rabbitmq 密码\nmy_ip = 192.168.48.101\n# 控制节点的 IP\nlog_dir = /var/log/nova\nstate_path = /var/lib/nova\n[api_database]\nconnection = mysql+pymysql://nova:NOVA_DBPASS@controller/nova_api\n# NOVA_DBPASS 为数据库 Nova 账户密码\n[database]\nconnection = mysql+pymysql://nova:NOVA_DBPASS@controller/nova\n# NOVA_DBPASS 为数据库 Nova 账户密码\n[api]\nauth_strategy = keystone\n[keystone_authtoken]\nauth_url = http://controller:5000/v3\nmemcached_servers = controller:11211\nauth_type = password\nproject_domain_name = Default\nuser_domain_name = Default\nproject_name = service\nusername = nova\npassword = NOVA_PASS\n# NOVA_PASS 为 Nova 服务的密码\n[vnc]\nenabled = true\nserver_listen = \\$my_ip\nserver_proxyclient_address = \\$my_ip\n[glance]\napi_servers = http://controller:9292\n[oslo_concurrency]\nlock_path = /var/lib/nova/tmp\n[placement]\nregion_name = RegionOne\nproject_domain_name = Default\nproject_name = service\nauth_type = password\nuser_domain_name = Default\nauth_url = http://controller:5000/v3\nusername = placement\npassword = PLACEMENT_PASS\n# PLACEMENT_PASS 为 placement 服务的密码\nEOF\n#同步数据库\nsu -s /bin/sh -c \"nova-manage api_db sync\" nova\nsu -s /bin/sh -c \"nova-manage cell_v2 map_cell0\" nova\nsu -s /bin/sh -c \"nova-manage cell_v2 create_cell --name=cell1 --verbose\" nova\nsu -s /bin/sh -c \"nova-manage db sync\" nova\n#验证cell0和cell1注册正确\nsu -s /bin/sh -c \"nova-manage cell_v2 list_cells\" nova\n\n#启动服务\nsystemctl enable \\\n  openstack-nova-api.service \\\n  openstack-nova-scheduler.service \\\n  openstack-nova-conductor.service \\\n  openstack-nova-novncproxy.service --now\n```\n\n```\nsh nova-controller.sh\n```\n\n![image-20241208204427484](https://i0.hdslb.com/bfs/article/8a6b800069b36d39f2da32d097bcc531697559838.png)\n\n### compute\n\n操作节点[compute]\n\n确认计算节点是否支持虚拟机硬件加速（x86_64）\n\n```\negrep -c '(vmx|svm)' /proc/cpuinfo\n```\n\n如果返回值为0则不支持硬件加速。\n\n`这时候请回到文章开头前情提要部分，认真看看如何开启硬件加速`\n\n不好好看文章，你就要回到开头呗，累吧？\n\n```\nmkdir openstack-install && cd openstack-install\nvim nova-compute.sh\n```\n\n```shell\n#!/bin/bash\ndnf install openstack-nova-compute -y\nmv /etc/nova/nova.conf{,.bak}\ncat > /etc/nova/nova.conf <<EOF\n[DEFAULT]\nenabled_apis = osapi_compute,metadata\ntransport_url = rabbit://openstack:RABBIT_PASS@controller:5672/\n#替换RABBIT_PASS为RabbitMQ中openstack账户的密码。\nmy_ip = 192.168.48.102\ncompute_driver = libvirt.LibvirtDriver\ninstances_path = /var/lib/nova/instances\nlog_dir = /var/log/nova\nlock_path = /var/lock/nova\nstate_path = /var/lib/nova\n[api]\nauth_strategy = keystone\n[keystone_authtoken]\nauth_url = http://controller:5000/v3\nmemcached_servers = controller:11211\nauth_type = password\nproject_domain_name = Default\nuser_domain_name = Default\nproject_name = service\nusername = nova\npassword = NOVA_PASS\n#替换NOVA_PASS为nova用户的密码。\n[vnc]\nenabled = true\nserver_listen = \\$my_ip\nserver_proxyclient_address = \\$my_ip\nnovncproxy_base_url = http://192.168.48.101:6080/vnc_auto.html\n#建议设置成192.168.48.101，也就是controller，这个决定你在页面访问实例控制台的地址，如果你是自己的电脑访问，然后你又没有设置hosts映射到controller，你会访问不到的，改成ip可以访问\n[glance]\napi_servers = http://controller:9292\n[oslo_concurrency]\nlock_path = /var/lib/nova/tmp\n[placement]\nregion_name = RegionOne\nproject_domain_name = Default\nproject_name = service\nauth_type = password\nuser_domain_name = Default\nauth_url = http://controller:5000/v3\nusername = placement\npassword = PLACEMENT_PASS\n#PLACEMENT_PASS 为 Placement 服务密码\nEOF\nsystemctl enable libvirtd.service openstack-nova-compute.service --now\n```\n\n```\nsh nova-compute.sh\n```\n\n### 验证服务\n\n操作节点[controller]\n\n```bash\nsource /root/admin-openrc\nopenstack compute service list --service nova-compute\n#当你向环境中添加新的计算节点时，确保这些新节点被加入到正确的Cell中\nsu -s /bin/sh -c \"nova-manage cell_v2 discover_hosts --verbose\" nova\n#列出服务组件，验证每个流程都成功启动和注册：\nopenstack compute service list\n#列出身份服务中的API端点，验证与身份服务的连接：\nopenstack catalog list\n#列出镜像服务中的镜像，验证与镜像服务的连接：\nopenstack image list\n#检查cells是否运作成功，以及其他必要条件是否已具备。\nnova-status upgrade check\n```\n\n![image-20241208214423919](https://i0.hdslb.com/bfs/article/16727e56c1c7a2a3e209419f940f5fcf697559838.png)\n\n![image-20241208215425973](https://i0.hdslb.com/bfs/article/cdf477ca098924d427b6d7a9380b2976697559838.png)\n\n![image-20241208215352075](https://i0.hdslb.com/bfs/article/7f18164303fde4980f34307fb17b39ed697559838.png)\n\n## Neutron\n\nNeutron是OpenStack的网络服务，提供虚拟交换机、IP路由、DHCP等功能。\n\n### controller\n\n操作节点[controller]\n\n```\ncd openstack-install\nvim neutron-controller.sh\n```\n\n```bash\n#!/bin/bash\n#创建数据库并授权\necho \"CREATE DATABASE neutron;\" | mysql -u root -pMARIADB_PASS\necho \"GRANT ALL PRIVILEGES ON neutron.* TO 'neutron'@'localhost' IDENTIFIED BY 'NEUTRON_DBPASS';\" | mysql -u root -pMARIADB_PASS\necho \"GRANT ALL PRIVILEGES ON neutron.* TO 'neutron'@'%' IDENTIFIED BY 'NEUTRON_DBPASS';\" | mysql -u root -pMARIADB_PASS\nmysql -u root -pMARIADB_PASS -e \"FLUSH PRIVILEGES;\"\n#创建neutron用户和服务\nsource /root/admin-openrc\nopenstack user create --domain default --password NEUTRON_PASS neutron\nopenstack role add --project service --user neutron admin\nopenstack service create --name neutron \\\n  --description \"OpenStack Networking\" network\n#部署 Neutron API 服务\nopenstack endpoint create --region RegionOne \\\n  network public http://controller:9696\nopenstack endpoint create --region RegionOne \\\n  network internal http://controller:9696\nopenstack endpoint create --region RegionOne \\\n  network admin http://controller:9696\n#安装软件包\ndnf install -y openstack-neutron openstack-neutron-linuxbridge ebtables ipset openstack-neutron-ml2\n#配置Neutron\nmv /etc/neutron/neutron.conf{,.bak}\ncat >/etc/neutron/neutron.conf<<\"EOF\"\n[database]\nconnection = mysql+pymysql://neutron:NEUTRON_DBPASS@controller/neutron\n\n[DEFAULT]\ncore_plugin = ml2\nservice_plugins = router\nallow_overlapping_ips = true\ntransport_url = rabbit://openstack:RABBIT_PASS@controller\nauth_strategy = keystone\nnotify_nova_on_port_status_changes = true\nnotify_nova_on_port_data_changes = true\n\n[keystone_authtoken]\nwww_authenticate_uri = http://controller:5000\nauth_url = http://controller:5000\nmemcached_servers = controller:11211\nauth_type = password\nproject_domain_name = Default\nuser_domain_name = Default\nproject_name = service\nusername = neutron\npassword = NEUTRON_PASS\n\n[nova]\nauth_url = http://controller:5000\nauth_type = password\nproject_domain_name = Default\nuser_domain_name = Default\nregion_name = RegionOne\nproject_name = service\nusername = nova\npassword = NOVA_PASS\n\n[oslo_concurrency]\nlock_path = /var/lib/neutron/tmp\n\n[experimental]\nlinuxbridge = true\nEOF\n#配置ML2，ML2具体配置可以根据用户需求自行修改，本文使用的是provider network + linuxbridge**\nmv /etc/neutron/plugins/ml2/ml2_conf.ini{,.bak}\n#修改/etc/neutron/plugins/ml2/ml2_conf.ini\ncat > /etc/neutron/plugins/ml2/ml2_conf.ini << EOF\n[ml2]\ntype_drivers = flat,vlan,vxlan\ntenant_network_types = vxlan\nmechanism_drivers = linuxbridge,l2population\nextension_drivers = port_security\n\n[ml2_type_flat]\nflat_networks = provider\n\n[ml2_type_vxlan]\nvni_ranges = 1:1000\n\n[securitygroup]\nenable_ipset = true\nEOF\n\n#修改/etc/neutron/plugins/ml2/linuxbridge_agent.ini\ncat > /etc/neutron/plugins/ml2/linuxbridge_agent.ini <<EOF\n\n[linux_bridge]\nphysical_interface_mappings = provider:ens33\n# ens33 为第一块网卡名称\n[vxlan]\nenable_vxlan = true\nlocal_ip = 192.168.48.101\nl2_population = true\n# 192.168.48.101 为控制节点的 IP\n[securitygroup]\nenable_security_group = true\nfirewall_driver = neutron.agent.linux.iptables_firewall.IptablesFirewallDriver\nEOF\n#配置Layer-3代理\nmv /etc/neutron/l3_agent.ini{,.bak}\ncat > /etc/neutron/l3_agent.ini << EOF\n[DEFAULT]\ninterface_driver = linuxbridge\nEOF\n#配置DHCP代理 \nmv /etc/neutron/dhcp_agent.ini{,.bak}\ncat > /etc/neutron/dhcp_agent.ini << EOF\n[DEFAULT]\ninterface_driver = linuxbridge\ndhcp_driver = neutron.agent.linux.dhcp.Dnsmasq\nenable_isolated_metadata = true\nEOF\n#配置metadata代理\nmv /etc/neutron/metadata_agent.ini{,.bak}\ncat >> /etc/neutron/metadata_agent.ini << EOF\n[DEFAULT]\nnova_metadata_host = controller\nmetadata_proxy_shared_secret = METADATA_SECRET\n# METADATA_SECRET 为 元数据 的密钥\nEOF\n\ncat >> /etc/nova/nova.conf << EOF\n#追加在末尾\n[neutron]\nauth_url = http://controller:5000\nauth_type = password\nproject_domain_name = default\nuser_domain_name = default\nregion_name = RegionOne\nproject_name = service\nusername = neutron\npassword = NEUTRON_PASS\nservice_metadata_proxy = true\nmetadata_proxy_shared_secret = METADATA_SECRET\n#NEUTRON_PASS  为 neutron 服务的密码\n#METADATA_SECRET 为上边设置的元数据密钥\nEOF\n#创建/etc/neutron/plugin.ini的符号链接\nln -s /etc/neutron/plugins/ml2/ml2_conf.ini /etc/neutron/plugin.ini\nsu -s /bin/sh -c \"neutron-db-manage --config-file /etc/neutron/neutron.conf --config-file /etc/neutron/plugins/ml2/ml2_conf.ini upgrade head\" neutron\nsystemctl restart openstack-nova-api\nsystemctl enable neutron-server.service neutron-linuxbridge-agent.service \\\nneutron-dhcp-agent.service neutron-metadata-agent.service neutron-l3-agent.service --now\n```\n\n```\nsh neutron-controller.sh\n```\n\n### compute\n\n操作节点[compute]\n\n```\ncd openstack-install\nvim neutron-compute.sh\n```\n\n```shell\n#!/bin/bash\ndnf install openstack-neutron-linuxbridge ebtables ipset -y\n#配置neutron\ncat >/etc/neutron/neutron.conf << \"EOF\"\n[DEFAULT]\ntransport_url = rabbit://openstack:RABBIT_PASS@controller\nauth_strategy = keystone\n\n[keystone_authtoken]\nwww_authenticate_uri = http://controller:5000\nauth_url = http://controller:5000\nmemcached_servers = controller:11211\nauth_type = password\nproject_domain_name = Default\nuser_domain_name = Default\nproject_name = service\nusername = neutron\npassword = NEUTRON_PASS\n\n[oslo_concurrency]\nlock_path = /var/lib/neutron/tmp\nEOF\n#修改/etc/neutron/plugins/ml2/linuxbridge_agent.ini\ncat > /etc/neutron/plugins/ml2/linuxbridge_agent.ini <<EOF\n\n[linux_bridge]\nphysical_interface_mappings = provider:ens33\n# ens33 为第一块网卡名称\n[vxlan]\nenable_vxlan = true\nlocal_ip = 192.168.48.102\nl2_population = true\n# 192.168.48.102 为计算节点的 IP\n[securitygroup]\nenable_security_group = true\nfirewall_driver = neutron.agent.linux.iptables_firewall.IptablesFirewallDriver\nEOF\n#配置nova compute服务使用neutron\ncat >> /etc/nova/nova.conf << EOF\n#追加在末尾\n[neutron]\nauth_url = http://controller:5000\nauth_type = password\nproject_domain_name = default\nuser_domain_name = default\nregion_name = RegionOne\nproject_name = service\nusername = neutron\npassword = NEUTRON_PASS\nservice_metadata_proxy = true\nmetadata_proxy_shared_secret = METADATA_SECRET\n#NEUTRON_PASS  为 neutron 服务的密码\n#METADATA_SECRET 为上边设置的元数据密钥\nEOF\nsystemctl restart openstack-nova-compute.service\nsystemctl enable neutron-linuxbridge-agent --now\n```\n\n```\nsh neutron-compute.sh\n```\n\n### 验证服务\n\n操作节点[controller]\n\n```\nsource admin-openrc\nopenstack network agent list\n```\n\n确保五个都是up你再做下一步\n\n![image-20241208222944410](https://i0.hdslb.com/bfs/article/a3a30d77f9e5abafb5b929f7010f1877697559838.png)\n\n## Cinder\n\nCinder是OpenStack的存储服务，提供块设备的创建、发放、备份等功能。\n\n### controller\n\n操作节点[controller]\n\n```\ncd openstack-install\nvim cinder-controller.sh\n```\n\n`my_ip = 192.168.48.101为控制节点ip`\n\n```bash\n#!/bin/bash\necho \"CREATE DATABASE cinder;\" | mysql -u root -pMARIADB_PASS\necho \"GRANT ALL PRIVILEGES ON cinder.* TO 'cinder'@'localhost' IDENTIFIED BY 'CINDER_DBPASS';\" | mysql -u root -pMARIADB_PASS\necho \"GRANT ALL PRIVILEGES ON cinder.* TO 'cinder'@'%' IDENTIFIED BY 'CINDER_DBPASS';\" | mysql -u root -pMARIADB_PASS\nmysql -u root -pMARIADB_PASS -e \"FLUSH PRIVILEGES;\"\nsource /root/admin-openrc\nopenstack user create --domain default --password CINDER_PASS cinder\nopenstack role add --project service --user cinder admin\nopenstack service create --name cinderv3 \\\n  --description \"OpenStack Block Storage\" volumev3\nopenstack endpoint create --region RegionOne \\\n  volumev3 public http://controller:8776/v3/%\\(project_id\\)s\nopenstack endpoint create --region RegionOne \\\n  volumev3 internal http://controller:8776/v3/%\\(project_id\\)s\nopenstack endpoint create --region RegionOne \\\n  volumev3 admin http://controller:8776/v3/%\\(project_id\\)s\ndnf install openstack-cinder-api openstack-cinder-scheduler -y\ncat >/etc/cinder/cinder.conf<<\"EOF\"\n[DEFAULT]\ntransport_url = rabbit://openstack:RABBIT_PASS@controller\nauth_strategy = keystone\nmy_ip = 192.168.48.101\n[database]\nconnection = mysql+pymysql://cinder:CINDER_DBPASS@controller/cinder\n[keystone_authtoken]\nwww_authenticate_uri = http://controller:5000\nauth_url = http://controller:5000\nmemcached_servers = controller:11211\nauth_type = password\nproject_domain_name = Default\nuser_domain_name = Default\nproject_name = service\nusername = cinder\npassword = CINDER_PASS\n[oslo_concurrency]\nlock_path = /var/lib/cinder/tmp\nEOF\nsu -s /bin/sh -c \"cinder-manage db sync\" cinder\ncat >> /etc/nova/nova.conf << EOF\n[cinder]\nos_region_name = RegionOne\nEOF\nsystemctl restart openstack-nova-api\nsystemctl enable openstack-cinder-api openstack-cinder-scheduler  --now\n```\n\n```\nsh cinder-controller.sh\n```\n\n### Storage\n\n关闭所有节点(运行不了，请回开头，复制关闭顺序脚本)<font color='red'>（注意关闭顺序，这里不在说明，回头看）</font>\n\n<font color='red'>操作节点[所有节点]</font>\n\n```\nsh stop.sh\n```\n\n给compute添加一块100g的磁盘\n\n![image-20241209211926972](https://i0.hdslb.com/bfs/article/87d2c3924d10efdb684d6f2dd0846fac697559838.png)\n\n`操作节点[Storage]`\n\n按照前情提要里的**Storage**节点，添加一块`新硬盘`，我这里是`/dev/sdb`\n\nCinder支持很多类型的后端存储，本指导使用最简单的lvm为参考，如果您想使用如ceph等其他后端，请自行配置。\n\n```\nmkdir openstack-install && cd openstack-install\nvim cinder-storage.sh\n```\n\n```ini\n#!/bin/bash\ndnf install lvm2 device-mapper-persistent-data scsi-target-utils rpcbind nfs-utils openstack-cinder-volume openstack-cinder-backup -y\n#配置lvm卷组\npvcreate /dev/sdb\nvgcreate cinder-volumes /dev/sdb\n# sdb 为划分给块存储使用的磁盘\n# 如有多个磁盘，则需重复以上两个命令\n\n#配置cinder\nmv /etc/cinder/cinder.conf{,.bak}\ncat >/etc/cinder/cinder.conf<<\"EOF\"\n[DEFAULT]\ntransport_url = rabbit://openstack:RABBIT_PASS@controller\nauth_strategy = keystone\nmy_ip = 192.168.0.4\nenabled_backends = lvm\nglance_api_servers = http://controller:9292\n[keystone_authtoken]\nwww_authenticate_uri = http://controller:5000\nauth_url = http://controller:5000\nmemcached_servers = controller:11211\nauth_type = password\nproject_domain_name = default\nuser_domain_name = default\nproject_name = service\nusername = cinder\npassword = CINDER_PASS\n[database]\nconnection = mysql+pymysql://cinder:CINDER_DBPASS@controller/cinder\n[lvm]\nvolume_driver = cinder.volume.drivers.lvm.LVMVolumeDriver\nvolume_group = cinder-volumes\ntarget_protocol = iscsi\ntarget_helper = lioadm\n[oslo_concurrency]\nlock_path = /var/lib/cinder/tmp\nEOF\nsystemctl enable openstack-cinder-volume target --now\n\n```\n\n```\nsh cinder-storage.sh\n```\n\n至此，Cinder服务的部署已全部完成，可以在controller通过以下命令进行简单的验证\n\n> `配置cinder backup （可选）`\n>\n> cinder-backup是可选的备份服务，cinder同样支持很多种备份后端，本文使用swift存储，如果您想使用如NFS等后端，请自行配置，例如可以参考[OpenStack官方文档](https://docs.openstack.org/cinder/2023.1/admin/nfs-backend.html)对NFS的配置说明。\n>\n> 修改`/etc/cinder/cinder.conf`，在`[DEFAULT]`中新增\n>\n> ```ini\n> [DEFAULT]\n> backup_driver = cinder.backup.drivers.swift.SwiftBackupDriver\n> backup_swift_url = SWIFT_URL\n> ```\n>\n> 这里的`SWIFT_URL`是指环境中swift服务的URL，在部署完swift服务后，执行`openstack catalog show object-store`命令获取。\n>\n> ```\n> systemctl start openstack-cinder-backup \n> ```\n\n### 验证服务\n\n操作节点[controller]\n\n```\nsource admin-openrc\nsystemctl restart httpd memcached\nopenstack volume service list\n```\n\n![image-20241208234946287](https://i0.hdslb.com/bfs/article/de4c86bdf2f44d43f1637058cf5ea496697559838.png)\n\n## Horizon\n\nHorizon是OpenStack提供的前端页面，可以让用户通过网页鼠标的操作来控制OpenStack集群，而不用繁琐的CLI命令行。Horizon一般部署在控制节点。\n\n操作节点[controller]\n\n```\ncd openstack-install\nvim horizon-controller.sh\n```\n\n```ini\ndnf install openstack-dashboard -y\ncp /etc/openstack-dashboard/local_settings{,.bak}\nsed -i 's/^ALLOWED_HOSTS/#&/' /etc/openstack-dashboard/local_settings\nsed -i 's/^OPENSTACK_HOST/#&/' /etc/openstack-dashboard/local_settings\nsed -i 's/^OPENSTACK_KEYSTONE_URL/#&/' /etc/openstack-dashboard/local_settings\nsed -i 's/^TIME_ZONE/#&/' /etc/openstack-dashboard/local_settings\ncat >>/etc/openstack-dashboard/local_settings << \"EOF\"\nOPENSTACK_HOST = \"controller\"\nALLOWED_HOSTS = ['*']\nOPENSTACK_KEYSTONE_URL =  \"http://controller:5000/v3\"\nSESSION_ENGINE = 'django.contrib.sessions.backends.cache'\nCACHES = {\n'default': {\n    'BACKEND': 'django.core.cache.backends.memcached.MemcachedCache',\n    'LOCATION': 'controller:11211',\n    }\n}\nOPENSTACK_KEYSTONE_MULTIDOMAIN_SUPPORT = True\nOPENSTACK_KEYSTONE_DEFAULT_DOMAIN = \"Default\"\nOPENSTACK_KEYSTONE_DEFAULT_ROLE = \"member\"\nWEBROOT = '/dashboard'\nTIME_ZONE = \"Asia/Shanghai\"\nPOLICY_FILES_PATH = \"/etc/openstack-dashboard\"\n\nOPENSTACK_API_VERSIONS = {\n    \"identity\": 3,\n    \"image\": 2,\n    \"volume\": 3,\n}\nEOF\nsystemctl restart httpd memcached\n```\n\n```\nsh horizon-controller.sh\n```\n\n至此，horizon服务的部署已全部完成，打开浏览器，输入`http://192.168.48.101/dashboard`，打开horizon登录页面。\n\n![image-20241209003341910](https://i0.hdslb.com/bfs/article/d075519bb58011ef9d399b85fa3cd923697559838.png)\n\n![image-20241209003519051](https://i0.hdslb.com/bfs/article/b5de3b3f3ad748374ede0379f1cdc29b697559838.png)\n\n## Swift\n\nSwift 提供了弹性可伸缩、高可用的分布式对象存储服务，适合存储大规模非结构化数据。\n\n### controller\n\n操作节点[controller]\n\n```ini\ncd openstack-install\nvim swift-controller-1.sh\n```\n\n```ini\n#!/bin/bash\n#创建服务凭证以及API端点。\n# 创建swift用户\nsource /root/admin-openrc\nopenstack user create --domain default --password SWIFT_PASS swift\n# 添加admin角色\nopenstack role add --project service --user swift admin\n# 创建对象存储服务\nopenstack service create --name swift --description \"OpenStack Object Storage\" object-store\n#创建API端点。\nopenstack endpoint create --region RegionOne object-store public http://controller:8080/v1/AUTH_%\\(project_id\\)s\nopenstack endpoint create --region RegionOne object-store internal http://controller:8080/v1/AUTH_%\\(project_id\\)s\nopenstack endpoint create --region RegionOne object-store admin http://controller:8080/v1 \n#安装Swift。\ndnf install openstack-swift-proxy python3-swiftclient \\\npython3-keystoneclient python3-keystonemiddleware memcached -y\n#配置proxy-server。\n#Swift RPM包里已经包含了一个基本可用的proxy-server.conf，只需要手动修改其中的ip（controller可以不改，看你自己需要）和SWIFT_PASS即可。\nsed -i \"s/password = swift/password = SWIFT_PASS/g\" /etc/swift/proxy-server.conf\n```\n\n```\nsh swift-controller-1.sh\n```\n\n### Storage\n\n本节点，添加了四块硬盘作为swift使用的硬盘\n\n<font color='red'>关闭所有节点，回头看物理关闭顺序</font>\n\n给<font color='red'>storage</font>添加4张硬盘，添加完之后就可以开机了\n\n![image-20241209211943192](https://i0.hdslb.com/bfs/article/27f4d5b41f470c1836a5920ed5603321697559838.png)\n\n操作节点[Storage]\n\n```\ncd openstack-install\nvim swift-storage-1.sh\n```\n\n```ini\n#!/bin/bash\ndnf install openstack-swift-account openstack-swift-container openstack-swift-object -y\ndnf install xfsprogs rsync -y \n#将sdc,sdd,sde,sdf设备格式化为XFS：\nmkfs.xfs -f /dev/sdc\nmkfs.xfs -f /dev/sdd\nmkfs.xfs -f /dev/sde\nmkfs.xfs -f /dev/sdf\n#创建安装点目录结构：\nmkdir -p /srv/node/sdc\nmkdir -p /srv/node/sdd\nmkdir -p /srv/node/sde\nmkdir -p /srv/node/sdf\n#写入自动挂载\ncat >> /etc/fstab << EOF\n/dev/sdc /srv/node/sdc xfs noatime 0 2\n/dev/sdd /srv/node/sdd xfs noatime 0 2\n/dev/sde /srv/node/sde xfs noatime 0 2\n/dev/sdf /srv/node/sdf xfs noatime 0 2\nEOF\n#挂载设备\nsystemctl daemon-reload\nmount -t xfs /dev/sdc /srv/node/sdc\nmount -t xfs /dev/sdd /srv/node/sdd\nmount -t xfs /dev/sde /srv/node/sde\nmount -t xfs /dev/sdf /srv/node/sdf\n#如果用户不需要容灾功能，以上步骤只需要创建一个设备即可，同时可以跳过下面的rsync配置。\nmv /etc/rsyncd.conf{,.bak}\ncat>/etc/rsyncd.conf<<EOF\n[DEFAULT]\nuid = swift\ngid = swift\nlog file = /var/log/rsyncd.log\npid file = /var/run/rsyncd.pid\naddress = 192.168.48.103\n#192.168.48.103为storage的ip\n[account]\nmax connections = 2\npath = /srv/node/\nread only = False\nlock file = /var/lock/account.lock\n\n[container]\nmax connections = 2\npath = /srv/node/\nread only = False\nlock file = /var/lock/container.lock\n\n[object]\nmax connections = 2\npath = /srv/node/\nread only = False\nlock file = /var/lock/object.lock\nEOF\nsystemctl enable rsyncd.service --now\n#编辑/etc/swift目录的account-server.conf、container-server.conf和object-server.conf文件，替换bind_ip为存储节点的IP地址。\nsudo sed -i 's/^bind_ip = 127\\.0\\.0\\.1$/bind_ip = 192.168.48.103/' /etc/swift/account-server.conf /etc/swift/container-server.conf /etc/swift/object-server.conf\n#确保挂载点目录结构的正确所有权。\nchown -R swift:swift /srv/node\n#创建recon目录并确保其拥有正确的所有权。\nmkdir -p /var/cache/swift\nchown -R root:swift /var/cache/swift\nchmod -R 775 /var/cache/swift\n```\n\n```\nsh swift-storage-1.sh\n```\n\n### controller\n\n操作节点[controller]\n\n```\ncd openstack-install\nvim swift-controller-2.sh\n```\n\n```ini\n#!/bin/bash\n#创建和分发初始环\n#转到/etc/swift目录。(所以操作在此目录，执行)\ncd /etc/swift\n##第一部分（6202）创建用户环\nswift-ring-builder account.builder create 10 3 1\n#将每个存储节点添加到环中。\nswift-ring-builder account.builder add \\\n   --region 1 --zone 1 --ip 192.168.48.103 \\\n   --port 6202 --device sdc --weight 100\nswift-ring-builder account.builder add \\\n   --region 1 --zone 1 --ip 192.168.48.103 \\\n   --port 6202 --device sdd --weight 100\nswift-ring-builder account.builder add \\\n   --region 1 --zone 2 --ip 192.168.48.103 \\\n   --port 6202 --device sde --weight 100\nswift-ring-builder account.builder add \\\n   --region 1 --zone 2 --ip 192.168.48.103 \\\n   --port 6202 --device sdf --weight 100\nswift-ring-builder account.builder rebalance\nswift-ring-builder account.builder\n##第二部分（6201）创建容器环\nswift-ring-builder container.builder create 10 3 1\nswift-ring-builder container.builder add \\\n   --region 1 --zone 1 --ip 192.168.48.103 \\\n   --port 6201 --device sdc --weight 100\nswift-ring-builder container.builder add \\\n   --region 1 --zone 1 --ip 192.168.48.103 \\\n   --port 6201 --device sdd --weight 100\nswift-ring-builder container.builder add \\\n   --region 1 --zone 2 --ip 192.168.48.103 \\\n   --port 6201 --device sde --weight 100\nswift-ring-builder container.builder add \\\n   --region 1 --zone 2 --ip 192.168.48.103 \\\n   --port 6201 --device sdf --weight 100\nswift-ring-builder container.builder\nswift-ring-builder container.builder rebalance\n\n##第三部分（6200）创建对象环\nswift-ring-builder object.builder create 10 3 1\nswift-ring-builder object.builder add \\\n   --region 1 --zone 1 --ip 192.168.48.103 \\\n   --port 6200 --device sdc --weight 100\nswift-ring-builder object.builder add \\\n   --region 1 --zone 1 --ip 192.168.48.103 \\\n   --port 6200 --device sdd --weight 100\nswift-ring-builder object.builder add \\\n   --region 1 --zone 2 --ip 192.168.48.103 \\\n   --port 6200 --device sde --weight 100\nswift-ring-builder object.builder add \\\n   --region 1 --zone 2 --ip 192.168.48.103 \\\n   --port 6200 --device sdf --weight 100\nswift-ring-builder object.builder\nswift-ring-builder object.builder rebalance\n#将account.ring.gz，container.ring.gz以及 object.ring.gz文件复制到每个存储节点和运行代理服务的任何其他节点上的/etc/swift目录。\nscp /etc/swift/account.ring.gz \\\n     /etc/swift/container.ring.gz \\\n     /etc/swift/object.ring.gz \\\n     192.168.48.103:/etc/swift\n\nmv  /etc/swift/swift.conf{,.bak}\ncat> /etc/swift/swift.conf<<EOF\n[swift-hash]\nswift_hash_path_suffix = swift\nswift_hash_path_prefix = swift\n[storage-policy:0]\nname = Policy-0\ndefault = yes\nEOF\n-------------------------------------------------------------------------------------\n#将控制节点的swift配置文件复制到存储节点（storage）\nsshpass -p 'Lj201840.' scp /etc/swift/swift.conf 192.168.48.103:/etc/swift\n\n#swift_hash_path_suffix和swift_hash_path_prefix作为哈希算法的一部分用于确定数据在集群中的位置。\n#这些值应该保持机密，并且在部署集群之后不能更改丢失。可自定义\n-------------------------------------------------------------------------------------\n#在所有节点确保对配置目录拥有适当的所有权：\n####存储节点与控制节点同时执行（注意！！！！两个节点同时执行）\n#操作节点[controller，storage]\n\nchown -R root:swift /etc/swift \nyum install ansible -y\ncat << EOF >> /etc/ansible/hosts\n[storage]\n192.168.48.103 ansible_user=root\nEOF\nansible storage -m command -a \"chown -R root:swift /etc/swift\" -b --become-user root\n#在控制器节点和任何其他运行代理服务的节点上，启动对象存储代理服务及其相关性，并将它们配置为在系统启动时启动(存储节点无代理服务)\n#-------------------------------------------------------------------------------------\n#重启服务(操作节点[controller]\nsystemctl enable openstack-swift-proxy.service memcached.service --now\nsystemctl restart openstack-swift-proxy.service memcached.service\n\n```\n\n```\nsh swift-controller-2.sh\n```\n\n### Storage\n\n```\ncd openstack-install\nvim swift-storage-2.sh\n```\n\n```ini\n#!/bin/bash\n#在存储节点启动所有服务\n systemctl enable openstack-swift-account.service openstack-swift-account-auditor.service \\\n  openstack-swift-account-reaper.service openstack-swift-account-replicator.service\n systemctl start openstack-swift-account.service openstack-swift-account-auditor.service \\\n  openstack-swift-account-reaper.service openstack-swift-account-replicator.service\n systemctl enable openstack-swift-container.service \\\n  openstack-swift-container-auditor.service openstack-swift-container-replicator.service \\\n  openstack-swift-container-updater.service\n systemctl start openstack-swift-container.service \\\n  openstack-swift-container-auditor.service openstack-swift-container-replicator.service \\\n  openstack-swift-container-updater.service\n systemctl enable openstack-swift-object.service openstack-swift-object-auditor.service \\\n  openstack-swift-object-replicator.service openstack-swift-object-updater.service\n systemctl start openstack-swift-object.service openstack-swift-object-auditor.service \\\n  openstack-swift-object-replicator.service openstack-swift-object-updater.service\nyum install ansible -y\ncat << EOF >> /etc/ansible/hosts\n[controller]\n192.168.48.101 ansible_user=root\nEOF\nansible controller -m command -a \"systemctl restart httpd memcached\" -b --become-user root\nansible controller -m command -a \"systemctl restart openstack-nova*\" -b --become-user root\n```\n\n```\nsh swift-storage-2.sh\n```\n\n### 验证\n\n操作节点[controller]\n\n```\nsource /root/admin-openrc\ncd /etc/swift\nswift stat\n[root@controller swift]# swift stat\n               Account: AUTH_07a1ce96dca54f1bb0d3b968f1343617\n            Containers: 0\n               Objects: 0\n                 Bytes: 0\n       X-Put-Timestamp: 1684919814.32783\n           X-Timestamp: 1684919814.32783\n            X-Trans-Id: txd6f3affa0140455b935ff-00646dd605\n          Content-Type: text/plain; charset=utf-8\nX-Openstack-Request-Id: txd6f3affa0140455b935ff-00646dd605\n\n#测试上传镜像\n[root@controller swift]# cd\n[root@controller ~]# swift upload demo /root/openstack-install/iso/cirros-0.4.0-x86_64-disk.img --object-name image\nimage\n```\n\n## Heat\n\nHeat是 OpenStack 自动编排服务，基于描述性的模板来编排复合云应用，也称为`Orchestration Service`。Heat 的各服务一般安装在`Controller`节点上。\n\n操作节点[controller]\n\n```\ncd openstack-install\nvim heat-controller.sh\n```\n\n```ini\n#！/bin/bash\necho \"CREATE DATABASE heat;\" | mysql -u root -pMARIADB_PASS\necho \"GRANT ALL PRIVILEGES ON heat.* TO 'heat'@'localhost' IDENTIFIED BY 'HEAT_DBPASS';\" | mysql -u root -pMARIADB_PASS\necho \"GRANT ALL PRIVILEGES ON heat.* TO 'heat'@'%' IDENTIFIED BY 'HEAT_DBPASS';\" | mysql -u root -pMARIADB_PASS\nmysql -u root -pMARIADB_PASS -e \"FLUSH PRIVILEGES;\"\nsource /root/admin-openrc\n#创建heat用户\nopenstack user create --domain default --password HEAT_PASS heat\n#添加 admin 角色到 heat 用户上\nopenstack role add --project service --user heat admin\n##创建heat和 heat-cfn 服务实体\nopenstack service create --name heat \\\n  --description \"Orchestration\" orchestration\nopenstack service create --name heat-cfn \\\n  --description \"Orchestration\"  cloudformation  \n##创建 Orchestration 服务的 API 端点\nopenstack endpoint create --region RegionOne \\\n  orchestration public http://controller:8004/v1/%\\(tenant_id\\)s\nopenstack endpoint create --region RegionOne \\\n  orchestration internal http://controller:8004/v1/%\\(tenant_id\\)s\nopenstack endpoint create --region RegionOne \\\n  orchestration admin http://controller:8004/v1/%\\(tenant_id\\)s\n\nopenstack endpoint create --region RegionOne \\\n  cloudformation public http://controller:8000/v1\nopenstack endpoint create --region RegionOne \\\n  cloudformation internal http://controller:8000/v1\nopenstack endpoint create --region RegionOne \\\n  cloudformation admin http://controller:8000/v1\n  #创建stack管理的额外信息\n  #创建 heat domain\n  #控制节点\n#为栈创建 heat 包含项目和用户的域\nopenstack domain create --description \"Stack projects and users\" heat\n\n#在 heat 域中创建管理项目和用户的heat_domain_admin用户：\nopenstack user create --domain heat --password=HEAT_DOMAIN_USER_PASS heat_domain_admin\n\n#)添加admin角色到 heat 域 中的heat_domain_admin用户，启用heat_domain_admin用户#管理栈的管理权限\nopenstack role add --domain heat --user-domain heat --user heat_domain_admin admin\n\n#为栈创建 heat 包含项目和用户的域\nopenstack role create heat_stack_owner\n\n#添加heat_stack_owner 角色到demo 项目和用户，启用demo 用户管理栈。\nopenstack role add --project demo --user demo heat_stack_owner\n#必须添加 heat_stack_owner 角色到每个管理栈的用户。\n\n#heat_stack_user 角色\nopenstack role create heat_stack_user\ndnf install openstack-heat-api openstack-heat-api-cfn openstack-heat-engine -y\n\nmv /etc/heat/heat.conf{,.bak}\ncat > /etc/heat/heat.conf << EOF\n[database]\nconnection = mysql+pymysql://heat:HEAT_DBPASS@controller/heat  \n#HEAT_DBPASS是HEAT数据库密码\n[DEFAULT]\ntransport_url = rabbit://openstack:RABBIT_PASS@controller\nheat_metadata_server_url = http://controller:8000\nheat_waitcondition_server_url = http://controller:8000/v1/waitcondition\nstack_domain_admin = heat_domain_admin\nstack_domain_admin_password = HEAT_DOMAIN_PASS\nstack_user_domain_name = heat\n#RABBIT_PASS为Rabbitmq服务密码 用户名是openstack\n[keystone_authtoken]\nwww_authenticate_uri = http://controller:5000\nauth_url = http://controller:5000\nmemcached_servers = controller:11211\nauth_type = password\nproject_domain_name = default\nuser_domain_name = default\nproject_name = service\nusername = heat\npassword = HEAT_PASS\n#HEAT_PASS是heat用户密码\n[trustee]\nauth_type = password\nauth_url = http://controller:5000\nusername = heat\npassword = HEAT_PASS\n#HEAT_PASS是heat用户密码\nuser_domain_name = default\n[clients_keystone]\nauth_uri = http://controller:5000\nEOF\n\nsu -s /bin/sh -c \"heat-manage db_sync\" heat\n##启动 Orchestration 编排服务heat组件并将其设置为随系统启动\nsystemctl enable openstack-heat-api.service \\\n  openstack-heat-api-cfn.service openstack-heat-engine.service --now\n\nsystemctl restart openstack-heat-api.service \\\n  openstack-heat-api-cfn.service openstack-heat-engine.service\nsystemctl restart httpd memcached\n```\n\n```\nsh heat-controller.sh\n```\n\n验证\n\n```bash\nsource /root/admin-openrc\nsystemctl list-unit-files |grep openstack-heat*\nopenstack service list\nopenstack orchestration service list\n#该输出显示表明在控制节点上有应该四个heat-engine组件。该输出显示表明在控制节点上有应该四个heat-engine组件。\n```\n\n![image-20241209213416843](https://i0.hdslb.com/bfs/article/9514b588eb3d45443e2c00ad67ef4be8697559838.png)\n\n## 创建实例\n\n### 创建实例类型\n\n左侧选择管理员，点击计算，点击实例类型，右侧点击创建实例类型。\n\n![image-20240106230035149](https://i0.hdslb.com/bfs/article/31a02695e61aa72b806624303faa117f697559838.png)\n\n根据以上图片步骤依次填入：实例名称、VCPU数量、内存大小、根磁盘大小，确认无误后点击创建实例类型。\n\n### 创建镜像\n\n测试镜像：https://download.cirros-cloud.net/0.6.2/cirros-0.6.2-x86_64-disk.img\n\n<font color='red'>有两种上传方式（二选一）！！！</font>\n\n<font color='red'>1.Windows上传镜像方式</font>\n\n左侧选择管理员，点击计算，点击镜像，右侧点击创建镜像。\n\nWindows下载到本地即可\n\n![image-20240106230649633](https://i0.hdslb.com/bfs/article/f7578d6c654e573a00ad4205cc93ad90697559838.png)\n\n根据以上图片步骤依次填入：镜像名称、选择文件、镜像格式，确认无误后点击创建镜像。\n**注**：演示上传的 img 镜像格式需选用 QCOW2 - QEMU模拟器 才可正常加载。\n\n\n\n<font color='red'>2.Linux上传镜像方式</font>\n\n```\nsource admin-openrc\nwget https://download.cirros-cloud.net/0.6.2/cirros-0.6.2-x86_64-disk.img\n#可能会下载不到，可以复制链接到浏览器下载，然后移到/root/目录下\nglance image-create --name \"cirros\" \\\n  --file cirros-0.6.2-x86_64-disk.img \\\n  --disk-format qcow2 --container-format bare \\\n  --visibility=public\n\nopenstack image list\n\n[root@controller-1 ~]# openstack image list\n+--------------------------------------+--------+--------+\n| ID                                   | Name   | Status |\n+--------------------------------------+--------+--------+\n| 627761da-7f8c-4780-842a-e50e62f5c464 | cirros | active |\n+--------------------------------------+--------+--------+\n\n```\n\n### 创建内部网络\n\n左侧选择管理员，点击网络，点击网络，右侧点击创建网络。\n\n![image-20240106231124036](https://i0.hdslb.com/bfs/article/da09616a700395a6a6b0a877b21881a8697559838.png)\n\n![image-20240106231151367](https://i0.hdslb.com/bfs/article/346ecd635cac54617bca36b5094b51f1697559838.png)\n\n![image-20240106231323081](https://i0.hdslb.com/bfs/article/deaf52e986c04953e5f8a7d5a22ce293697559838.png)\n\n### 创建外部网络\n\n左侧选择管理员，点击网络，点击网络，右侧点击创建网络。\n\n<font color='red'>如果你是按照本文档搭建的，就填provider</font>\n\n![image-20240106231633793](https://i0.hdslb.com/bfs/article/caf436ffce78df4fa7a353c5acd0fd5a697559838.png)\n\n![image-20240106231854446](https://i0.hdslb.com/bfs/article/0f81a174f4be20a69836af42df878d6a697559838.png)\n\n![image-20240106232011057](https://i0.hdslb.com/bfs/article/3a29278808500fb7c038b2e24e3dc6a1697559838.png)\n\n### 创建路由\n\n左侧选择管理员，点击网络，点击路由，右侧点击创建路由。\n\n![image-20240106232138022](https://i0.hdslb.com/bfs/article/c5558e4990fef2d297f7c07ff6f51b23697559838.png)\n\n\n\n![image-20240106232201129](https://i0.hdslb.com/bfs/article/f93314ea12af0e1102e58d94ffbb9a05697559838.png)\n\n![image-20240106232242376](https://i0.hdslb.com/bfs/article/11f7bdd637060c4a48d01388782f508f697559838.png)\n\n### 添加安全组规则\n\n![image-20240106232342515](https://i0.hdslb.com/bfs/article/16c7efc7747cd2934ae9ec777de4662e697559838.png)\n\n![image-20240106232725982](https://i0.hdslb.com/bfs/article/ded540227dcbc19e9f05c82c68984be9697559838.png)\n\n最后效果长这样\n\n![image-20240106232758711](https://i0.hdslb.com/bfs/article/cf4db72bfde7068dfb912d6470b70148697559838.png)\n\n### 创建实例\n\n![image-20240106232939110](https://i0.hdslb.com/bfs/article/c3a1fab81557f5fa7a121a9098b1b3fa697559838.png)\n\n![image-20240106233038731](https://i0.hdslb.com/bfs/article/fb99edf0005108a2cbc1071f583039d9697559838.png)\n\n![image-20240106233101509](https://i0.hdslb.com/bfs/article/ecdcc6fd8b07e6fcf2b6fa84ade65f33697559838.png)\n\n![image-20240106233129659](https://i0.hdslb.com/bfs/article/3be68c8a12b638ba19d720e8e8549712697559838.png)\n\n然后点击创建实例\n\n分配浮动ip\n\n![image-20240106233251169](https://i0.hdslb.com/bfs/article/7e2458b0235855e76d263700ed3b2dc8697559838.png)\n\n![image-20240106233418787](https://i0.hdslb.com/bfs/article/6b4d2468dd370387a38a85e513577cdd697559838.png)\n\n<font color='red'>结论：创建实例成功</font>\n\n<div class=\"tbsm\" style=\"margin-top:54px;\">\n<div class=\"tbsm-top\"><span><svg t=\"1674654360507\" class=\"icon\" viewBox=\"0 0 1024 1024\" version=\"1.1\" xmlns=\"http://www.w3.org/2000/svg\" p-id=\"987\" data-spm-anchor-id=\"a313x.7781069.0.i0\" width=\"35\" height=\"35\"><path d=\"M410.49 97.74H155.08a56.74 56.74 0 0 0-56.84 56.73V410a56.84 56.84 0 0 0 56.84 56.84h255.41A56.83 56.83 0 0 0 467.32 410V154.58a56.83 56.83 0 0 0-56.83-56.84zM410.49 558.74H155.08a56.74 56.74 0 0 0-56.84 56.73V871a56.84 56.84 0 0 0 56.84 56.84h255.41A56.83 56.83 0 0 0 467.32 871V615.58a56.83 56.83 0 0 0-56.83-56.84zM871.49 558.74H616.08a56.74 56.74 0 0 0-56.84 56.73V871a56.84 56.84 0 0 0 56.84 56.84h255.41A56.83 56.83 0 0 0 928.32 871V615.58a56.83 56.83 0 0 0-56.83-56.84z\" fill=\"#66EEFF\" p-id=\"988\"></path><path d=\"M410.49 558.74h-4.14A475 475 0 0 0 299.52 859.6a481.16 481.16 0 0 0 4.84 68.22h106.13A56.83 56.83 0 0 0 467.32 871V615.58a56.83 56.83 0 0 0-56.83-56.84zM871.49 558.74H616.08a56.74 56.74 0 0 0-56.84 56.73V871a56.84 56.84 0 0 0 56.84 56.84h255.41A56.83 56.83 0 0 0 928.32 871V615.58a56.83 56.83 0 0 0-56.83-56.84z\" fill=\"#C2F8FF\" p-id=\"989\"></path></svg></span><span style=\"font-size:30px;\"> 特别声明</span></div>\n<div class=\"tbsm-wz\">千屹博客旗下的所有文章，是通过本人课堂学习和课外自学所精心整理的知识巨著<br/>难免会有出错的地方<br/>如果细心的你发现了小失误，可以在下方评论区告诉我，或者私信我！<br />非常感谢大家的热烈支持！</div>\n</div>\n","tags":["OpenEuler","OpenStack"],"categories":["云原生"]},{"title":"Nginx入门笔记","url":"/posts/c0d89ad/","content":"\n<meta name=\"referrer\" content=\"no-referrer\"/>\n\n# Nginx入门笔记\n\n## Nginx介绍\n\nNginx是一个高性能的HTTP、反向代理服务器\n\n主要功能：\n\n- 反向代理\n- 实现集群和负载均衡\n- 静态资源虚拟化\n\nNginx的版本：\n\n- Nginx开源版 http://nginx.org/en/\n\n  官方原始的Nginx版本\n\n- Nginx plus商业版\n\n  开箱即用，集成了大量功能\n\n- Open Resty https://openresty.org/cn/\n\n  OpenResty是一个基于Nginx与 Lua 的高性能 Web 平台，其内部集成了大量精良的 Lua 库、第三方模块以及大多数的依赖项。**更适用于需要大量二次开发的场景，有极强的扩展性**\n\n- Tengine https://tengine.taobao.org/\n\n  由淘宝网发起的Web服务器项目。它在[Nginx](../img/http://nginx.org/)的基础上，针对大访问量网站的需求，添加了很多高级功能和特性。Tengine的性能和稳定性已经在大型的网站如[淘宝网](../img/http://www.taobao.com/)，[天猫商城](../img/http://www.tmall.com/)等得到了很好的检验。相比于Open Resty，扩展性不够强，但是能够满足绝多数使用场景\n\n## 什么是代理\n\n正向代理\n\n正向代理可以理解为「客户端」的代理\n\n![image-20241123005914731](../img/Nginx%EF%BC%9A%E4%BB%8E%E5%85%A5%E9%97%A8%E5%88%B0%E7%B2%BE%E9%80%9A/c116df24e7f9f8c6918c5ebec8502f41697559838.png)\n\n**反向代理**\n\n反向代理可以理解为「服务器」的代理\n\n![image-20241123010005591](../img/Nginx%EF%BC%9A%E4%BB%8E%E5%85%A5%E9%97%A8%E5%88%B0%E7%B2%BE%E9%80%9A/899292a6b0aa16ad51cbd09b4baf69ef697559838.png)\n\n## Nginx安装\n\n以下有两种方式，按需选择，编译会慢一点，但是可以离线安装，不需要从网络下载所需的包，Rpm安装全部安装都需要网络。两个都差不多<font color='red'>（我接下来测试全部用编译安装）</font>\n\n### 编译安装\n\n不限制;Linux系统\n\n这里我就用<font color='red'>OpenEuler22.03LTS</font>做演示，命令都和CentOS差不多，不做过多解释\n\n1.安装必要工具\n\n```bash\nyum install -y tar gcc make pcre pcre-devel zlib zlib-devel openssl openssl-devel\n```\n\n2.下载源码包\n\n官网：[nginx: download](https://nginx.org/en/download.html)\n\n![image-20241122231106092](../img/Nginx%EF%BC%9A%E4%BB%8E%E5%85%A5%E9%97%A8%E5%88%B0%E7%B2%BE%E9%80%9A/580cb024ffb5db3c1f204000c89c9ce8697559838.png)\n\n你可以右键复制链接在虚拟机下载\n\n```\nwget https://nginx.org/download/nginx-1.26.2.tar.gz\n```\n\n也可以直接点击红色框框的下载下来然后上传到虚拟机（root用户一般都上传到/root）去\n\n![image-20241122231808602](../img/Nginx%EF%BC%9A%E4%BB%8E%E5%85%A5%E9%97%A8%E5%88%B0%E7%B2%BE%E9%80%9A/7869f6ff8b1d460f71f41fbf4b85f131697559838.png)\n\n3.创建nginx安装目录并解压安装包\n\n```bash\nmkdir -p /etc/nginx/\n#解压并移动到/app/nginx\ntar -zxf nginx-1.26.2.tar.gz\n#进入安装目录\ncd nginx-1.26.2\n# 配置nginx安装路径\n./configure --prefix=/etc/nginx/\n# 编译&&安装\nmake && make install\n```\n\n4.设置守护进程实现自启动\n\n```bash\ncat > /etc/systemd/system/nginx.service <<\"EOF\"\n[Unit]\nDescription=nginx\nAfter=network.target remote-fs.target nss-ookup.target\n\n[Service]\nType=forking\nPIDFile=/etc/nginx/logs/nginx.pid\nExecStartPre=/etc/nginx/sbin/nginx -t -c /etc/nginx/conf/nginx.conf\nExecStart=/etc/nginx/sbin/nginx -c /etc/nginx/conf/nginx.conf\nExecReload=/etc/nginx/sbin/nginx -s reload\nExecStop=/etc/nginx/sbin/nginx -s stop\nExecQuit=/etc/nginx/sbin/nginx -s quit\nPrivateTmp=true\n\n[Install]\nWantedBy=multi-user.target\nEOF\n# 重载配置\nsystemctl daemon-reload\n# 加入自启\nsystemctl enable nginx\n# 启动nginx\nsystemctl start nginx\n\n\n#将nginx可执行文件添加到$PATH，这样才能全局使用nginx命令\ncat >> /etc/profile << \"EOF\"\nexport PATH=$PATH:/etc/nginx/sbin\nEOF\nsource /etc/profile\n```\n\n5.访问测试页\n\n访问你虚拟机的ip就行\n\n![image-20241123000006823](../img/Nginx%EF%BC%9A%E4%BB%8E%E5%85%A5%E9%97%A8%E5%88%B0%E7%B2%BE%E9%80%9A/87529991daa95c5b5e5a4261e7ffd235697559838.png)\n\n\n\n到这编译版nginx安装成功\n\n普及一下nginx命令：\n\n`systemctl start nginx` 启动nginx\n\n`nginx -s reload` 重载nginx\n\n### RPM安装\n\n有两个系统的教程，我下面有标注\n\n官网文档：[nginx: Linux packages](https://nginx.org/en/linux_packages.html)\n\n![image-20241123000502440](../img/Nginx%EF%BC%9A%E4%BB%8E%E5%85%A5%E9%97%A8%E5%88%B0%E7%B2%BE%E9%80%9A/a42764bd1d0c8bcecd5ab7c714610307697559838.png)\n\n`Centos7或Centos8`\n\n```bash\nyum install yum-utils -y\n#添加nginx源\ncat >/etc/yum.repos.d/nginx.repo << \"EOF\"\n[nginx-stable]\nname=nginx stable repo\nbaseurl=http://nginx.org/packages/centos/$releasever/$basearch/\ngpgcheck=1\nenabled=1\ngpgkey=https://nginx.org/keys/nginx_signing.key\nmodule_hotfixes=true\n\n[nginx-mainline]\nname=nginx mainline repo\nbaseurl=http://nginx.org/packages/mainline/centos/$releasever/$basearch/\ngpgcheck=1\nenabled=0\ngpgkey=https://nginx.org/keys/nginx_signing.key\nmodule_hotfixes=true\nEOF\nyum install nginx -y\nsystemctl enable nginx --now\n```\n\n\n\n`OpenEuler系统`\n\n因为没有适配openeuler的版本，这里直接用centos8的来代替，兼容的没关系，你可以根据你的系统去自行替换\n\n原本是\\$releasever的，但是没有`openeuler`的版本直接用8来代替也就是centos8，`openeuler兼容centos`\n\n```bash\ncat >/etc/yum.repos.d/nginx.repo << \"EOF\"\n[nginx-stable]\nname=nginx stable repo\n#baseurl=http://nginx.org/packages/centos/$releasever/$basearch/\nbaseurl=http://nginx.org/packages/centos/8/$basearch/\ngpgcheck=1\nenabled=1\ngpgkey=https://nginx.org/keys/nginx_signing.key\nmodule_hotfixes=true\n[nginx-mainline]\nname=nginx mainline repo\n#baseurl=http://nginx.org/packages/mainline/centos/$releasever/$basearch/\nbaseurl=http://nginx.org/packages/mainline/centos/8/$basearch/\ngpgcheck=1\nenabled=0\ngpgkey=https://nginx.org/keys/nginx_signing.key\nmodule_hotfixes=true\nEOF\nyum install nginx -y\nsystemctl enable nginx --now\n```\n\n访问测试页\n\n访问你虚拟机的ip就行\n\n![image-20241123000006823](../img/Nginx%EF%BC%9A%E4%BB%8E%E5%85%A5%E9%97%A8%E5%88%B0%E7%B2%BE%E9%80%9A/87529991daa95c5b5e5a4261e7ffd235697559838.png)\n\n### 关闭防火墙\n\n```\nsystemctl disable firewalld &> /dev/null\nsystemctl stop firewalld\nsed -i \"s#SELINUX=enforcing#SELINUX=disabled#g\" /etc/selinux/config\nsetenforce 0\n#重启服务器\nreboot\n```\n\n## Nginx目录\n\n![image-20241123010256150](../img/Nginx%EF%BC%9A%E4%BB%8E%E5%85%A5%E9%97%A8%E5%88%B0%E7%B2%BE%E9%80%9A/47f2615f3de2a93e9c9b5109fde01e77697559838.png)\n\n```\nconf #配置文件\n\t｜-nginx.conf # 主配置文件\n\t｜-其他配置文件 # 可通过那个include关键字，引入到了nginx.conf生效\n\t\nhtml #静态页面\n\nlogs（默认不是放在这里，可以在配置文件中修改为这里）\n\t｜-access.log #访问日志(每次访问都会记录)\n\t｜-error.log #错误日志\n\t｜-nginx.pid #进程号\n\t\nsbin\n\t｜-nginx #主进程文件\n\t\n*_temp #运行时，生成临时文件\n```\n\n## Nginx进程模型\n\n一个Master：监听请求，并分配worker进程处理\n\n默认一个worker进程（可以在配置文件中修改worker数量）：处理客户端请求\n\n![image-20241123010359608](../img/Nginx%EF%BC%9A%E4%BB%8E%E5%85%A5%E9%97%A8%E5%88%B0%E7%B2%BE%E9%80%9A/2eba1a00c5ff87d3be9fd32dc200ae69697559838.png)\n\n每个worker之间彼此独立，每一个worker处理多个请求\n\n![image-20241123010441249](../img/Nginx%EF%BC%9A%E4%BB%8E%E5%85%A5%E9%97%A8%E5%88%B0%E7%B2%BE%E9%80%9A/5f12722e2bf72c4351938dca90f8db9a697559838.png)\n\n## Nginx配置文件\n\n[Nginx配置生成工具](https://www.digitalocean.com/community/tools/nginx?global.app.lang=zhCN)\n\n### nginx.conf默认配置文件\n\n这是nginx默认的配置文件\n\n展示部分核心配置，后续更多配置会在后面进行慢慢升华\n\n```bash\n[root@localtion ~]# vim /etc/nginx/conf/nginx.conf\n# Nginx 主配置文件\n# master进程会启动worker进程，该选项设置在系统中显示启动该进程的用户名（一般不改动，默认nobody）\n# user nobody\n# 设置工作进程的数量，通常设置为自动或与CPU核心数相同\nworker_processes  1;     #默认为1，表示开启一个业务进程\n\n# 错误日志放置的路径 notice、info是错误日志的级别，比如：info就是日志级别大于info才生成日志\n# 默认地址为/var/log/nginx/error.log ，可通过nginx -V返回的--eror-log-path字段获取实际值\n#error_log  logs/error.log;\n#error_log  logs/error.log  notice;\n#error_log  logs/error.log  info;\n\n# pid文件存放路径,默认：/var/run/nginx/nginx.pid，可通过nginx -V返回的--pid-path字段获取实际值\n#pid        logs/nginx.pid;\n\n# 事件驱动模块配置\nevents {\n    # 每个工作进程的最大连接数\n    worker_connections  1024;   # 单个业务进程可接受连接数\n}\n\n# HTTP 模块配置\nhttp {\n    # 引入 mime.types 文件，用于定义文件扩展名与MIME类型的映射关系\n    include       mime.types;  \n    # 默认MIME类型，当请求的文件类型不在mime.types中定义时使用\n    default_type  application/octet-stream;\n    \n     # 访问日志格式\n    #log_format  main  '$remote_addr - $remote_user [$time_local] \"$request\" '\n    #                  '$status $body_bytes_sent \"$http_referer\" '\n    #                  '\"$http_user_agent\" \"$http_x_forwarded_for\"';\n\n    # 访问日志地址，默认：/var/log/nginx/access.log，可通过nginx -V返回的--http-log-path字段获取实际值\n    #access_log  logs/access.log  main;\n\n    \n    # 是否开启sendfile传输文件，开启可以提高效率\n    sendfile        on;   \n    # 连接超时时间\n    keepalive_timeout  65;\n\n    # 服务器模块配置\n    server {\n        # 监听80端口\n        listen       80;\n        # 服务器名称\n        server_name  localhost;  #可以设置主机名和域名\n        # 根目录配置\n        location / {\n            root   html; # 设置网站根目录\n            index  index.html index.htm; # 默认首页文件\n        }\n        # 错误页面配置\n        error_page   500 502 503 504  /50x.html;\n        # 定义50x.html错误页面的位置\n        location = /50x.html {\n            root   html;\n        }\n    }\n}\n```\n\n刚刚访问安装成功后的测试页\n\n测试有的index文件在/etc/nginx/html/index.html\n\n一般所有的网页的文件都放在nginx安装目录下的html下\n\n这里nginx的根目录`/`，监听的端口是80\n\n> ```bash\n>     location / {\n>         root   html; # 设置网站根目录\n>         index  index.html index.htm; # 默认首页文件\n>     } # 根目录配置\n>         location / {\n>             root   html; # 设置网站根目录\n>             index  index.html index.htm; # 默认首页文件\n>         }\n> ```\n\n每次修改配置文件要重载配置\n\n```\nnginx -s reload\n```\n\n### sendfile配置\n\n在高负载情况下，启用Nginx的sendfile功能可以减少CPU和内存的使用，提高服务器性能，因为它允许数据直接从磁盘传输到网络，无需先加载到Nginx的内存中。这不仅降低了CPU使用率，还减少了内存占用，从而提高了I/O效率和服务器的吞吐量，并且降低了响应延迟。\n\n```\nhttp{\n\tsendfile:on # off\n}\n\n# 或者指定某个server开启\nserver {\n    location / {\n        sendfile on;\n        ...\n    }\n}\n```\n\n![image-20241123015101492](../img/Nginx%EF%BC%9A%E4%BB%8E%E5%85%A5%E9%97%A8%E5%88%B0%E7%B2%BE%E9%80%9A/c05595dddd92c8f886d7edb1a86a1459697559838.png)\n\n### gzip配置\n\n```yaml\nhttp{\n   gzip on; # 开启压缩，压缩后发送给客户端\n\tgzip_min_length 1;# 设置最小压缩下限。1就是小于1字节的文件不压缩\n\tgzip_comp_level 3 # 压缩级别0-9，值越大文件就压缩的越小，相应的会损耗更多性能\n\tgzip_type text/plain application/javascript image/* # 指定哪些 MIME 类型，开启压缩（不写默认全部），可以使用通配符 image/* 就是所有图片。具体哪些类型可以看conf/mime.types文件\n}\n```\n\nnginx 中的 gzip 压缩分为动态压缩、静态压缩\n\n- 动态压缩：服务器给客户端返回响应时，消耗自身的资源进行实时压缩，保证客户端拿到 gzip 格式的文件\n\n  gzip on开启的就是动态压缩，gzip_comp_level设置的级别高，可能会造成CPU占用过高（文章：[简单一招竟把nginx服务器性能提升50倍](https://www.toutiao.com/article/7329343713828897280/?app=news_article&timestamp=1707783801&use_new_style=1&req_id=202402130823202F9A6100389685E57A11&group_id=7329343713828897280&share_token=F2E89DA7-CC1F-4AAC-9BCC-A82B8020A9D6&tt_from=weixin&utm_source=weixin&utm_medium=toutiao_ios&utm_campaign=client_share&wxshare_count=1&source=m_redirect)）\n\n- 静态压缩：直接将预先压缩过的 .gz 文件返回给客户端，不再实时压缩文件，如果找不到 .gz 文件，会使用对应的原始文件\n\n  该功能需要模块： `ngx_http_gzip_static_module`（默认不会被构建）\n\n  我们可以通过下面命令查看，当前安装的是否包含该模块\n\n我们可以通过下面命令查看，当前安装的是否包含该模块\n\n```\nnginx -V\n```\n\n![image-20241123155117730](../img/Nginx%EF%BC%9A%E4%BB%8E%E5%85%A5%E9%97%A8%E5%88%B0%E7%B2%BE%E9%80%9A/8ef963f00a9b45cfe1d7c4630613f286697559838.png)\n\n如若没有，则要重新编译：\n\n```bash\ncd nginx-1.26.2/\n./configure --prefix=/etc/nginx --with-http_gzip_static_module\n# 指定编译配置，这个参数安装模块`ngx_http_gzip_static_module` 一定要指定你的安装目录\nmake \n# 编译\nmake install \n# 安装\n```\n\n启用以下配置\n\n```\nhttp {\n    gzip  on;\n}\n```\n\n记得重载配置\n\n```\nnginx -s reload\n```\n\n### Server配置\n\n虚拟主机配置（可以启用多个），多个server字段，会根据请求的域名+端口从前向后匹配\n\n以下是例子：\n\n如果是公网：qianyios.top这个域名要解析到这个这个服务器的公网ip\n\n如果是内网：这个域名要在本机进行hosts匹配映射`ip qianyios.top`\n\n```bash\nhttp {\n......\n    # 虚拟主机(相当于一样站点)\n    server {\n        # 监听80端口\n        listen       80;\n        # 服务器名称\n        #server_name  *.qianyios.top; 当你配置了通配符域名，就是不管你是www.qianyios.top还是xxx.qianyios.top,等各种前缀都能访问到这里\n        \n        server_name  qianyios.top;  #可以设置主机名和域名，如果有多个，用空格隔开，支持通配符\n        #访问的时候就是域名+端口就可以访问到这个server下的网站\n        \n        #我会在这里插入例子，下面我会展示例子！！！\n    }\n}\n```\n\n【`例子1`】当访问`http://qianyios.top:80`就会访问以下页面（也就是nginx欢迎页），这里只是例子，你可以根据你自己情况匹配\n\n`/`  这个路径很特殊，只要用户访问的地址qianyios.top:80后面没有加什么被其他location定位到的话都会来到这个\n\n```bash\nhttp {\n......\n    server {\n        listen       80;\n        server_name  qianyios.top; \n        location / {\n            root   html; # 设置网站根目录\n            index  index.html index.htm; # 默认首页文件\n            #当访问的时候会在nginx目录下的html/下寻找index.html index.htm;\n        }\n }\n```\n\n\n\n【`例子2`】当访问`http://qianyios.top:80/abc/`就会访问以下页面，一个server可以存在多个location，但是其定位的路径不要出现相同的位置。比如：有两个`location /abc{内容}`\n\n注意有两个误区\n\n①如果root是/home 这里`实际访问路径`是`/home`/abc/index.html\n\n②如果root是/home/abc 这里`实际访问路径`是`/home/abc`/abc/index.html\n\n其实root的功能就是将qianyios.top:80定义为root（网站根目录），然后访问地址后面的/abc就会加在实际访问路径里\n\n```bash\nhttp {\n......\n    server {\n        listen       80;\n        server_name  qianyios.top; \n         location / {\n            root   html; # 设置网站根目录\n            index  index.html index.htm; # 默认首页文件\n            #当访问的时候会在nginx目录下的html/下寻找index.html index.htm;\n        }\n        \n        \n        location /abc {\n        #这个/abc下的网站根目录可以不用在nginx目录下，你可以定义其他位置\n            root   /home; # 设置定位/abc站点以/home为网站根目录\n            index  index.html index.htm; # 默认首页文件\n            #当访问的时候会在/home目录下寻找index.html index.htm;\n        }\n }\n```\n\n![image-20241123170434381](../img/Nginx%EF%BC%9A%E4%BB%8E%E5%85%A5%E9%97%A8%E5%88%B0%E7%B2%BE%E9%80%9A/577916afe2be2c88b14ae9378c9fc1af697559838.png)\n\n```\nmkdir /home/abc\necho \"welccome to /home/abc\" >> /home/abc/index.html\nnginx -s reload\nhttp://qianyios.top:80/abc\n```\n\n这里又会有两个报错\n\n![image-20241123183422466](../img/Nginx%EF%BC%9A%E4%BB%8E%E5%85%A5%E9%97%A8%E5%88%B0%E7%B2%BE%E9%80%9A/5873d1b533412e5d3a4e7a9bcb12c70b697559838.png)\n\n我们要去找index.html文件只有像以下输入命令才会能找得到\n\n```\n[root@localtion ~]# ls /home/abc/\nindex.html\n```\n\n如果你只是访问`http://qianyios.top:80/abc`实际访问路径是/home/abc，但是我认为nginx会因为abc是个文件，我们本身的目的就是要去abc下去找index.html,所以最后要加个`/`\n\n但是呢在宿主机的浏览器实际访问地址是`http://192.168.48.101/abc`（这里是我的宿主机，我没做hosts映射，我就用ip了，我只在虚拟机做了映射一样的。）注意，这里我最后没加斜杠它自动给我加上了。\n\n![image-20241123182819923](../img/Nginx%EF%BC%9A%E4%BB%8E%E5%85%A5%E9%97%A8%E5%88%B0%E7%B2%BE%E9%80%9A/e7d01edd407e19c7f16c0cd2da09cdb7697559838.png)\n\n总结：我搞不懂两者怎么回事，可能linux不会自动加上吧，浏览器会，就是说如果在虚拟机访问要加`/`。为了规范就是不管在哪都在配置文件加上末尾的斜杠\n\n\n\n【`例子3`】\n\n一般静态文件会用alias,比如说/var/www/images/下有个图片\n\n![image-20241123185235133](../img/Nginx%EF%BC%9A%E4%BB%8E%E5%85%A5%E9%97%A8%E5%88%B0%E7%B2%BE%E9%80%9A/e731dd6519e452b921376c3c6636369e697559838.png)\n\n当我设置了以下配置\n\n```bash\nlocation /images/ {\n\t# alias设置请求的别名，用于替换文件系统路径。\n       alias /var/www/images/;\n}\n```\n\n重载配置之后\n\n访问http://192.168.48.101/images/1.png\n\n<img src=\"../img/Nginx%EF%BC%9A%E4%BB%8E%E5%85%A5%E9%97%A8%E5%88%B0%E7%B2%BE%E9%80%9A/53570cebb87de92b4f0013d184981561697559838.png\" alt=\"image-20241123185936964\" style=\"zoom:67%;\" />\n\n结论：\n\n访问地址：`192.168.48.101/images`/1.png\n\n实际访问地址：`/var/www/images`/1.png\n\n同类型的案例再来一个\n\n```bash\nlocation /abc/ {\n   alias   /home/abc/; \n   index  index.html index.htm; # 默认首页文件\n   #当访问的时候会在/home目录下寻找index.html index.htm;\n}\n```\n\n![image-20241123185910023](../img/Nginx%EF%BC%9A%E4%BB%8E%E5%85%A5%E9%97%A8%E5%88%B0%E7%B2%BE%E9%80%9A/046d119d652f6d6665fd25e56bb520f6697559838.png)\n\n\n\n\n\n【`例子4`】\n\n精确匹配（顾名思义不做过多解释了）\n\n访问：http://qianyios.top/50x.html\n\n```\nlocation = /50x.html {\n            root   html;\n        }\n```\n\n\n\n【`例子5`】\n\n- `~`：大小写敏感（正则表达式）\n- `=` : 精确匹配（必须全部相等）\n- `~*`：忽略大小写（正则表达式），这里要注意忽略大小写的意思是请求的字符大小写都可以， 但是不会进行大小转换，请求的大小写对应的文件必须存在。\n- `^~` ：只需匹配uri部分\n- `@` ：内部服务跳转\n\n```bash\n#1.精确匹配\n location = /index.html {\n  root /etc/nginx/html;\n}\n# 则匹配到http://192.168.48.101/index.html这种请求。\n\n#2.大小写铭感匹配\n location ~ /ABC/ {\n    [ configuration ]\n }\n #请求示例\n #http://qianyios.top/ABC/ [成功]\n #http://qianyios.top/abc/ [失败]\n\n#3.大小写不敏感匹配\nlocation ~* /abc.html {\n    [ configuration ]\n}\n# 则会忽略 uri 部分的大小写\n#http://qianyios.top/ABC.html [成功] 可以成功匹配，但是目录中要ABC.html文件\n#http://qianyios.top/abc.html [成功] 可以成功匹配，但是目录中要abc.html文件\n\n#4.指定后缀匹配\nlocation ~* \\.(gif|jpg|jpeg|png)$ {\n root /var/www/images;\n}\n#http://qianyios.top/1.png [成功]\n\n#5.忽略正则匹配\nlocation ^~ /images/ {\n   alias /var/www/images;\n}\n#以 /img/ 开头的请求，都会匹配上\n#http://qianyios.top/images/1.jpg  [成功]\n#http://qianyios.top/images/1.png [成功]\n```\n\n`注意：`如果配置了`#5`，那么所有url里请求 /images/ 下的图片会被上面`#5`的处理，因为 `^~` 指令匹配到了/image/，则不检查`#4`正则表达式。对比这两个location，可以**设置不同目录，相同文件进行实验。**\n\n## 反向代理和正向代理\n\n### 反向代理\n\n![image-20241124002646957](../img/Nginx%EF%BC%9A%E4%BB%8E%E5%85%A5%E9%97%A8%E5%88%B0%E7%B2%BE%E9%80%9A/04df1bf721056ca83bb4a9b2537992ad697559838.png)\n\n根据以上的代码可以知道，我们设置三个server，分别表示3个网站，他们都有对应的域名，然后通过配置反向代理（右边的配置文件）实现反向代理。即：当用户访问user1.com，nginx就会将请求转到发到https://website1.com上。对应的后端服务器web1接收到请求并返回响应给 Nginx，Nginx 接收到来自后端服务器的响应，并将其返回给用户。\n\n- 对于 `user1.com` 的请求，Nginx 将其转发到 `http://website1.com/`。\n- 对于 `user2.com` 的请求，Nginx 将其转发到 `http://website2.com/`。\n- 对于 `user3.com` 的请求，Nginx 将其转发到 `http://website3.com/`。\n\n图片中说的无法跳过nginx去直接访问后端服务器，说法太死了，只能说是个例，如果项目本身就不想让你知道后端的地址，只想让你通过nginx来进行访问，方便管理，举个例子，就好像baidu.com    总不能说baidu.com只绑定到一个机子上吧，他肯定会有一个庞大的负载均衡以及反向代理集群，去均衡负载分散流量等操作，如果只绑定到一个机子，也承受不住每天几百万的访问下面会讲到负载均衡。就好像上面的图片的例子，我的后端三个都是百度的网站，有三个不同的域名，但是不可能让用户去记住三个域名吧，所以有个nginx去做反向代理，然后设置一个baidu.com去代理这三个web也可以做到反向代理\n\n\n\n### 正向代理\n\n用户需要通过代理服务器去访问外网。这个代理服务器可以是其他工具不一定是nginx\n\n![image-20241124004405332](../img/Nginx%EF%BC%9A%E4%BB%8E%E5%85%A5%E9%97%A8%E5%88%B0%E7%B2%BE%E9%80%9A/d2846d2fd31a99a6ddf810b47222a881697559838.png)\n\n\n\n<font color='red'>总结</font>：简单来说局域网访问互联网就是正向代理,互联网访问局域网就是反向代理.这些都是隧道式代理，进出都要经过代理服务器\n\n## 负载均衡\n\n### **负载均衡策略**\n\n**轮询**\n\n默认情况下使用轮询方式，逐一转发，这种方式适用于无状态请求。(在无参数情况下平均分配所有请求)\n\n![image-20241125174222842](../img/Nginx%EF%BC%9A%E4%BB%8E%E5%85%A5%E9%97%A8%E5%88%B0%E7%B2%BE%E9%80%9A/db573abf75aa87a347a2483e6d949110697559838.png)\n\n```bash\nhttp {\n#upstream和server是同一级别，都包含在http内\n    upstream qianyi {\n        server website1.com   weight=10 down;  #每十次请求之后轮询到下一个\n        server website2.com   weight=1;\n        server website3.com   weight=1 backup;\n    }\n\n    server {\n        listen 80;\n\tserver_name qianyios.top\n        location / {\n            proxy_pass http://qianyi;#名字随意，要和upstream后的名字一样\n        }\n    }\n}\n```\n\n> `down`：表示当前的server暂时不参与负载\n>\n> `weight`：默认为1.weight越大，负载的权重就越大。\n>\n> `backup`： 其它所有的非backup机器down或者忙的时候，请求backup机器。\n\n`ip_hash`\n\n对用户的ip进行计算：`Hash(IP)%upstream_node_count`，返回要使用机器的索引\n\n每一个用户会固定分配到一台机器，防止在A机器上创建Session的用户，后续被分配到其他机器，导致Session失效\n\n开启ip_hash后，如果想要移除一台server，必须使用down配置。如果直接删除，会导致upstream_node_count变化，使得所有用户访问的访问的机器发生变化\n\n缺点：\n\n- 增加服务节点会导致upstream_node_count变化，进而导致所有用户访问的机器变化\n- 某个用户短时间发起大量请求，会打到一台固定的机器，导致这台机器性能大幅下降，而其他机器可能还是空闲\n\n```bash\nupstream test_server{\n    # 开启ip_hash，\n    ip_hash;\n    \n\t\tserver web1.com:80;\n\t\tserver web2.com:80;\n}\n```\n\n`least_conn`\n\n尽可能将请求转发到当前连接数最少的后端服务器\n\n```\nupstream test_server{\n    least_conn;\n    \n\t\tserver web1.com:80;\n\t\tserver web2.com:80;\n}\n```\n\n下面例子，开启least_conn，Nginx会优先转发到Tomcat3\n\n![image-20241126232643480](../img/Nginx%EF%BC%9A%E4%BB%8E%E5%85%A5%E9%97%A8%E5%88%B0%E7%B2%BE%E9%80%9A/e6f48aa1bd0b54d7d4c3f7248146b954697559838.png)\n\n\n\n`url_hash`\n\n根据用户访问的url定向转发请求\n\n`fair`\n\n根据后端服务器响应时间转发请求\n\n\n\n<font color='red'>总结</font>：当我们访问http://qianyios.top时在upstream无参数的情况下，这三个网页都会平均的访问，且地址栏里的qianyios.top不会变\n\n其次有参数时，都会按照参数的性质，进行轮询访问\n\n## 动静分离\n\n- 静：前端项目（静态资源）\n- 动：接口服务\n- 域名A.com访问到A项目、B.com访问到B项目\n\n  Api.com访问接口服务\n\n  将3个域名都解析到Nginx所在机器\n\n```bash\n# 前端\nserver {\n        listen       80;\n        server_name  A.com;\n        \n        location ~ {  \n            root /websit/xxx; # A项目目录\n            index  index.html index.htm;\n        }\n\n        error_page   500 502 503 504  /50x.html;\n        location = /50x.html {\n            root   html;\n        }\n}\nserver {\n        listen       80;\n        server_name  B.com;\n        \n        location ~ {  \n            root /websit/xxx; # B项目目录\n            index  index.html index.htm;\n        }\n\n        error_page   500 502 503 504  /50x.html;\n        location = /50x.html {\n            root   html;\n        }\n}\n\n# 接口\nserver {\n        listen       80;\n        server_name  Api.com;\n\t\t\t\t\n\t# 接口\n\tlocation  {\n        proxy_pass http://接口机器的IP:端口;\n        }\n\n        error_page   500 502 503 504  /50x.html;\n        location = /50x.html {\n            root   html;\n        }\n}\n```\n\n```bash\nlocation ~* /(js|css|img){\n\troot html;\n  index  index.html index.htm;\n}\n\n#   ~* 表示这是一个不区分大小写的正则表达式匹配。\n#   /(css|img|js) 意味着这个location块将匹配所有以/css、/img或/js结尾的URL路径。\n#  Nginx会在服务器的文件系统中对应的html目录下查找文件。\n```\n\n## URL重写\n\n### return\n\n把Http重定向为Https\n\n```bash\nserver {\n        listen       80;\n        server_name  www.qianyios.com;\n\t\tlocation / { \n\t\t\treturn 302 https://www.qianyios.com$request_uri \n\t\t\t# 302是状态码\n\t\t\t# $request_uri是路径和参数 ，例如：/xxx/xx?xx=xx\n        }\n}\n```\n\n### rewrite\n\n```bash\nrewrite是URL重写的关键指令，根据regex（正则表达式）部分内容，重定向到replacement，结尼是flag标记。\n\nrewrite    <regex>   <replacement>  [flag];\n关键字\t\t\t\t正则\t\t\t\t替代内容     flagt标记\n\n正则：per1森容正则表达式语句进行规则匹配\n替代内容：将正则匹配的内容替换成replacement\n\nflag标记说明：\nlast  #本条规则匹配完成后，继续向下匹配新的1ocation URI规则\nbreak #本条规则匹配完成即终止，不再匹配后面的任何规则\n\nredirect #返回302临重定向，游览器地址会显示跳转后的URL地址\npermanent #返回301永久重定向，测览器地址栏会显示跳转后的URL地址\n```\n\n把Http重定向为Https\n\n```bash\nserver {\n        listen       80;\n        server_name  www.qianyios.com;\n\t\tlocation / { \n\t\t   rewrite ^/(.*) https://www.qianyios.top.com/$1 redirect;\n\t\t   # 匹配到uri的/后的内容，并放到$1中，执行重定向\n        \t  proxy_pass http://xxx;\n        }\n}\n```\n\n当你尝试访问http://www.qianyios.top/1.html时，由于上述rewrite指令的存在，你的浏览器实际上会被引导至https://www.qianyios.top.com/1.html\n\n上述命令改成return会更高效\n\n```bash\nreturn 301 https://www.qianyios.top.com$request_uri;\n```\n\n实例：\n\n```bash\nrewrite ^/([0-9]+).html$  /index.jsp?pageNum=$1 break;\n```\n\n假设我们的真实地址是192.168.48.101/index.jsp?pageNum=12   但是我不想客户知道真实地址\n\n配置了这个规则之后，他就会变成192.168.48.101/12.html\n\n我们访问192.168.48.101/12.html（但是12.html是不存在的）之后，他会把流量转发到192.168.48.101/index.jsp?pageNum=12（真实地址）\n\n## Nginx网关服务器\n\n企业中，无论是前端页面、静态资源、接口，都是通过Nginx进行访问（使用proxy_pass），这时候这台Nginx服务器就成为了网关服务器（承担入口的功能）\n\n![image-20241203004657289](../img/Nginx%EF%BC%9A%E4%BB%8E%E5%85%A5%E9%97%A8%E5%88%B0%E7%B2%BE%E9%80%9A/836a165f1c9207a3043222f47a626fbe697559838.png)\n\n所以，我们启动web服务器的防火墙，设置其只能接受这台Nginx服务器的请求\n\n```\nsystemctl start firewalld\n```\n\n**添加rich规则**\n\n```bash\n#这里的192.168.48.101是网关服务器(nginx)地址\nfirewall-cmd --permanent --add-rich-rule=\"rule family=\"ipv4\" source address=\"192.168.48.101\" port protocol=\"tcp\" port=\"8080\" accept\" \n```\n\n- `firewall-cmd`：这是用来与firewalld进行交互的命令行工具。\n- `--permanent`：表示这个更改会永久生效，即使系统重启后也会保留。不过请注意，为了使永久性规则立即生效，您需要重新加载防火墙配置。\n- `--add-rich-rule=\"规则\"`：这是用来添加一条富规则到firewalld的参数。富规则允许更复杂的条件和操作。\n\n在引号内的部分定义了具体的规则：\n\n- `rule family=\"ipv4\"`：指定这条规则适用于IPv4协议。\n- `source address=\"192.168.48.101\"`：规则只适用于源地址为`192.168.48.101`的流量。\n- `port protocol=\"tcp\" port=\"8080\"`：这条规则针对的是TCP协议，并且仅限于端口号为`8080`的连接。\n- `accept`：这表示如果所有上述条件都满足，则接受（允许）该网络流量。\n\n配置完之后重启firewalld\n\n```\nsystemctl restart firewalld\n```\n\n这时候，原本web开启了防火墙之后，不管访问web地址还是nginx服务器都无法访问到我们的web\n\n且nginx配置`proxy_pass http://192.168.48.105:8080`反向代理到web\n\n但是，我们在web端配置了防火墙规则之后，让web同意接收来自nginx的192.168.48.101的请求，且自身开放8080端口，这样我们访问192.168.48.101（这是nginx的地址反向代理到了web）就可以访问web了\n\n**移除rich规则**\n\n```bash\n#这里的192.168.48.101是网关服务器(nginx)地址\nfirewall-cmd --permanent --remove-rich-rule=\"rule family=\"ipv4\" source address=\"192.168.48.101\" port protocol=\"tcp\" port=\"8080\" accept\" \n```\n\n**查看所有规则**\n\n```shell\nfirewall-cmd --list-all #所有开启的规则\n```\n\n## 防盗链配置\n\n当我们请求到一个页面后，这个页面一般会再去请求其中的静态资源，这时候请求头中，会有一个refer字段，表示当前这个请求的来源，我们可以限制指定来源的请求才返回，否则就不返回，这样可以节省资源\n\n![image-20241208130819031](../img/Nginx%EF%BC%9A%E4%BB%8E%E5%85%A5%E9%97%A8%E5%88%B0%E7%B2%BE%E9%80%9A/f2a13ea3f204061b76d98e2e31cd4c7a697559838.png)\n\n![image-20241208130344746](../img/Nginx%EF%BC%9A%E4%BB%8E%E5%85%A5%E9%97%A8%E5%88%B0%E7%B2%BE%E9%80%9A/0ca270e01ec4bfe1567668978813d129697559838.png)\n\n```shell\nvalid_referers none|server_name\n```\n\n设置有效的refer值\n\n- none：不校验refer\n- server_name：校验refer地址是否为server_name（server_name可以使用通配符）\n\n注意：` if ($invalid_referer)`中if后有个空格，不写就会报错\n\n```bash\nnginx: [emerg] unknown directive \"if($invalid_referer)\" in /usr/local/nginx/conf/nginx.conf:27\n```\n\n1.例子：这里设置nginx服务器中的img目录下的图片必须refer为https://blog.qianyios.top才能访问\n\n```bash\nserver {\n        listen       80;\n        server_name  localhost;\n\t  location /img{\n                valid_referers https://blog.qianyios.top/;\n                if ($invalid_referer){#无效的refere\n                        return 403;#返回状态码403\n                }\n                root html;\n                index  index.html index.htm;\n        }\n\n}\n```\n\n这样其他人，不管是引用图片到他自己web或者直接在地址栏输入直接访问都不行\n\n![](../img/Nginx%EF%BC%9A%E4%BB%8E%E5%85%A5%E9%97%A8%E5%88%B0%E7%B2%BE%E9%80%9A/7fb961c8f95308e9743eb7fc9df5284e697559838.png)\n\n如果可以开放`直接在地址栏输入直接访问`可以加none\n\n```bash\nvalid_referers none https://blog.qianyios.top/;\n```\n\n\n\n2.直接跳转到自定义图片\n\n假设123.png是写有禁止盗取字样的图片\n\n假设我的图片是http://qianyios.top/images/1.png\n\n他会直接跳转到/var/www/image/123.png\n\n```bash\nlocation ^~ /image/ {\n   root /var/www/;\n}\n\nlocation ^~ /images/ {\n          valid_referers qianyios.top;\n          if ($invalid_referer){#无效的refere\n             rewrite ^/images/(.*)$ /image/123.png break;\n             #return 302 /abc/123.png;\n          }\n          root /var/www/;\n}\n```\n\n`^/images/(.*)$` 匹配所有以 `/images/` 开头的路径，并捕获后续部分（即 `(.*)`）。\n\n\n\n用curl工具进行访问\n\n```\nhttp://qianyios.top/images/1.png\n```\n\n![image-20241208135031449](../img/Nginx%EF%BC%9A%E4%BB%8E%E5%85%A5%E9%97%A8%E5%88%B0%E7%B2%BE%E9%80%9A/6ca1eecc22842f0abf39f7c04507077c697559838.png)\n\n带引用的访问\n\n```bash\ncurl -e \"http://qianyios.top\" -I http://qianyios.top/images/1.png\n```\n\n![image-20241208135300813](../img/Nginx%EF%BC%9A%E4%BB%8E%E5%85%A5%E9%97%A8%E5%88%B0%E7%B2%BE%E9%80%9A/006941d2d540486aa7f755741a4ab8a4697559838.png)\n\n## 高可用配置\n\n### 背景\n\n如下图，如果只有一个Nginx作为网关，一旦出现故障会导致全部服务不可用\n\n![image-20241208141302678](../img/Nginx%EF%BC%9A%E4%BB%8E%E5%85%A5%E9%97%A8%E5%88%B0%E7%B2%BE%E9%80%9A/b906e3608c6e725550da4bfc278674bc697559838.png)\n\n高可用方案：\n\n![image-20241208141351424](../img/Nginx%EF%BC%9A%E4%BB%8E%E5%85%A5%E9%97%A8%E5%88%B0%E7%B2%BE%E9%80%9A/4cc5dca9cc81adcfba9708bcf287674c697559838.png)\n\n注意：Nginx主备机器配置要基本一致，如果配置相差较大，在切换时大量流量进入备用机，容易造成宕机\n\n**VRRP协议**\n\nkeepalived是基于VRRP（Virtual Router Redundancy Protocol）协议的\n\nVRRP可以将多个Nginx网关机器分为 master、backup两种类型，并生成一个VIP（`虚拟IP:Virtual IP Address`）\n\n每台机器上的keepalived会相互通信，根据其他机器上的keepalived进程是否存在，判断服务器状态，如果默认的`Master`停止了，就会在剩下的`Backup`机器中，竞选出一台Nginx服务器作为Master\n\n由Master服务器使用这个VIP，用户访问时，访问的是VIP\n\n```\nyum install -y keepalived\n```\n\n```bash\n#keepalived的配置文件\nvim /etc/keepalived/keepalived.conf\n```\n\nnginx1的配置\n\n```shell\n! Configuration File for keepalived\n\nglobal_defs {\n   # keepalived邮件通知（可配置多个）\n   notification_email {\n     acassen@firewall.loc\n     failover@firewall.loc\n     sysadmin@firewall.loc\n   }\n   # 邮件发件人地址\n   notification_email_from Alexandre.Cassen@firewall.loc\n   # 邮件服务器（SMTP）地址\n   smtp_server 192.168.200.1\n   # 连接SMTP服务器的超时时间\n   smtp_connect_timeout 30\n   # 后面会提到\n   router_id lb1 # 路由id，可以随意取，但是要保证每个配置了keepalive的机器不重复就行\n   \n   # vrrp相关配置，用的比较少\n   vrrp_skip_check_adv_addr\n   vrrp_strict\n   vrrp_garp_interval 0\n   vrrp_gna_interval 0\n}\n# 节点名可以随意取，但要保证主、备节点之间保持一致即可\nvrrp_instance VI_1 {\n    state MASTER  #主服务器\n    interface eth160 #vip到时候会生成在这个网卡下\n    virtual_router_id 51\n    priority 100  #优先级\n    advert_int 1  #检测间隔时间\n    authentication {   #认证机制，这样可以区分实现不同作用的keepalived集群，不会混乱\n        auth_type PASS # 指定了认证类型为密码（PASS）\n        auth_pass 1111  # 设置了认证密码，这里设置的密码是\"1111\"\n    }\n    virtual_ipaddress {\n        192.168.48.200 #总ip\n    }\n}\n\n······其余配置······\n}\n```\n\n- `authentication`、`virtual_router_id`、`virtual_ipaddress`这几个一样的机器，才算是同一个组里。这个组才会选出一个作为Master机器\n\nnginx2的配置\n\n```bash\n! Configuration File for keepalived\n\nglobal_defs {\n   router_id lb2\n}\n\nvrrp_instance VI_1 {\n    state BACKUP  #主服务器\n    interface eth160 #vip到时候会生成在这个网卡下\n    virtual_router_id 51\n    priority 50  #降低优先级\n    advert_int 1  #检测间隔时间\n    authentication {   #认证机制，这样可以区分实现不同作用的keepalived集群，不会混乱\n        auth_type PASS # 指定了认证类型为密码（PASS）\n        auth_pass 1111  # 设置了认证密码，这里设置的密码是\"1111\"\n    }\n    virtual_ipaddress {\n        192.168.48.200 #总ip\n    }\n}\n\n······其余配置······\n}\n```\n\n配置完成后，重启keepalived就可以实现高可用\n\n> 假设我访问192.168.48.200就会访问到竞争到master的服务器，然后master是个nginx网关，将流量负载到Tomcat，假设master节点挂了，vip就会跳转backup的ens160上，这样访问192.168.48.200就会访问到backup的服务器，当master恢复，那vip就会跳回到master。\n\n这里有keepalived实验过程\n\n可以看一下\n\n[K8S高可用集群（内部etcd） | 严千屹博客](https://blog.qianyios.top/posts/7158/#测试集群负载均衡高可用)\n\n<div class=\"tbsm\" style=\"margin-top:54px;\">\n<div class=\"tbsm-top\"><span><svg t=\"1674654360507\" class=\"icon\" viewBox=\"0 0 1024 1024\" version=\"1.1\" xmlns=\"http://www.w3.org/2000/svg\" p-id=\"987\" data-spm-anchor-id=\"a313x.7781069.0.i0\" width=\"35\" height=\"35\"><path d=\"M410.49 97.74H155.08a56.74 56.74 0 0 0-56.84 56.73V410a56.84 56.84 0 0 0 56.84 56.84h255.41A56.83 56.83 0 0 0 467.32 410V154.58a56.83 56.83 0 0 0-56.83-56.84zM410.49 558.74H155.08a56.74 56.74 0 0 0-56.84 56.73V871a56.84 56.84 0 0 0 56.84 56.84h255.41A56.83 56.83 0 0 0 467.32 871V615.58a56.83 56.83 0 0 0-56.83-56.84zM871.49 558.74H616.08a56.74 56.74 0 0 0-56.84 56.73V871a56.84 56.84 0 0 0 56.84 56.84h255.41A56.83 56.83 0 0 0 928.32 871V615.58a56.83 56.83 0 0 0-56.83-56.84z\" fill=\"#66EEFF\" p-id=\"988\"></path><path d=\"M410.49 558.74h-4.14A475 475 0 0 0 299.52 859.6a481.16 481.16 0 0 0 4.84 68.22h106.13A56.83 56.83 0 0 0 467.32 871V615.58a56.83 56.83 0 0 0-56.83-56.84zM871.49 558.74H616.08a56.74 56.74 0 0 0-56.84 56.73V871a56.84 56.84 0 0 0 56.84 56.84h255.41A56.83 56.83 0 0 0 928.32 871V615.58a56.83 56.83 0 0 0-56.83-56.84z\" fill=\"#C2F8FF\" p-id=\"989\"></path></svg></span><span style=\"font-size:30px;\"> 特别声明</span></div>\n<div class=\"tbsm-wz\">千屹博客旗下的所有文章，是通过本人课堂学习和课外自学所精心整理的知识巨著<br/>难免会有出错的地方<br/>如果细心的你发现了小失误，可以在下方评论区告诉我，或者私信我！<br />非常感谢大家的热烈支持！</div>\n</div>\n","tags":["Nginx"],"categories":["笔记"]},{"title":"华为ensp模拟器安装教程","url":"/posts/f8bb3dfe/","content":"\n<meta name=\"referrer\" content=\"no-referrer\"/>\n\n# 华为ensp模拟器安装教程\n\n请留意：经过多年，Windows系统已经推出多个新版本，因此可能会出现各种不相容的状况，故此此文仅供参考，如有疑问，请自行处理。eNSP模拟器从2019年开始不再有新版本更新，最近的版本是1.3.00.100 V100R003C00SPC100。\n\n## 安装准备\n\n下载地址1：[自建](https://resource.qianyios.top/%E7%BD%91%E7%BB%9C/ensp%E5%8F%8A%E9%99%84%E5%B1%9E%E5%AE%89%E8%A3%85%E5%8C%85.7z)   `速度较慢`\n\n下载地址2：[ensp及依赖安装包](https://www.alipan.com/s/ZaW6Nf5Y7RH)\n\n这个下载之后是ensp及依赖安装包.exe123，重命名把后面的123删除即可\n\n## 安装环境检查\n\n检查之前是否已经安装过 eNSP 和依赖软件，如果有先请卸载，包括依赖软件一起卸载。\n\n如果之前安装过 eNSP ，请使用注册表清理工具清理一下注册表【`此步骤谨慎操作，注册表比较重要，请在有备份的情况下清理，清理出错可能会导致系统不可用`】。\n\neNSP安装和使用过程中请将 Windows 防火墙关闭。\n\nWindows11安装需要关闭`内核隔离`选项。\n\n![image-20241203171543779](../img/%E5%8D%8E%E4%B8%BAensp%E6%A8%A1%E6%8B%9F%E5%99%A8%E5%AE%89%E8%A3%85%E6%95%99%E7%A8%8B/a375a8bc67d690b3ef34e90ca7e28a66697559838.png)\n\n## 安装winPcap\n\n双击安装包，一直下一步到这，保持默认，继续下一步\n\n![image-20241203171543779](../img/%E5%8D%8E%E4%B8%BAensp%E6%A8%A1%E6%8B%9F%E5%99%A8%E5%AE%89%E8%A3%85%E6%95%99%E7%A8%8B/bc24e40e903e1abd505fb43ce11207b5697559838.png)\n\n![image-20241203171557056](../img/%E5%8D%8E%E4%B8%BAensp%E6%A8%A1%E6%8B%9F%E5%99%A8%E5%AE%89%E8%A3%85%E6%95%99%E7%A8%8B/1be2bb1ff1c3b662a0b2d2dadfea5e07697559838.png)\n\n点击finish即可\n\n## 安装Wireshark\n\n双击安装包打开，一直下一步，到这，保持默认，继续下一步\n\n![image-20241203171834891](../img/%E5%8D%8E%E4%B8%BAensp%E6%A8%A1%E6%8B%9F%E5%99%A8%E5%AE%89%E8%A3%85%E6%95%99%E7%A8%8B/c8df9d2644951a197201edba2574b81f697559838.png)\n\n保持默认，继续下一步\n\n![image-20241203171846995](../img/%E5%8D%8E%E4%B8%BAensp%E6%A8%A1%E6%8B%9F%E5%99%A8%E5%AE%89%E8%A3%85%E6%95%99%E7%A8%8B/fa609b4d9ef4ba9159970a96d7f9fc08697559838.png)\n\n可以自行选择安装路径，但是`不建议`,我这里是c盘内存不多了\n\n**![image-20241203171947349](../img/%E5%8D%8E%E4%B8%BAensp%E6%A8%A1%E6%8B%9F%E5%99%A8%E5%AE%89%E8%A3%85%E6%95%99%E7%A8%8B/493e445292ef501067f2ef1686c1d2bc697559838.png)**\n\n保持默认，下一步\n\n![image-20241203172018191](../img/%E5%8D%8E%E4%B8%BAensp%E6%A8%A1%E6%8B%9F%E5%99%A8%E5%AE%89%E8%A3%85%E6%95%99%E7%A8%8B/4cc79174256632880fee34825c87d1e8697559838.png)\n\n保持默认，下一步\n\n![image-20241203172028555](../img/%E5%8D%8E%E4%B8%BAensp%E6%A8%A1%E6%8B%9F%E5%99%A8%E5%AE%89%E8%A3%85%E6%95%99%E7%A8%8B/eef0cbf7e6d313c41566acd870fda609697559838.png)\n\n安装过程中，会跳出一个安装节目，保持默认，下一步即可\n\n![image-20241203172121518](../img/%E5%8D%8E%E4%B8%BAensp%E6%A8%A1%E6%8B%9F%E5%99%A8%E5%AE%89%E8%A3%85%E6%95%99%E7%A8%8B/ff29ea5aa56d6b96d3239f973c202adf697559838.png)\n\n都不选下一步\n\n![](../img/%E5%8D%8E%E4%B8%BAensp%E6%A8%A1%E6%8B%9F%E5%99%A8%E5%AE%89%E8%A3%85%E6%95%99%E7%A8%8B/fcd161c3697825329981f29a356e1713697559838.png)\n\n最后点击finish，返回wireshark安装界面\n\n啥也不选，点击finish\n\n![image-20241203172223040](../img/%E5%8D%8E%E4%B8%BAensp%E6%A8%A1%E6%8B%9F%E5%99%A8%E5%AE%89%E8%A3%85%E6%95%99%E7%A8%8B/55c12a84c792a7f4f47e0a86fa801617697559838.png)\n\n## 安装VirtualBox\n\n双击安装包打开，一直下一步，到这，保持默认，继续下一步<font color='red'>（自行选择安装路径，也可以默认）</font>\n\n![image-20241203172517015](../img/%E5%8D%8E%E4%B8%BAensp%E6%A8%A1%E6%8B%9F%E5%99%A8%E5%AE%89%E8%A3%85%E6%95%99%E7%A8%8B/ac77030dc58ca8b825272cf988a1a101697559838.png)\n\n![image-20241203172554183](../img/%E5%8D%8E%E4%B8%BAensp%E6%A8%A1%E6%8B%9F%E5%99%A8%E5%AE%89%E8%A3%85%E6%95%99%E7%A8%8B/c95708108bdb65a7783d0f67ffdfc03b697559838.png)\n\n![image-20241203172603260](../img/%E5%8D%8E%E4%B8%BAensp%E6%A8%A1%E6%8B%9F%E5%99%A8%E5%AE%89%E8%A3%85%E6%95%99%E7%A8%8B/4c83f8903f39350c6cf0d4dd4e7a0fbf697559838.png)\n\n然后点击安装到这\n\n![image-20241203172618811](../img/%E5%8D%8E%E4%B8%BAensp%E6%A8%A1%E6%8B%9F%E5%99%A8%E5%AE%89%E8%A3%85%E6%95%99%E7%A8%8B/2cd27f0028dc3ffb0ad6691fc7fd4ca4697559838.png)\n\n![image-20241203172633234](../img/%E5%8D%8E%E4%B8%BAensp%E6%A8%A1%E6%8B%9F%E5%99%A8%E5%AE%89%E8%A3%85%E6%95%99%E7%A8%8B/202b9840a5bd7f42f7cf3c68d2e8599a697559838.png)\n\n![image-20241203172653003](../img/%E5%8D%8E%E4%B8%BAensp%E6%A8%A1%E6%8B%9F%E5%99%A8%E5%AE%89%E8%A3%85%E6%95%99%E7%A8%8B/ef82bb16ba5f586c10b9ae1b918343f8697559838.png)\n\n![image-20241203172706558](../img/%E5%8D%8E%E4%B8%BAensp%E6%A8%A1%E6%8B%9F%E5%99%A8%E5%AE%89%E8%A3%85%E6%95%99%E7%A8%8B/408fc2de78aebdcd1b4f56e76e10de7e697559838.png)\n\n## 安装ensp\n\n![image-20241203172734710](../img/%E5%8D%8E%E4%B8%BAensp%E6%A8%A1%E6%8B%9F%E5%99%A8%E5%AE%89%E8%A3%85%E6%95%99%E7%A8%8B/0a807069ff5eb210324a13d80b0dfd98697559838.png)\n\n![image-20241203172819522](../img/%E5%8D%8E%E4%B8%BAensp%E6%A8%A1%E6%8B%9F%E5%99%A8%E5%AE%89%E8%A3%85%E6%95%99%E7%A8%8B/407464c59d82bd07cfbca76977b6ae1a697559838.png)\n\n![image-20241203172835791](../img/%E5%8D%8E%E4%B8%BAensp%E6%A8%A1%E6%8B%9F%E5%99%A8%E5%AE%89%E8%A3%85%E6%95%99%E7%A8%8B/c8db7f418347183a82ce800c7060cab7697559838.png)\n\n![image-20241203172910954](../img/%E5%8D%8E%E4%B8%BAensp%E6%A8%A1%E6%8B%9F%E5%99%A8%E5%AE%89%E8%A3%85%E6%95%99%E7%A8%8B/14ccb131956bed02d3b737bc05fb0915697559838.png)\n\n然后一直下一步，安装即可\n\n![image-20241203173017563](../img/%E5%8D%8E%E4%B8%BAensp%E6%A8%A1%E6%8B%9F%E5%99%A8%E5%AE%89%E8%A3%85%E6%95%99%E7%A8%8B/6e20a84905fd08e69477d5bca190c395697559838.png)\n\n## 打开ensp\n\n![image-20241203173104621](../img/%E5%8D%8E%E4%B8%BAensp%E6%A8%A1%E6%8B%9F%E5%99%A8%E5%AE%89%E8%A3%85%E6%95%99%E7%A8%8B/1cfd3eeadc3f24829d853e5cda7015c7697559838.png)\n\n![image-20241203173125141](../img/%E5%8D%8E%E4%B8%BAensp%E6%A8%A1%E6%8B%9F%E5%99%A8%E5%AE%89%E8%A3%85%E6%95%99%E7%A8%8B/834005ebe3fecadfda62227b8b8305ea697559838.png)\n\n有报错了，启动一个AR\n\n![image-20250316174953299](../img/%E5%8D%8E%E4%B8%BAensp%E6%A8%A1%E6%8B%9F%E5%99%A8%E5%AE%89%E8%A3%85%E6%95%99%E7%A8%8B/ef9ff3d7fefea5c96ca9c6f223ce030a697559838.png)\n\n![image-20241203173318129](../img/%E5%8D%8E%E4%B8%BAensp%E6%A8%A1%E6%8B%9F%E5%99%A8%E5%AE%89%E8%A3%85%E6%95%99%E7%A8%8B/9cb5e2cb92113f2149c8c480de188cde697559838.png)\n\n因为刚刚安装VirtualBox最后没有重启电脑，你`重启一下电脑`就行了\n\n要确保是这个地址\n\n![image-20241203173633633](../img/%E5%8D%8E%E4%B8%BAensp%E6%A8%A1%E6%8B%9F%E5%99%A8%E5%AE%89%E8%A3%85%E6%95%99%E7%A8%8B/dea4d80b355a0cb41aadba8717596a16697559838.png)\n\n然后你再去启动就可以启动了\n\n\n\n如果还是`不行`，AR路由器还是启动不了，你才执行下面的操作\n\n按`win键`搜索`运行`输入regedit\n\n![image-20250316174447550](../img/%E5%8D%8E%E4%B8%BAensp%E6%A8%A1%E6%8B%9F%E5%99%A8%E5%AE%89%E8%A3%85%E6%95%99%E7%A8%8B/7ce123a68ab56fcb54fe80203ac03a20697559838.png)\n\n你直接导航到\n\n```\n计算机\\HKEY_LOCAL_MACHINE\\SYSTEM\\CurrentControlSet\\Services\\VBoxDrv\n```\n\n将Start的值改成3，然后重启电脑\n\n![image-20250316174742089](../img/%E5%8D%8E%E4%B8%BAensp%E6%A8%A1%E6%8B%9F%E5%99%A8%E5%AE%89%E8%A3%85%E6%95%99%E7%A8%8B/e6e92cd9760a698eb433d03bebeb9869697559838.png)\n\n\n\n<div class=\"tbsm\" style=\"margin-top:54px;\">\n<div class=\"tbsm-top\"><span><svg t=\"1674654360507\" class=\"icon\" viewBox=\"0 0 1024 1024\" version=\"1.1\" xmlns=\"http://www.w3.org/2000/svg\" p-id=\"987\" data-spm-anchor-id=\"a313x.7781069.0.i0\" width=\"35\" height=\"35\"><path d=\"M410.49 97.74H155.08a56.74 56.74 0 0 0-56.84 56.73V410a56.84 56.84 0 0 0 56.84 56.84h255.41A56.83 56.83 0 0 0 467.32 410V154.58a56.83 56.83 0 0 0-56.83-56.84zM410.49 558.74H155.08a56.74 56.74 0 0 0-56.84 56.73V871a56.84 56.84 0 0 0 56.84 56.84h255.41A56.83 56.83 0 0 0 467.32 871V615.58a56.83 56.83 0 0 0-56.83-56.84zM871.49 558.74H616.08a56.74 56.74 0 0 0-56.84 56.73V871a56.84 56.84 0 0 0 56.84 56.84h255.41A56.83 56.83 0 0 0 928.32 871V615.58a56.83 56.83 0 0 0-56.83-56.84z\" fill=\"#66EEFF\" p-id=\"988\"></path><path d=\"M410.49 558.74h-4.14A475 475 0 0 0 299.52 859.6a481.16 481.16 0 0 0 4.84 68.22h106.13A56.83 56.83 0 0 0 467.32 871V615.58a56.83 56.83 0 0 0-56.83-56.84zM871.49 558.74H616.08a56.74 56.74 0 0 0-56.84 56.73V871a56.84 56.84 0 0 0 56.84 56.84h255.41A56.83 56.83 0 0 0 928.32 871V615.58a56.83 56.83 0 0 0-56.83-56.84z\" fill=\"#C2F8FF\" p-id=\"989\"></path></svg></span><span style=\"font-size:30px;\"> 特别声明</span></div>\n<div class=\"tbsm-wz\">千屹博客旗下的所有文章，是通过本人课堂学习和课外自学所精心整理的知识巨著<br/>难免会有出错的地方<br/>如果细心的你发现了小失误，可以在下方评论区告诉我，或者私信我！<br />非常感谢大家的热烈支持！</div>\n</div>","tags":["eNSP"],"categories":["网络"]},{"title":"Samba服务器实战","url":"/posts/a8a56b19/","content":"\n<meta name=\"referrer\" content=\"no-referrer\"/>\n\n# Samba服务器实战\n\nSamba是在Linux和UNIX系统上实现SMB协议的一个免费软件，由服务器及客户端程序构成。SMB（Server Messages Block，信息服务块）是一种在局域网上共享文件和打印机的一种通信协议，它为局域网内的不同计算机之间提供文件及打印机等资源的共享服务。SMB协议是客户机/服务器型协议，客户机通过该协议可以访问服务器上的共享文件系统、打印机及其他资源。通过设置“NetBIOS over TCP/IP”使得Samba不但能与局域网络主机分享资源，还能与全世界的电脑分享资源。\n\n## 主机拓扑\n\n| 主机名   | os                | ip             | 内存 | 硬盘 |\n| -------- | ----------------- | -------------- | ---- | ---- |\n| qianyios | Openeuler22.03LTS | 192.168.48.101 | 2G   | 100G |\n\n## 安装Samba\n\n```bash\ndnf  install -y samba\n#关闭防火墙\nsystemctl disable firewalld &> /dev/null\nsystemctl stop firewalld\nsed -i \"s#SELINUX=enforcing#SELINUX=disabled#g\" /etc/selinux/config\nsetenforce 0\n```\n\n## Samba共享服务的匿名访问\n\n### 配置文件\n\nsamba服务器最主要的配置文件其实只有一个，就是/etc/samba/samb.conf，这个配置文件可以分为两个部分，一个部分是全局参数，一部分是共享资源相关参数。\n\n```\nvim /etc/samba/smb.conf\n```\n\n先取消[homes]、[printers]的项目，添加[share]项目如下\n\n```bash\n[global]\n        #与主机名相关的设置\n        #工作组名称\n        workgroup = SAMBA\n        security = user\n        passdb backend = tdbsam\n        printing = cups\n        printcap name = cups\n        load printers = yes\n        cups options = raw\n        ##添加此项，开启匿名用户访问\n        map to guest = Bad User\n        include = /etc/samba/usershares.conf\n[share]\n\t#设置共享路径\n        path = /abc \n        ##公共访问\n\t public=yes\n\t ##能够访问\n        browseable=yes\n        ##写权限\n        writable=yes\n        ##设置权限\n        create mask=0644\n        directory mask=0755\n```\n\n### 创建共享路径，并给权限\n\n```bash\nmkdir /abc\nchmod 777 /abc\nsystemctl enable --now smb.service\n#linux创建测试文件,客户端查看\necho \"text\" >> /abc/test.txt\n```\n\n文件夹地址栏输入\\\\192.168.48.101\\share,他会提示你输入用户和密码，用户名是nobody，密码不用输，然后就客户端就可以看见linux创建的测试文件\n\n![image-20241127103444665](../img/Samba%E6%9C%8D%E5%8A%A1%E5%99%A8%E5%AE%9E%E6%88%98/94bce6da82dfd0554d7247c17b83883d697559838-1732698207215-37.png)\n\n客户端创建文件夹，linux查看\n\n![image-20241127103714433](../img/Samba%E6%9C%8D%E5%8A%A1%E5%99%A8%E5%AE%9E%E6%88%98/de470210d7e0c0e0672fc033642f2132697559838-1732698207215-38.png)\n\n![image-20241127103729198](../img/Samba%E6%9C%8D%E5%8A%A1%E5%99%A8%E5%AE%9E%E6%88%98/3c56d0e57aef146c93f28b0c72f479b7697559838-1732698207215-39.png)\n\n## Samba共享服务的用户身份验证\n\n### 配置文件\n\n```\nvim /etc/samba/smb.conf\n```\n\n```bash\n[global]\n        #与主机名相关的设置\n        #工作组名称\n        workgroup = SAMBA\n        security = user\n        passdb backend = tdbsam\n        printing = cups\n        printcap name = cups\n        load printers = yes\n        cups options = raw\n        ##添加此项，开启匿名用户访问\n       ## map to guest = Bad User   #（删除匿名访问）\n        include = /etc/samba/usershares.conf\n[share]\n\t#设置共享路径\n        path = /abc\n        ##公共访问\n        # public=yes   #（删除公共访问）\n         ##能够访问\n        browseable=yes\n        ##写权限\n        #writable=yes  #（删除写入权限）\n        ##设置权限\n        create mask=0644\n        directory mask=0755\n        ##允许访问的用户\n        valid users=qianyios, qianyios1\n        ##允许写入的用户\n        write list=qianyios\n```\n\n### 创建smb用户\n\n```bash\nuseradd qianyios\nuseradd qianyios1\nsmbpasswd -a qianyios\n#有以下提示\nNew SMB password:    ##设置密码\nRetype new SMB password:   ##确认密码\nAdded user qianyios.\n#qianyios1也是这样的操作\nsmbpasswd -a qianyios1\n```\n\n![image-20241127104829402](../img/Samba%E6%9C%8D%E5%8A%A1%E5%99%A8%E5%AE%9E%E6%88%98/c8c2d257064d8e75cd91d4ed99bb5f1a697559838-1732698207216-40.png)\n\n列出smb用户列表\n\n```\npdbedit -L\n```\n\n![image-20241127104533486](../img/Samba%E6%9C%8D%E5%8A%A1%E5%99%A8%E5%AE%9E%E6%88%98/c02eec4ab5bdde5310baad610570a1a9697559838-1732698207216-41.png)\n\n```bash\n#重启\nsystemctl restart smb.service \n```\n\n用linux的smb客户端进行测试\n\n```\ndnf install -y samba-client\n```\n\n![image-20241127110308605](../img/Samba%E6%9C%8D%E5%8A%A1%E5%99%A8%E5%AE%9E%E6%88%98/308dd394ef1734fbd888f0f2be759431697559838-1732698207216-42.png)\n\n![image-20241127110418511](../img/Samba%E6%9C%8D%E5%8A%A1%E5%99%A8%E5%AE%9E%E6%88%98/0de632c049d81127f434ddb27f14d629697559838-1732698207216-43.png)\n\n刚好根据前面的配置文件\n\n```bash\n##允许访问的用户\nvalid users=qianyios, qianyios1\n##允许写入的用户\nwrite list=qianyios\n```\n\nqianyios可创建文件qianyios1不可以创建，但是可以读取文件\n\n### windows客户的测试\n\n由于之前做匿名测试连接\n\n要在cmd清理网络驱动器缓存\n\n```\nnet use * /del\n```\n\n![image-20241127110815836](../img/Samba%E6%9C%8D%E5%8A%A1%E5%99%A8%E5%AE%9E%E6%88%98/f931c126ff59ec70ac108644a8c41cc1697559838-1732698207216-44.png)\n\n![image-20241127110903495](../img/Samba%E6%9C%8D%E5%8A%A1%E5%99%A8%E5%AE%9E%E6%88%98/1e64aa6ffe7cb63b8c602e4349df21d6697559838-1732698207216-45.png)\n\n在qianyios用户下可以创建文件夹\n\n![image-20241127110927236](../img/Samba%E6%9C%8D%E5%8A%A1%E5%99%A8%E5%AE%9E%E6%88%98/cd1cbca8829c9780740fe38c9394ab3f697559838-1732698207216-46.png)\n\n用qianyios1试一下\n\n![image-20241127111029950](../img/Samba%E6%9C%8D%E5%8A%A1%E5%99%A8%E5%AE%9E%E6%88%98/ed497502d42661ac546f8c6dd19f3d1e697559838-1732698207216-47.png)\n\n可查看文件但不能创建文件\n\n![image-20241127111102850](../img/Samba%E6%9C%8D%E5%8A%A1%E5%99%A8%E5%AE%9E%E6%88%98/44aa217c0cbeadb5db805527ac933d16697559838-1732698207216-48.png)\n\n## Samba共享服务的账户名映射（账户别名登录）\n\n### 配置映射文件和Samba配置文件\n\n```\ncat > /etc/samba/smbusers <<\"EOF\"\nqianyios = qyos\nqianyios1 = qyos1\nEOF\n```\n\n```bash\nvim /etc/samba/smb.conf\n\n#添加以下内容在对应位置\nusername map = /etc/samba/smbusers\n```\n\n![image-20241127143636914](../img/Samba%E6%9C%8D%E5%8A%A1%E5%99%A8%E5%AE%9E%E6%88%98/87dccb8046521751a8fb4c6a1fece7dc697559838-1732698207216-49.png)\n\n重启服务\n\n```\n systemctl restart smb.service\n```\n\n### windows客户端测试\n\ncmd清理缓存\n\n```\nnet use * /del\n```\n\n![image-20241127144418512](../img/Samba%E6%9C%8D%E5%8A%A1%E5%99%A8%E5%AE%9E%E6%88%98/50fcf31a611d893cfbefb76405830281697559838-1732698207216-50.png)\n\nqyos可以登入\n\n![image-20241127144427418](../img/Samba%E6%9C%8D%E5%8A%A1%E5%99%A8%E5%AE%9E%E6%88%98/ac5da9c652a080898de1f9fe10b2d610697559838-1732698207216-51.png)\n\nqyos1也可以登入\n\n![image-20241127144805385](../img/Samba%E6%9C%8D%E5%8A%A1%E5%99%A8%E5%AE%9E%E6%88%98/b37c230b24ec42f47308b03457c3e726697559838-1732698207216-52.png)\n\n## Samba共享服务的访问控制列表\n\n禁止某个网段访问\n\nhosts deny=192.168.48.  ##添加拒绝192.168.48段访问share\n\n或者如果你想允许除了192.168.48.0/24之外的所有主机访问：\n\nhosts allow = ALL EXCEPT 192.168.48.\n\n```\nvim /etc/samba/smb.conf\n```\n\n```bash\n[share]\n        #设置共享路径\n        path = /abc\n        ##公共访问\n        # public=yes   #（删除公共访问）\n         ##能够访问\n        browseable=yes\n        ##写权限\n        #writable=yes  #（删除写入权限）\n        ##设置权限\n        create mask=0644\n        directory mask=0755\n        ##允许访问的用户\n        valid users=qianyios,qianyios1\n        ##允许写入的用户\n        write list=qianyios\n        ##添加拒绝192.168.48段访问share\n\t hosts deny=192.168.48.  \n```\n\n```bash\n##重启Samba服务\nsystemctl restart smb.service  \n```\n\nwindows就不测试了用linux的smb客户端来测试一下\n\n```\nsmbclient //192.168.48.101/share -U qyos\n```\n\n![image-20241127164357033](../img/Samba%E6%9C%8D%E5%8A%A1%E5%99%A8%E5%AE%9E%E6%88%98/021707c6b725ec020e7985e8d6836995697559838-1732698207216-53.png)\n\n我们本机是192.168.48.101的，因为禁用了192.168.48.0/24的网段访问，所以都访问不了\n\n## 将samba挂载到linux使用\n\n记得取消的禁止访问哦\n\n```bash\n#创建挂载点\nmkdir -p /opt/share\n#安装附属\nyum install cifs-utils  -y\n#将共享文件夹挂载到挂载点\nmount.cifs //192.168.48.101/share /opt/share -o username=qianyios\ndf -h\nls /opt/share\n```\n\n![image-20241127165315328](../img/Samba%E6%9C%8D%E5%8A%A1%E5%99%A8%E5%AE%9E%E6%88%98/2b8fad94cb15fa94683165f81211fa61697559838-1732698207216-54.png)\n\n已挂载成功\n\n<div class=\"tbsm\" style=\"margin-top:54px;\">\n<div class=\"tbsm-top\"><span><svg t=\"1674654360507\" class=\"icon\" viewBox=\"0 0 1024 1024\" version=\"1.1\" xmlns=\"http://www.w3.org/2000/svg\" p-id=\"987\" data-spm-anchor-id=\"a313x.7781069.0.i0\" width=\"35\" height=\"35\"><path d=\"M410.49 97.74H155.08a56.74 56.74 0 0 0-56.84 56.73V410a56.84 56.84 0 0 0 56.84 56.84h255.41A56.83 56.83 0 0 0 467.32 410V154.58a56.83 56.83 0 0 0-56.83-56.84zM410.49 558.74H155.08a56.74 56.74 0 0 0-56.84 56.73V871a56.84 56.84 0 0 0 56.84 56.84h255.41A56.83 56.83 0 0 0 467.32 871V615.58a56.83 56.83 0 0 0-56.83-56.84zM871.49 558.74H616.08a56.74 56.74 0 0 0-56.84 56.73V871a56.84 56.84 0 0 0 56.84 56.84h255.41A56.83 56.83 0 0 0 928.32 871V615.58a56.83 56.83 0 0 0-56.83-56.84z\" fill=\"#66EEFF\" p-id=\"988\"></path><path d=\"M410.49 558.74h-4.14A475 475 0 0 0 299.52 859.6a481.16 481.16 0 0 0 4.84 68.22h106.13A56.83 56.83 0 0 0 467.32 871V615.58a56.83 56.83 0 0 0-56.83-56.84zM871.49 558.74H616.08a56.74 56.74 0 0 0-56.84 56.73V871a56.84 56.84 0 0 0 56.84 56.84h255.41A56.83 56.83 0 0 0 928.32 871V615.58a56.83 56.83 0 0 0-56.83-56.84z\" fill=\"#C2F8FF\" p-id=\"989\"></path></svg></span><span style=\"font-size:30px;\"> 特别声明</span></div>\n<div class=\"tbsm-wz\">千屹博客旗下的所有文章，是通过本人课堂学习和课外自学所精心整理的知识巨著<br/>难免会有出错的地方<br/>如果细心的你发现了小失误，可以在下方评论区告诉我，或者私信我！<br />非常感谢大家的热烈支持！</div>\n</div>","tags":["Samba"],"categories":["运维"]},{"title":"OpenEuler22.03 LTS部署Zabbix","url":"/posts/1ca7aa3d/","content":"\n<meta name=\"referrer\" content=\"no-referrer\"/>\n\n# OpenEuler22.03 LTS部署Zabbix\n\n以下文档部分参考：[Zabbix 6.2 安装：国产系统篇（OpenEuler）-zabbix 5.0安装](https://www.51cto.com/article/722701.html)\n\n## 主机拓扑图\n\n| 主机名        | ip             | 硬盘 | cpu  | 备注   |\n| ------------- | -------------- | ---- | ---- | ------ |\n| zabbix-server | 192.168.48.101 | 100g | 2v   | 主控   |\n| zabbix-agent  | 192.168.48.102 | 100g | 2v   | 测试机 |\n\n## 基础配置\n\n操作节点：[server]\n\n不要一股脑的复制，注意修改网卡的名字，我这里是ens33，包括修改ip段，比如我的是`192.168.48.`你就要修改成你的`172.8.3.`最后那一个主机位就不用管，其他不变\n\n```bash\nvi system_init.sh\n```\n\n```shell\n#!/bin/bash\nif [ $# -eq 2 ];then\n  echo \"设置主机名为：$1\"\n  echo \"ens33设置IP地址为：192.168.48.$2\"\nelse\n  echo  \"使用方法：sh $0 主机名 主机位\"\n  exit 2\nfi\n\necho \"--------------------------------------\"\necho \"1.正在设置主机名：$1\"\nhostnamectl set-hostname $1\n\necho \"2.正在关闭firewalld、selinux\"\nsystemctl disable firewalld &> /dev/null\nsystemctl stop firewalld\nsed -i \"s#SELINUX=enforcing#SELINUX=disabled#g\" /etc/selinux/config\nsetenforce 0\n\n\necho \"3.正在设置ens33：192.168.48.$2\"\ncat > /etc/sysconfig/network-scripts/ifcfg-ens33 <<EOF\nTYPE=Ethernet\nPROXY_METHOD=none\nBROWSER_ONLY=no\nBOOTPROTO=static\nDEFROUTE=yes\nIPV4_FAILURE_FATAL=no\nIPV6INIT=yes\nIPV6_AUTOCONF=yes\nIPV6_DEFROUTE=yes\nIPV6_FAILURE_FATAL=no\nNAME=ens33\nUUID=53b402ff-5865-47dd-a853-7afcd6521738\nDEVICE=ens33\nONBOOT=yes\nIPADDR=192.168.48.$2\nGATEWAY=192.168.48.2\nPREFIX=24\nDNS1=192.168.48.2\nDNS2=114.114.114.114\nEOF\nnmcli c reload\nnmcli c up ens33\n\n\necho \"4.新增华为云源\"\nmkdir /etc/yum.repos.d/bak/\ncp /etc/yum.repos.d/* /etc/yum.repos.d/bak/\nsleep 3\n#切换为华为云，下载速度更快\nsed -i 's/\\$basearch/x86_64/g' /etc/yum.repos.d/openEuler.repo\nsed -i 's/http\\:\\/\\/repo.openeuler.org/https\\:\\/\\/mirrors.huaweicloud.com\\/openeuler/g' /etc/yum.repos.d/openEuler.repo\n\necho \"5.更新yum源软件包缓存\"\n yum clean all && yum makecache\n\necho \"6.添加hosts解析\"\ncat > /etc/hosts <<EOF\n127.0.0.1   localhost localhost.localdomain localhost4 localhost4.localdomain4\n::1         localhost localhost.localdomain localhost6 localhost6.localdomain6\n192.168.48.101 zabbix-server\n192.168.48.102 zabbix-agent\nEOF\n\necho \"7.安装chrony服务，并同步时间\"\nyum install chrony -y\nsystemctl enable chronyd --now\ntimedatectl set-timezone Asia/Shanghai\ntimedatectl set-local-rtc 1\ntimedatectl set-ntp yes\nchronyc -a makestep\nchronyc tracking\nchronyc sources\n\necho \"8.必备工具安装\"\nyum install wget psmisc vim net-tools telnet socat device-mapper-persistent-data lvm2 git gcc -y\n\necho \"9.重启\"\nreboot\n\n```\n\n运行\n\n```bash\nsh system_init.sh 主机名  主机位\n\n[zabbix-server] sh system_init.sh zabbix-server 101\n\n[zabbix-agent] sh system_init.sh zabbix-agent 102\n\n```\n\n## zabbix-server安装\n\n### zabbix服务段安装\n\n操作节点：[server]\n\n```bash\n#创建zabbix用户\ngroupadd --system zabbix\nuseradd --system -g zabbix -d /usr/lib/zabbix -s /sbin/nologin -c \"Zabbix Monitoring System\" zabbix\n#创建zabbix安装目录\nmkdir -p /app/zabbix\n```\n\n[下载 Zabbix 源码](https://www.zabbix.com/download_sources)\n\n![image-20241113000651160](../img/OpenEuler22.03%20LTS%E9%83%A8%E7%BD%B2Zabbix/49a030b3bf3a051bf26a6bdcbe1f64e255933597.png)\n\n```bash\n#server端下载源码包,你也可以手动下载上传到虚拟机即可，我是放到了root目录下\nwget https://cdn.zabbix.com/zabbix/sources/stable/7.0/zabbix-7.0.5.tar.gz\ntar -zxvf zabbix-7.*.tar.gz\n```\n\n开始编译安装\n\n- `prefix` 指定安装目录。\n- `enable-server` 启用 Zabbix Server。\n- `enable-agent` 启用 Zabbix agent。\n- `with-mysql` 后端指定数据库为mysql。\n- `net-snmp` 支持 snmp 协议。\n\n其实还有很多参数,大家可以参考 ./configure --help 自行研究 ，官方文档里也有案例\n\n```bash\n#安装需要的组件\ndnf -y install mysql-devel libevent-devel pcre-devel\n#开始编译（/app/zabbix）是zabbix的安装目录，以下编译会安装在/app/zabbix\nmv zabbix-7.0.5 zabbix && cd zabbix\n./configure --prefix=/app/zabbix --enable-server --enable-agent --with-mysql\n```\n\n出现这个页面是编译完成\n\n![image-20241113003302745](../img/OpenEuler22.03%20LTS%E9%83%A8%E7%BD%B2Zabbix/947a7ccd94bea32563c823c2f6d8513b55933597.png)\n\n```bash\n#开始安装\nmake && make install\n#安装完成！\n```\n\n![image-20241113003537003](../img/OpenEuler22.03%20LTS%E9%83%A8%E7%BD%B2Zabbix/5257a198e548d997c7fd18a99a686fd055933597.png)\n\n整体目录情况\n\n![image-20241113003611525](../img/OpenEuler22.03%20LTS%E9%83%A8%E7%BD%B2Zabbix/dfe08330e50249db5901faf896e6589d55933597.png)\n\n### PHP部分\n\nopenEuler 22.04 自带8.0版本，所以符合6.0以上版本的需求。\n\n![image-20241113003920331](../img/OpenEuler22.03%20LTS%E9%83%A8%E7%BD%B2Zabbix/65f8f2a540a55dbe58769fe925df07e355933597.png)\n\n```bash\ndnf -y install php php-fpm\n```\n\n### Apache\n\n由于安装PHP会自动安装apache（httpd）服务，所以安装过程并未提及apache的安装过程\n\n现在移动zabbix前端网页文件到/var/http/html（这是apache网页的运行根目录文件）\n\n```bash\n[root@zabbix-sever zabbix]# pwd\n/root/zabbix\n#我现在/root/zabbix是刚刚解压源码包的地方，别走错了，看你的位置在哪\ncd /root/zabbix\n#这个命令会递归地复制 ui 目录下的所有内容，包括子目录和文件，到 /var/www/html/ 目录中并且保留文件的权限和属性\ncp -rp ui/* /var/www/html/\n#启动apache\nsystemctl start httpd && systemctl enable httpd\nsystemctl start php-fpm && systemctl enable php-fpm\n```\n\n访问192.168.48.101\n\n选择中文\n\n![image-20241113004815682](../img/OpenEuler22.03%20LTS%E9%83%A8%E7%BD%B2Zabbix/ad59308fa51e608b7ba3d4102cc050cd55933597.png)\n\n这里显示有些php扩展没下载等\n\n![image-20241113004839965](../img/OpenEuler22.03%20LTS%E9%83%A8%E7%BD%B2Zabbix/d027395f9a7ea2887fd98ed3866170a155933597.png)\n\n```\ndnf -y install php-gd php-mysqlnd php-bcmath php-xml php-mbstring\n```\n\n安装完依赖此时不需要重启任何服务，接下来调整PHP的配置文件。\n\n根据报错来调整三个值分别是 `post_max_size`,`max_execution_time`,`max_input_time`。\n\n- 所要求的最小PHP post大小是16M (配置项\"post_max_size\")。\n- 所要求的最小PHP脚本执行时间是300 (配置项 \"max_execution_time\")。\n- 所要求的PHP脚本最小解析时间是300 (配置项\"max_input_time\")。\n\n```bash\n#一键修改命令\nsed -i 's/post_max_size = 8M/post_max_size = 16M/g' /etc/php.ini\nsed -i 's/max_execution_time = 30/max_execution_time = 300/g' /etc/php.ini\nsed -i 's/max_input_time = 60/max_input_time = 300/g' /etc/php.ini\n```\n\n改完之后需要重启php-fpm服务。\n\n```\nsystemctl restart php-fpm\n```\n\n刷新页面就ok了\n\n![image-20241113005733127](../img/OpenEuler22.03%20LTS%E9%83%A8%E7%BD%B2Zabbix/042bd7ef89e62f03bf6df00e095e972855933597.png)\n\n### 安装mysql\n\n#### 安装mysql\n\n```bash\ndnf -y install mysql-server\nsystemctl start mysqld && systemctl enable mysqld\nmysql_secure_installation\n\n#提示信息：VALIDATE PASSWORD COMPONENT can be u ····· gh. Would you like to setup VALIDATE PASSWORD component?\n#验证密码组件可用于测试密码和提高安全性。它检查密码的强度，并允许用户只设置那些足够安全的密码。要设置VALIDATE PASSWORD组件吗？\nPress y|Y for Yes, any other key for No: NO (填NO)\nNew password: \nRe-enter new password:\n#输入你的秘密，我这里是qianyios007\n#是否删除匿名用户\nRemove anonymous users?  (Press y|Y for Yes, any other key for No) : Y\n#是否禁止root用户远程登录\nDisallow root login remotely? (Press y|Y for Yes, any other key for No) : No\n#是否删除测试数据库？\nRemove test database and access to it? (Press y|Y for Yes, any other key for No) : Y\n#是否重新加载特权表吗？\nReload privilege tables now?  (Press y|Y for Yes, any other key for No) : Y\n\n# 验证登入数据库\nmysql -u root -pqianyios007\n\n```\n\n![image-20241113002206219](../img/OpenEuler22.03%20LTS%E9%83%A8%E7%BD%B2Zabbix/bc5f63fe3e98602ca6b7b5f91c7d80fe55933597.png)\n\n#### 创建Zabbix所需要的数据库和用户\n\n```bash\nmysql -u root -pqianyios007\n#创建一个名为zabbix的新数据库，并指定字符集为utf8mb4，排序规则为utf8mb4_bin。\ncreate database zabbix character set utf8mb4 collate utf8mb4_bin;\n#创建一个新用户zabbix，该用户只能从localhost连接，密码设置为123456。\ncreate user zabbix@localhost identified by '123456';\n#授予zabbix用户对zabbix数据库的所有表的所有权限。\ngrant all privileges on zabbix.* to zabbix@localhost;\n#设置全局变量log_bin_trust_function_creators为1，这允许创建存储函数时不受二进制日志的限制\nset global log_bin_trust_function_creators = 1;\nquit;\n```\n\n#### 导入Zbbix 的数据文件\n\n```bash\ncd /root/zabbix\ncat database/mysql/schema.sql | mysql -uzabbix -p123456 zabbix\ncat database/mysql/images.sql | mysql -uzabbix -p123456 zabbix\ncat database/mysql/data.sql | mysql -uzabbix -p123456 zabbix\nmysql -u root -pqianyios007\n#相关数据导入完成后关掉log_bin_trust_function_creators功能。\nset global log_bin_trust_function_creators = 0;\nquit;\n```\n\n完成这部分，就可以在前端进入数据库配配置界面。\n\n![image-20241113011128139](../img/OpenEuler22.03%20LTS%E9%83%A8%E7%BD%B2Zabbix/ab5ba4a44f0a35fd34f04be13e5e0d7955933597.png)\n\n![image-20241113011239994](../img/OpenEuler22.03%20LTS%E9%83%A8%E7%BD%B2Zabbix/73aeb632f7ed517bab752da75d11706a55933597.png)\n\n![image-20241113011250313](../img/OpenEuler22.03%20LTS%E9%83%A8%E7%BD%B2Zabbix/b236034d98b75d19563d32c44a8022f555933597.png)\n\n报错了，此时会出现无法创建，这是由于目标目录没有权限导致的，可以点击<font color='cornflowerblue'>蓝色字体(网页中下载配置文件)</font>将配置得好的文件下载下来，然后传到前端提示的目录里，该文这里路径为：\n\n```\n/var/www/html/conf/\n```\n\n![image-20241113011413414](../img/OpenEuler22.03%20LTS%E9%83%A8%E7%BD%B2Zabbix/b47c8262ee60d1dc80860c4deae796fe55933597.png)\n\n自行下载用工具传过去即可\n\n![image-20241113011854494](../img/OpenEuler22.03%20LTS%E9%83%A8%E7%BD%B2Zabbix/6e84e5ae52509a8f01279aa523251dd355933597.png)\n\n放过去之后刷新即可\n\n> <font color='red'>管理员用户名密码为Admin/zabbix</font>\n\n![image-20241113012114792](../img/OpenEuler22.03%20LTS%E9%83%A8%E7%BD%B2Zabbix/182897f98cbd0dc652868b0158b703b255933597.png)\n\n服务端安装成功!\n\n![image-20241113012126819](../img/OpenEuler22.03%20LTS%E9%83%A8%E7%BD%B2Zabbix/8640ed2d6b5405dbfb48e3d1a38341d355933597.png)\n\n### zabbix-server基本配置\n\n这里可以看姐server端是没有启动的，说明要对于他进行配置\n\n![image-20241113082126854](../img/OpenEuler22.03%20LTS%E9%83%A8%E7%BD%B2Zabbix/d0b1b11c6596b52a2c5b5995cf62985955933597.png)\n\n首先来说说zabbix server 目录的一些情况\n\n- 程序文件路径为/app/zabbix/sbin/\n- 配置文件路径为/app/zabbix/etc/\n\n1. 编辑配置文件\n\n```yaml\nsed -i 's|^LogFile=.*|LogFile=/var/log/zabbix/zabbix_server.log|' /app/zabbix/etc/zabbix_server.conf\nsed -i '/^# DBPassword=/a \\  DBPassword=123456' /app/zabbix/etc/zabbix_server.conf\nsed -i '/^# PidFile=\\/tmp\\/zabbix_server.pid$/a \\  PidFile=/var/log/zabbix/zabbix_server.pid' /app/zabbix/etc/zabbix_server.conf\n```\n\n2. 制作zabbix server守护文件\n\n```bash\ncat > /usr/lib/systemd/system/zabbix-server.service <<\"EOF\"\n[Unit]\nDescription=Zabbix Server\nAfter=syslog.target\nAfter=network.target\nAfter=postgresql.service\nAfter=pgbouncer.service\nAfter=postgresql-13.service\n\n[Service]\nEnvironment=\"CONFFILE=/app/zabbix/etc/zabbix_server.conf\"\nEnvironmentFile=-/etc/sysconfig/zabbix-server\nType=forking\nRestart=on-failure\n#pid文件要改哦，看你在哪个位置\nPIDFile=/var/log/zabbix/zabbix_server.pid\nKillMode=control-group\nExecStart=/app/zabbix/sbin/zabbix_server -c $CONFFILE\nExecStop=/bin/kill -SIGTERM $MAINPID\nRestartSec=10s\nTimeoutSec=0\n\n[Install]\nWantedBy=multi-user.target\nEOF\n```\n\n由于是源码编译安装，所以存放日志文件的目录不存在，所以需要自行创建和给予权限\n\n```bash\nmkdir /var/log/zabbix\nchown zabbix:zabbix /var/log/zabbix\n```\n\n启动zabbix-server和查看服务的状态。\n\n```bash\nsystemctl start zabbix-server && systemctl enable zabbix-server\nsystemctl status zabbix-server\n```\n\n![image-20241113083832700](../img/OpenEuler22.03%20LTS%E9%83%A8%E7%BD%B2Zabbix/55aefc3518aa2a6e2a40c1f18b982a3955933597.png)\n\n查看日志也正常\n\n```\ntail -f /var/log/zabbix/zabbix_server.log\n```\n\n![image-20241113084050766](../img/OpenEuler22.03%20LTS%E9%83%A8%E7%BD%B2Zabbix/cf3182ac66d49a911ed82e4ff42eb24755933597.png)\n\n查看网页已经在运行了\n![image-20241113084136313](../img/OpenEuler22.03%20LTS%E9%83%A8%E7%BD%B2Zabbix/e31a1197e294576aa3f2641537a70163697559838.png)\n\n## zabbix-agent安装\n\n### server端安装agent\n\n操作节点[server]\n\n```bash\n#制作 Zabbix agent 守护文件\ncat > /usr/lib/systemd/system/zabbix-agent.service<<\"EOF\"\n[Unit]\nDescription=Zabbix Agent\nAfter=syslog.target\nAfter=network.target\n[Service]\nEnvironment=\"CONFFILE=/app/zabbix/etc/zabbix_agentd.conf\"\nType=simple\nRestart=on-failure\n#PID文件要改\nPIDFile=/var/log/zabbix/zabbix_agentd.pid\nKillMode=control-group\nExecStart=/app/zabbix/sbin/zabbix_agentd -c $CONFFILE\nExecStop=/bin/kill -SIGTERM $MAINPID\nRestartSec=10s\nUser=zabbix\nGroup=zabbix\n[Install]\nWantedBy=multi-user.target\nEOF\n#修改agent配置文件也是和server一样修改日志文件和pid文件位置\nsed -i 's|^LogFile=.*|LogFile=/var/log/zabbix/zabbix_agentd.log|' /app/zabbix/etc/zabbix_agentd.conf\n\nsed -i '/^# PidFile=\\/tmp\\/zabbix_agentd.pid$/a \\  PidFile=/var/log/zabbix/zabbix_agentd.pid' /app/zabbix/etc/zabbix_agentd.conf\n#启动zabbix agent\nsystemctl daemon-reload\nsystemctl start zabbix-agent && systemctl enable zabbix-agent\n```\n\n> <font color='red'>这样在server主机的zabbix的server端和agent端已经安装好了，但是现在就是说只有一个agent端也就是本机，只能监控自己，现在就教你们去监控其他机子</font>\n\n![image-20241113143603974](../img/OpenEuler22.03%20LTS%E9%83%A8%E7%BD%B2Zabbix/9d09dd27353c1514fd817b4ca8af8818697559838.png)\n\n### 其他主机安装agent\n\n操作节点：[zabbix-agent]\n\n```bash\n#agent端下载源码包,你也可以手动下载上传到虚拟机即可，我是放到了root目录下\nwget https://cdn.zabbix.com/zabbix/sources/stable/7.0/zabbix-7.0.5.tar.gz\ntar -zxvf zabbix-7.*.tar.gz\n#创建zabbix用户\ngroupadd --system zabbix\nuseradd --system -g zabbix -d /usr/lib/zabbix -s /sbin/nologin -c \"Zabbix Monitoring System\" zabbix\n#创建zabbix安装目录\nmkdir -p /app/zabbix\n#安装需要的组件\ndnf -y install mysql-devel libevent-devel pcre-devel\n#开始编译（/app/zabbix）是zabbix的安装目录，以下编译会安装在/app/zabbix 这里只需要启用agent即可server不用\nmv zabbix-7.0.5 zabbix && cd zabbix\n./configure --prefix=/app/zabbix --enable-agent \n#开始安装\nmake install\n#修改配置文件\nsed -i 's|^LogFile=.*|LogFile=/var/log/zabbix/zabbix_agentd.log|' /app/zabbix/etc/zabbix_agentd.conf\nsed -i '/^# PidFile=\\/tmp\\/zabbix_agentd.pid$/a \\  PidFile=/var/log/zabbix/zabbix_agentd.pid' /app/zabbix/etc/zabbix_agentd.conf\n#修改测试机agent配置文件里的serve-ip，这里要填server机的ip（修改192.168.48.101即可）\nsed -i 's/Server=127.0.0.1/Server=192.168.48.101/g' /app/zabbix/etc/zabbix_agentd.conf\nsed -i 's/ServerActive=127.0.0.1/ServerActive=192.168.48.101/g' /app/zabbix/etc/zabbix_agentd.conf\n#zabbix-agent修改成你测试机的主机名\nsed -i 's/Hostname=Zabbix server/Hostname=zabbix-agent/g' /app/zabbix/etc/zabbix_agentd.conf\n\n#制作 Zabbix agent 守护文件\ncat > /usr/lib/systemd/system/zabbix-agent.service<<\"EOF\"\n[Unit]\nDescription=Zabbix Agent\nAfter=syslog.target\nAfter=network.target\n[Service]\nEnvironment=\"CONFFILE=/app/zabbix/etc/zabbix_agentd.conf\"\nType=simple\nRestart=on-failure\n#PID文件要改\nPIDFile=/var/log/zabbix/zabbix_agentd.pid\nKillMode=control-group\nExecStart=/app/zabbix/sbin/zabbix_agentd -c $CONFFILE\nExecStop=/bin/kill -SIGTERM $MAINPID\nRestartSec=10s\nUser=zabbix\nGroup=zabbix\n[Install]\nWantedBy=multi-user.target\nEOF\n#由于是源码编译安装，所以存放日志文件的目录不存在，所以需要自行创建和给予权限\nmkdir /var/log/zabbix\nchown zabbix:zabbix /var/log/zabbix\n#启动zabbix agent\nsystemctl daemon-reload\nsystemctl start zabbix-agent && systemctl enable zabbix-agent\n```\n\nzabbix页面配置测试机监控端\n\n![image-20241113150026254](../img/OpenEuler22.03%20LTS%E9%83%A8%E7%BD%B2Zabbix/7b2a2ff9084a796a1490d2d1ff0afb5b697559838.png)\n\n![image-20241113150133543](../img/OpenEuler22.03%20LTS%E9%83%A8%E7%BD%B2Zabbix/d72bc3471d4faf086a5786bf7982a72d697559838.png)\n\n![image-20241113150518858](../img/OpenEuler22.03%20LTS%E9%83%A8%E7%BD%B2Zabbix/9c745a1be14218cc8fec182d30c54701697559838.png)\n\n最终效果，点击添加即可\n\n![image-20241113150550231](../img/OpenEuler22.03%20LTS%E9%83%A8%E7%BD%B2Zabbix/8bf61dcdd9e7e18e502ba46213a734a4697559838.png)\n\n![image-20241113152007961](../img/OpenEuler22.03%20LTS%E9%83%A8%E7%BD%B2Zabbix/d9683d405ab9cfa7d529c6b1d58d0a5b697559838.png)\n\n测试端的机子已经添加好了\n\n## 测试\n\n### Zabbix Web 配置模板(监听 Port 80)\n\n操作节点：[zabbix-agent]\n\n#### 安装nginx并配置网页\n\n因为没有适配openeuler的版本，这里直接用centos8的来代替，兼容的没关系，你可以根据你的系统去自行替换\n\n```bash\ncat >/etc/yum.repos.d/nginx.repo << \"EOF\"\n[nginx-stable]\nname=nginx stable repo\n#baseurl=http://nginx.org/packages/centos/$releasever/$basearch/\n#原本是$releasever的，但是没有openeuler的版本直接用8来代替也就是centos8，openeuler兼容centos\nbaseurl=http://nginx.org/packages/centos/8/$basearch/\ngpgcheck=1\nenabled=1\ngpgkey=https://nginx.org/keys/nginx_signing.key\nmodule_hotfixes=true\n\n[nginx-mainline]\nname=nginx mainline repo\n#baseurl=http://nginx.org/packages/mainline/centos/$releasever/$basearch/\nbaseurl=http://nginx.org/packages/mainline/centos/8/$basearch/\ngpgcheck=1\nenabled=0\ngpgkey=https://nginx.org/keys/nginx_signing.key\nmodule_hotfixes=true\nEOF\nyum install nginx -y\nsystemctl enable nginx --now\n```\n\n这样就可以随时安装最新版本的nginx\n\n添加测试网页\n\n`/etc/nginx/conf.d/default.conf`\n\n```bash\n[root@zabbix-agent ~]# cat /etc/nginx/conf.d/default.conf\nserver {\n#80端口\n    listen       80;\n    server_name  localhost;\n\n    #access_log  /var/log/nginx/host.access.log  main;\n\n    location / {\n    #这里就是网站的根目录了\n        root   /usr/share/nginx/html;\n        index  index.html index.htm;\n    }\n    error_page   500 502 503 504  /50x.html;\n    location = /50x.html {\n        root   /usr/share/nginx/html;\n    }\n    #。。。。。\n}\n```\n\n直接修改80端口下的网站里面的内容\n\n```\nvim /usr/share/nginx/html/index.html\n```\n\n里面的内容全部删了,写入以下内容，然后保存退出即可\n\n```\n<h1>welcome to qianyios.blog</h1>\n```\n\n重启服务\n\n```\nnginx -s reload\n```\n\n![image-20241116181113300](../img/OpenEuler22.03%20LTS%E9%83%A8%E7%BD%B2Zabbix/757fe1ce34333c57d7b4d507eb8db740697559838.png)\n\n#### 配置80端口模板\n\n创建监控80端口状态的模板\n\n![image-20241116185125433](../img/OpenEuler22.03%20LTS%E9%83%A8%E7%BD%B2Zabbix/6e6a8c1481a46fe120dc4a1307ad9d48697559838.png)\n\n创建监控项\n\n![image-20241116201133039](../img/OpenEuler22.03%20LTS%E9%83%A8%E7%BD%B2Zabbix/7252cf1b23304a449061a6bcde24373b697559838.png)\n\n![image-20241116205532638](../img/OpenEuler22.03%20LTS%E9%83%A8%E7%BD%B2Zabbix/ed563023ab274f9a62403ee99b7503de697559838.png)\n\n创建触发器\n\n点击触发器，创建触发器\n\n![image-20241116201342794](../img/OpenEuler22.03%20LTS%E9%83%A8%E7%BD%B2Zabbix/7b5b4548528b33487f880c3c7443fdaf697559838.png)\n\n![image-20241116201548422](../img/OpenEuler22.03%20LTS%E9%83%A8%E7%BD%B2Zabbix/b33191927a10b59889e5c29b333fbb80697559838.png)\n\n创建图形\n\n![image-20241116201716163](../img/OpenEuler22.03%20LTS%E9%83%A8%E7%BD%B2Zabbix/df9becd1a23c51fb6875d041da3b6630697559838.png)\n\n![image-20241116201748272](../img/OpenEuler22.03%20LTS%E9%83%A8%E7%BD%B2Zabbix/325a8be80a46be5c23c862011d1955be697559838.png)\n\n#### 配置测试机应用80端口模板\n\n![image-20241116202908169](../img/OpenEuler22.03%20LTS%E9%83%A8%E7%BD%B2Zabbix/3f958de07947d70beffc35ed0cec8e9e697559838.png)\n\n更新一下\n\n![image-20241116204210574](../img/OpenEuler22.03%20LTS%E9%83%A8%E7%BD%B2Zabbix/5c88a77095f55137059019a0e7af3a1b697559838.png)\n\n#### 80端口模板测试\n\n![image-20241116205844643](../img/OpenEuler22.03%20LTS%E9%83%A8%E7%BD%B2Zabbix/cb0734669d4409483a6bcf2afbf4c529697559838.png)\n\n当我们模拟80端口down\n\n```\nsystemctl stop nginx\n```\n\n![image-20241116205932836](../img/OpenEuler22.03%20LTS%E9%83%A8%E7%BD%B2Zabbix/92dfcb1d1774bac8af5ab15fecdda2bc697559838.png)\n\n![image-20241116210138178](../img/OpenEuler22.03%20LTS%E9%83%A8%E7%BD%B2Zabbix/812219ac4a182e68dd4a161a1b0def8b697559838.png)\n\n然后我们再开起来\n\n```\nsystemctl start nginx\n```\n\n![image-20241116210022189](../img/OpenEuler22.03%20LTS%E9%83%A8%E7%BD%B2Zabbix/e83cbcb6a36d9638463775bf664d8141697559838.png)\n\n到此监测80端口成功\n\n<div class=\"tbsm\" style=\"margin-top:54px;\">\n<div class=\"tbsm-top\"><span><svg t=\"1674654360507\" class=\"icon\" viewBox=\"0 0 1024 1024\" version=\"1.1\" xmlns=\"http://www.w3.org/2000/svg\" p-id=\"987\" data-spm-anchor-id=\"a313x.7781069.0.i0\" width=\"35\" height=\"35\"><path d=\"M410.49 97.74H155.08a56.74 56.74 0 0 0-56.84 56.73V410a56.84 56.84 0 0 0 56.84 56.84h255.41A56.83 56.83 0 0 0 467.32 410V154.58a56.83 56.83 0 0 0-56.83-56.84zM410.49 558.74H155.08a56.74 56.74 0 0 0-56.84 56.73V871a56.84 56.84 0 0 0 56.84 56.84h255.41A56.83 56.83 0 0 0 467.32 871V615.58a56.83 56.83 0 0 0-56.83-56.84zM871.49 558.74H616.08a56.74 56.74 0 0 0-56.84 56.73V871a56.84 56.84 0 0 0 56.84 56.84h255.41A56.83 56.83 0 0 0 928.32 871V615.58a56.83 56.83 0 0 0-56.83-56.84z\" fill=\"#66EEFF\" p-id=\"988\"></path><path d=\"M410.49 558.74h-4.14A475 475 0 0 0 299.52 859.6a481.16 481.16 0 0 0 4.84 68.22h106.13A56.83 56.83 0 0 0 467.32 871V615.58a56.83 56.83 0 0 0-56.83-56.84zM871.49 558.74H616.08a56.74 56.74 0 0 0-56.84 56.73V871a56.84 56.84 0 0 0 56.84 56.84h255.41A56.83 56.83 0 0 0 928.32 871V615.58a56.83 56.83 0 0 0-56.83-56.84z\" fill=\"#C2F8FF\" p-id=\"989\"></path></svg></span><span style=\"font-size:30px;\"> 特别声明</span></div>\n<div class=\"tbsm-wz\">千屹博客旗下的所有文章，是通过本人课堂学习和课外自学所精心整理的知识巨著<br/>难免会有出错的地方<br/>如果细心的你发现了小失误，可以在下方评论区告诉我，或者私信我！<br />非常感谢大家的热烈支持！</div>\n</div>","tags":["Zabbix"],"categories":["运维"]},{"title":"Butterfly主题美化之路","url":"/posts/23d5be7c/","content":"\n<meta name=\"referrer\" content=\"no-referrer\"/>\n\n# Butterfly主题美化之路\n\n以下内容摘自[Butterfly - A Simple and Card UI Design theme for Hexo](https://butterfly.js.org/)\n\n## 安装主题\n\n在hexo根目录下执行\n\ngitee（适合中国大陆）\n\n```\ngit clone -b master https://gitee.com/immyw/hexo-theme-butterfly.git themes/butterfly\n```\n\ngithub（建议先用这个）\n\n```\ngit clone -b master https://github.com/jerryc127/hexo-theme-butterfly.git themes/butterfly\n```\n\n> 升级方法：在主题目录下，运行git pull\n\n也可以用npm方法安装\n\n```\nnpm install hexo-theme-butterfly\n```\n\n> 升级方法：在 Hexo 根目录下，运行 `npm update hexo-theme-butterfly`\n\n## 应用主题\n\n在hexo根目录写下的_config.yml有个theme：修改为以下\n\n```\ntheme: butterfly\n```\n\n如果你没有 pug 以及 stylus 的渲染器，请下载安装：\n\n```\nnpm install hexo-renderer-pug hexo-renderer-stylus hexo-butterfly-extjs --save \n```\n\n## Front-matter\n\nFront-matter 是 markdown 文件最上方以 --- 分隔的区域，用于指定个别档案的变数。\n\nPage Front-matter 用于 配置页面\nPost Front-matter 用于 配置文章页\n\n> 如果标注的参数，可根据自己需要添加，不用全部都写在 markdown 里 可选\n\n1. Page Front-matter\n\n```\n---\ntitle:\ndate:\nupdated:\ntype:\ncomments:\ndescription:\nkeywords:\ntop_img:\nmathjax:\nkatex:\naside:\naplayer:\nhighlight_shrink:\nrandom:\nlimit:\n  type:\n  value:\n---\n```\n\n| 参数             | 解释                                                         |\n| ---------------- | ------------------------------------------------------------ |\n| title            | 【必需】页面标题                                             |\n| date             | 【必需】页面创建日期                                         |\n| type             | 【必需】标签、分类和友情链接三个页面需要配置                 |\n| updated          | 【可选】页面更新日期                                         |\n| description      | 【可选】页面描述                                             |\n| keywords         | 【可选】页面关键词                                           |\n| comments         | 【可选】显示页面评论模块 （默认 true）                       |\n| top_img          | 【可选】页面顶部图片                                         |\n| mathjax          | 【可选】显示 mathjax （当设置 mathjax 的 per_page： false 时，才需要配置，默认 false） |\n| katex            | 【可选】显示 katex （当设置 katex 的 per_page： false 时，才需要配置，默认 false） |\n| aside            | 【可选】显示侧边栏 （默认 true）                             |\n| aplayer          | 【可选】在需要的页面加载 aplayer 的 js 和 css，请参考文章下面的 配置音樂 |\n| highlight_shrink | 【可选】配置代码框是否展开 （true/false） （默认为设置中 highlight_shrink 的配置） |\n| random           | 【可选】配置友情链接是否随机排序（默认为 false）             |\n| limit            | 【可选】配置说显示数量                                       |\n| limit.type       | 【可选】配置说显示数量的类型 （date 或者 num）               |\n| limit.value      | 【可选】配置说显示数量的值                                   |\n\n2. Post Front-matter\n\n```\n---\ntitle:\ndate:\nupdated:\ntags:\ncategories:\nkeywords:\ndescription:\ntop_img:\ncomments:\ncover:\ntoc:\ntoc_number:\ntoc_style_simple:\ncopyright:\ncopyright_author:\ncopyright_author_href:\ncopyright_url:\ncopyright_info:\nmathjax:\nkatex:\naplayer:\nhighlight_shrink:\naside:\nabcjs:\n---\n```\n\n| 写法                  | 解释                                                         |\n| --------------------- | ------------------------------------------------------------ |\n| title                 | 【必需】文章标题                                             |\n| date                  | 【必需】页面创建日期                                         |\n| updated               | 【可选】页面更新日期                                         |\n| description           | 【可选】页面描述                                             |\n| tags                  | 【可选】文章标签                                             |\n| keywords              | 【可选】页面关键词                                           |\n| top_img               | 【可选】页面顶部图片                                         |\n| categories            | 【可选】文章分类                                             |\n| cover                 | 【可选】文章缩略图（如果没有设置 top_img，文章页顶部将显示缩略图，可设为 false/图片地址/留空） |\n| comments              | 【可选】显示文章评论模块（默认 true）                        |\n| toc                   | 【可选】显示文章 TOC（默认为设置中 toc 的 enable 配置）      |\n| toc_number            | 【可选】显示 toc_number（默认为设置中 toc 的 number 配置）   |\n| toc_style_simple      | 【可选】显示 toc 简洁模式                                    |\n| copyright             | 【可选】显示文章版权模块（默认为设置中 post_copyright 的 enable 配置） |\n| copyright_author      | 【可选】文章版权模块的文章作者                               |\n| copyright_author_href | 【可选】文章版权模块的链接文章作者                           |\n| copyright_url         | 【可选】文章版权模块的链接文章链接                           |\n| copyright_info        | 【可选】文章版权模块的文字版权声明                           |\n| mathjax               | 【可选】显示 mathjax（当设置 mathjax 的 per_page： false 时，才需要配置，默认 false ） |\n| katex                 | 【可选】显示 katex （当设置 katex 的 per_page： false 时，才需要配置，默认 false ） |\n| aplayer               | 【可选】在需要的页面加载 aplayer 的 js 和 css，请参考文章下面的 配置音乐 |\n| highlight_shrink      | 【可选】配置代码框是否展开（true/false）（默认为设置中 highlight_shrink 的配置） |\n| aside                 | 【可选】显示侧边栏 （默认 true）                             |\n| abcjs                 | 【可选】加载 abcjs （当设置 abcjs 的 per_page： false 时，才需要配置，默认 false ） |\n\n## 标签页\n\n> 标签页文件名不一定是 tags， 例子中的 tags 只是一个示例\n> 记得添加 `type: \"tags\"`\n\n1. 前往你的 Hexo 的根目录\n\n2. 输入 `hexo new page tags`\n\n3. 你会找到 这个文件source/tags/index.md\n\n4. 修改此文档 ：\n\n```\n---\ntitle: 标签\ndate: 2018-01-05 00:00:00\ntype: \"tags\"\norderby: random\norder: 1\n---\n```\n\n![image-20241105124440059](../img/Butterfly%E4%B8%BB%E9%A2%98%E7%BE%8E%E5%8C%96%E4%B9%8B%E8%B7%AF/3370a63ac484df599c1e8a50c2fd5798697559838.png)\n\n| 参数    | 解释                                                         |\n| ------- | ------------------------------------------------------------ |\n| type    | 【必须】页面类型，必须为 tags                                |\n| orderby | 【可选】排序方式 ：<br/>random - 随机排序 / name - 标签名字排序 / length - 标签数量排序 |\n| order   | 【可选】排序次序： 1（升序），-1（降序）                     |\n\n## 分类页\n\n> 分类页文件名不一定是 categories， 例子中的 categories 只是一个示例\n> 记得添加 `type: \"categories\"`\n\n1. 前往你的 Hexo 的根目录\n2. 输入 `hexo new page categories`\n3. 你会找到 这个文件source/categories/index.md\n4. 修改此文档 ：\n\n```\n---\ntitle: 分类\ndate: 2024-11-05 12:44:54\ntype: \"categories\"\n---\n```\n\n![image-20241105124524423](../img/Butterfly%E4%B8%BB%E9%A2%98%E7%BE%8E%E5%8C%96%E4%B9%8B%E8%B7%AF/27b8cbdd42c35ba2150bdb500580d6be697559838.png)\n\n## 友情链接\n\n> 友情链接页文件名不一定是 link， 例子中的 link 只是一个示例\n> 记得添加 `type: \"link\"`\n\n1. 前往你的 Hexo 的根目录\n2. 输入 `hexo new page link`\n3. 你会找到 这个文件source/link/index.md\n4. 修改此文档 ：\n\n```\n---\ntitle: 友情链接\ndate: 2024-11-05 12:47:52\ntype: \"link\"\n---\n```\n\n在 Hexo 根目录中的 （如果没有 _data 文件夹，请自行创建），创建一个文件 `source/_data/link.yml`\n\n```\n- class_name: 友情链接\n  class_desc: 那些人，那些事\n  link_list:\n    - name: Hexo\n      link: https://hexo.io/zh-tw/\n      avatar: https://d33wubrfki0l68.cloudfront.net/6657ba50e702d84afb32fe846bed54fba1a77add/827ae/logo.svg\n      descr: 快速、簡單且強大的網誌框架\n\n- class_name: 网站\n  class_desc: 值得推荐的网站\n  link_list:\n    - name: 严千屹\n      link: https://blog.qianyios.top/\n      avatar: https://blog.qianyios.top/img/fluid.png\n      descr: 博客\n```\n\n## 404页面\n\n```\n# A simple 404 page\nerror_404:\n  enable: false\n  subtitle: '页面不存在'\n  background: /img/error-page.png\n```\n\n## 配置文件速读\n\n```\n# --------------------------------------\n# Hexo Butterfly Theme Configuration\n# If you have any questions, please refer to the documentation\n# Chinese: https://butterfly.js.org/\n# English: https://butterfly.js.org/en/\n# --------------------------------------\n\n# --------------------------------------\n# Navigation Settings\n# --------------------------------------\n\nnav:\n  # 导航栏 Logo 图片\n  logo:\n  # 是否显示标题\n  display_title: true\n  # 是否固定导航栏\n  fixed: false\n\nmenu:\n  # 首页: / || fas fa-home\n  # 列表||fas fa-list:\n  #   音乐: /music/ || fas fa-music\n  #   电影: /movies/ || fas fa-video\n  首页: / || fas fa-home\n  标签: /tags/ || fas fa-tags\n  分类: /categories/ || fas fa-folder-open\n  友链: /link/ || fas fa-link\n  列表 || fas fa-list || hide:\n    音乐: /music/ || fas fa-music\n    电影: /movies/ || fas fa-video\n\n# --------------------------------------\n# Code Blocks Settings\n# --------------------------------------\n\ncode_blocks:\n  # 代码块主题: darker / pale night / light / ocean / false\n  theme: light\n  # 是否使用 Mac 风格\n  macStyle: true\n  # 代码块高度限制（单位: px）\n  height_limit: 200\n  # 是否自动换行\n  word_wrap: false\n\n  # 工具栏\n  # 是否显示复制按钮\n  copy: true\n  # 是否显示语言标籤\n  language: true\n  # true: 收缩代码块 | false: 展开代码块 | none: 展开代码块并隐藏按钮\n  shrink: false\n  # 是否显示全屏显示代码块按钮\n  fullpage: false\n\n# 社交媒体链接\n# 格式:\n#   icon: 链接 || 描述 || 颜色\nsocial:\n  # fab fa-github: https://github.com/xxxxx || Github || '#24292e'\n  # fas fa-envelope: mailto:xxxxxx@gmail.com || Email || '#4a7dbe'\n\n# --------------------------------------\n# 图片设置\n# --------------------------------------\n\n# 网站的 favicon 图标\nfavicon: https://blog.qianyios.top/img/fluid.png\n# 头像设置\navatar:\n# 头像图片链接\n  img: https://blog.qianyios.top/img/fluid.png\n  # 是否启用头像效果\n  effect: true\n\n# 禁用所有横幅图片\ndisable_top_img: true\n\n# 如果页面未设置横幅，则显示默认的横幅图片\ndefault_top_img:\n\n# 主页的横幅图片\nindex_img:\n\n# 归档页的横幅图片\narchive_img:\n\n# 注意: 是标籤页（单个标籤），不是标籤页面（所有标籤）\ntag_img:\n\n# 标籤页的横幅图片，可以为每个标籤设置横幅图片\n# 格式:\n#  - 标籤名: 图片链接\ntag_per_img:\n\n# 注意: 是分类页（单个分类），不是分类页面（所有分类）\ncategory_img:\n\n# 分类页的横幅图片，可以为每个分类设置横幅图片\n# 格式:\n#  - 分类名: 图片链接\n# Format:\n#  - category name: xxxxx\ncategory_per_img:\n\n# 页脚的背景图片\nfooter_img: false\n\n# 网站背景\n# 可以设置为颜色或图片\n# 图片格式: url(http://xxxxxx.com/xxx.jpg)\nbackground:\n\n# 封面设置\ncover:\n  # 是否禁用封面\n  index_enable: true\n  aside_enable: true\n  archives_enable: true\n  # 当未设置封面时，显示默认封面\n  default_cover:\n    # - xxx.jpg\n\n# 替换损坏的图片\nerror_img:\n# 友链页面的错误图片\n  flink: /img/friend_404.gif\n# 文章页面的错误图片\n  post_page: /img/404.jpg\n\n# 简单的 404 页面\nerror_404:\n  # 是否启用 404 页面\n  enable: false\n  # 404 页面的副标题\n  subtitle: '页面不存在！'\n  # 404 页面的卡片背景图片\n  background: /img/error-page.png\n\n# 文章元数据设置\npost_meta:\n  # 主页页面\n  page:\n    # 日期类型: created / updated / both\n    date_type: created\n    # 日期格式: date / relative\n    date_format: date\n    # 是否显示分类\n    categories: true\n    # 是否显示标籤\n    tags: false\n    # 是否显示文字标籤\n    label: true\n\n  # 文章页面\n  post:\n    # 元数据位置: left / center\n    position: left\n    # 日期类型: created / updated / both\n    date_type: both\n    # 日期格式: date / relative\n    date_format: date\n    categories: true\n    tags: true\n    label: true\n\n# --------------------------------------\n# 首页设置\n# --------------------------------------\n\n# 首页头图的设置\n# 默认: 头图全屏，站点信息在中间\n# 站点信息的位置，例如: 300px/300em/300rem/10%\nindex_site_info_top:\n# 头图的高度，例如: 300px/300em/300rem\nindex_top_img_height:\n\n# 首页的副标题设置\nsubtitle:\n  # 是否启用副标题\n  enable: false\n  # 是否启用打字机效果\n  effect: true\n  # 自定义 typed.js\n  # https://github.com/mattboldt/typed.js/#customization\n  typed_option:\n  # 来源 - 调用第三方服务 API（仅限中文）\n  # 它将首先显示来源，然后显示副标题内容\n  # 选择: false/1/2/3\n  # false - 禁用此功能\n  # 1 - hitokoto.cn\n  # 2 - yijuzhan.com\n  # 3 - jinrishici.com\n  source: false\n  # 如果关闭打字机效果，副标题将仅显示 sub 的第一行内容\n  sub:\n\n#首页上的文章布局\n# 1：封面在左边，信息在右边\n# 2：封面在右边，信息在左边\n# 3：封面和信息在左右交替\n# 4：封面在上面，信息在下面\n# 5：信息显示在封面上\n# 6：砌体布局——覆盖在顶部，信息在底部\n# 7：砌体布局-信息显示在封面上\nindex_layout: 3\n\n# 在首页显示文章简介\n# 1: 描述\n# 2: 两者（如果存在描述，将显示描述，否则显示自动摘要）\n# 3: 自动摘要（默认）\n# false: 不显示文章简介\nindex_post_content:\n  method: 1\n  # If you set method to 2 or 3, the length need to config\n  length: 500\n\n# --------------------------------------\n# 文章设置\n# --------------------------------------\n\ntoc:\n# 是否在文章中显示目录\n  post: true\n# 是否在文章中显示目录\n  page: false\n# 是否显示目录编号\n  number: true\n# 是否默认展开目录\n  expand: false\n  # 是否使用简洁风格（仅适用于文章）\n  style_simple: false\n    # 是否显示滚动百分比\n  scroll_percent: true\n\npost_copyright:\n# 是否启用版权声明\n  enable: true\n  # 是否进行文章 URL 解码\n  decode: false\n  # 作者链接\n  author_href: https://blog.qianyios.top\n  license: CC BY-NC-SA 4.0\n  license_url: https://creativecommons.org/licenses/by-nc-sa/4.0/\n\n# 赞助/打赏\nreward:\n# 是否启用打赏\n  enable: false\n  # 打赏案例文本\n  text:\n  QR_code:\n    # - img: /img/wechat.jpg\n    #   link:\n    #   text: wechat\n    # - img: /img/alipay.jpg\n    #   link:\n    #   text: alipay\n\n# 文章编辑\n# 轻鬆在线浏览和编辑博客源代码\npost_edit:\n# 是否启用在线编辑\n  enable: false\n  # url: https://github.com/user-name/repo-name/edit/branch-name/subdirectory-name/\n  # For example: https://github.com/jerryc127/butterfly.js.org/edit/main/source/\n  url:\n\n# 相关文章\nrelated_post:\n# 是否显示相关文章\n  enable: false\n  # 显示的文章数量\n  limit: 6\n  # Choose: created / updated\n  date_type: created\n\n# 选择: 1 / 2 / false\n# 1: “下一篇文章”将链接到旧文章\n# 2: “下一篇文章”将链接到新文章\n# false: 禁用分页\npost_pagination: 1\n\n# 显示文章过期通知\nnoticeOutdate:\n  # 是否启用过期通知\n  enable: true\n  # Style: simple / flat\n  style: flat\n  # 多少天后显示通知\n  limit_day: 365\n  # Position: top / bottom\n  position: top\n  message_prev: 已经过了\n  message_next: 天自上次更新，文章内容可能已过时。\n\n# --------------------------------------\n# 页脚设置\n# --------------------------------------\nfooter:\n  owner:\n    enable: true\n    since: 2024\n  # 自定义文本\n  custom_text: 严千屹博客\n  # Copyright of theme and framework\n  copyright: true\n\n# --------------------------------------\n# 侧边栏设置\n# --------------------------------------\n\naside:\n# 是否启用侧边栏\n  enable: true\n  # 是否默认隐藏侧边栏\n  hide: false\n  # 是否在右下角显示隐藏侧边栏的按钮\n  button: true\n  # 移动设备上是否启用侧边栏\n  mobile: true\n   # 侧边栏位置：left / right\n  position: right\n  display:\n    # 归档页面是否显示侧边栏\n    archive: true\n    # 标籤页面是否显示侧边栏\n    tag: true\n    # 分类页面是否显示侧边栏\n    category: true\n  card_author:\n  # 是否显示作者信息卡片\n    enable: true\n    # 作者描述\n    description:\n    button:\n    # 是否显示按钮\n      enable: false\n      icon: fab fa-github\n      text: Follow Me\n      link: https://github.com/xxxxxx\n  card_announcement:\n  # 是否显示公告卡片\n    enable: true\n    # 公告内容\n    content: 鄙人初耕运维门道，华为云计算hcip证书获得者，往后深耕Linux，docker，k8s运维。\n  card_recent_post:\n  # 是否显示最近文章卡片\n    enable: true\n    # 显示文章数量，0 表示显示所有\n    limit: 5\n      # 排序方式：date / updated\n    sort: date\n    sort_order:\n  card_newest_comments:\n  # 是否显示最新评论卡片\n    enable: false\n    sort_order:\n    # 显示评论数量\n    limit: 6\n     # 单位：分钟，保存数据到 localStorage\n    storage: 10\n     # 是否显示头像\n    avatar: true\n  card_categories:\n   # 是否显示分类卡片\n    enable: true\n    # 显示分类数量，0 表示显示所有\n    limit: 8\n    # Choose: none / true / false\n    expand: none\n    sort_order:\n  card_tags:\n  # 是否显示标籤卡片\n    enable: true\n    # 显示标籤数量，0 表示显示所有\n    limit: 40\n    # 是否启用颜色\n    color: false\n    # 标籤排序方式：random/name/length\n    orderby: random\n    # 排序顺序：1 表示升序，-1 表示降序\n    order: 1\n    sort_order:\n  card_archives:\n      # 是否显示归档卡片\n    enable: true\n    # 归档类型：monthly / yearly\n    type: monthly\n    # 日期格式，例如：YYYY年MM月\n    format: MMMM YYYY\n    # 排序顺序：1 表示升序，-1 表示降序\n    order: -1\n    # 显示归档数量，0 表示显示所有\n    limit: 8\n    sort_order:\n  card_post_series:\n  # 是否显示系列文章卡片\n    enable: true\n    # 标题显示系列名称\n    series_title: false\n    # 排序方式：title 或 date\n    orderBy: 'date'\n    # 排序顺序：1 表示升序，-1 表示降序\n    order: -1\n  card_webinfo:\n  # 是否显示网站信息卡片\n    enable: true\n    # 是否显示文章数量\n    post_count: true\n    # 是否显示最后推送日期\n    last_push_date: true\n    sort_order:\n    # 发佈日期与当前日期的时间差\n    # 格式：Month/Day/Year Time 或 Year/Month/Day Time\n    # 如果不启用此功能，请留空\n    runtime_date:\n\n# --------------------------------------\n# 右下角按钮设置\n# --------------------------------------\n\n# 右下角按钮与底部的距离（默认单位：px）\nrightside_bottom:\n\n# 简繁转换设置\ntranslate:\n# 是否启用简繁转换\n  enable: false\n  # 按钮文本\n  default: 繁\n  # 网站语言（1 - 繁体中文 / 2 - 简体中文）\n  defaultEncoding: 2\n  # 转换延迟\n  translateDelay: 0\n  # 按钮在简体中文时的文本\n  msgToTraditionalChinese: '繁'\n  # 按钮在繁体中文时的文本\n  msgToSimplifiedChinese: '簡'\n\n#閲读模式\nreadmode: true\n\n# 暗黑模式设置\ndarkmode:\n# 是否启用暗黑模式\n  enable: true\n  # 切换暗黑/明亮模式的按钮\n  button: true\n  # 是否自动切换暗黑/明亮模式\n  # autoChangeMode: 1  跟随系统设置，如果系统不支持暗黑模式，则在晚上 6 点到早上 6 点之间切换暗黑模式\n  # autoChangeMode: 2  在晚上 6 点到早上 6 点之间切换暗黑模式\n  # autoChangeMode: false  不自动切换\n  autoChangeMode: false\n  # 设置明亮模式时间，值在 0 到 24 之间。如果未设置，默认值为 6 和 18 \n  start:\n  end:\n\n# 在返回顶部按钮中显示滚动百分比\nrightside_scroll_percent: false\n\n# 不要修改以下设置，除非你知道它们的工作原理\n# 选择：readmode,translate,darkmode,hideAside,toc,chat,comment\n# 不要重複相同的值\nrightside_item_order:\n# 是否启用右侧项目顺序\n  enable: false\n  # 隐藏的默认项目：readmode,translate,darkmode,hideAside\n  hide:\n  # 显示的默认项目：toc,chat,comment\n  show:\n\n# --------------------------------------\n# 全局设置\n# --------------------------------------\n\n# 锚点设置\nanchor:\n  # 滚动时，URL 将根据标题 ID 更新\n  auto_update: false\n # 点击标题滚动并更新锚点\n  click_to_scroll: false\n# 图片标题\nphotofigcaption: false\n# 複制设置\ncopy:\n# 是否启用複制功能\n  enable: true\n  # 在複制的内容后添加版权信息\n  copyright:\n    enable: true\n    # 当複制字符数超过 limit_count 时添加版权信息\n    limit_count: 150\n\n# 需要安装 hexo-wordcount 插件\nwordcount:\n# 是否启用字数统计\n  enable: true\n  # 在文章元信息中显示字数统计\n  post_wordcount: true\n  # 在文章元信息中显示閲读时间\n  min2read: true\n  # 在侧边栏网站信息中显示总字数\n  total_wordcount: true\n\n# 不蒜子 PV / UV 统计\nbusuanzi:\n  site_uv: true\n  site_pv: true\n  page_pv: true\n\n# --------------------------------------\n# 数学公式设置\n# --------------------------------------\n\n# 关于 per_page\n# 如果设置为 true，将在每个页面加载 mathjax/katex 脚本\n# 如果设置为 false，将根据你的设置加载 mathjax/katex 脚本（在页面的 front-matter 中添加 'mathjax: true' 或者 'katex: true'）\nmath:\n  # 选择：mathjax, katex\n  # 如果不需要数学公式，保持为空\n  use:\n  per_page: true\n  hide_scrollbar: false\n\n  mathjax:\n    # 启用上下文菜单\n    enableMenu: true\n    # 选择：all / ams / none，这控制是否对公式编号以及如何编号\n    tags: none\n\n  katex:\n    # 启用複制 KaTeX 公式\n    copy_tex: false\n\n# --------------------------------------\n# 搜索设置\n# --------------------------------------\n\nsearch:\n  # 选择：algolia_search / local_search / docsearch\n  # 如果不需要搜索功能，保持为空\n  use:\n  placeholder:\n\n  # Algolia 搜索\n  algolia_search:\n    # 每页搜索结果数量\n    hitsPerPage: 6\n\n  # 本地搜索\n  local_search:\n    # 页面加载时预加载搜索数据\n    preload: false\n    # 每篇文章显示的顶部 n 个搜索结果，设置为 -1 显示所有结果\n    top_n_per_article: 1\n    # 将 HTML 字符串反转义为可读内容\n    unescape: false\n    CDN:\n\n  # Docsearch\n  # https://docsearch.algolia.com/\n  docsearch:\n    appId:\n    apiKey:\n    indexName:\n    option:\n\n# --------------------------------------\n# 分享系统\n# --------------------------------------\n\nshare:\n  # 选择：sharejs / addtoany\n  # 如果不需要分享功能，保持为空\n  use: sharejs\n\n  # Share.js\n  # https://github.com/overtrue/share.js\n  sharejs:\n    sites: facebook,twitter,wechat,weibo,qq\n\n  # AddToAny\n  # https://www.addtoany.com/\n  addtoany:\n    item: facebook,twitter,wechat,sina_weibo,facebook_messenger,email,copy_link\n\n# --------------------------------------\n# 评论系统\n# --------------------------------------\n\ncomments:\n  # 最多两个评论系统，第一个将作为默认显示\n  # 如果不需要评论功能，保持为空\n  # 选择：Disqus/Disqusjs/Livere/Gitalk/Valine/Waline/Utterances/Facebook Comments/Twikoo/Giscus/Remark42/Artalk\n  # 两个评论系统的格式：Disqus,Waline\n  use:\n  # 按钮旁边显示评论系统名称\n  text: true\n  # 懒加载：评论系统将在评论元素进入浏览器视口时加载\n  # 如果设置为 true，评论计数将无效\n  lazyload: false\n  # 在文章顶部图片中显示评论计数\n  count: false\n  # 在主页显示评论计数\n  card_post_count: false\n\n# Disqus\n# https://disqus.com/\ndisqus:\n  shortname:\n  # For newest comments widget\n  apikey:\n\n# Alternative Disqus - Render comments with Disqus API\n# https://github.com/SukkaW/DisqusJS\ndisqusjs:\n  shortname:\n  apikey:\n  option:\n\n# Livere\n# https://www.livere.com/\nlivere:\n  uid:\n\n# Gitalk\n# https://github.com/gitalk/gitalk\ngitalk:\n  client_id:\n  client_secret:\n  repo:\n  owner:\n  admin:\n  option:\n\n# Valine\n# https://valine.js.org\nvaline:\n  appId:\n  appKey:\n  avatar: monsterid\n  # This configuration is suitable for domestic custom domain name users, overseas version will be automatically detected (no need to manually fill in)\n  serverURLs:\n  bg:\n  # Use Valine visitor count as the page view count\n  visitor: false\n  option:\n\n# Waline - A simple comment system with backend support fork from Valine\n# https://waline.js.org/\nwaline:\n  serverURL:\n  bg:\n  # Use Waline pageview count as the page view count\n  pageview: false\n  option:\n\n# Utterances\n# https://utteranc.es/\nutterances:\n  repo:\n  # Issue Mapping: pathname/url/title/og:title\n  issue_term: pathname\n  # Theme: github-light/github-dark/github-dark-orange/icy-dark/dark-blue/photon-dark\n  light_theme: github-light\n  dark_theme: photon-dark\n  js:\n  option:\n\n# Facebook Comments Plugin\n# https://developers.facebook.com/docs/plugins/comments/\nfacebook_comments:\n  app_id:\n  # optional\n  user_id:\n  pageSize: 10\n  # Choose: social / time / reverse_time\n  order_by: social\n  lang: en_US\n\n# Twikoo\n# https://github.com/imaegoo/twikoo\ntwikoo:\n  envId:\n  region:\n  # Use Twikoo visitor count as the page view count\n  visitor: false\n  option:\n\n# Giscus\n# https://giscus.app/\ngiscus:\n  repo:\n  repo_id:\n  category_id:\n  light_theme: light\n  dark_theme: dark\n  js:\n  option:\n\n# Remark42\n# https://remark42.com/docs/configuration/frontend/\nremark42:\n  host:\n  siteId:\n  option:\n\n# Artalk\n# https://artalk.js.org/guide/frontend/config.html\nartalk:\n  server:\n  site:\n  # Use Artalk visitor count as the page view count\n  visitor: false\n  option:\n\n# --------------------------------------\n# 聊天服务配置\n# --------------------------------------\n\nchat:\n  # 聊天服务类型，可选值：chatra/tidio/crisp，如果不需要聊天功能则留空\n  use: \n  # 推荐使用聊天按钮，会在网站右下角创建一个按钮，并隐藏原始按钮\n  rightside_button: false\n  # 原始聊天按钮在向上滚动时显示，向下滚动时隐藏\n  button_hide_show: false\n\n# https://chatra.io/\nchatra:\n  id:\n\n# https://www.tidio.com/\ntidio:\n  public_key:\n\n# https://crisp.chat/en/\ncrisp:\n  website_id:\n\n# --------------------------------------\n# 分析服务配置\n# --------------------------------------\n\n# https://tongji.baidu.com/web/welcome/login\nbaidu_analytics:\n\n# https://analytics.google.com/analytics/web/\ngoogle_analytics:\n\n# https://www.cloudflare.com/zh-tw/web-analytics/\ncloudflare_analytics:\n\n# https://clarity.microsoft.com/\nmicrosoft_clarity:\n\n# https://umami.is/\numami_analytics:\n  enable: false\n  # For self-hosted setups, configure the hostname of the Umami instance\n  serverURL:\n  website_id:\n  option:\n  UV_PV:\n    site_uv: false\n    site_pv: false\n    page_pv: false\n    # Umami Cloud (API key) / self-hosted Umami (token)\n    token:\n\n# --------------------------------------\n# 广告配置\n# --------------------------------------\n\n# Google Adsense\ngoogle_adsense:\n  enable: false\n  auto_ads: true\n  js: https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js\n  client:\n  enable_page_level_ads: true\n\n# Insert ads manually\n# Leave it empty if you don't need ads\nad:\n  # Insert ads in the index (every three posts)\n  index:\n  # Insert ads in aside\n  aside:\n  # Insert ads in the post (before pagination)\n  post:\n\n# --------------------------------------\n# 站点验证配置\n# --------------------------------------\n\n\nsite_verification:\n  # - name: google-site-verification\n  #   content: xxxxxx\n  # - name: baidu-site-verification\n  #   content: xxxxxxx\n\n# --------------------------------------\n# 美化 / 效果\n# --------------------------------------\n# 主题颜色自定义\n# 注意：颜色值必须用双引号，如 \"#000\"，否则可能会导致错误！\n# 主题颜色配置\n# theme_color:\n#   是否启用主题颜色\n#   enable: true\n#   主颜色\n#   main: \"#49B1F5\"\n#   分页器颜色\n#   paginator: \"#00c4b6\"\n#   按钮悬停颜色\n#   button_hover: \"#FF7242\"\n#   文本选择颜色\n#   text_selection: \"#00c4b6\"\n#   链接颜色\n#   link_color: \"#99a9bf\"\n#   元数据颜色\n#   meta_color: \"#858585\"\n#   水平线颜色\n#   hr_color: \"#A4D8FA\"\n#   代码前景色\n#   code_foreground: \"#F47466\"\n#   代码背景色\n#   code_background: \"rgba(27, 31, 35, .05)\"\n#   目录颜色\n#   toc_color: \"#00c4b6\"\n#   引用块填充颜色\n#   blockquote_padding_color: \"#49b1f5\"\n#   引用块背景颜色\n#   blockquote_background_color: \"#49b1f5\"\n#   滚动条颜色\n#   scrollbar_color: \"#49b1f5\"\n#   浅色模式下的主题颜色\n#   meta_theme_color_light: \"ffffff\"\n#   深色模式下的主题颜色\n#   meta_theme_color_dark: \"#0d0d0d\"\n\n# 分类和标籤页面的用户界面设置\n# 选择：index - 与主页 UI 相同 / default - 与归档 UI 相同\n# 留空或设置为 index\ncategory_ui:\ntag_ui:\n\n# Rounded corners for UI elements\nrounded_corners_ui: true\n\n# 拉伸行使每行宽度相等\ntext_align_justify: false\n\n# 为页眉和页脚添加遮罩\nmask:\n  header: true\n  footer: true\n\n# 加载动画\npreloader:\n  enable: false\n  # 资源\n  # 1. 全屏加载\n  # 2. 进度条\n  source: 1\n  # pace theme (see https://codebyzach.github.io/pace/)\n  pace_css_url:\n\n# 页面过渡效果\nenter_transitions: true\n\n# 默认显示模式 - light (默认) / dark\ndisplay_mode: light\n\n# 美化文章内容的配置\nbeautify:\n  # 是否启用美化\n  enable: false\n  # 指定美化的范围 (site 或 post)\n  field: post\n  # 指定标题前缀图标，如 '\\f0c1'\n  title-prefix-icon:\n  # 指定标题前缀图标的颜色，如 '#F47466'\n  title-prefix-icon-color:\n\n# 全局字体设置\n# 除非您知道它们的工作原理，否则不要修改以下设置\nfont:\n  global_font_size:\n  code_font_size:\n  font_family:\n  code_font_family:\n\n# 网站标题和副标题的字体设置\nblog_title_font:\n  font_link:\n  font_family:\n\n# 分隔符图标的设置\nhr_icon:\n# 是否启用分隔符图标\n  enable: true\n  # Font Awesome 图标的 unicode 值，如 '\\3423'\n  icon:\n  icon_top:\n\n# 打字机效果\n# https://github.com/disjukr/activate-power-mode\nactivate_power_mode:\n  # 是否启用打字机效果\n  enable: false\n  # 是否启用彩色效果\n  colorful: true\n  # 是否启用震动效果\n  shake: true\n  # 是否在移动设备上启用\n  mobile: false\n\n# 背景效果\n# --------------------------------------\n\n# canvas_ribbon\n# 参见: https://github.com/hustcc/ribbon.js\ncanvas_ribbon:\n  # 是否启用 canvas_ribbon\n  enable: false\n  # ribbon 的大小\n  size: 150\n  # ribbon 的不透明度 (0 ~ 1)\n  alpha: 0.6\n  zIndex: -1\n  # 是否点击更改颜色\n  click_to_change: false\n  # 是否在移动设备上启用\n  mobile: false\n\n# Fluttering Ribbon\ncanvas_fluttering_ribbon:\n  enable: false\n  mobile: false\n\n# canvas_nest\n# https://github.com/hustcc/canvas-nest.js\ncanvas_nest:\n  # 是否启用 canvas_nest\n  enable: true\n  # 线条颜色，默认: '0,0,0'; RGB 值: (R,G,B).(注意: 使用 ',' 分隔.)\n  color: '0,0,255'\n  # 线条的不透明度 (0~1)\n  opacity: 0.7\n  # 背景的 z-index 属性\n  zIndex: -1\n  # 线条数量\n  count: 99\n  # 是否在移动设备上启用\n  mobile: false\n\n# 鼠标点击效果: 烟花\nfireworks:\n  # 是否启用烟花效果\n  enable: true\n  zIndex: 9999\n  # 是否在移动设备上启用\n  mobile: false\n\n# 鼠标点击效果: 心形符号\nclick_heart:\n  # 是否启用心形符号效果\n  enable: false\n  # 是否在移动设备上启用\n  mobile: false\n\n# 鼠标点击效果: 文字\nclickShowText:\n  # 是否启用文字效果\n  enable: false\n  text:\n    # - I\n    # - LOVE\n    # - YOU\n  fontSize: 15px\n  # 是否随机显示文字\n  random: false\n  # 是否在移动设备上启用\n  mobile: false\n\n# --------------------------------------\n# Lightbox Settings\n# --------------------------------------\n\n# Choose: fancybox / medium_zoom\n# https://github.com/francoischalifour/medium-zoom\n# https://fancyapps.com/fancybox/\n# Leave it empty if you don't need lightbox\nlightbox:\n\n# --------------------------------------\n# 标籤外挂设置\n# --------------------------------------\n\n# 系列\nseries:\n# 是否启用系列\n  enable: false\n  # 按标题或日期排序\n  orderBy: 'title'\n  # 排序顺序：1 表示升序，-1 表示降序\n  order: 1\n  number: true\n\n# ABCJS - ABC 音乐符号插件\n# https://github.com/paulrosen/abcjs\nabcjs:\n  enable: false\n  per_page: true\n\n# Mermaid\n# https://github.com/mermaid-js/mermaid\nmermaid:\n  enable: false\n  # Write Mermaid diagrams using code blocks\n  code_write: false\n  # built-in themes: default / forest / dark / neutral\n  theme:\n    light: default\n    dark: dark\n\n# chartjs\n# see https://www.chartjs.org/docs/latest/\nchartjs:\n  enable: false\n  # Do not modify unless you understand how they work.\n  # The default settings are only used when the MD syntax is not specified.\n  # General font color for the chart\n  fontColor:\n    light: 'rgba(0, 0, 0, 0.8)'\n    dark: 'rgba(255, 255, 255, 0.8)'\n  # General border color for the chart\n  borderColor:\n    light: 'rgba(0, 0, 0, 0.1)'\n    dark: 'rgba(255, 255, 255, 0.2)'\n  # Background color for scale labels on radar and polar area charts\n  scale_ticks_backdropColor:\n    light: 'transparent'\n    dark: 'transparent'\n\n# Note - Bootstrap Callout\nnote:\n  # Note tag style values:\n  #  - simple    bs-callout old alert style. Default.\n  #  - modern    bs-callout new (v2-v3) alert style.\n  #  - flat      flat callout style with background, like on Mozilla or StackOverflow.\n  #  - disabled  disable all CSS styles import of note tag.\n  style: flat\n  icons: true\n  border_radius: 3\n  # Offset lighter of background in % for modern and flat styles (modern: -12 | 12; flat: -18 | 6).\n  # Offset also applied to label tag variables. This option can work with disabled note tag.\n  light_bg_offset: 0\n\n# --------------------------------------\n# 其他设置\n# --------------------------------------\n\n# https://github.com/MoOx/pjax\npjax:\n# 是否启用 pjax\n  enable: false\n # 排除指定页面不使用 pjax，如 '/music/'\n  exclude:\n    # - /xxxxxx/\n\n# 注入 CSS 和脚本 (aplayer/meting)\naplayerInject:\n# 是否启用注入\n  enable: false\n  # 是否每页启用\n  per_page: true\n\n# Snackbar - Toast Notification\n# https://github.com/polonel/SnackBar\n# position: top-left / top-center / top-right / bottom-left / bottom-center / bottom-right\nsnackbar:\n  enable: false\n  position: bottom-left\n  # The background color of Toast Notification in light mode and dark mode\n  bg_light: '#49b1f5'\n  bg_dark: '#1f1f1f'\n\n# Instant.page\n# https://instant.page/\ninstantpage: false\n\n# Pangu - 在中文字符和英文字符之间插入空格\n# https://github.com/vinta/pangu.js\npangu:\n  enable: false\n  # Specify the field to use pangu (site or post)\n  field: site\n\n# Lazyload\n# https://github.com/verlok/vanilla-lazyload\nlazyload:\n  enable: false\n  # Specify the field to use lazyload (site or post)\n  field: site\n  placeholder:\n  blur: false\n\n# PWA\n# See https://github.com/JLHwung/hexo-offline\n# ---------------\npwa:\n  enable: false\n  manifest:\n  apple_touch_icon:\n  favicon_32_32:\n  favicon_16_16:\n  mask_icon:\n\n# Open graph meta tags\n# https://hexo.io/docs/helpers#open-graph\nOpen_Graph_meta:\n  enable: true\n  option:\n    # twitter_card:\n    # twitter_image:\n    # twitter_id:\n    # twitter_site:\n    # google_plus:\n    # fb_admins:\n    # fb_app_id:\n\n# Add the vendor prefixes to ensure compatibility\ncss_prefix: true\n\n# Inject\n# 插入代码到 head（在 '</head>' 标籤之前）和底部（在 '</body>' 标籤之前）\ninject:\n  head:\n    # - <link rel=\"stylesheet\" href=\"/xxx.css\">\n    - <meta name=\"referrer\" content=\"no-referrer\"/>\n  bottom:\n    # - <script src=\"xxxx\"></script>\n\n# CDN 设置\n# 除非你知道它们的工作原理，否则不要修改以下设置\nCDN:\n  # 内部和第三方脚本的 CDN 提供商\n  # 两者的选项：local/jsdelivr/unpkg/cdnjs/custom\n  # 注意： Dev 版本只能使用 'local' 作为内部脚本\n  # 注意：将第三方脚本设置为 'local' 时，需要安装 hexo-butterfly-extjs\n  internal_provider: local\n  third_party_provider: local\n\n  # 是否在 URL 中添加版本号，true 或 false\n  version: false\n\n  # 自定义格式\n  # 例如：https://cdn.staticfile.org/${cdnjs_name}/${version}/${min_cdnjs_file}\n  custom_format:\n\n  option:\n    # abcjs_basic_js:\n    # activate_power_mode:\n    # algolia_js:\n    # algolia_search:\n    # aplayer_css:\n    # aplayer_js:\n    # artalk_css:\n    # artalk_js:\n    # blueimp_md5:\n    # busuanzi:\n    # canvas_fluttering_ribbon:\n    # canvas_nest:\n    # canvas_ribbon:\n    # chartjs:\n    # click_heart:\n    # clickShowText:\n    # disqusjs:\n    # disqusjs_css:\n    # docsearch_css:\n    # docsearch_js:\n    # egjs_infinitegrid:\n    # fancybox:\n    # fancybox_css:\n    # fireworks:\n    # fontawesome:\n    # gitalk:\n    # gitalk_css:\n    # giscus:\n    # instantpage:\n    # instantsearch:\n    # katex:\n    # katex_copytex:\n    # lazyload:\n    # local_search:\n    # main:\n    # main_css:\n    # mathjax:\n    # medium_zoom:\n    # mermaid:\n    # meting_js:\n    # pangu:\n    # prismjs_autoloader:\n    # prismjs_js:\n    # prismjs_lineNumber_js:\n    # pjax:\n    # sharejs:\n    # sharejs_css:\n    # snackbar:\n    # snackbar_css:\n    # translate:\n    # twikoo:\n    # typed:\n    # utils:\n    # valine:\n    # waline_css:\n    # waline_js:\n```\n\n## 语言\n\n修改 Hexo 根目录下的配置文件 `_config.yml`\n\n默认语言是 en\n\n主题支持\n\n- default(en)\n- zh-CN （简体中文）\n- zh-TW （台湾繁体中文）\n- zh-HK （香港繁体中文）\n- ja （日语）\n- ko（韩语）\n\n![image-20241105130223438](../img/Butterfly%E4%B8%BB%E9%A2%98%E7%BE%8E%E5%8C%96%E4%B9%8B%E8%B7%AF/0228241de3d58331ba40050aea7268a0697559838.png)\n\n## 导航\n\n### 参数设置\n\n```\nnav:\n  # 导航栏 Logo 图片\n  logo:\n  # 是否显示标题\n  display_title: true\n  # 是否固定导航栏\n  fixed: false\n```\n\n### 目录\n\n导航的文字可自行更改：\n\n格式：名字: 路径 `||` 图标名\n\n例如：\n\n```yaml\nmenu:\n首页: / || fas fa-home\n时间轴: /archives/ || fas fa-archive\n标签: /tags/ || fas fa-tags\n分类: /categories/ || fas fa-folder-open\n清单||fa fa-heartbeat:\n照片: /Gallery/ || fas fa-images\n友链: /link/ || fas fa-link\n关于: /about/ || fas fa-heart\n列表||fas fa-list:\n  音乐: /music/ || fas fa-music\n  电影: /movies/ || fas fa-video\n```\n\n默认子目录是展开的，如果你想要隐藏，在子目录里添加`hide:`\n\n```yaml\n列表 || fas fa-list || hide:\n  音乐: /music/ || fas fa-music\n  电影: /movies/ || fas fa-video\n```\n\n我的目录：\n\n```yaml\nmenu:\n  首页: / || fas fa-home\n  标签: /tags/ || fas fa-tags\n  分类: /categories/ || fas fa-folder-open\n  友链: /link/ || fas fa-link\n  列表 || fas fa-list || hide:\n    音乐: /music/ || fas fa-music\n    电影: /movies/ || fas fa-video\n```\n\n## 代码高亮\n\nHighlight.js 是用 JavaScript 编写的语法高亮工具。它适用于 浏览器以及服务器上。它几乎可以与任何 标记，不依赖于任何其他框架，并且具有自动语言 检波。\n\n```\n#卸载默认的高亮插件\nnpm uninstall  hexo-prism-plugin\n通过 NPM 包安装Highlight.js \nnpm install highlight.js\nhexo clean && hexo g && hexo s\n```\n\n## 评论系统\n\n我用的是twikoo（vercel部署）免费\n\n具体配置可参考 [云函数部署 | Twikoo 文档](https://twikoo.js.org/backend.html#vercel-部署)\n\n```\ntwikoo:\n  envId: https://填写vercel部署好的域名，建议自定义域名\n  region:\n  # Use Twikoo visitor count as the page view count\n  visitor: false\n  option:\n```\n\n## 文章加密\n\n```\nnpm install --save hexo-blog-encrypt\n```\n\n在文章开头添加`passwd`\n\n```\n---\ntitle: Hello World\npassword: hello\n#密码就是hello\nwrong_pass_message: '抱歉, 这个密码看着不太对, 请再试试.'\nwrong_hash_message: '抱歉, 这个文章不能被校验, 不过您还是能看看解密后的内容.'\nmessage: 前往关于页联系本人\n---\n```\n\n能否成功加密有个前提条件，访问网站的协议要是https，所以你要给你的网站添加`ssl证书`即可，没有添加的即使输入密码也没有效果，解锁不了的\n\n![image-20241108212212875](../img/Butterfly%E4%B8%BB%E9%A2%98%E7%BE%8E%E5%8C%96%E4%B9%8B%E8%B7%AF/8d36bf594e87766274f4eca3ba31484c697559838.png)\n\n## 文章自动编号\n\n我是自己加了一个`hexo-theme-butterfly\\source\\css\\my.css`添加了以下内容。\n\n```\n/*文章编号*/\n/* 让 h1 触发重置 h2-h6 的计数 */\n.post-content h1 {\n    counter-reset: main-section !important;  /* 关键：确保每个 h1 重新开始 h2 计数 */\n}\n\n/* h2 作为主要编号（1. 2. 3.）*/\n.post-content h2 {\n    counter-increment: main-section !important;\n    counter-reset: sub-section !important;\n}\n\n.post-content h2::before {\n    content: counter(main-section) \". \" !important;\n}\n\n/* h3 作为次级编号（1.1 1.2 2.1 2.2） */\n.post-content h3 {\n    counter-increment: sub-section !important;\n    counter-reset: sub-sub-section !important;\n}\n\n.post-content h3::before {\n    content: counter(main-section) \".\" counter(sub-section) \". \" !important;\n}\n\n/* h4 三级编号（1.1.1 2.1.1） */\n.post-content h4 {\n    counter-increment: sub-sub-section !important;\n    counter-reset: sub-sub-sub-section !important;\n}\n\n.post-content h4::before {\n    content: counter(main-section) \".\" counter(sub-section) \".\" counter(sub-sub-section) \". \" !important;\n}\n\n/* h5 四级编号（1.1.1.1 2.1.1.1） */\n.post-content h5 {\n    counter-increment: sub-sub-sub-section !important;\n    counter-reset: sub-sub-sub-sub-section !important;\n}\n\n.post-content h5::before {\n    content: counter(main-section) \".\" counter(sub-section) \".\" counter(sub-sub-section) \".\" counter(sub-sub-sub-section) \". \" !important;\n}\n\n/* h6 五级编号（1.1.1.1.1 2.1.1.1.1） */\n.post-content h6 {\n    counter-increment: sub-sub-sub-sub-section !important;\n}\n\n.post-content h6::before {\n    content: counter(main-section) \".\" counter(sub-section) \".\" counter(sub-sub-section) \".\" counter(sub-sub-sub-section) \".\" counter(sub-sub-sub-sub-section) \". \" !important;\n}\n\n/* 设置标题之间的间距 */\n.post-content h2 { margin: 40px 0; }\n.post-content h3 { margin: 30px 0; }\n.post-content h4 { margin: 20px 0; }\n.post-content h5 { margin: 15px 0; }\n.post-content h6 { margin: 10px 0; }\n\n/*侧边栏开始编号*/\n/* 初始化 toc-level-2 的计数器 */\n.toc {\n    counter-reset: toc-section;\n}\n\n/* 让 toc-level-2 作为编号的起点 */\n.toc .toc-level-2 {\n    counter-reset: toc-subsection; /* 每个 toc-level-2 开始新的子计数 */\n    counter-increment: toc-section; /* 增加一级计数 */\n}\n\n/* 在链接前面添加编号 */\n.toc .toc-level-2 > a::before {\n    content: counter(toc-section) \".\";\n    font-weight: bold;\n    margin-right: 5px;\n}\n\n/* toc-level-3 开始二级编号 */\n.toc .toc-level-3 {\n    counter-reset: toc-subsubsection;\n    counter-increment: toc-subsection;\n}\n\n.toc .toc-level-3 > a::before {\n    content: counter(toc-section) \".\" counter(toc-subsection) \".\";\n    font-weight: bold;\n    margin-right: 5px;\n}\n\n/* toc-level-4 开始三级编号 */\n.toc .toc-level-4 {\n    counter-increment: toc-subsubsection;\n}\n\n.toc .toc-level-4 > a::before {\n    content: counter(toc-section) \".\" counter(toc-subsection) \".\" counter(toc-subsubsection) \".\";\n    font-weight: bold;\n    margin-right: 5px;\n}\n\n/* 隐藏主题自带的编号 */\n.toc .toc-number {\n    display: none;\n}\nspan.toc-text {\n    margin-left: -10px;\n}\n```\n\n效果图\n\n![image-20241117192718651](../img/Butterfly%E4%B8%BB%E9%A2%98%E7%BE%8E%E5%8C%96%E4%B9%8B%E8%B7%AF/image-20241117192718651.png)\n\n## 支持KaTeX数学公式和下标\n\n### 上下标支持：\n\nHexo 需要使用 Markdown 渲染引擎将 md 文件渲染成 html 文件，Hexo 默认使用 hexo-renderer-marked，可以换成 hexo-renderer-markdown-it。\n\n[hexo-renderer-markdown-it](https://github.com/hexojs/hexo-renderer-markdown-it) 拥有更好的性能，而且可以通过插件扩展功能，如：上标、下标、引用注脚、emoji、KaTex 公式、多维表格等等。\n\n先卸载 Hexo 默认引擎\n\n```\nnpm un hexo-renderer-marked --save\n```\n\n安装 markdown-it 引擎\n\n```\nnpm i hexo-renderer-markdown-it --save\n```\n\n在站点配置文件 _config.yml 中增加以下配置\n\n```\nmarkdown:\n  markdown:\n  preset: 'default'\n  render:\n    html: true\n    xhtmlOut: false\n    langPrefix: 'language-'\n    breaks: true\n    linkify: true\n    typographer: true\n    quotes: '“”‘’'\n  enable_rules:\n  disable_rules:\n  plugins:\n    - 'markdown-it-footnote'\n    - 'markdown-it-ins'\n    - 'markdown-it-mark'\n    - 'markdown-it-sub'\n    - 'markdown-it-sup'\n  images:\n    lazyload: false\n    prepend_root: false\n    post_asset: true\n```\n\n```\n配置中的 typographer: true 的作用是显示特殊格式字符\n\n写法：\n(c) (C) (r) (R) (tm) (TM) (p) (P) +-\n\n效果：\n© © ® ® ™ ™ (p) (P) ±\n```\n\n其他用法，可以参考 markdown-it 的[官方效果演示 Demo](https://markdown-it.github.io/)\n\n### 数学公式\n\n```\nnpm i @traptitech/markdown-it-katex --save\n```\n\n在站点配置文件 _config.yml 中增加以下配置\n\n```\nmarkdown_it_katex:\n  plugins:\n  - plugin:\n    name: '@traptitech/markdown-it-katex'\n    options: # see https://katex.org/docs/options.html\n      blockClass: \"math-block\"\n      strict: false\n      throwOnError: false\n      errorColor: \"#cc0000\"\n```\n\n![image-20250123234349921](../img/Butterfly%E4%B8%BB%E9%A2%98%E7%BE%8E%E5%8C%96%E4%B9%8B%E8%B7%AF/f6c459201fe2d2f36e88e4bbf96e00da697559838.png)\n\n<div class=\"tbsm\" style=\"margin-top:54px;\">\n<div class=\"tbsm-top\"><span><svg t=\"1674654360507\" class=\"icon\" viewBox=\"0 0 1024 1024\" version=\"1.1\" xmlns=\"http://www.w3.org/2000/svg\" p-id=\"987\" data-spm-anchor-id=\"a313x.7781069.0.i0\" width=\"35\" height=\"35\"><path d=\"M410.49 97.74H155.08a56.74 56.74 0 0 0-56.84 56.73V410a56.84 56.84 0 0 0 56.84 56.84h255.41A56.83 56.83 0 0 0 467.32 410V154.58a56.83 56.83 0 0 0-56.83-56.84zM410.49 558.74H155.08a56.74 56.74 0 0 0-56.84 56.73V871a56.84 56.84 0 0 0 56.84 56.84h255.41A56.83 56.83 0 0 0 467.32 871V615.58a56.83 56.83 0 0 0-56.83-56.84zM871.49 558.74H616.08a56.74 56.74 0 0 0-56.84 56.73V871a56.84 56.84 0 0 0 56.84 56.84h255.41A56.83 56.83 0 0 0 928.32 871V615.58a56.83 56.83 0 0 0-56.83-56.84z\" fill=\"#66EEFF\" p-id=\"988\"></path><path d=\"M410.49 558.74h-4.14A475 475 0 0 0 299.52 859.6a481.16 481.16 0 0 0 4.84 68.22h106.13A56.83 56.83 0 0 0 467.32 871V615.58a56.83 56.83 0 0 0-56.83-56.84zM871.49 558.74H616.08a56.74 56.74 0 0 0-56.84 56.73V871a56.84 56.84 0 0 0 56.84 56.84h255.41A56.83 56.83 0 0 0 928.32 871V615.58a56.83 56.83 0 0 0-56.83-56.84z\" fill=\"#C2F8FF\" p-id=\"989\"></path></svg></span><span style=\"font-size:30px;\"> 特别声明</span></div>\n<div class=\"tbsm-wz\">千屹博客旗下的所有文章，是通过本人课堂学习和课外自学所精心整理的知识巨著<br/>难免会有出错的地方<br/>如果细心的你发现了小失误，可以在下方评论区告诉我，或者私信我！<br />非常感谢大家的热烈支持！</div>\n</div>\n","tags":["Butterfly"],"categories":["Hexo"]},{"title":"JavaScript","url":"/posts/cc1b9611/","content":"\n<meta name=\"referrer\" content=\"no-referrer\"/>\n\n# JavaScript 基础\n\n本笔记整理自[黑马程序员前端JavaScript入门到精通全套视频教程，javascript核心进阶ES6语法、API、js高级等基础知识和实战教程](https://www.bilibili.com/video/BV1Y84y1L7Nn/?share_source=copy_web&vd_source=ee3bb79c6a500b8fb62eb9daab5faedb)\n\n## 介绍\n\n> 掌握 JavaScript 的引入方式，初步认识 JavaScript 的作用\n\n### 引入方式\n\nJavaScript 程序不能独立运行，它需要被嵌入 HTML 中，然后浏览器才能执行 JavaScript 代码。通过 `script` 标签将 JavaScript 代码引入到 HTML 中，有两种方式：\n\n#### 内部方式\n\n通过 `script` 标签包裹 JavaScript 代码\n\n```html\n<!DOCTYPE html>\n<html lang=\"en\">\n<head>\n  <meta charset=\"UTF-8\">\n  <title>JavaScript 基础 - 引入方式</title>\n</head>\n<body>\n  <!-- 内联形式：通过 script 标签包裹 JavaScript 代码 -->\n  <script>\n    alert('嗨，欢迎来严千屹博客学习前端技术！')\n  </script>\n</body>\n</html>\n```\n\n#### 外部形式\n\n一般将 JavaScript 代码写在独立的以 .js 结尾的文件中，然后通过 `script` 标签的 `src` 属性引入\n\n```javascript\n// demo.js\ndocument.write('嗨，欢迎来严千屹博客学习前端技术！')\n```\n\n```html\n<!DOCTYPE html>\n<html lang=\"en\">\n<head>\n  <meta charset=\"UTF-8\">\n  <title>JavaScript 基础 - 引入方式</title>\n</head>\n<body>\n  <!-- 外部形式：通过 script 的 src 属性引入独立的 .js 文件 -->\n  <script src=\"demo.js\"></script>\n</body>\n</html>\n```\n\n如果 script 标签使用 src 属性引入了某 .js 文件，那么 标签的代码会被忽略！！！如下代码所示：\n\n```html\n<!DOCTYPE html>\n<html lang=\"en\">\n<head>\n  <meta charset=\"UTF-8\">\n  <title>JavaScript 基础 - 引入方式</title>\n</head>\n<body>\n  <!-- 外部形式：通过 script 的 src 属性引入独立的 .js 文件 -->\n  <script src=\"demo.js\">\n    // 此处的代码会被忽略掉！！！！\n  \talert(666);  \n  </script>\n</body>\n</html>\n```\n\n###  注释和结束符\n\n通过注释可以屏蔽代码被执行或者添加备注信息，JavaScript 支持两种形式注释语法：\n\n#### 单行注释\n\n使用 `// ` 注释单行代码\n\n```html\n<!DOCTYPE html>\n<html lang=\"en\">\n<head>\n  <meta charset=\"UTF-8\">\n  <title>JavaScript 基础 - 注释</title>\n</head>\n<body>\n  \n  <script>\n    // 这种是单行注释的语法\n    // 一次只能注释一行\n    // 可以重复注释\n    document.write('嗨，欢迎来严千屹博客学习前端技术！');\n  </script>\n</body>\n</html>\n```\n\n#### 多行注释\n\n使用 `/* */` 注释多行代码\n\n```html\n<!DOCTYPE html>\n<html lang=\"en\">\n<head>\n  <meta charset=\"UTF-8\">\n  <title>JavaScript 基础 - 注释</title>\n</head>\n<body>\n  \n  <script>\n    /* 这种的是多行注释的语法 */\n    /*\n    \t更常见的多行注释是这种写法\n    \t在些可以任意换行\n    \t多少行都可以\n      */\n    document.write('嗨，欢迎来严千屹博客学习前端技术！')\n  </script>\n</body>\n</html>\n```\n\n**注：编辑器中单行注释的快捷键为 `ctrl + /`**\n\n### 结束符\n\n在 JavaScript 中 `;` 代表一段代码的结束，多数情况下可以省略 `;` 使用回车（enter）替代。\n\n```html\n<!DOCTYPE html>\n<html lang=\"en\">\n<head>\n  <meta charset=\"UTF-8\">\n  <title>JavaScript 基础 - 结束符</title>\n</head>\n<body>\n  \n  <script> \n    alert(1);\n    alert(2);\n    alert(1)\n    alert(2)\n  </script>\n</body>\n</html>\n```\n\n实际开发中有许多人主张书写 JavaScript 代码时省略结束符 `;`\n\n### 输入和输出\n\n输出和输入也可理解为人和计算机的交互，用户通过键盘、鼠标等向计算机输入信息，计算机处理后再展示结果给用户，这便是一次输入和输出的过程。\n\n举例说明：如按键盘上的方向键，向上/下键可以滚动页面，按向上/下键这个动作叫作输入，页面发生了滚动了这便叫输出。\n\n#### 输出\n\nJavaScript 可以接收用户的输入，然后再将输入的结果输出：\n\n`alert()`、`document.wirte()`\n\n以数字为例，向 `alert()` 或 `document.write()`输入任意数字，他都会以弹窗形式展示（输出）给用户。\n\n####  输入\n\n向 `prompt()` 输入任意内容会以弹窗形式出现在浏览器中，一般提示用户输入一些内容。\n\n```html\n<!DOCTYPE html>\n<html lang=\"en\">\n<head>\n  <meta charset=\"UTF-8\">\n  <title>JavaScript 基础 - 输入输出</title>\n</head>\n<body>\n  \n  <script> \n    // 1. 输入的任意数字，都会以弹窗形式展示\n    document.write('要输出的内容')\n    alert('要输出的内容');\n\n    // 2. 以弹窗形式提示用户输入姓名，注意这里的文字使用英文的引号\n    prompt('请输入您的姓名:')\n  </script>\n</body>\n</html>\n```\n\n## 变量\n\n> 了解变量、数据类型、运算符等基础概念，能够实现数据类型的转换，结合四则运算体会如何编程。\n\n- 体会现实世界中的事物与计算机的关系\n- 理解什么是数据并知道数据的分类\n- 理解变量存储数据的“容器”\n- 掌握常见运算符的使用，了解优先级关系\n- 知道 JavaScript 数据类型隐式转换的特征\n\n> 理解变量是计算机存储数据的“容器”，掌握变量的声明方式\n\n变量是计算机中用来存储数据的“容器”，它可以让计算机变得有记忆，通俗的理解变量就是使用【某个符号】来代表【某个具体的数值】（数据）\n\n```html\n<script>\n  // x 符号代表了 5 这个数值\n  x = 5\n  // y 符号代表了 6 这个数值\n  y = 6\n    \n  //举例： 在 JavaScript 中使用变量可以将某个数据（数值）记录下来！\n\n  // 将用户输入的内容保存在 num 这个变量（容器）中\n  num = prompt('请输入一数字!')\n\n  // 通过 num 变量（容器）将用户输入的内容输出出来\n  alert(num)\n  document.write(num)\n</script>\n```\n\n### 声明\n\n声明(定义)变量有两部分构成：声明关键字、变量名（标识）\n\n```html\n<!DOCTYPE html>\n<html lang=\"en\">\n<head>\n  <meta charset=\"UTF-8\">\n  <title>JavaScript 基础 - 声明和赋值</title>\n</head>\n<body>\n  \n  <script> \n    // let 变量名\n    // 声明(定义)变量有两部分构成：声明关键字、变量名（标识）\n    // let 即关键字，所谓关键字是系统提供的专门用来声明（定义）变量的词语\n    // age 即变量的名称，也叫标识符\n    let age\n  </script>\n</body>\n</html>\n```\n\n关键字是 JavaScript 中内置的一些英文词汇（单词或缩写），它们代表某些特定的含义，如 `let` 的含义是声明变量的，看到 `let`  后就可想到这行代码的意思是在声明变量，如 `let age;` \n\n`let` 和 `var` 都是 JavaScript 中的声明变量的关键字，推荐使用 `let` 声明变量！！！\n\n### 赋值\n\n声明（定义）变量相当于创造了一个空的“容器”，通过赋值向这个容器中添加数据。\n\n```html\n<!DOCTYPE html>\n<html lang=\"en\">\n<head>\n  <meta charset=\"UTF-8\">\n  <title>JavaScript 基础 - 声明和赋值</title>\n</head>\n<body>\n  \n  <script> \n    // 声明(定义)变量有两部分构成：声明关键字、变量名（标识）\n    // let 即关键字，所谓关键字是系统提供的专门用来声明（定义）变量的词语\n    // age 即变量的名称，也叫标识符\n    let age\n    // 赋值，将 18 这个数据存入了 age 这个“容器”中\n    age = 18\n    // 这样 age 的值就成了 18\n    document.write(age)\n    \n    // 也可以声明和赋值同时进行\n    let str = 'hello world!'\n    alert(str);\n  </script>\n</body>\n</html>\n```\n\n### 关键字\n\nJavaScript 使用专门的关键字 `let` 和 `var` 来声明（定义）变量，在使用时需要注意一些细节：\n\n以下是使用 `let` 时的注意事项：\n\n1. 允许声明和赋值同时进行\n2. 不允许重复声明\n3. 允许同时声明多个变量并赋值\n4. JavaScript 中内置的一些关键字不能被当做变量名\n\n以下是使用 `var` 时的注意事项：\n\n2. 允许声明和赋值同时进行\n2. 允许重复声明\n3. 允许同时声明多个变量并赋值\n\n大部分情况使用 `let` 和 `var` 区别不大，但是 `let` 相较 `var` 更严谨，因此推荐使用 `let`，后期会更进一步介绍二者间的区别。\n\n### 变量名命名规则\n\n关于变量的名称（标识符）有一系列的规则需要遵守：\n\n1. 只能是字母、数字、下划线、$，且不能能数字开头\n2. 字母区分大小写，如 Age 和 age 是不同的变量\n3. JavaScript 内部已占用于单词（关键字或保留字）不允许使用\n4. 尽量保证变量具有一定的语义，见字知义\n\n注：所谓关键字是指 JavaScript 内部使用的词语，如 `let` 和`var`，保留字是指 JavaScript 内部目前没有使用的词语，但是将来可能会使用词语。\n\n```html\n<!DOCTYPE html>\n<html lang=\"en\">\n<head>\n  <meta charset=\"UTF-8\">\n  <title>JavaScript 基础 - 变量名命名规则</title>\n</head>\n<body>\n  \n  <script> \n    let age = 18 // 正确\n    let age1 = 18 // 正确\n    let _age = 18 // 正确\n\n    // let 1age = 18; // 错误，不可以数字开头\n    let $age = 18 // 正确\n    let Age = 24 // 正确，它与小写的 age 是不同的变量\n    // let let = 18; // 错误，let 是关键字\n    let int = 123 // 不推荐，int 是保留字\n  </script>\n</body>\n</html>\n```\n\n## 常量\n\n概念：使用 const 声明的变量称为“常量”。\n\n使用场景：当某个变量永远不会改变的时候，就可以使用 const 来声明，而不是let。\n\n命名规范：和变量一致\n\n~~~javascript\nconst PI = 3.14\n~~~\n\n>注意： 常量不允许重新赋值,声明的时候必须赋值（初始化）\n\n## 数据类型\n\n> 计算机世界中的万事成物都是数据。\n\n计算机程序可以处理大量的数据，为了方便数据的管理，将数据分成了不同的类型：\n\n注：通过 typeof 关键字检测数据类型\n\n```html\n<!DOCTYPE html>\n<html lang=\"en\">\n<head>\n  <meta charset=\"UTF-8\">\n  <title>JavaScript 基础 - 数据类型</title>\n</head>\n<body>\n  \n  <script> \n    // 检测 1 是什么类型数据，结果为 number\n    document.write(typeof 1)\n  </script>\n</body>\n</html>\n```\n\n### 数值类型\n\n即我们数学中学习到的数字，可以是整数、小数、正数、负数\n\n```html\n<!DOCTYPE html>\n<html lang=\"en\">\n<head>\n  <meta charset=\"UTF-8\">\n  <title>JavaScript 基础 - 数据类型</title>\n</head>\n<body>\n  \n  <script> \n    let score = 100 // 正整数\n    let price = 12.345 // 小数\n    let temperature = -40 // 负数\n\n    document.write(typeof score) // 结果为 number\n    document.write(typeof price) // 结果为 number\n    document.write(typeof temperature) // 结果为 number\n  </script>\n</body>\n</html>\n```\n\nJavaScript 中的数值类型与数学中的数字是一样的，分为正数、负数、小数等。\n\n### 字符串类型\n\n通过单引号（ `''`） 、双引号（ `\"\"`）或反引号包裹的数据都叫字符串，单引号和双引号没有本质上的区别，推荐使用单引号。\n\n注意事项：\n\n1. 无论单引号或是双引号必须成对使用\n2. 单引号/双引号可以互相嵌套，但是不以自已嵌套自已\n3. 必要时可以使用转义符 `\\`，输出单引号或双引号\n\n```html\n<!DOCTYPE html>\n<html lang=\"en\">\n<head>\n  <meta charset=\"UTF-8\">\n  <title>JavaScript 基础 - 数据类型</title>\n</head>\n<body>\n  \n  <script> \n    let user_name = '小明' // 使用单引号\n    let gender = \"男\" // 使用双引号\n    let str = '123' // 看上去是数字，但是用引号包裹了就成了字符串了\n    let str1 = '' // 这种情况叫空字符串\n\t\t\n    documeent.write(typeof user_name) // 结果为 string\n    documeent.write(typeof gender) // 结果为 string\n    documeent.write(typeof str) // 结果为 string\n  </script>\n</body>\n</html>\n```\n\n### 布尔类型\n\n表示肯定或否定时在计算机中对应的是布尔类型数据，它有两个固定的值 `true` 和 `false`，表示肯定的数据用 `true`，表示否定的数据用 `false`。\n\n```html\n<!DOCTYPE html>\n<html lang=\"en\">\n<head>\n  <meta charset=\"UTF-8\">\n  <title>JavaScript 基础 - 数据类型</title>\n</head>\n<body>\n  \n  <script> \n    //  pink老师帅不帅？回答 是 或 否\n    let isCool = true // 是的，摔死了！\n    isCool = false // 不，套马杆的汉子！\n\n    document.write(typeof isCool) // 结果为 boolean\n  </script>\n</body>\n</html>\n```\n\n### undefined\n\n未定义是比较特殊的类型，只有一个值 undefined，只声明变量，不赋值的情况下，变量的默认值为 undefined，一般很少【直接】为某个变量赋值为 undefined。\n\n```html\n<!DOCTYPE html>\n<html lang=\"en\">\n<head>\n  <meta charset=\"UTF-8\">\n  <title>JavaScript 基础 - 数据类型</title>\n</head>\n<body>\n  \n  <script> \n    // 只声明了变量，并末赋值\n    let tmp;\n    document.write(typeof tmp) // 结果为 undefined\n  </script>\n</body>\n</html>\n```\n\n**注：JavaScript 中变量的值决定了变量的数据类型。**\n\n## 类型转换\n\n> 理解弱类型语言的特征，掌握显式类型转换的方法\n\n在 JavaScript 中数据被分成了不同的类型，如数值、字符串、布尔值、undefined，在实际编程的过程中，不同数据类型之间存在着转换的关系。\n\n### 隐式转换\n\n某些运算符被执行时，系统内部自动将数据类型进行转换，这种转换称为隐式转换。\n\n```html\n<!DOCTYPE html>\n<html lang=\"en\">\n<head>\n  <meta charset=\"UTF-8\">\n  <title>JavaScript 基础 - 隐式转换</title>\n</head>\n<body>\n  <script> \n    let num = 13 // 数值\n    let num2 = '2' // 字符串\n\n    // 结果为 132\n    // 原因是将数值 num 转换成了字符串，相当于 '13'\n    // 然后 + 将两个字符串拼接到了一起\n    console.log(num + num2)\n\n    // 结果为 11\n    // 原因是将字符串 num2 转换成了数值，相当于 2\n    // 然后数值 13 减去 数值 2\n    console.log(num - num2)\n\n    let a = prompt('请输入一个数字')\n    let b = prompt('请再输入一个数字')\n\n    alert(a + b);\n  </script>\n</body>\n</html>\n```\n\n注：数据类型的隐式转换是 JavaScript 的特征，后续学习中还会遇到，目前先需要理解什么是隐式转换。\n\n补充介绍模板字符串的拼接的使用\n\n### 显式转换\n\n编写程序时过度依靠系统内部的隐式转换是不严禁的，因为隐式转换规律并不清晰，大多是靠经验总结的规律。为了避免因隐式转换带来的问题，通常根逻辑需要对数据进行显示转换。\n\n#### Number\n\n通过 `Number` 显示转换成数值类型，当转换失败时结果为 `NaN`（Not a Number）即不是一个数字。\n\n```html\n<!DOCTYPE html>\n<html lang=\"en\">\n<head>\n  <meta charset=\"UTF-8\">\n  <title>JavaScript 基础 - 隐式转换</title>\n</head>\n<body>\n  <script>\n    let t = '12'\n    let f = 8\n\n    // 显式将字符串 12 转换成数值 12\n    t = Number(t)\n\n    // 检测转换后的类型\n    // console.log(typeof t);\n    console.log(t + f) // 结果为 20\n\n    // 并不是所有的值都可以被转成数值类型\n    let str = 'hello'\n    // 将 hello 转成数值是不现实的，当无法转换成\n    // 数值时，得到的结果为 NaN （Not a Number）\n    console.log(Number(str))\n  </script>\n</body>\n</html>\n```\n\n## 运算符\n\n> 理解什么是流程控制，知道条件控制的种类并掌握其对应的语法规则，具备利用循环编写简易ATM取款机程序能力\n\n- 运算符\n- 语句\n- 综合案例\n\n### 算术运算符\n\n数字是用来计算的，比如：乘法 * 、除法 / 、加法 + 、减法 - 等等，所以经常和算术运算符一起。\n\n算术运算符：也叫数学运算符，主要包括加、减、乘、除、取余（求模）等\n\n| 运算符 | 作用                                                 |\n| ------ | ---------------------------------------------------- |\n| +      | 求和                                                 |\n| -      | 求差                                                 |\n| *      | 求积                                                 |\n| /      | 求商                                                 |\n| **%**  | 取模（取余数），开发中经常用于作为某个数字是否被整除 |\n\n> 注意：在计算失败时，显示的结果是 NaN （not a number）\n\n```javascript\n// 算术运算符\nconsole.log(1 + 2 * 3 / 2) //  4 \nlet num = 10\nconsole.log(num + 10)  // 20\nconsole.log(num + num)  // 20\n\n// 1. 取模(取余数)  使用场景：  用来判断某个数是否能够被整除\nconsole.log(4 % 2) //  0  \nconsole.log(6 % 3) //  0\nconsole.log(5 % 3) //  2\nconsole.log(3 % 5) //  3\n\n// 2. 注意事项 : 如果我们计算失败，则返回的结果是 NaN (not a number)\nconsole.log('pink老师' - 2)\nconsole.log('pink老师' * 2)\nconsole.log('pink老师' + 2)   // pink老师2\n```\n\n### 赋值运算符\n\n赋值运算符：对变量进行赋值的运算符\n\n =     将等号右边的值赋予给左边, 要求左边必须是一个容器\n\n| 运算符 | 作用     |\n| ------ | -------- |\n| +=     | 加法赋值 |\n| -+     | 减法赋值 |\n| *=     | 乘法赋值 |\n| /=     | 除法赋值 |\n| %=     | 取余赋值 |\n\n```javascript\n<script>\nlet num = 1\n// num = num + 1\n// 采取赋值运算符\n// num += 1\nnum += 3\nconsole.log(num)\n</script>\n```\n\n### 自增/自减运算符\n\n| 符号 | 作用 | 说明                       |\n| ---- | ---- | -------------------------- |\n| ++   | 自增 | 变量自身的值加1，例如: x++ |\n| --   | 自减 | 变量自身的值减1，例如: x-- |\n\n1. ++在前和++在后在单独使用时二者并没有差别，而且一般开发中我们都是独立使用\n2. ++在后（后缀式）我们会使用更多\n\n> 注意：\n>\n> 1. 只有变量能够使用自增和自减运算符\n> 2. ++、-- 可以在变量前面也可以在变量后面，比如: x++  或者  ++x \n\n```javascript\n<script>\n    // let num = 10\n    // num = num + 1\n    // num += 1\n    // // 1. 前置自增\n    // let i = 1\n    // ++i\n    // console.log(i)\n\n    // let i = 1\n    // console.log(++i + 1)\n    // 2. 后置自增\n    // let i = 1\n    // i++\n    // console.log(i)\n    // let i = 1\n    // console.log(i++ + 1)\n\n    // 了解 \n    let i = 1\n    console.log(i++ + ++i + i)\n  </script>\n```\n\n### 比较运算符\n\n使用场景：比较两个数据大小、是否相等，根据比较结果返回一个布尔值（true / false）\n\n| 运算符 | 作用                                   |\n| ------ | -------------------------------------- |\n| >      | 左边是否大于右边                       |\n| <      | 左边是否小于右边                       |\n| >=     | 左边是否大于或等于右边                 |\n| <=     | 左边是否小于或等于右边                 |\n| ===    | 左右两边是否`类型`和`值`都相等（重点） |\n| ==     | 左右两边`值`是否相等                   |\n| !=     | 左右值不相等                           |\n| !==    | 左右两边是否不全等                     |\n\n```javascript\n<script>\n  console.log(3 > 5)\n  console.log(3 >= 3)\n  console.log(2 == 2)\n  // 比较运算符有隐式转换 把'2' 转换为 2  双等号 只判断值\n  console.log(2 == '2')  // true\n  // console.log(undefined === null)\n  // === 全等 判断 值 和 数据类型都一样才行\n  // 以后判断是否相等 请用 ===  \n  console.log(2 === '2')\n  console.log(NaN === NaN) // NaN 不等于任何人，包括他自己\n  console.log(2 !== '2')  // true  \n  console.log(2 != '2') // false \n  console.log('-------------------------')\n  console.log('a' < 'b') // true\n  console.log('aa' < 'ab') // true\n  console.log('aa' < 'aac') // true\n  console.log('-------------------------')\n</script>\n```\n\n### 逻辑运算符\n\n使用场景：可以把多个布尔值放到一起运算，最终返回一个布尔值\n\n| 符号 | 名称   | 日常读法 | 特点                       | 口诀           |\n| ---- | ------ | -------- | -------------------------- | -------------- |\n| &&   | 逻辑与 | 并且     | 符号两边有一个假的结果为假 | 一假则假       |\n| \\|\\| | 逻辑或 | 或者     | 符号两边有一个真的结果为真 | 一真则真       |\n| !    | 逻辑非 | 取反     | true变false  false变true   | 真变假，假变真 |\n\n| A     | B     | A && B | A \\|\\| B | !A    |\n| ----- | ----- | ------ | -------- | ----- |\n| false | false | false  | false    | true  |\n| false | true  | false  | true     | true  |\n| true  | false | false  | true     | false |\n| true  | true  | true   | true     | false |\n\n```javascript\n<script>\n    // 逻辑与 一假则假\n    console.log(true && true)\n    console.log(false && true)\n    console.log(3 < 5 && 3 > 2)\n    console.log(3 < 5 && 3 < 2)\n    console.log('-----------------')\n    // 逻辑或 一真则真\n    console.log(true || true)\n    console.log(false || true)\n    console.log(false || false)\n    console.log('-----------------')\n    // 逻辑非  取反\n    console.log(!true)\n    console.log(!false)\n\n    console.log('-----------------')\n\n    let num = 6\n    console.log(num > 5 && num < 10)\n    console.log('-----------------')\n  </script>\n```\n\n### 运算符优先级\n\n ![image-20241108214226197](../img/JavaScript%E5%9F%BA%E7%A1%80/8f4c37d84a7c0bd219784f4c3b4e49fd697559838.png)\n\n> 逻辑运算符优先级： ！> && >  ||  \n\n## 语句\n\n### 表达式和语句\n\n![67101792498](../img/JavaScript%E5%9F%BA%E7%A1%80/59c2f242554310a9bc6b4f440e818757697559838.png)\n\n\n\n### 分支语句\n\n分支语句可以根据条件判定真假，来选择性的执行想要的代码\n\n分支语句包含：\n\n1. if分支语句（重点）\n2. 三元运算符\n3. switch语句\n\n#### if 分支语句\n\n语法：\n\n~~~javascript\nif(条件表达式) {\n  // 满足条件要执行的语句\n}\n~~~\n\n小括号内的条件结果是布尔值，为 true 时，进入大括号里执行代码；为false，则不执行大括号里面代码\n\n小括号内的结果若不是布尔类型时，会发生类型转换为布尔值，类似Boolean()\n\n如果大括号只有一个语句，大括号可以省略，但是，俺们不提倡这么做~\n\n~~~javascript\n<script>\n    // 单分支语句\n    // if (false) {\n    //   console.log('执行语句')\n    // }\n    // if (3 > 5) {\n    //   console.log('执行语句')\n    // }\n    // if (2 === '2') {\n    //   console.log('执行语句')\n    // }\n    //  1. 除了0 所有的数字都为真\n    //   if (0) {\n    //     console.log('执行语句')\n    //   }\n    // 2.除了 '' 所有的字符串都为真 true\n    // if ('pink老师') {\n    //   console.log('执行语句')\n    // }\n    // if ('') {\n    //   console.log('执行语句')\n    // }\n    // // if ('') console.log('执行语句')\n\n    // 1. 用户输入\n    let score = +prompt('请输入成绩')\n    // 2. 进行判断输出\n    if (score >= 700) {\n      alert('恭喜考入黑马程序员')\n    }\n    console.log('-----------------')\n\n  </script>\n~~~\n\n#### if双分支语句\n\n如果有两个条件的时候，可以使用 if else 双分支语句\n\n~~~javascript\nif (条件表达式){\n  // 满足条件要执行的语句\n} else {\n  // 不满足条件要执行的语句\n}\n~~~\n\n例如：\n\n~~~javascript\n <script>\n    // 1. 用户输入\n    let uname = prompt('请输入用户名:')\n    let pwd = prompt('请输入密码:')\n    // 2. 判断输出\n    if (uname === 'pink' && pwd === '123456') {\n      alert('恭喜登录成功')\n    } else {\n      alert('用户名或者密码错误')\n    }\n  </script>\n~~~\n\n#### if 多分支语句\n\n使用场景： 适合于有多个条件的时候\n\n~~~javascript\n <script>\n    // 1. 用户输入\n    let score = +prompt('请输入成绩：')\n    // 2. 判断输出\n    if (score >= 90) {\n      alert('成绩优秀，宝贝，你是我的骄傲')\n    } else if (score >= 70) {\n      alert('成绩良好，宝贝，你要加油哦~~')\n    } else if (score >= 60) {\n      alert('成绩及格，宝贝，你很危险~')\n    } else {\n      alert('成绩不及格，宝贝，我不想和你说话，我只想用鞭子和你说话~')\n    }\n  </script>\n~~~\n\n#### 三元运算符（三元表达式）\n\n**使用场景**： 一些简单的双分支，可以使用  三元运算符（三元表达式），写起来比 if  else双分支 更简单\n\n**符号**：? 与 : 配合使用\n\n语法：\n\n~~~javascript\n条件 ? 表达式1 ： 表达式2\n~~~\n\n例如：\n\n~~~javascript\n// 三元运算符（三元表达式）\n// 1. 语法格式\n// 条件 ? 表达式1 : 表达式2 \n\n// 2. 执行过程 \n// 2.1 如果条件为真，则执行表达式1\n// 2.2 如果条件为假，则执行表达式2\n\n// 3. 验证\n// 5 > 3 ? '真的' : '假的'\nconsole.log(5 < 3 ? '真的' : '假的')\n\n// let age = 18 \n// age = age + 1\n//  age++\n\n// 1. 用户输入 \nlet num = prompt('请您输入一个数字:')\n// 2. 判断输出- 小于10才补0\n// num = num < 10 ? 0 + num : num\nnum = num >= 10 ? num : 0 + num\nalert(num)\n~~~\n\n#### switch语句（了解）\n\n使用场景： 适合于有多个条件的时候，也属于分支语句，大部分情况下和 if多分支语句 功能相同\n\n注意：\n\n1. switch case语句一般用于等值判断, if适合于区间判断\n2. switchcase一般需要配合break关键字使用 没有break会造成case穿透\n3. if 多分支语句开发要比switch更重要，使用也更多\n\n例如：\n\n~~~javascript\n// switch分支语句\n// 1. 语法\n// switch (表达式) {\n//   case 值1:\n//     代码1\n//     break\n\n//   case 值2:\n//     代码2\n//     break\n//   ...\n//   default:\n//     代码n\n// }\n\n<script>\n  switch (2) {\n    case 1:\n    console.log('您选择的是1')\n    break  // 退出switch\n    case 2:\n    console.log('您选择的是2')\n    break  // 退出switch\n    case 3:\n    console.log('您选择的是3')\n    break  // 退出switch\n    default:\n    console.log('没有符合条件的')\n  }\n</script>\n~~~\n\n#### 断点调试\n\n**作用：**学习时可以帮助更好的理解代码运行，工作时可以更快找到bug\n\n浏览器打开调试界面\n\n1. 按F12打开开发者工具\n2. 点到源代码一栏 （ sources ）\n3. 选择代码文件\n\n**断点：**在某句代码上加的标记就叫断点，当程序执行到这句有标记的代码时会暂停下来\n\n\n\n### 循环语句\n\n使用场景：重复执行 指定的一段代码，比如我们想要输出10次 '我学的很棒'\n\n学习路径：\n\n1.while循环\n\n2.for 循环（重点）\n\n#### while循环\n\nwhile :  在…. 期间， 所以 while循环 就是在满足条件期间，重复执行某些代码。\n\n**语法：**\n\n~~~javascript\nwhile (条件表达式) {\n   // 循环体    \n}\n~~~\n\n例如：\n\n~~~javascript\n// while循环: 重复执行代码\n\n// 1. 需求: 利用循环重复打印3次 '月薪过万不是梦，毕业时候见英雄'\nlet i = 1\nwhile (i <= 3) {\n  document.write('月薪过万不是梦，毕业时候见英雄~<br>')\n  i++   // 这里千万不要忘了变量自增否则造成死循环\n}\n~~~\n\n循环三要素：\n\n1.初始值 （经常用变量）\n\n2.终止条件\n\n3.变量的变化量\n\n例如：\n\n~~~javascript\n<script>\n  // // 1. 变量的起始值\n  // let i = 1\n  // // 2. 终止条件\n  // while (i <= 3) {\n  //   document.write('我要循环三次 <br>')\n  //   // 3. 变量的变化量\n  //   i++\n  // }\n  // 1. 变量的起始值\n  let end = +prompt('请输入次数:')\nlet i = 1\n// 2. 终止条件\nwhile (i <= end) {\n  document.write('我要循环三次 <br>')\n  // 3. 变量的变化量\n  i++\n}\n\n</script>\n~~~\n\n#### 中止循环\n\n`break`   中止整个循环，一般用于结果已经得到, 后续的循环不需要的时候可以使用（提高效率）  \n\n`continue`  中止本次循环，一般用于排除或者跳过某一个选项的时候\n\n~~~javascript\n<script>\n    // let i = 1\n    // while (i <= 5) {\n    //   console.log(i)\n    //   if (i === 3) {\n    //     break  // 退出循环\n    //   }\n    //   i++\n\n    // }\n\n\n    let i = 1\n    while (i <= 5) {\n      if (i === 3) {\n        i++\n        continue\n      }\n      console.log(i)\n      i++\n\n    }\n  </script>\n~~~\n\n#### 无限循环\n\n1.while(true) 来构造“无限”循环，需要使用break退出循环。（常用）\n\n2.for(;;) 也可以来构造“无限”循环，同样需要使用break退出循环。\n\n~~~javascript\n// 无限循环  \n// 需求： 页面会一直弹窗询问你爱我吗？\n// (1). 如果用户输入的是 '爱'，则退出弹窗\n// (2). 否则一直弹窗询问\n\n// 1. while(true) 无限循环\n// while (true) {\n//   let love = prompt('你爱我吗?')\n//   if (love === '爱') {\n//     break\n//   }\n// }\n\n// 2. for(;;) 无限循环\nfor (; ;) {\n  let love = prompt('你爱我吗?')\n  if (love === '爱') {\n    break\n  }\n}\n~~~\n\n### 总结\n\n> **if 多分支语句和 switch的区别：**\n>\n> 1. 共同点\n>\n>    - 都能实现多分支选择， 多选1 \n>    - 大部分情况下可以互换\n>\n> 2. 区别：\n>\n>    - switch…case语句通常处理case为比较**确定值**的情况，而if…else…语句更加灵活，通常用于**范围判断**(大于，等于某个范围)。\n>    - switch 语句进行判断后直接执行到程序的语句，效率更高，而if…else语句有几种判断条件，就得判断多少次\n>    - switch 一定要注意 必须是 ===  全等，一定注意 数据类型，同时注意break否则会有穿透效果\n>    - 结论：\n>      - 当分支比较少时，if…else语句执行效率高。\n>      - 当分支比较多时，switch语句执行效率高，而且结构更清晰。\n\n## 综合案例-ATM存取款机\n\n\n\n![67101878155](../img/JavaScript%E5%9F%BA%E7%A1%80/d4768c75053104c3ba05da6a283df2ce697559838.png)\n\n\n\n分析：\n\n①：提示输入框写到循环里面（无限循环）\n\n②：用户输入4则退出循环 break\n\n③：提前准备一个金额预先存储一个数额 money\n\n④：根据输入不同的值，做不同的操作\n\n​     (1)  取钱则是减法操作， 存钱则是加法操作，查看余额则是直接显示金额\n\n​     (2) 可以使用 if else if 多分支 来执行不同的操作\n\n完整代码：\n\n~~~javascript\n<script>\n  // 1. 开始循环 输入框写到 循环里面\n  // 3. 准备一个总的金额\n  let money = 100\nwhile (true) {\n  let re = +prompt(`\n请您选择操作：\n1.存钱\n2.取钱\n3.查看余额\n4.退出\n`)\n  // 2. 如果用户输入的 4 则退出循环， break  写到if 里面，没有写到switch里面， 因为4需要break退出循环\n  if (re === 4) {\n    break\n  }\n  // 4. 根据输入做操作\n  switch (re) {\n    case 1:\n      // 存钱\n      let cun = +prompt('请输入存款金额')\n      money = money + cun\n      break\n      case 2:\n      // 存钱\n      let qu = +prompt('请输入取款金额')\n      money = money - qu\n      break\n      case 3:\n      // 存钱\n      alert(`您的银行卡余额是${money}`)\n      break\n  }\n}\n</script>\n~~~\n\n## for 语句\n\n> 掌握 for 循环语句，让程序具备重复执行能力\n\n`for` 是 JavaScript 提供的另一种循环控制的话句，它和 `while` 只是语法上存在差异。\n\n### for语句的基本使用\n\n1. 实现循环的 3 要素\n\n```html\n<script>\n  // 1. 语法格式\n  // for(起始值; 终止条件; 变化量) {\n  //   // 要重复执行的代码\n  // }\n\n  // 2. 示例：在网页中输入标题标签\n  // 起始值为 1\n  // 变化量 i++\n  // 终止条件 i <= 6\n  for(let i = 1; i <= 6; i++) {\n    document.write(`<h${i}>循环控制，即重复执行<h${i}>`)\n  }\n</script>\n```\n\n2. 变化量和死循环，`for` 循环和 `while` 一样，如果不合理设置增量和终止条件，便会产生死循环。\n\n\n3. 跳出和终止循环\n\n```html\n<script>\n    // 1. continue \n    for (let i = 1; i <= 5; i++) {\n        if (i === 3) {\n            continue  // 结束本次循环，继续下一次循环\n        }\n        console.log(i)\n    }\n    // 2. break\n    for (let i = 1; i <= 5; i++) {\n        if (i === 3) {\n            break  // 退出结束整个循环\n        }\n        console.log(i)\n    }\n</script>\n```\n\n结论：\n\n- `JavaScript` 提供了多种语句来实现循环控制，但无论使用哪种语句都离不开循环的3个特征，即起始值、变化量、终止条件，做为初学者应着重体会这3个特征，不必过多纠结三种语句的区别。\n- 起始值、变化量、终止条件，由开发者根据逻辑需要进行设计，规避死循环的发生。\n- 当如果明确了循环的次数的时候推荐使用`for`循环,当不明确循环的次数的时候推荐使用`while`循环\n\n>注意：`for` 的语法结构更简洁，故 `for` 循环的使用频次会更多。\n\n\n\n### 循环嵌套\n\n利用循环的知识来对比一个简单的天文知识，我们知道地球在自转的同时也在围绕太阳公转，如果把自转和公转都看成是循环的话，就相当于是循环中又嵌套了另一个循环。\n\n![universe](../img/JavaScript%E5%9F%BA%E7%A1%80/d2c0e179a219843bdaf30e1781734889697559838.gif)\n\n实际上 JavaScript 中任何一种循环语句都支持循环的嵌套，如下代码所示：\n\n![64791826139](../img/JavaScript%E5%9F%BA%E7%A1%80/797b531035e1adb675ec853fba7b7414697559838.png)\n\n```html\n// 1. 外面的循环 记录第n天 \nfor (let i = 1; i < 4; i++) {\n    document.write(`第${i}天 <br>`)\n    // 2. 里层的循环记录 几个单词\n    for (let j = 1; j < 6; j++) {\n        document.write(`记住第${j}个单词<br>`)\n    }\n}\n```\n\n记住，外层循环循环一次，里层循环循环全部\n\n#### 倒三角\n\n~~~javascript\n // 外层打印几行\nfor (let i = 1; i <= 5; i++) {\n    // 里层打印几个星星\n    for (let j = 1; j <= i; j++) {\n        document.write('★')\n    }\n    document.write('<br>')\n}\n~~~\n\n ![64791867895](../img/JavaScript%E5%9F%BA%E7%A1%80/3789b2ee2b9fac332b31937f402b9b88697559838.png)\n\n#### 九九乘法表\n\n样式css\n\n~~~css\nspan {\n    display: inline-block;\n    width: 100px;\n    padding: 5px 10px;\n    border: 1px solid pink;\n    margin: 2px;\n    border-radius: 5px;\n    box-shadow: 2px 2px 2px rgba(255, 192, 203, .4);\n    background-color: rgba(255, 192, 203, .1);\n    text-align: center;\n    color: hotpink;\n}\n~~~\n\njavascript \n\n~~~javascript\n // 外层打印几行\nfor (let i = 1; i <= 9; i++) {\n    // 里层打印几个星星\n    for (let j = 1; j <= i; j++) {\n        // 只需要吧 ★ 换成  1 x 1 = 1   \n        document.write(`\n\t\t<div> ${j} x ${i} = ${j * i} </div>\n     `)\n    }\n    document.write('<br>')\n}\n~~~\n\n![64791873467](../img/JavaScript%E5%9F%BA%E7%A1%80/ca033fbc176da1c0580090729f41add7697559838.png)\n\n## 数组\n\n> 知道什么是数组及其应用的场景，掌握数组声明及访问的语法。\n\n### 数组是什么？\n\n**数组：**(Array)是一种可以按顺序保存数据的数据类型\n\n**使用场景：**如果有多个数据可以用数组保存起来，然后放到一个变量中，管理非常方便\n\n### 数组的基本使用\n\n#### 定义数组和数组单元\n\n```html\n<script>\n  // 1. 语法，使用 [] 来定义一个空数组\n  // 定义一个空数组，然后赋值给变量 classes\n  // let classes = [];\n\n  // 2. 定义非空数组\n  let classes = ['小明', '小刚', '小红', '小丽', '小米']\n</script>\n```\n\n通过 `[]` 定义数组，数据中可以存放真正的数据，如小明、小刚、小红等这些都是数组中的数据，我们这些数据称为数组单元，数组单元之间使用英文逗号分隔。\n\n#### 访问数组和数组索引\n\n使用数组存放数据并不是最终目的，关键是能够随时的访问到数组中的数据（单元）。其实 JavaScript 为数组中的每一个数据单元都编了号，通过数据单元在数组中的编号便可以轻松访问到数组中的数据单元了。\n\n我们将数据单元在数组中的编号称为索引值，也有人称其为下标。\n\n索引值实际是按着数据单元在数组中的位置依次排列的，注意是从` 0` 开始的，如下图所示：\n\n![array](../img/JavaScript%E5%9F%BA%E7%A1%80/5012790158782c15696a69570a182692697559838.jpg)\n\n观察上图可以数据单元【小明】对应的索引值为【0】，数据单元【小红】对应的索引值为【2】\n\n```html\n<script>\n  let classes = ['小明', '小刚', '小红', '小丽', '小米']\n  \n  // 1. 访问数组，语法格式为：变量名[索引值]\n  document.write(classes[0] // 结果为：小明\n  document.write(classes[1] // 结果为：小刚\n  document.write(classes[4] // 结果为：小米\n  \n  // 2. 通过索引值还可以为数组单重新赋值\n  document.write(classes[3] // 结果为：小丽\n  // 重新为索引值为 3 的单元赋值\n  classes[3] = '小小丽'\n  document.wirte(classes[3]; // 结果为： 小小丽\n</script>\n```\n\n#### 数据单元值类型\n\n数组做为数据的集合，它的单元值可以是任意数据类型\n\n```html\n<script>\n  // 6. 数组单值类型可以是任意数据类型\n\n  // a) 数组单元值的类型为字符类型\n  let list = ['HTML', 'CSS', 'JavaScript']\n  // b) 数组单元值的类型为数值类型\n  let scores = [78, 84, 70, 62, 75]\n  // c) 混合多种类型\n  let mixin = [true, 1, false, 'hello']\n</script>\n```\n\n#### 数组长度属性\n\n重申一次，数组在 JavaScript 中并不是新的数据类型，它属于对象类型。\n\n```html\n<script>\n  // 定义一个数组\n  let arr = ['html', 'css', 'javascript']\n  // 数组对应着一个 length 属性，它的含义是获取数组的长度\n  console.log(arr.length) // 3\n</script>\n```\n\n### 操作数组\n\n数组做为对象数据类型，不但有 `length` 属性可以使用，还提供了许多方法：\n\n1. push 动态向数组的尾部添加一个单元\n2. unshit 动态向数组头部添加一个单元\n3. pop 删除最后一个单元\n4. shift 删除第一个单元\n5. splice 动态删除任意单元\n\n使用以上4个方法时，都是直接在原数组上进行操作，即成功调任何一个方法，原数组都跟着发生相应的改变。并且在添加或删除单元时 `length` 并不会发生错乱。\n\n```html\n<script>\n  // 定义一个数组\n  let arr = ['html', 'css', 'javascript']\n\n  // 1. push 动态向数组的尾部添加一个单元\n  arr.push('Nodejs')\n  console.log(arr)\n  arr.push('Vue')\n\n  // 2. unshit 动态向数组头部添加一个单元\n  arr.unshift('VS Code')\n  console.log(arr)\n\n  // 3. splice 动态删除任意单元\n  arr.splice(2, 1) // 从索引值为2的位置开始删除1个单元\n  console.log(arr)\n\n  // 4. pop 删除最后一个单元\n  arr.pop()\n  console.log(arr)\n\n  // 5. shift 删除第一个单元\n  arr.shift()\n  console.log(arr)\n</script>\n```\n\n## 函数\n\n> 理解封装的意义，能够通过函数的声明实现逻辑的封装，知道对象数据类型的特征，结合数学对象实现简单计算功能。\n\n- 理解函数的封装的特征\n- 掌握函数声明的语法\n- 理解什么是函数的返回值\n- 知道并能使用常见的内置函数\n\n> 理解函数的封装特性，掌握函数的语法规则\n\n### 声明和调用\n\n函数可以把具有相同或相似逻辑的代码“包裹”起来，通过函数调用执行这些被“包裹”的代码逻辑，这么做的优势是有利于精简代码方便复用。\n\n#### 声明（定义）\n\n声明（定义）一个完整函数包括关键字、函数名、形式参数、函数体、返回值5个部分\n\n![function](../img/JavaScript%E5%9F%BA%E7%A1%80/a55aaafe880c7233191e50fe81643820697559838.jpg)\n\n#### 调用\n\n声明（定义）的函数必须调用才会真正被执行，使用 `()` 调用函数。\n\n```html\n<!DOCTYPE html>\n<html lang=\"en\">\n<head>\n  <meta charset=\"UTF-8\">\n  <title>JavaScript 基础 - 声明和调用</title>\n</head>\n<body>\n  <script>\n    // 声明（定义）了最简单的函数，既没有形式参数，也没有返回值\n    function sayHi() {\n      console.log('嗨~')\n    }\n    // 函数调用，这些函数体内的代码逻辑会被执行\n    // 函数名()\n        \n    sayHi()\n    // 可以重复被调用，多少次都可以\n    sayHi()\n  </script>\n</body>\n</html>\n```\n\n> 注：函数名的命名规则与变量是一致的，并且尽量保证函数名的语义。\n\n小案例： 小星星\n\n~~~javascript\n<script>\n        // 函数声明\n        function sayHi() {\n            // document.write('hai~')\n            document.write(`*<br>`)\n            document.write(`**<br>`)\n            document.write(`***<br>`)\n            document.write(`****<br>`)\n            document.write(`*****<br>`)\n            document.write(`******<br>`)\n            document.write(`*******<br>`)\n            document.write(`********<br>`)\n            document.write(`*********<br>`)\n        }\n        // 函数调用\n        sayHi()\n        sayHi()\n        sayHi()\n        sayHi()\n        sayHi()\n    </script>\n~~~\n\n###  参数\n\n通过向函数传递参数，可以让函数更加灵活多变，参数可以理解成是一个变量。\n\n声明（定义）一个功能为打招呼的函数\n\n- 传入数据列表\n- 声明这个函数需要传入几个数据\n- 多个数据用逗号隔开\n\n```html\n<!DOCTYPE html>\n<html lang=\"en\">\n<head>\n  <meta charset=\"UTF-8\">\n  <title>JavaScript 基础 - 函数参数</title>\n</head>\n<body>\n\n  <script>\n    // 声明（定义）一个功能为打招呼的函数\n    // function sayHi() {\n    //   console.log('嗨~')\n    // }\n    // 调用函数\n    // sayHi()\n\t\n\n    // 这个函数似乎没有什么价值，除非能够向不同的人打招呼\n    // 这就需要借助参数来实现了\n    function sayHi(name) {\n      // 参数 name 可以被理解成是一个变量\n      console.log(name)\n      console.log('嗨~' + name)\n    }\n\n    // 调用 sayHi 函数，括号中多了 '小明'\n    // 这时相当于为参数 name 赋值了\n    sayHi('小明')// 结果为 小明\n\n    // 再次调用 sayHi 函数，括号中多了 '小红'\n    // 这时相当于为参数 name 赋值了\n    sayHi('小红') // 结果为 小红\n  </script>\n</body>\n</html>\n```\n\n总结：\n\n1. 声明（定义）函数时的形参没有数量限制，当有多个形参时使用 `,` 分隔\n2. 调用函数传递的实参要与形参的顺序一致\n\n#### 形参和实参\n\n形参：声明函数时写在函数名右边小括号里的叫形参（形式上的参数）\n\n实参：调用函数时写在函数名右边小括号里的叫实参（实际上的参数）\n\n形参可以理解为是在这个函数内声明的变量（比如 num1 = 10）实参可以理解为是给这个变量赋值\n\n开发中尽量保持形参和实参个数一致\n\n```html\n<!DOCTYPE html>\n<html lang=\"en\">\n<head>\n  <meta charset=\"UTF-8\">\n  <title>JavaScript 基础 - 函数参数</title>\n</head>\n<body>\n  <script>\n    // 声明（定义）一个计算任意两数字和的函数\n    // 形参 x 和 y 分别表示任意两个数字，它们是两个变量\n    function count(x, y) {\n      console.log(x + y);\n    }\n    // 调用函数，传入两个具体的数字做为实参\n    // 此时 10 赋值给了形参 x\n    // 此时 5  赋值给了形参 y\n    count(10, 5); // 结果为 15\n  </script>\n</body>\n</html>\n```\n\n### 返回值\n\n函数的本质是封装（包裹），函数体内的逻辑执行完毕后，函数外部如何获得函数内部的执行结果呢？要想获得函数内部逻辑的执行结果，需要通过 `return` 这个关键字，将内部执行结果传递到函数外部，这个被传递到外部的结果就是返回值。\n\n```html\n<!DOCTYPE html>\n<html lang=\"en\">\n<head>\n  <meta charset=\"UTF-8\">\n  <title>JavaScript 基础 - 函数返回值</title>\n</head>\n<body>\n\n  <script>\n    // 定义求和函数\n    function count(a, b) {\n      let s = a + b\n      // s 即为 a + b 的结果\n      // 通过 return 将 s 传递到外部\n      return s\n    }\n\n    // 调用函数，如果一个函数有返回值\n    // 那么可将这个返回值赋值给外部的任意变量\n    let total = count(5, 12)\n  </script>\n</body>\n</html>\n```\n\n总结：\n\n1. 在函数体中使用return 关键字能将内部的执行结果交给函数外部使用\n2. 函数内部只能出现1 次 return，并且 return 下一行代码不会再被执行，所以return 后面的数据不要换行写\n3. return会立即结束当前函数\n4. 函数可以没有return，这种情况默认返回值为 undefined\n\n### 作用域\n\n通常来说，一段程序代码中所用到的名字并不总是有效和可用的，而限定这个名字的可用性的代码范围就是这个名字的作用域。\n\n作用域的使用提高了程序逻辑的局部性，增强了程序的可靠性，减少了名字冲突。\n\n#### 全局作用域\n\n作用于所有代码执行的环境(整个 script 标签内部)或者一个独立的 js 文件\n\n处于全局作用域内的变量，称为全局变量\n\n#### 局部作用域\n\n作用于函数内的代码环境，就是局部作用域。 因为跟函数有关系，所以也称为函数作用域。\n\n处于局部作用域内的变量称为局部变量\n\n>如果函数内部，变量没有声明，直接赋值，也当全局变量看，但是强烈不推荐\n>\n>但是有一种情况，函数内部的形参可以看做是局部变量。\n\n### 匿名函数\n\n函数可以分为具名函数和匿名函数\n\n匿名函数：没有名字的函数,无法直接使用。\n\n#### 函数表达式\n\n~~~javascript\n// 声明\nlet fn = function() { \n   console.log('函数表达式')\n}\n// 调用\nfn()\n~~~\n\n#### 立即执行函数\n\n~~~javascript\n(function(){ xxx  })();\n(function(){xxxx}());\n~~~\n\n>无需调用，立即执行，其实本质已经调用了\n>\n>多个立即执行函数之间用分号隔开\n\n在能够访问到的情况下 先局部 局部没有在找全局\n\n## 对象\n\n> 知道对象数据类型的特征，能够利用数组对象渲染页面\n\n- 理解什么是对象，掌握定义对象的语法\n- 掌握数学对象的使用\n\n> 对象是 JavaScript 数据类型的一种，之前已经学习了数值类型、字符串类型、布尔类型、undefined。对象数据类型可以被理解成是一种数据集合。它由属性和方法两部分构成。\n\n### 语法\n\n声明一个对象类型的变量与之前声明一个数值或字符串类型的变量没有本质上的区别。\n\n```html\n<!DOCTYPE html>\n<html lang=\"en\">\n<head>\n  <meta charset=\"UTF-8\">\n  <title>JavaScript 基础 - 对象语法</title>\n</head>\n<body>\n\n  <script>\n    // 声明字符串类型变量\n    let str = 'hello world!'\n    \n    // 声明数值类型变量\n    let num = 199\n\n    // 声明对象类型变量，使用一对花括号\n    // user 便是一个对象了，目前它是一个空对象\n    let user = {}\n  </script>\n</body>\n</html>\n```\n\n### 属性和访问\n\n数据描述性的信息称为属性，如人的姓名、身高、年龄、性别等，一般是名词性的。\n\n1. 属性都是成 对出现的，包括属性名和值，它们之间使用英文 `:` 分隔\n2. 多个属性之间使用英文 `,` 分隔\n3. 属性就是依附在对象上的变量\n4. 属性名可以使用 `\"\"` 或 `''`，一般情况下省略，除非名称遇到特殊符号如空格、中横线等\n\n```html\n<!DOCTYPE html>\n<html lang=\"en\">\n<head>\n  <meta charset=\"UTF-8\">\n  <title>JavaScript 基础 - 对象语法</title>\n</head>\n<body>\n\n  <script>\n    // 通过对象描述一个人的数据信息\n    // person 是一个对象，它包含了一个属性 name\n    // 属性都是成对出现的，属性名 和 值，它们之间使用英文 : 分隔\n    let person = {\n      name: '小明', // 描述人的姓名\n      age: 18, // 描述人的年龄\n      stature: 185, // 描述人的身高\n      gender: '男', // 描述人的性别\n    }\n  </script>\n</body>\n</html>\n```\n\n声明对象，并添加了若干属性后，可以使用 `.` 或 `[]` 获得对象中属性对应的值，我称之为属性访问。\n\n```html\n<!DOCTYPE html>\n<html lang=\"en\">\n<head>\n  <meta charset=\"UTF-8\">\n  <title>JavaScript 基础 - 对象语法</title>\n</head>\n<body>\n\n  <script>\n    // 通过对象描述一个人的数据信息\n    // person 是一个对象，它包含了一个属性 name\n    // 属性都是成对出现的，属性名 和 值，它们之间使用英文 : 分隔\n    let person = {\n      name: '小明', // 描述人的姓名\n      age: 18, // 描述人的年龄\n      stature: 185, // 描述人的身高\n      gender: '男', // 描述人的性别\n    };\n    \n    // 访问人的名字\n    console.log(person.name) // 结果为 小明\n    // 访问人性别\n    console.log(person.gender) // 结果为 男\n    // 访问人的身高\n    console.log(person['stature'] // 结果为 185\n   // 或者\n    console.log(person.stature) // 结果同为 185\n  </script>\n</body>\n</html>\n```\n\n扩展：也可以动态为对象添加属性，动态添加与直接定义是一样的，只是语法上更灵活。\n\n```html\n<!DOCTYPE html>\n<html lang=\"en\">\n<head>\n  <meta charset=\"UTF-8\">\n  <title>JavaScript 基础 - 对象语法</title>\n</head>\n<body>\n\n  <script>\n    // 声明一个空的对象（没有任何属性）\n\tlet user = {}\n    // 动态追加属性\n    user.name = '小明'\n    user['age'] = 18\n    \n    // 动态添加与直接定义是一样的，只是语法上更灵活\n  </script>\n</body>\n</html>\n```\n\n### 方法和调用\n\n数据行为性的信息称为方法，如跑步、唱歌等，一般是动词性的，其本质是函数。\n\n1. 方法是由方法名和函数两部分构成，它们之间使用 : 分隔\n2. 多个属性之间使用英文 `,` 分隔\n3. 方法是依附在对象中的函数\n4. 方法名可以使用 `\"\"` 或 `''`，一般情况下省略，除非名称遇到特殊符号如空格、中横线等\n\n```html\n<!DOCTYPE html>\n<html lang=\"en\">\n<head>\n  <meta charset=\"UTF-8\">\n  <title>JavaScript 基础 - 对象方法</title>\n</head>\n<body>\n\n  <script>\n    // 方法是依附在对象上的函数\n    let person = {\n      name: '小红',\n      age: 18,\n      // 方法是由方法名和函数两部分构成，它们之间使用 : 分隔\n      singing: function () {\n        console.log('两只老虎，两只老虎，跑的快，跑的快...')\n      },\n      run: function () {\n        console.log('我跑的非常快...')\n      }\n    }\n  </script>\n</body>\n</html>\n```\n\n声明对象，并添加了若干方法后，可以使用 `.` 或 `[]` 调用对象中函数，我称之为方法调用。\n\n```html\n<!DOCTYPE html>\n<html lang=\"en\">\n<head>\n  <meta charset=\"UTF-8\">\n  <title>JavaScript 基础 - 对象方法</title>\n</head>\n<body>\n\n  <script>\n    // 方法是依附在对象上的函数\n    let person = {\n      name: '小红',\n      age: 18,\n      // 方法是由方法名和函数两部分构成，它们之间使用 : 分隔\n      singing: function () {\n        console.log('两只老虎，两只老虎，跑的快，跑的快...')\n      },\n      run: function () {\n        console.log('我跑的非常快...')\n      }\n    }\n    \n    // 调用对象中 singing 方法\n    person.singing()\n    // 调用对象中的 run 方法\n    person.run()\n\n  </script>\n</body>\n</html>\n```\n\n扩展：也可以动态为对象添加方法，动态添加与直接定义是一样的，只是语法上更灵活。\n\n```html\n<!DOCTYPE html>\n<html lang=\"en\">\n<head>\n  <meta charset=\"UTF-8\">\n  <title>JavaScript 基础 - 对象方法</title>\n</head>\n<body>\n\n  <script>\n    // 声明一个空的对象（没有任何属性，也没有任何方法）\n\tlet user = {}\n    // 动态追加属性\n    user.name = '小明'\n    user.['age'] = 18\n    \n    // 动态添加方法\n    user.move = function () {\n      console.log('移动一点距离...')\n    }\n    \n  </script>\n</body>\n</html>\n```\n\n**注：无论是属性或是方法，同一个对象中出现名称一样的，后面的会覆盖前面的。**\n\n### null\n\nnull 也是 JavaScript 中数据类型的一种，通常只用它来表示不存在的对象。使用 typeof 检测类型它的类型时，结果为 `object`。\n\n#### 遍历对象\n\n~~~javascript\nlet obj = {\n      uname: 'pink',\n      age: 18,\n      sex: '男'\n    }\n    console.log(obj['uname'];//输出某个属性名的值\n    \n    for(let i in obj) {\n      // i 属性名  字符串  带引号    obj.'uname'     i ===  'uname'\n      // obj[k]  属性值    obj['uname']   obj[i]\n      console.log(i)  //输出所有属性名\n    }\n    for(let i in obj) {\n      // i 属性名  字符串  带引号    obj.'uname'     i ===  'uname'\n      // obj[i]  属性值    obj['uname']   obj[i]\n      console.log(obj[i]  //输出所有属性的值\n    }\n~~~\n\nfor in 不提倡遍历数组 因为 k 是 字符串  \n\n![image-20241110152447210](../img/JavaScript%E5%9F%BA%E7%A1%80/image-20241110152447210.png)\n\n### 案例\n\n```html\n<script>\n    let student = [\n      { name: '小米', age: 18, sex: '男', homedown: '河南' },\n      { name: '小美', age: 12, sex: '女', homedown: '北京' },\n      { name: '小三', age: 13, sex: '男', homedown: '湖北' },\n      { name: '小四', age: 15, sex: '女', homedown: '广东' }\n    ]\n    for (let i = 0; i <= student.length; i++) {\n        // console.log(i) //下标索引号\n        // console.log(student[i] //数组元素=每个对象\n        console.log(student[i].name) //输出每个对象的名字\n        //console.log(student[i].age) //输出每个对象的年龄\n      }\n  </script>\n```\n\n![image-20241110151302747](../img/JavaScript%E5%9F%BA%E7%A1%80/583a7fa87f4f161fbd9359148f429d5d697559838.png)\n\n## 内置对象\n\n回想一下我们曾经使用过的 `console.log`，`console`其实就是 JavaScript 中内置的对象，该对象中存在一个方法叫 `log`，然后调用 `log` 这个方法，即 `console.log()`。\n\n除了 `console` 对象外，JavaScritp 还有其它的内置的对象\n\n### Math\n\n`Math` 是 JavaScript 中内置的对象，称为数学对象，这个对象下即包含了属性，也包含了许多的方法。\n\n#### 属性\n\n- Math.PI，获取圆周率\n\n```javascript\n// 圆周率\nconsole.log(Math.PI);\n```\n\n#### 方法\n\n- Math.random，生成 0 到 1 间的随机数\n\n```javascript\n// 0 ~ 1 之间的随机数, 包含 0 不包含 1\nMath.random()\n```\n\n- Math.ceil，数字向上取整\n\n```javascript\n// 舍弃小数部分，整数部分加1\nMath.ceil(3.4)\n```\n\n- Math.floor，数字向下取整\n\n```javascript\n// 舍弃小数部分，整数部分不变\nMath.floor(4.68)\n```\n\n- Math.round，四舍五入取整\n\n```javascript\n// 取整，四舍五入原则\nMath.round(5.46539)\nMath.round(4.849)\n```\n\n- Math.max，在一组数中找出最大的\n\n```javascript\n// 找出最大值\nMath.max(10, 21, 7, 24, 13)\n```\n\n- Math.min，在一组数中找出最小的\n\n```javascript\n// 找出最小值\nMath.min(24, 18, 6, 19, 21)\n```\n\n- Math.pow，幂方法\n\n```javascript\n// 求某个数的多少次方\nMath.pow(4, 2) // 求 4 的 2 次方\nMath.pow(2, 3) // 求 2 的 3 次方\n```\n\n- Math.sqrt，平方根\n\n```javascript\n// 求某数的平方根\nMath.sqrt(16)\n```\n\n数学对象提供了比较多的方法，这里不要求强记，通过演示数学对象的使用，加深对对象的理解。\n\n","tags":["JavaScript"],"categories":["编程"]},{"title":"OpenEuler部署K8s-1.31.1","url":"/posts/50cdf140/","content":"\n<meta name=\"referrer\" content=\"no-referrer\"/>\n\n# OpenEuler部署K8s-1.31.1\n\n## 主机拓扑图\n\n| 主机名 | ip             | 内存 | 硬盘 | cpu  | OS                      |\n| ------ | -------------- | ---- | ---- | ---- | ----------------------- |\n| master | 192.168.48.101 | 5G   | 100G | 2    | openEuler-22.03-LTS-SP4 |\n| node01 | 192.168.48.102 | 5G   | 100G | 2    | openEuler-22.03-LTS-SP4 |\n| node02 | 192.168.48.103 | 5G   | 100G | 2    | openEuler-22.03-LTS-SP4 |\n\n镜像下载地址：[OpenEuler-22.03-LTS](https://mirrors.nju.edu.cn/openeuler/openEuler-22.03-LTS-SP4/ISO/x86_64/)\n\n下载名为openEuler-22.03-LTS-SP4-x86_64-dvd.iso\n\n## 基本配置\n\n注意一下你的网卡叫什么，我的是ens33，如果你是其他的记得替换，不要无脑的复制粘贴，看看脚本那些需要改的，目测需要改的是ip这些，还有第三步和第六步\n\n### 基本配置\n\n操作节点：[所有节点]\n\n```\nvi k8s_system_init.sh\n```\n\n```\n#!/bin/bash\nif [ $# -eq 2 ];then\n  echo \"设置主机名为：$1\"\n  echo \"ens33设置IP地址为：192.168.48.$2\"\nelse\n  echo  \"使用方法：sh $0 主机名 主机位\"\n  exit 2\nfi\n\necho \"--------------------------------------\"\necho \"1.正在设置主机名：$1\"\nhostnamectl set-hostname $1\n\necho \"2.正在关闭firewalld、selinux\"\nsystemctl disable firewalld &> /dev/null\nsystemctl stop firewalld\nsed -i \"s#SELINUX=enforcing#SELINUX=disabled#g\" /etc/selinux/config\nsetenforce 0\n\n\necho \"3.正在设置ens33：192.168.48.$2\"\ncat > /etc/sysconfig/network-scripts/ifcfg-ens33 <<EOF\nTYPE=Ethernet\nPROXY_METHOD=none\nBROWSER_ONLY=no\nBOOTPROTO=static\nDEFROUTE=yes\nIPV4_FAILURE_FATAL=no\nIPV6INIT=yes\nIPV6_AUTOCONF=yes\nIPV6_DEFROUTE=yes\nIPV6_FAILURE_FATAL=no\nNAME=ens33\nUUID=53b402ff-5865-47dd-a853-7afcd6521738\nDEVICE=ens33\nONBOOT=yes\nIPADDR=192.168.48.$2\nGATEWAY=192.168.48.2\nPREFIX=24\nDNS1=192.168.48.2\nDNS2=114.114.114.114\nEOF\nnmcli c reload\nnmcli c up ens33\n\n\necho \"4.新增华为云源、k8s源\"\nmkdir /etc/yum.repos.d/bak/\ncp /etc/yum.repos.d/* /etc/yum.repos.d/bak/\nsleep 3\ncat <<EOF | tee /etc/yum.repos.d/kubernetes.repo\n[kubernetes]\nname=Kubernetes\nbaseurl=https://mirrors.aliyun.com/kubernetes-new/core/stable/v1.31/rpm/\nenabled=1\ngpgcheck=1\ngpgkey=https://mirrors.aliyun.com/kubernetes-new/core/stable/v1.31/rpm/repodata/repomd.xml.key\nEOF\n#切换为华为云，下载速度更快\nsed -i 's/\\$basearch/x86_64/g' /etc/yum.repos.d/openEuler.repo\nsed -i 's/http\\:\\/\\/repo.openeuler.org/https\\:\\/\\/mirrors.huaweicloud.com\\/openeuler/g' /etc/yum.repos.d/openEuler.repo\n\necho \"5.更新yum源软件包缓存\"\n yum clean all && yum makecache\n\necho \"6.添加hosts解析\"\ncat > /etc/hosts <<EOF\n127.0.0.1   localhost localhost.localdomain localhost4 localhost4.localdomain4\n::1         localhost localhost.localdomain localhost6 localhost6.localdomain6\n192.168.48.101 master\n192.168.48.102 node01\n192.168.48.103 node02\nEOF\n\n\necho \"7.关闭swap分区\"\nswapoff -a && sysctl -w vm.swappiness=0 &> /dev/null\nsed -ri '/^[^#]*swap/s@^@#@' /etc/fstab\n\n\necho \"8.安装chrony服务，并同步时间\"\nyum install chrony -y\nsystemctl enable chronyd --now\ntimedatectl set-timezone Asia/Shanghai\ntimedatectl set-local-rtc 1\ntimedatectl set-ntp yes\nchronyc -a makestep\nchronyc tracking\nchronyc sources\n\n\necho \"9.必备工具安装\"\nyum install wget psmisc vim net-tools telnet socat device-mapper-persistent-data lvm2 git -y\n\necho \"10.重启\"\nreboot\n\n```\n\n运行脚本\n\n```\nsh k8s_system_init.sh 主机名  主机位\n\n[master] sh k8s_system_init.sh master 101\n\n[node01] sh k8s_system_init.sh node01 102\n\n[node02] sh k8s_system_init.sh node02 103\n```\n\n### 配置ssh免密\n\n操作节点:[所有节点]\n\n注意修改你的主机密码和主机列表的主机名\n\n```\nyum install -y sshpass \ncat > sshmianmi.sh << \"EOF\"\n#!/bin/bash\n# 目标主机列表\nhosts=(\"master\" \"node01\" \"node02\")\n# 密码\npassword=\"Lj201840.\"\n# 生成 SSH 密钥对\nssh-keygen -t rsa -N \"\" -f ~/.ssh/id_rsa\n\n# 循环遍历目标主机\nfor host in \"${hosts[@]}\"\ndo\n    # 复制公钥到目标主机\n    sshpass -p \"$password\" ssh-copy-id -o StrictHostKeyChecking=no \"$host\"\n    \n    # 验证免密登录\n    sshpass -p \"$password\" ssh -o StrictHostKeyChecking=no \"$host\" \"echo '免密登录成功'\"\ndone\nEOF\n\nsh sshmianmi.sh\n```\n\n### 配置内核路由转发及网桥过滤以及安装ipset及ipvsadm\n\n操作节点:[所有节点]\n\n```\nsed -i 's/net.ipv4.ip_forward=0/net.ipv4.ip_forward=1/g' /etc/sysctl.conf\ncat > /etc/sysctl.d/k8s.conf << EOF\nnet.bridge.bridge-nf-call-ip6tables = 1\nnet.bridge.bridge-nf-call-iptables = 1\nnet.ipv4.ip_forward = 1\nvm.swappiness = 0\nEOF\n# 配置加载br_netfilter模块\ncat <<EOF | sudo tee /etc/modules-load.d/k8s.conf\noverlay\nbr_netfilter\nEOF\n#加载br_netfilter overlay模块\nmodprobe br_netfilter\nmodprobe overlay\nsysctl --system\nsysctl -p \n# 使用新添加配置文件生效\nsysctl -p /etc/sysctl.d/k8s.conf  \nyum -y install ipset ipvsadm\ncat > /etc/sysconfig/modules/ipvs.module <<EOF\n#!/bin/bash\nmodprobe -- ip_vs\nmodprobe -- ip_vs_rr\nmodprobe -- ip_vs_wrr\nmodprobe -- ip_vs_sh\nmodprobe -- nf_conntrack\nEOF\n#授权、运行、检查是否加载\nchmod 755 /etc/sysconfig/modules/ipvs.module &&  /etc/sysconfig/modules/ipvs.module\n查看对应的模块是否加载成功\nlsmod | grep -e ip_vs -e nf_conntrack_ipv4\n```\n\n## containerd容器环境安装\n\n操作节点：[所有节点]\n\n```\n#下载所需软件包\nwget https://github.com/containerd/containerd/releases/download/v1.7.22/containerd-1.7.22-linux-amd64.tar.gz\nwget https://github.com/opencontainers/runc/releases/download/v1.1.15/runc.amd64\nwget https://github.com/containernetworking/plugins/releases/download/v1.5.1/cni-plugins-linux-amd64-v1.5.1.tgz\n\n#安装containerd\ntar Cxzvf /usr/local containerd-1.7.22-linux-amd64.tar.gz\n# 创建服务，所有主机都要操作\ncat << EOF > /usr/lib/systemd/system/containerd.service\n[Unit]\nDescription=containerd container runtime\nDocumentation=https://containerd.io\nAfter=network.target local-fs.target\n\n[Service]\nExecStartPre=-/sbin/modprobe overlay\nExecStart=/usr/local/bin/containerd\n\nType=notify\nDelegate=yes\nKillMode=process\nRestart=always\nRestartSec=5\n\n# Having non-zero Limit*s causes performance problems due to accounting overhead\n# in the kernel. We recommend using cgroups to do container-local accounting.\nLimitNPROC=infinity\nLimitCORE=infinity\n\n# Comment TasksMax if your systemd version does not supports it.\n# Only systemd 226 and above support this version.\nTasksMax=infinity\nOOMScoreAdjust=-999\n\n[Install]\nWantedBy=multi-user.target\nEOF\nsystemctl daemon-reload && systemctl enable --now containerd\n\n#安装runc\ninstall -m 755 runc.amd64 /usr/local/sbin/runc\n#安装cni\nmkdir -p /opt/cni/bin && tar -xzf cni-plugins-linux-amd64-v1.5.1.tgz -C /opt/cni/bin/\n\n#生成容器配置文件\nmkdir -p /etc/containerd && containerd config default > /etc/containerd/config.toml\nsed -i 's#sandbox_image = \"registry.k8s.io/pause:.*\"#sandbox_image = \"registry.aliyuncs.com/google_containers/pause:3.10\"#' /etc/containerd/config.toml\nsed -i 's/SystemdCgroup = false/SystemdCgroup = true/g' /etc/containerd/config.toml\n\ncat >/etc/crictl.yaml <<\"EOF\"\nruntime-endpoint: unix:///run/containerd/containerd.sock\nimage-endpoint: unix:///run/containerd/containerd.sock\ntimeout: 10\ndebug: false\nEOF\n\n#配置containerd镜像加速\n# 修改 /etc/containerd/config.toml 中的 config_path\nsed -i 's|^  config_path =.*$|  config_path = \"/etc/containerd/certs.d\"|' /etc/containerd/config.toml\n\n# 创建必要的目录\nmkdir -p /etc/containerd/certs.d/docker.io\nmkdir -p /etc/containerd/certs.d/registry.k8s.io\n\n# 配置 docker.io 的 hosts.toml\ncat <<EOF > /etc/containerd/certs.d/docker.io/hosts.toml\nserver = \"https://docker.io\"\n[host.\"https://docker.m.daocloud.io\"]\n  capabilities = [\"pull\", \"resolve\"]\n[host.\"https://reg-mirror.giniu.com\"]\n  capabilities = [\"pull\", \"resolve\"]\nEOF\n\n# 配置 registry.k8s.io 的 hosts.toml\ncat <<EOF > /etc/containerd/certs.d/registry.k8s.io/hosts.toml\nserver = \"https://registry.k8s.io\"\n[host.\"https://k8s.m.daocloud.io\"]\n  capabilities = [\"pull\", \"resolve\", \"push\"]\nEOF\n\n# 重启 containerd 服务\nsystemctl daemon-reload\nsystemctl restart containerd.service\n\n```\n\n## 安装K8s1.31.1\n\n操作节点:[所有节点]\n\n不出意外第一步安装的就是1.31.1的版本\n\n```\nyum install -y kubelet kubeadm kubectl --disableexcludes=kubernetes\n#  配置kubelet为了实现docker使用的cgroupdriver与kubelet使用的cgroup的一致性，建议修改如下文件内容。所有节点均要安装\nsed -i 's/^KUBELET_EXTRA_ARGS=/KUBELET_EXTRA_ARGS=\"--cgroup-driver=systemd\"/g' /etc/sysconfig/kubelet\n\n#设置kubelet为开机自启动即可，由于没有生成配置文件，集群初始化后自动启动\nsystemctl enable kubelet --now\n```\n\n开始安装K8s\n\n操作节点:[master]\n\n```\nkubeadm config print init-defaults > /etc/kubernetes/init-default.yaml\n\n# 修改为国内阿里源\nsed -i 's/registry.k8s.io/registry.aliyuncs.com\\/google_containers/' /etc/kubernetes/init-default.yaml\n \n# 设置 apiServerIP 地址. 请自行替换192.168.48.101为自己master的IP\nsed -i 's/1.2.3.4/192.168.48.101/' /etc/kubernetes/init-default.yaml\n\nsed -i '/serviceSubnet: 10.96.0.0\\/12/a \\  podSubnet: 192.168.0.0/16' /etc/kubernetes/init-default.yaml\n\nsed -i 's/1.31.0/1.31.1/g' /etc/kubernetes/init-default.yaml\n#拉取所需镜像\nkubeadm config images pull --config /etc/kubernetes/init-default.yaml\n\nkubeadm init --image-repository registry.aliyuncs.com/google_containers --upload-certs\n```\n\n如果要重置集群，或者报错则运行以下命令，报错了就找原因看看哪里出错了\n\n```\nkubeadm reset\n[reset] Are you sure you want to proceed? [y/N]: y\n#输入Y\n\nsudo rm -rf /etc/kubernetes/manifests/*\nsudo iptables -F && sudo ipvsadm --clear\n```\n\n初始化后运行以下命令\n\n```\nmkdir -p $HOME/.kube\nsudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config\nsudo chown $(id -u):$(id -g) $HOME/.kube/config\n```\n\n## 加入node节点\n\n```\nkubeadm token create --print-join-command\n```\n\n生成以下信息\n\n```\nkubeadm join 192.168.48.101:6443 --token mxybd6.j56dbce9cy698ejr --discovery-token-ca-cert-hash sha256:c1b1c7248f6aeea4d01244a226489958bfaaaa76926077b5c09b143c760b68e9\n```\n\n将这个命令复制给node01和node02运行就可以加入集群了\n\n## 安装网络插件\n\n```\necho '185.199.108.133 raw.githubusercontent.com' >> /etc/hosts\ncurl https://raw.githubusercontent.com/projectcalico/calico/v3.25.1/manifests/calico.yaml -O\nsed -i '/- name: WAIT_FOR_DATASTORE/i \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ - name: IP_AUTODETECTION_METHOD\\n              value: interface=ens33' calico.yaml\nsed -i 's| docker.io/calico/| registry.cn-hangzhou.aliyuncs.com/qianyios/|' calico.yaml\nkubectl apply -f calico.yaml\n```\n\n等待十几分钟这样子，就出现以下全部ready和running就说明K8s集群部署成功\n\n```\nkubectl get pods -A\n```\n\n![image-20241008204558946](../img/OpenEuler%E9%83%A8%E7%BD%B2K8s-1.31.1/bb20dc5992b31b8ce4352cda63a47d3e697559838-1728392228410-5.png)\n\n## K8S-dashboard\n\n### 配置yaml\n\n```\nwget https://raw.githubusercontent.com/kubernetes/dashboard/v2.7.0/aio/deploy/recommended.yaml\nsed -i 's/kubernetesui\\/dashboard:v2.7.0/registry.cn-hangzhou.aliyuncs.com\\/qianyios\\/dashboard:v2.7.0/g' recommended.yaml\nsed -i 's/kubernetesui\\/metrics-scraper:v1.0.8/registry.cn-hangzhou.aliyuncs.com\\/qianyios\\/metrics-scraper:v1.0.8/g' recommended.yaml\n```\n\n修改配置文件\n\n```\nvim recommended.yaml\n---\nkind: Service\napiVersion: v1\nmetadata:\n  labels:\n    app: kubernetes-dashboard\n  name: kubernetes-dashboard\n  namespace: kubernetes-dashboard\nspec:\n  ports:\n    - port: 443\n      targetPort: 8443\n      nodePort: 30001\n  type: NodePort\n  selector:\n    app: kubernetes-dashboard\n\n---\n```\n\n运行\n\n```\nkubectl apply -f recommended.yaml\n```\n\n### 创建cluster-admin用户\n\n```\n#创建service account并绑定默认cluster-admin管理员群角色\n#创建用户\nkubectl create serviceaccount dashboard-admin -n kubernetes-dashboard\n#用户授权\nkubectl create clusterrolebinding dashboard-admin --clusterrole=cluster-admin --serviceaccount=kubernetes-dashboard:dashboard-admin\n#获取用户Token\nkubectl create token dashboard-admin -n kubernetes-dashboard\n```\n\n记录token\n\n```\neyJhbGciOiJSUzI1NiIsImtpZCI6IjhsSUtJbk93YU5xR1V2ZndOS0lFMnpVLVR1cEl1YUF5U0JBd2NRUXFHVE0ifQ.eyJhdWQiOlsiaHR0cHM6Ly9rdWJlcm5ldGVzLmRlZmF1bHQuc3ZjLmNsdXN0ZXIubG9jYWwiXSwiZXhwIjoxNzI4Mzk1MzcxLCJpYXQiOjE3MjgzOTE3NzEsImlzcyI6Imh0dHBzOi8va3ViZXJuZXRlcy5kZWZhdWx0LnN2Yy5jbHVzdGVyLmxvY2FsIiwianRpIjoiYjA5NjA2OTEtNTVkNy00YzhmLTliZGItZDRkNzljYTU0YTJiIiwia3ViZXJuZXRlcy5pbyI6eyJuYW1lc3BhY2UiOiJrdWJlcm5ldGVzLWRhc2hib2FyZCIsInNlcnZpY2VhY2NvdW50Ijp7Im5hbWUiOiJkYXNoYm9hcmQtYWRtaW4iLCJ1aWQiOiIwYzU0YWE0OC0zYTFkLTQyNmYtODI5ZS01ODVjZWNjMzEyYjAifX0sIm5iZiI6MTcyODM5MTc3MSwic3ViIjoic3lzdGVtOnNlcnZpY2VhY2NvdW50Omt1YmVybmV0ZXMtZGFzaGJvYXJkOmRhc2hib2FyZC1hZG1pbiJ9.dYb1MRmrKqNSTs2SKGsXZT_Nq4xtt3JeQEXOaHIjvFNtn_iCk1qTuY6oUBE8xdRv4S1oyqb52udGj0Zb5gYpMEBIfpQxTL_KJkeR-1S-tyl2U1FsH6UCnPE_j7KWh5suU3YJncIhQ26Ei7hC12WuZ9l-_UD3mL2tEPzwjbhnT0qir2Qe4rqrSJNNSQHrtwNVD2O-zv13VaUx6azXArec2GPDYR5ZYbSqMXuklaelwtZoKPLzP0DFnZy4jJ4n1JM7PRzqS5sWT_2nMgpSFZ_a5E0b7knvcNvyQHgHzeIYTrY88wjaCQi3x3cIn2hUvtVsroZySjx3Mz-ZECco5WN-eQ\n```\n\n浏览器访问即可并输入以上token\n\n```\nhttps://192.168.48.101:30001/\n```\n\n![image-20241008205011179](../img/OpenEuler%E9%83%A8%E7%BD%B2K8s-1.31.1/2f4d9987d1d4fd3c05638ef58883a199697559838-1728392228410-6.png)\n\n至此K8s-1.31.1部署完成\n\n<div class=\"tbsm\" style=\"margin-top:54px;\">\n<div class=\"tbsm-top\"><span><svg t=\"1674654360507\" class=\"icon\" viewBox=\"0 0 1024 1024\" version=\"1.1\" xmlns=\"http://www.w3.org/2000/svg\" p-id=\"987\" data-spm-anchor-id=\"a313x.7781069.0.i0\" width=\"35\" height=\"35\"><path d=\"M410.49 97.74H155.08a56.74 56.74 0 0 0-56.84 56.73V410a56.84 56.84 0 0 0 56.84 56.84h255.41A56.83 56.83 0 0 0 467.32 410V154.58a56.83 56.83 0 0 0-56.83-56.84zM410.49 558.74H155.08a56.74 56.74 0 0 0-56.84 56.73V871a56.84 56.84 0 0 0 56.84 56.84h255.41A56.83 56.83 0 0 0 467.32 871V615.58a56.83 56.83 0 0 0-56.83-56.84zM871.49 558.74H616.08a56.74 56.74 0 0 0-56.84 56.73V871a56.84 56.84 0 0 0 56.84 56.84h255.41A56.83 56.83 0 0 0 928.32 871V615.58a56.83 56.83 0 0 0-56.83-56.84z\" fill=\"#66EEFF\" p-id=\"988\"></path><path d=\"M410.49 558.74h-4.14A475 475 0 0 0 299.52 859.6a481.16 481.16 0 0 0 4.84 68.22h106.13A56.83 56.83 0 0 0 467.32 871V615.58a56.83 56.83 0 0 0-56.83-56.84zM871.49 558.74H616.08a56.74 56.74 0 0 0-56.84 56.73V871a56.84 56.84 0 0 0 56.84 56.84h255.41A56.83 56.83 0 0 0 928.32 871V615.58a56.83 56.83 0 0 0-56.83-56.84z\" fill=\"#C2F8FF\" p-id=\"989\"></path></svg></span><span style=\"font-size:30px;\"> 特别声明</span></div>\n<div class=\"tbsm-wz\">千屹博客旗下的所有文章，是通过本人课堂学习和课外自学所精心整理的知识巨著<br/>难免会有出错的地方<br/>如果细心的你发现了小失误，可以在下方评论区告诉我，或者私信我！<br />非常感谢大家的热烈支持！</div>\n</div>","tags":["OpenEuler","K8s"],"categories":["云原生"]},{"title":"Linux安装Mysql8.4.2 LTS","url":"/posts/32ce47c9/","content":"\n<meta name=\"referrer\" content=\"no-referrer\"/>\n\n# Linux安装Mysql8.4.2 LTS\n\n## 下载安装包\n\n下载地址：[MySQL](https://dev.mysql.com/downloads/mysql/)\n\n根据自己的系统选择哦！\n\n我的系统是OpenEuler22.03LTS兼容红帽安装包\n\n![image-20240908141022472](../img/Linux%E5%AE%89Mysql8.4.2%20LTS%EF%BC%88%E4%BB%A5rpm%E5%8C%85%E5%AE%89%E8%A3%85%EF%BC%89.assets/b6bd0beb860af13cbd1155822d54b8c3697559838.png)\n\n下载之后上传到root目录下\n\n![image-20240908141150263](../img/Linux%E5%AE%89Mysql8.4.2%20LTS%EF%BC%88%E4%BB%A5rpm%E5%8C%85%E5%AE%89%E8%A3%85%EF%BC%89.assets/ca4177bf8ec777a34d4a62e04ce8b4af697559838.png)\n\n创建安装目录并解压安装包到此目录下\n\n```\nmkdir mysql8.4.2lts\ntar -xvf mysql-8.4.2-1.el8.x86_64.rpm-bundle.tar -C mysql8.4.2lts\ncd mysql8.4.2lts/\nls\n```\n\n已经解压完成了哦\n\n![image-20240908141612404](../img/Linux%E5%AE%89Mysql8.4.2%20LTS%EF%BC%88%E4%BB%A5rpm%E5%8C%85%E5%AE%89%E8%A3%85%EF%BC%89.assets/d1f85f051509e83d816c26f2f6240b35697559838.png)\n\n## 开始安装\n\n删除旧版本的mysql和mariadb\n\n```\n# 卸载 mariadb 相关的包\nyum remove mariadb mariadb-config mariadb-libs -y\n\n# 如果之前安装过 MySQL 社区版，也需要一并移除\nyum remove mysql-community-common mysql-community-icu-data-files mysql-community-client-plugins mysql-community-libs mysql-community-client mysql-community-server mysql-community-libs-compat -y\n```\n\n最好按照以下顺序按照，不然会报错\n\n```\n#全局的依赖（common）\nrpm -ivh mysql-community-common-8.4.2-1.el8.x86_64.rpm\nrpm -ivh mysql-community-icu-data-files-8.4.2-1.el8.x86_64.rpm\nrpm -ivh mysql-community-client-plugins-8.4.2-1.el8.x86_64.rpm\nrpm -ivh mysql-community-libs-8.4.2-1.el8.x86_64.rpm\nrpm -ivh mysql-community-client-8.4.2-1.el8.x86_64.rpm\nrpm -ivh mysql-community-server-8.4.2-1.el8.x86_64.rpm\n#php依赖文件\nrpm -ivh mysql-community-libs-compat-8.4.2-1.el8.x86_64.rpm\n```\n\n<font color='red'>注意：如果需要搭载php使用，需要安装7.7，因为rpm -ivh mysql-community-libs-compat是php的依赖。；如果不安装php，则无需安装7.7的依赖。</font>\n\n## 数据库基础配置\n\n### 启动数据库并且设置自启动\n\n```\nsystemctl enable mysqld --now\n```\n\n### 查看启动进程\n\n```\nps -ef | grep mysql\n```\n\n![image-20240908144458980](../img/Linux%E5%AE%89Mysql8.4.2%20LTS%EF%BC%88%E4%BB%A5rpm%E5%8C%85%E5%AE%89%E8%A3%85%EF%BC%89.assets/6810095115b61df251616389ab64b3da697559838.png)\n\n### 查看初始密码\n\n```\ngrep 'temporary password' /var/log/mysqld.log\n```\n\n```\n2024-09-08T06:44:47.204524Z 6 [Note] [MY-010454] [Server] A temporary password is generated for root@localhost: zo+&q(qYG21X\n密码是zo+&q(qYG21X\n```\n\n### 修改密码\n\n```\nmysql -uroot -p\"zo+&q(qYG21X\"\nalter user 'root'@'localhost' identified by 'Qianyios007@';\n```\n\n以后你就可以用以下目录登入mysql了\n\n```\nmysql -uroot -p\"Qianyios007@\"\n```\n\n<div class=\"tbsm\" style=\"margin-top:54px;\">\n<div class=\"tbsm-top\"><span><svg t=\"1674654360507\" class=\"icon\" viewBox=\"0 0 1024 1024\" version=\"1.1\" xmlns=\"http://www.w3.org/2000/svg\" p-id=\"987\" data-spm-anchor-id=\"a313x.7781069.0.i0\" width=\"35\" height=\"35\"><path d=\"M410.49 97.74H155.08a56.74 56.74 0 0 0-56.84 56.73V410a56.84 56.84 0 0 0 56.84 56.84h255.41A56.83 56.83 0 0 0 467.32 410V154.58a56.83 56.83 0 0 0-56.83-56.84zM410.49 558.74H155.08a56.74 56.74 0 0 0-56.84 56.73V871a56.84 56.84 0 0 0 56.84 56.84h255.41A56.83 56.83 0 0 0 467.32 871V615.58a56.83 56.83 0 0 0-56.83-56.84zM871.49 558.74H616.08a56.74 56.74 0 0 0-56.84 56.73V871a56.84 56.84 0 0 0 56.84 56.84h255.41A56.83 56.83 0 0 0 928.32 871V615.58a56.83 56.83 0 0 0-56.83-56.84z\" fill=\"#66EEFF\" p-id=\"988\"></path><path d=\"M410.49 558.74h-4.14A475 475 0 0 0 299.52 859.6a481.16 481.16 0 0 0 4.84 68.22h106.13A56.83 56.83 0 0 0 467.32 871V615.58a56.83 56.83 0 0 0-56.83-56.84zM871.49 558.74H616.08a56.74 56.74 0 0 0-56.84 56.73V871a56.84 56.84 0 0 0 56.84 56.84h255.41A56.83 56.83 0 0 0 928.32 871V615.58a56.83 56.83 0 0 0-56.83-56.84z\" fill=\"#C2F8FF\" p-id=\"989\"></path></svg></span><span style=\"font-size:30px;\"> 特别声明</span></div>\n<div class=\"tbsm-wz\">千屹博客旗下的所有文章，是通过本人课堂学习和课外自学所精心整理的知识巨著<br/>难免会有出错的地方<br/>如果细心的你发现了小失误，可以在下方评论区告诉我，或者私信我！<br />非常感谢大家的热烈支持！</div>\n</div>\n","tags":["OpenEuler","Mysql"],"categories":["运维"]},{"title":"基于K8S的CICD系统实现","url":"/posts/40462/","content":"\n<meta name=\"referrer\" content=\"no-referrer\"/>\n\n# 基于K8S的CICD系统实现\n\n## 前情提要\n\n在此声明，这个项目需要有32G+以上的运行内存，不然继续不了，32G运行内存电脑勉强能（阉割版流畅）运行，而且也是关了一台harbor2才能勉强运行，关了没事的，因为harbor是高可用集群，有一台harbor1就行了。\n\n## 系统拓扑图\n\n运行内存严格按照我的以下的内存规格来填写，这是勉强能运行的配置参数，如果内存多的话自行加多即可\n\nK8S集群\n\n| 主机名   | ip1（NAT）     | 系统                | 磁盘1 | 磁盘2 | 内存 | cpu  |\n| -------- | -------------- | ------------------- | ----- | ----- | ---- | ---- |\n| master1  | 192.168.48.101 | OpenEuler-22.04-LTS | 100G  | 100G  | 6.2G | 2v2c |\n| master2  | 192.168.48.102 | OpenEuler-22.04-LTS | 100G  | 100G  | 6.2G | 2v2c |\n| master3  | 192.168.48.103 | OpenEuler-22.04-LTS | 100G  | 100G  | 6.2G | 2v2c |\n| node01   | 192.168.48.104 | OpenEuler-22.04-LTS | 100G  |       | 9.9G | 2v2c |\n| 高可用ip | 192.168.48.200 |                     |       |       |      |      |\n\nharbor集群\n\n| 角色                                | 主机名         | ip             | 系统                | 资源最低要求                            |\n| ----------------------------------- | -------------- | -------------- | ------------------- | --------------------------------------- |\n| Harbor1<br />nginx<br />Keepalived1 | harbor1        | 192.168.48.106 | OpenEuler-22.04-LTS | CPU：1核 <br />内存：1G <br />硬盘：40G |\n| Harbor2<br />nginx<br />Keepalived2 | harbor2        | 192.168.48.107 | OpenEuler-22.04-LTS | CPU：1核 <br />内存：1G <br />硬盘：40G |\n| postgresql<br />Redis<br />NFS共享  | zujian         | 192.168.48.108 | OpenEuler-22.04-LTS | CPU：1核 <br />内存：1G <br />硬盘：40G |\n| 高可用ip                            | 192.168.48.100 |                |                     |                                         |\n\n系统架构图\n\n![image-20241111220607255](../img/%E5%9F%BA%E4%BA%8EK8S%E7%9A%84CICD%E7%B3%BB%E7%BB%9F%E5%AE%9E%E7%8E%B0/image-20241111220607255-1731333971370-4.png)\n\n系统流程图\n\n![image-20241111215652395](../img/%E5%9F%BA%E4%BA%8EK8S%E7%9A%84CICD%E7%B3%BB%E7%BB%9F%E5%AE%9E%E7%8E%B0/image-20241111215652395-1731333422328-1.png)\n\n## 部署K8S高可用集群\n\n[OpenEuler-部署K8S高可用集群（内部etcd） - 严千屹博客 (qianyios.top)](https://blog.qianyios.top/posts/62904/)\n\n## 部署ceph集群\n\n> 注意：原文章是部署在master1，node01，node02，由于硬件原因，现在需要部署在三台master，所以原文章开头加硬盘，你也只需要加在三台master上，请自己注意在2.1-2位置修改集群名称和硬盘名称。包括要下载的镜像，就在三台master下载就行了，接着你就可以继续做了\n\n[基于K8S1.28.2实验rook部署ceph - 严千屹博客 (qianyios.top)](https://blog.qianyios.top/posts/58032/)\n\n以下进行cephfs存储做存储声明即Storageclass，方便后续jenkins和gitlab调用\n\n### 创建cephfs文件系统\n\n操作节点[master1]\n\n```\ncd\ncd rook/deploy/examples\ncat >rook-cephfs.yaml << \"EOF\"\napiVersion: ceph.rook.io/v1\nkind: CephFilesystem\nmetadata:\n  name: rook-cephfs      #修改名字\n  namespace: rook-ceph \nspec:\n  metadataPool:\n    replicated:\n      size: 3\n      requireSafeReplicaSize: true # 参数指示是否要求副本数量必须是偶数\n    parameters:\n      compression_mode:\n        none\n  dataPools:\n    - name: replicated\n      failureDomain: host\n      replicated:\n        size: 3\n        requireSafeReplicaSize: false\n      parameters:\n        compression_mode:\n          none\n  preserveFilesystemOnDelete: true #当删除CephFilesystem资源时，是否保留Ceph集群中的实际文件系统。若设为true则保留，方便后续恢复使用。\n  metadataServer:\n    activeCount: 3\n    activeStandby: true\n    placement:\n      podAntiAffinity:\n        preferredDuringSchedulingIgnoredDuringExecution:\n          - weight: 100\n            podAffinityTerm:\n              labelSelector:\n                matchExpressions:\n                  - key: app\n                    operator: In\n                    values:\n                      - rook-ceph-mds\n              topologyKey: topology.kubernetes.io/zone\n    priorityClassName: system-cluster-critical\n    livenessProbe:\n      disabled: false\n    startupProbe:\n      disabled: false\nEOF\nkubectl apply -f rook-cephfs.yaml \nkubectl get pod -n rook-ceph | grep rook-cephfs\n```\n\n可能要一分钟才会创建好\n\n`为什么我能直接在k8s直接运行ceph指令，而不进入pod，自行去第二步开通看部署ceph集群的`\n\n![image-20240501205306444](../img/%E5%9F%BA%E4%BA%8EK8S%E7%9A%84CICD%E7%B3%BB%E7%BB%9F%E5%AE%9E%E7%8E%B0/2a1d57c846a6ca7b49a5d0527332f138697559838.png)\n\n快捷链接：[在K8S中直接调用出ceph命令](https://blog.qianyios.top/posts/58032/#%E5%9C%A8K8S%E4%B8%AD%E7%9B%B4%E6%8E%A5%E8%B0%83%E7%94%A8%E5%87%BAceph%E5%91%BD%E4%BB%A4)\n\n```\n[root@master1 examples]# ceph fs status\nrook-cephfs - 0 clients\n===========\nRANK      STATE            MDS          ACTIVITY     DNS    INOS   DIRS   CAPS\n 0        active      rook-cephfs-f  Reqs:    0 /s    10     13     12      0\n 1        active      rook-cephfs-c  Reqs:    0 /s     0      0      0      0\n 2        active      rook-cephfs-d  Reqs:    0 /s    10     12     11      0\n0-s   standby-replay  rook-cephfs-a  Evts:    0 /s     0      0      0      0\n2-s   standby-replay  rook-cephfs-b  Evts:    0 /s     0      0      0      0\n1-s   standby-replay  rook-cephfs-e  Evts:    0 /s     0      0      0      0\n         POOL             TYPE     USED  AVAIL\n rook-cephfs-metadata   metadata     0   94.9G\nrook-cephfs-replicated    data       0   94.9G\nMDS version: ceph version 17.2.6 (d7ff0d10654d2280e08f1ab989c7cdf3064446a5) quincy (stable)\n[root@master1 examples]# ceph fs ls\nname: rook-cephfs, metadata pool: rook-cephfs-metadata, data pools: [rook-cephfs-replicated ]\n[root@master1 examples]#\n```\n\n`rook-cephfs-replicated`是下面存储声明需要用到的 pool\n\n### 创建Storageclass\n\n是k8s调用ceph的声明，通过这个Storageclass才能去调用ceph\n\n```yaml\ncd \ncd rook/deploy/examples\ncat > rook-cephfs-sc.yaml <<\"EOF\"\napiVersion: storage.k8s.io/v1\nkind: StorageClass\nmetadata:\n  name: rook-cephfs-sc\nprovisioner: rook-ceph.cephfs.csi.ceph.com\nparameters:\n  clusterID: rook-ceph #ceph集群命名空间\n  fsName: rook-cephfs  #cephfs，刚刚创建的文件系统\n  pool: rook-cephfs-replicated   #刚刚创建的fs所包含的pool\n\n  csi.storage.k8s.io/provisioner-secret-name: rook-csi-cephfs-provisioner\n  csi.storage.k8s.io/provisioner-secret-namespace: rook-ceph\n  csi.storage.k8s.io/controller-expand-secret-name: rook-csi-cephfs-provisioner\n  csi.storage.k8s.io/controller-expand-secret-namespace: rook-ceph\n  csi.storage.k8s.io/node-stage-secret-name: rook-csi-cephfs-node\n  csi.storage.k8s.io/node-stage-secret-namespace: rook-ceph\nreclaimPolicy: Delete\nallowVolumeExpansion: true\nEOF\nkubectl apply -f rook-cephfs-sc.yaml \nkubectl get sc\n```\n\n![image-20240914162514951](../img/%E5%9F%BA%E4%BA%8EK8S%E7%9A%84CICD%E7%B3%BB%E7%BB%9F%E5%AE%9E%E7%8E%B0/7385fd2c6cfbfd0d82bde000a657ef7a697559838.png)\n\n## 部署harbor进群\n\n[Harbor共享存储高可用 - 严千屹博客 (qianyios.top)](https://blog.qianyios.top/posts/40301/)\n\n### 配置仓库地址\n\n部署好后，需要将K8s各个节点，和harbor各个节点都要进行配置仓库地址\n\n操作节点：[所有节点]\n\n```\nvim /etc/docker/daemon.json\n```\n\n```\n# 客户端默认使用的是https协议，所以需要对docker做以下修改,在文件末尾添加insecure-registries\n[root@qianyios ~]# vim /etc/docker/daemon.json\n{\n   ................\n  \"registry-mirrors\": [],#无关紧要，不用看,\n  \"insecure-registries\": [ \"192.168.48.100\" ],#重要加这行，别忘了如果他不是最后一行一定要在末尾加逗号\n ................\n}\n\n# 修改后，重启docker使其生效\nsystemctl daemon-reload\nsystemctl restart docker\n\n# 利用docker info查看是否添加上\n[root@qianyios ~]# docker info\nContainers: 10\n Running: 1\n Paused: 0\n Stopped: 9\nImages: 37\n...\n Experimental: false\n Insecure Registries:\n  192.168.48.100   ###要确保有这个才行\n  127.0.0.0/8\n Registry Mirrors:\n```\n\n![image-20240505170836267](../img/%E5%9F%BA%E4%BA%8EK8S%E7%9A%84CICD%E7%B3%BB%E7%BB%9F%E5%AE%9E%E7%8E%B0/27c58491143f043c8571088a209586ba697559838.png)\n\n### 测试免密登入\n\n接下来测试免密登入，第一次登入要密码，第二次登入就不用了，第二次之后就是免密登入\n\n```\ndocker login 192.168.48.100\n```\n\n![image-20240505172454889](../img/%E5%9F%BA%E4%BA%8EK8S%E7%9A%84CICD%E7%B3%BB%E7%BB%9F%E5%AE%9E%E7%8E%B0/972ff9da32eb962e1e8fa9785fddaf5b697559838.png)\n\n免密登入成功！\n\n## 部署jenkins\n\n操作节点:[masetr1]\n\n### 创建rabc验证\n\n```yaml\ncd \ncd jenkins\ncat > jenkins-rabc.yaml << \"EOF\"\napiVersion: v1\nkind: ServiceAccount\nmetadata:\n  name: jenkins-admin\n  namespace: jenkins\n---\napiVersion: rbac.authorization.k8s.io/v1\nkind: ClusterRoleBinding\nmetadata:\n  name: jenkins-admin\nroleRef:\n  apiGroup: rbac.authorization.k8s.io\n  kind: ClusterRole\n  name: cluster-admin\nsubjects:\n- kind: ServiceAccount\n  name: jenkins-admin\n  namespace: jenkins\nEOF\n\nkubectl apply -f jenkins-rabc.yaml\n```\n\n### 创建jenkins用户的secret\n\n```yaml\ncd \ncd jenkins\ncat >jenkins-admin-secret.yaml << \"EOF\"\napiVersion: v1\nkind: Secret\nmetadata:\n  name: jenkins-admin-secret\n  namespace: jenkins\n  annotations:\n    kubernetes.io/service-account.name: jenkins-admin\ntype: kubernetes.io/service-account-token\nEOF\nkubectl apply -f jenkins-admin-secret.yaml\nkubectl get secret -n jenkins\n\n[root@master1 jenkins]# kubectl get secret -n jenkins\nNAME                   TYPE                                  DATA   AGE\njenkins-admin-secret   kubernetes.io/service-account-token   3      15s\n\n```\n\n### 创建pvc\n\n```yaml\n#创建命名空间\ncd\nkubectl create namespace jenkins\nmkdir jenkins\ncd jenkins\ncat > pvc.yaml << EOF\nkind: PersistentVolumeClaim\napiVersion: v1\nmetadata:\n  name: jenkins-pvc\n  namespace: jenkins\nspec:\n  storageClassName: rook-cephfs-sc  #这个是第4步部署完ceph集群创建的Storageclass\n  resources:\n    requests:\n      storage: 3Gi\n  accessModes:\n  - ReadWriteMany\nEOF\nkubectl apply -f pvc.yaml\nkubectl get pvc -n jenkins\n```\n\n![image-20240914162447149](../img/%E5%9F%BA%E4%BA%8EK8S%E7%9A%84CICD%E7%B3%BB%E7%BB%9F%E5%AE%9E%E7%8E%B0/a1b6f6efe993f8ba675b5b8a8e36f7a6697559838.png)\n\n### 部署jenkins\n\n自行在harbor仓库创建好cicd仓库\n\n![image-20240505231349308](../img/%E5%9F%BA%E4%BA%8EK8S%E7%9A%84CICD%E7%B3%BB%E7%BB%9F%E5%AE%9E%E7%8E%B0/46d5e045cb2dbfc4c06a2e5ed806a093697559838.png)\n\n构建jenkins镜像\n\n```\ndocker pull jenkins/jenkins\n```\n\n可能会出现拉取缓慢现象，也可以用以下方法进行构建\n\n[基于阿里云容器服务构建私人docker镜像 - 严千屹博客 (qianyios.top)](https://blog.qianyios.top/posts/54563/)\n\n构建之后就要进行拉取下载打标签，以下是我自己构建的，你可以用这个\n\n```\n#下载镜像\ndocker pull registry.cn-hangzhou.aliyuncs.com/qianyios/jenkins:latest\n\n#打标签\ndocker tag registry.cn-hangzhou.aliyuncs.com/qianyios/jenkins:latest 192.168.48.100/cicd/jenkins:latest\n\n#查看镜像\n[root@master1 jenkins]# docker images | grep jenk\n192.168.48.100/cicd/jenkins                                            latest    786c9e8a0cb8   6 days ago      472MB\nregistry.cn-hangzhou.aliyuncs.com/qianyios/jenkins                     latest    786c9e8a0cb8   6 days ago      472MB\n[root@master1 jenkins]#\n\n\n#推送镜像到harbor仓库\ndocker push 192.168.48.100/cicd/jenkins:latest\n```\n\n![image-20240505231712011](../img/%E5%9F%BA%E4%BA%8EK8S%E7%9A%84CICD%E7%B3%BB%E7%BB%9F%E5%AE%9E%E7%8E%B0/ae7ab0b491aa633847aef399c8dfea57697559838.png)\n\n```\n#给所有master节点打上master标签\nkubectl label node master1 k8s-type=master\nkubectl label node master2 k8s-type=master\nkubectl label node master3 k8s-type=master\n```\n\n```yaml\ncd \ncd jenkins\ncat >jenkins-deploy.yaml << \"EOF\"\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: jenkins\n  namespace: jenkins\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: jenkins-server\n  template:\n    metadata:\n      labels:\n        app: jenkins-server\n    spec:\n      securityContext:\n            fsGroup: 995\n            runAsUser: 1000\n      serviceAccountName: jenkins-admin\n      nodeSelector:\n        k8s-type: master\n      containers:\n        - name: jenkins\n          image: 192.168.48.100/cicd/jenkins:latest\n          imagePullPolicy: IfNotPresent\n          resources:\n            limits:\n              memory: \"2Gi\"\n              cpu: \"1000m\"\n            requests:\n              memory: \"500Mi\"\n              cpu: \"500m\"\n          ports:\n            - name: httpport\n              containerPort: 8080\n            - name: jnlpport\n              containerPort: 50000\n          livenessProbe:\n            httpGet:\n              path: \"/login\"\n              port: 8080\n            initialDelaySeconds: 90\n            periodSeconds: 10\n            timeoutSeconds: 5\n            failureThreshold: 5\n          readinessProbe:\n            httpGet:\n              path: \"/login\"\n              port: 8080\n            initialDelaySeconds: 60\n            periodSeconds: 10\n            timeoutSeconds: 5\n            failureThreshold: 3\n          volumeMounts:\n            - name: jenkins-data\n              mountPath: /var/jenkins_home\n            - name: kubectl\n              mountPath: /usr/bin/kubectl\n            - name: kube-config\n              mountPath: /root/.kube\n            - name: docker\n              mountPath: /usr/bin/docker\n            - name: docker-sock\n              mountPath: /var/run/docker.sock\n      volumes:\n        - name: jenkins-data\n          persistentVolumeClaim:\n              claimName: jenkins-pvc\n        - name: kubectl\n          hostPath:\n            path: /usr/bin/kubectl\n        - name: kube-config\n          hostPath:\n            path: /root/.kube\n        - name: docker\n          hostPath:\n            path: /usr/bin/docker\n        - name: docker-sock\n          hostPath:\n            path: /var/run/docker.sock\nEOF\nkubectl apply -f jenkins-deploy.yaml \nkubectl get pods -n jenkins\n```\n\n### 创建svc\n\n```\ncd \ncd jenkins\ncat >jenkins-svc.yaml << \"EOF\"\napiVersion: v1\nkind: Service\nmetadata:\n  name: jenkins-service\n  namespace: jenkins\n  annotations:\n      prometheus.io/scrape: 'true'\n      prometheus.io/path:   /\n      prometheus.io/port:   '8080'\nspec:\n  selector:\n    app: jenkins-server\n  type: NodePort\n  ports:\n  - port: 8080\n    targetPort: 8080\n    nodePort: 32000\n    name: httpport\n  - name: jnlpport\n    port: 50000\n    targetPort: 50000\nEOF\nkubectl apply -f jenkins-svc.yaml\nkubectl get svc -n jenkins\n```\n\n### 访问页面\n\n```\nhttp://192.168.48.200:32000/\n```\n\n![image-20240505235348080](../img/%E5%9F%BA%E4%BA%8EK8S%E7%9A%84CICD%E7%B3%BB%E7%BB%9F%E5%AE%9E%E7%8E%B0/f331ea4ab75c72cf7571526a60a28063697559838.png)\n\n```\nkubectl get pods -n jenkins\n#查看你的pod名字替换下面的名字即可(jenkins-799dc7cd88-d2n4k)\n\n#进入容器\nkubectl exec -it -n jenkins jenkins-799dc7cd88-d2n4k -- bash\n\n#修改Update Center源\nsed -i 's#https://updates.jenkins.io/update-center.json#http://mirrors.tuna.tsinghua.edu.cn/jenkins/updates/update-center.json#g' /var/jenkins_home/hudson.model.UpdateCenter.xml\n \n#替换插件源地址： \nsed -i 's#https://updates.jenkins.io/download#http://mirrors.aliyun.com/jenkins#g' /var/jenkins_home/updates/default.json\n#替换谷歌地址： \nsed -i 's#http://www.google.com#http://www.baidu.com#g' /var/jenkins_home/updates/default.json\n\n\n#查看网页密码\njenkins@jenkins-546cf958bd-kq5f2:~$ cat /var/jenkins_home/secrets/initialAdminPassword\n\nebfc1b12835f43c8a8c2677728e4aa55\n\n```\n\n![image-20240506000643463](../img/%E5%9F%BA%E4%BA%8EK8S%E7%9A%84CICD%E7%B3%BB%E7%BB%9F%E5%AE%9E%E7%8E%B0/2f2db2a27d4a0dd3d92e857870278526697559838.png)\n\n先点无，这里先不安装，后面再安装\n\n![image-20240928203306616](../img/%E5%9F%BA%E4%BA%8EK8S%E7%9A%84CICD%E7%B3%BB%E7%BB%9F%E5%AE%9E%E7%8E%B0/a425a18e9ecb98b0a4723c128312ab51697559838.png)\n\n使用admin账户继续\n\n![image-20240506001948294](../img/%E5%9F%BA%E4%BA%8EK8S%E7%9A%84CICD%E7%B3%BB%E7%BB%9F%E5%AE%9E%E7%8E%B0/1e989f1a5689f8f4553543ffc7c59867697559838.png)\n\n默认下一步\n\n![image-20240506002019436](../img/%E5%9F%BA%E4%BA%8EK8S%E7%9A%84CICD%E7%B3%BB%E7%BB%9F%E5%AE%9E%E7%8E%B0/bb4f8222efce7330d25b4e8d18973466697559838.png)\n\n自行去设置修改admin密码\n\n![image-20240506002313407](../img/%E5%9F%BA%E4%BA%8EK8S%E7%9A%84CICD%E7%B3%BB%E7%BB%9F%E5%AE%9E%E7%8E%B0/eeb716caa3cf3919a39af3f80d2b7848697559838.png)\n\n### 配置k8s等插件和实现功能\n\n#### 安装插件\n\n```\n安装插件：Git / Git Parameter/Pipeline/Config File Provider/Gitlab/Generic Webhook Trigger/Blue Ocean/Localization: Chinese /Kubernetes\n```\n\n在首页点击系统管理然后点击插件管理-----安装Kubernetes插件\n\n![image-20240506002747172](../img/%E5%9F%BA%E4%BA%8EK8S%E7%9A%84CICD%E7%B3%BB%E7%BB%9F%E5%AE%9E%E7%8E%B0/9bfce81b43fd7ab943762a4d6cbbc455697559838.png)\n\n安装之后需要等待他重启\n\n![image-20240506003015735](../img/%E5%9F%BA%E4%BA%8EK8S%E7%9A%84CICD%E7%B3%BB%E7%BB%9F%E5%AE%9E%E7%8E%B0/2c83d8d8cb866cc6de3f9c8130bcf8e1697559838.png)\n\n![image-20240506003148720](../img/%E5%9F%BA%E4%BA%8EK8S%E7%9A%84CICD%E7%B3%BB%E7%BB%9F%E5%AE%9E%E7%8E%B0/444846662a1acfce590742d4f47b2abd697559838.png)\n\n#### 配置K8s代理节点\n\n配置jenkins连接kubernetes\n\n点击系统管理-cloud\n\n![image-20240928213206053](../img/%E5%9F%BA%E4%BA%8EK8S%E7%9A%84CICD%E7%B3%BB%E7%BB%9F%E5%AE%9E%E7%8E%B0/cf008758ec9195ff1ec5f56b3c0ae4db697559838.png)\n\n点击Clouds-添加New cloud\n\n![image-20240928213240693](../img/%E5%9F%BA%E4%BA%8EK8S%E7%9A%84CICD%E7%B3%BB%E7%BB%9F%E5%AE%9E%E7%8E%B0/69c95d344dca55dea99b62a293aa8948697559838.png)\n\n点击create\n\n![image-20240928213328017](../img/%E5%9F%BA%E4%BA%8EK8S%E7%9A%84CICD%E7%B3%BB%E7%BB%9F%E5%AE%9E%E7%8E%B0/8e27c7fe9c9e9e0905c7fee4fbe1e1bc697559838.png)\n\n查看Kubernetes 服务证书 key\n\n    [root@master1 jenkins]# cat /etc/kubernetes/pki/ca.crt\n    -----BEGIN CERTIFICATE-----\n    MIIDBTCCAe2gAwIBAgIIcJ+z+Wx0m20wDQYJKoZIhvcNAQELBQAwFTETMBEGA1UE\n    AxMKa3ViZXJuZXRlczAeFw0yNDA5MjgxMTI5NDJaFw0zNDA5MjYxMTM0NDJaMBUx\n    EzARBgNVBAMTCmt1YmVybmV0ZXMwggEiMA0GCSqGSIb3DQEBAQUAA4IBDwAwggEK\n    AoIBAQDYeRyEbAJRMqWyAmQf0LfK9wecWoQSyKYX+gHDUvZMaQK/nkAfrEme5Wot\n    J8lcODlNAj0OImRRKkCzfBwlZl5WMYH3Roonn8z9j4hkUAX/EgTwMun1q0G/D1yV\n    zxcRSUxxiFDKlRCVsPxIsuHIUvTrAHkU0qpz1S4cITisF9o9hCvqZZZ/5fCudn7I\n    sLlDhxzL1TAI5R2hqZKFdondpoGxYF5oc2wuk+0g/3GJZeaGEO/9p5ySX/glamil\n    e5npU/EvLsG4er2UQqB7dc9wfxOT2p0Qlj7UjHcqgY8E6ufhd7GqYVKNDXSmKXiP\n    BZI5ba6/kZJj0nsSz3GnVdhFxUD1AgMBAAGjWTBXMA4GA1UdDwEB/wQEAwICpDAP\n    BgNVHRMBAf8EBTADAQH/MB0GA1UdDgQWBBT5qTcFwRrY/VSJtfAZK85ZCp2ViTAV\n    BgNVHREEDjAMggprdWJlcm5ldGVzMA0GCSqGSIb3DQEBCwUAA4IBAQDX+1q8NXKb\n    HWnfR75MORrQJ898B9M1FBoHfLRdsmmCJVrSQXbBbKn1zVoJL6YLdjDOx2NfWa8o\n    f1Y7KSme9Z6B4j57tGFQ/4LST4Cwk4PPh1v6nrwVesW6xE6ClHVZ0N1S4ggZi8ll\n    Wcv3ZCgdGrjSQm15xsRr4oN7XGY/B1kAZWU4defpcxhtIMtLQ7/m74hfYo/P5L/b\n    Wu1knzRSs1/Cna2GFkWx3BYfbG78ZPBIh17mN4vFAt/x8ZOZCJ+bb0Ey6upYnhjP\n    H2jiNrHcyJVnnDO4N6kMII9sh2n+gYvK45u+/Vw8nPElf72LkHFHOyQc8QD9opXF\n    LC9bmhoJuU9v\n    -----END CERTIFICATE-----\n\n![image-20240928213425808](../img/%E5%9F%BA%E4%BA%8EK8S%E7%9A%84CICD%E7%B3%BB%E7%BB%9F%E5%AE%9E%E7%8E%B0/91f86a090ce50d4e913757901517361f697559838.png)\n\n获取凭证\n\n> 不是低版本，请跳到下一步！！！！\n>\n> 低版本获取凭证方法，低版本会自动生成一个secret\n\n    [root@master1 ~]# SECRET_NAME=$(kubectl get serviceaccount jenkins-admin  -o=jsonpath='{.secrets[0].name}' -n jenkins)\n    [root@master1 ~]# kubectl get secrets $SECRET_NAME  -o=jsonpath='{.data.token}' -n jenkins | base64 -d\n\n> k8s1.28获取凭证方法，需要手动创建secret\n>\n> 使用kubectl create token获取的token会过期\n>\n> 这里手动创建secret，并查看相关token值\n\n编写jenkins-admin用户secret清单,并创建\n\n    cd /root/jenkins\n    cat >jenkins-admin-secret.yaml<< \"EOF\"\n    apiVersion: v1\n    kind: Secret\n    metadata:\n      name: jenkins-admin-secret\n      namespace: jenkins\n      annotations:\n        kubernetes.io/service-account.name: jenkins-admin\n    type: kubernetes.io/service-account-token\n    EOF\n     kubectl apply -f jenkins-admin-secret.yaml\n\n查看secret\n\n    kubectl get secret -n jenkins\n\n![image-20240928213605321](../img/%E5%9F%BA%E4%BA%8EK8S%E7%9A%84CICD%E7%B3%BB%E7%BB%9F%E5%AE%9E%E7%8E%B0/1029a221f55fb41ac9127d7e05ac64d4697559838.png)\n\n获取token\n\n    [root@master1 jenkins]# kubectl get secrets jenkins-admin-secret  -o=jsonpath='{.data.token}' -n jenkins | base64 -d\n    eyJhbGciOiJSUzI1NiIsImtpZCI6ImpaNkJTN3d0M0pFblBCSVBaaGFoNzdUTVNLMHZiTERxY09Ibmg4WEtFNTQifQ.eyJpc3MiOiJrdWJlcm5ldGVzL3NlcnZpY2VhY2NvdW50Iiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9uYW1lc3BhY2UiOiJqZW5raW5zIiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9zZWNyZXQubmFtZSI6ImplbmtpbnMtYWRtaW4tc2VjcmV0Iiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9zZXJ2aWNlLWFjY291bnQubmFtZSI6ImplbmtpbnMtYWRtaW4iLCJrdWJlcm5ldGVzLmlvL3NlcnZpY2VhY2NvdW50L3NlcnZpY2UtYWNjb3VudC51aWQiOiI3MTg2Mzg1Mi1jNDkwLTQyMDEtYTA2OS1lM2ZhOTcyNTgwODYiLCJzdWIiOiJzeXN0ZW06c2VydmljZWFjY291bnQ6amVua2luczpqZW5raW5zLWFkbWluIn0.sfofmctQos9fcEAf0hZEfEKN2WiG7GklOW6NMEdXbiJHkg5SNe8-MuJK4c4JtubyIA9IFhHo6PfQoFl8-2smuFaojjSKZKn2esJJ5enT_WNsbIdXmu4tg8a2571EikotiGKLpGHuLEZOLdTyswTsQW-FSQH7K16VmfUSzHCkKjV5eXNK3gpRj9p3voGWlBRQ3Jqfm6NWSKp_1_XZqFyi_KM8DOaMHhffN24ejwC2lvIzKNcZp80yY2rW4BkCI0dLN2GqUNlzB9QXYUslLtsigObukCdjY8EefCc34Rh68kq2UQVpXb9eTkyK50J9HEFJtLiuameD3Yx8gNE9xWJ4Vw\n\n![image-20240928213838987](../img/%E5%9F%BA%E4%BA%8EK8S%E7%9A%84CICD%E7%B3%BB%E7%BB%9F%E5%AE%9E%E7%8E%B0/5d35fd472547195b51a88ab988d01702697559838.png)\n\n配置kubernetes相关信息\n\n- > **Name**: 这个自定义， 默认的是`kubernetes`\n\n- > **Kubernetes URL**: `https://kubernetes.default`- 这个一般是从你的 service account 自动配置的\n\n- > **Kubernetes 服务证书 key**： 如果您有 Kubernetes 集群 CA 证书，您可以添加它以实现安全连接。您可以从 pod 位置获取证书/var/run/secrets/kubernetes.io/serviceaccount/ca.crt。如果您没有证书，您可以启用“ disable https certificate check”(禁用HTTPS证书检查)选项\n\n- > **Kubernetes Namespace**: 一般是 `default` 除非你要在一个特殊的命名空间 ，否则不要动他.因为我的jenkins部署在了jenkin命名空间，就用了jenkins\n\n- > **Credentials（凭据）**: 为了让 Jenkins 与 Kubernetes 集群通信，我们需要一个服务帐户令牌，该令牌具有在设置的命名空间中部署 pod 的权限\n\n- > **Jenkins URL**: `http://<your_jenkins_hostname>:port`\n\n- > **Jenkins tunnel**: `<your_jenkins_hostname>:50000` - 这就是用来和 Jenkins 启动的 agent 进行交互的端口\n\n修改名称和kubernetes地址及服务证书key\n\n> 此Kubernetes由于Jenkins 服务器在同一个 Kubernetes 集群中运行，这里直接通过service进行通讯\n>\n> 此服务证书key就是前几步获取的key\n\n添加凭证\n\n点击添加-\\>jenkins\n\n![image-20240928214022992](../img/%E5%9F%BA%E4%BA%8EK8S%E7%9A%84CICD%E7%B3%BB%E7%BB%9F%E5%AE%9E%E7%8E%B0/88c7b458474ca8db5d89bec785d81fc2697559838.png)\n\n> 选择Domain为全局凭据\n>\n> 类型选择为secret txt\n>\n> 范围选择为全局\n>\n> secret就是刚才获取的凭据\n>\n> 描述 就是凭据的名称\n\n![image-20240928214459767](../img/%E5%9F%BA%E4%BA%8EK8S%E7%9A%84CICD%E7%B3%BB%E7%BB%9F%E5%AE%9E%E7%8E%B0/db974a377f80c3958d46484be433e830697559838.png)\n\n点击添加\n\n选择凭据为刚才添加的,点击测试链接，验证 Kubernetes 集群的连接性\n\n![image-20240928214608024](../img/%E5%9F%BA%E4%BA%8EK8S%E7%9A%84CICD%E7%B3%BB%E7%BB%9F%E5%AE%9E%E7%8E%B0/c311dab5e0e86a2698f4f9ed84d9c0c3697559838.png)\n\n配置 Jenkins URL 详细信息\n\n> 对于在k8s集群内部运行的 Jenkins master，您可以使用 Kubernetes 集群的 Service 端点作为 Jenkins URL，因为代理 pod 可以通过内部服务 DNS 连接到集群\n>\n> url语法：http://.:8080\n>\n> jenkins-service.jenkins:8080\n>\n> 注意：Jenkins 通道（Jenkins tunnel）链接不需要加http://，否则无法正常通讯\n\n![image-20240928214829511](../img/%E5%9F%BA%E4%BA%8EK8S%E7%9A%84CICD%E7%B3%BB%E7%BB%9F%E5%AE%9E%E7%8E%B0/adc17f12dcabbcdeaf52ed546e6d431c697559838.png)\n\n创建成功\n\n![image-20240928214845932](../img/%E5%9F%BA%E4%BA%8EK8S%E7%9A%84CICD%E7%B3%BB%E7%BB%9F%E5%AE%9E%E7%8E%B0/2c5236e38fe3963d8a4e50ce094400e6697559838.png)\n\n#### 创建Jenkins代理镜像\n\n拉取jenkins代理镜像并上传到harbor仓库\n\n    docker pull jenkins/inbound-agent\n    #如果下不到可以用我的\n    docker pull registry.cn-hangzhou.aliyuncs.com/qianyios/inbound-agent:latest\n    docker tag registry.cn-hangzhou.aliyuncs.com/qianyios/inbound-agent:latest 192.168.48.100/library/inbound-agent:latest\n    docker push 192.168.48.100/library/inbound-agent:latest\n    docker images | grep inbound\n\n## 部署gitlab\n\n### 创建gitlab的secret\n\n```\n#长度为8个字符\n[root@master1 ~]# echo -n 'qianyios' | base64\ncWlhbnlpb3M=\n#qianyios将会成为gitlab页面的登入密码\n```\n\n```\nmkdir /root/gitlab\ncd /root/gitlab\n#创建namespace\nkubectl create namespace gitlab\n```\n\n```yaml\ncat >gitlab-secret-pwd.yaml << \"EOF\"\napiVersion: v1\ndata:\n  password: cWlhbnlpb3M=  #换成刚刚前面生成的密码\nkind: Secret\nmetadata:\n  creationTimestamp: null\n  name: gitlab-pwd\n  namespace: gitlab\nEOF\nkubectl apply -f gitlab-secret-pwd.yaml\nkubectl get secret -n gitlab\n```\n\n![image-20240928215102453](../img/%E5%9F%BA%E4%BA%8EK8S%E7%9A%84CICD%E7%B3%BB%E7%BB%9F%E5%AE%9E%E7%8E%B0/87d17c22886bf21b7dfffd601007c06a697559838.png)\n\n### 创建pvc\n\n```\ncat > gitlab-pvc.yaml <<\"EOF\"\nkind: PersistentVolumeClaim\napiVersion: v1\nmetadata:\n  name: gitlab-pvc-logs\n  namespace: gitlab\nspec:\n  storageClassName: rook-cephfs-sc\n  resources:\n    requests:\n      storage: 5Gi\n  accessModes:\n  - ReadWriteOnce\n---\nkind: PersistentVolumeClaim\napiVersion: v1\nmetadata:\n  name: gitlab-pvc-config\n  namespace: gitlab\nspec:\n  storageClassName: rook-cephfs-sc\n  resources:\n    requests:\n      storage: 1Gi\n  accessModes:\n  - ReadWriteOnce\n---\nkind: PersistentVolumeClaim\napiVersion: v1\nmetadata:\n  name: gitlab-pvc-data\n  namespace: gitlab\nspec:\n  storageClassName: rook-cephfs-sc\n  resources:\n    requests:\n      storage: 10Gi\n  accessModes:\n  - ReadWriteOnce\nEOF\n  \nkubectl apply -f gitlab-pvc.yaml \nkubectl get pvc -n gitlab\n```\n\n![image-20240510195549565](../img/%E5%9F%BA%E4%BA%8EK8S%E7%9A%84CICD%E7%B3%BB%E7%BB%9F%E5%AE%9E%E7%8E%B0/06a3898e71f0a5443a8c3e4e5f614558697559838.png)\n\n### 部署gitlab\n\n```\n#下载gitlab-ce镜像，镜像很大要1个G多\n docker pull gitlab/gitlab-ce\n# 如果下不了用我构建的镜像\ndocker pull registry.cn-hangzhou.aliyuncs.com/qianyios/gitlab:latest\n\n\n#镜像打标签#这个里我用了自己构建的镜像，你要是用这个gitlab/gitlab-ce自行替换\ndocker tag registry.cn-hangzhou.aliyuncs.com/qianyios/gitlab:latest 192.168.48.100/cicd/gitlab:latest\n\n#推送镜像\ndocker push 192.168.48.100/cicd/gitlab:latest\n```\n\n```\n给node节点打上k8s-type=node标签\nkubectl label nodes node01 k8s-type=node\n```\n\n```\ncat > gitlab-deploy.yaml << \"EOF\"\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  creationTimestamp: null\n  labels:\n    app: gitlab\n  name: gitlab\n  namespace: gitlab\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: gitlab\n  strategy: {}\n  template:\n    metadata:\n      creationTimestamp: null\n      labels:\n        app: gitlab\n    spec:\n      nodeSelector:\n        k8s-type: node\n      containers:\n      - image: 192.168.48.100/cicd/gitlab:latest  #更换镜像\n        imagePullPolicy: IfNotPresent\n        name: gitlab-ce\n        env:\n        - name: GITLAB_ROOT_PASSWORD\n          valueFrom:\n            secretKeyRef:\n              name: gitlab-pwd\n              key: password\n        - name: GITLAB_ROOT_MAIL\n          value: xiaoohu2002@126.com\n        ports:\n        - name: gitlab80\n          containerPort: 80\n        - name: gitlab22\n          containerPort: 22\n        - name: gitlab443\n          containerPort: 443\n        volumeMounts:\n        - name: gitlab-logs\n          mountPath: /var/log/gitlab\n        - name: gitlab-config\n          mountPath: /etc/gitlab\n        - name: gitlab-data\n          mountPath: /var/opt/gitlab\n      volumes:\n      - name: gitlab-logs\n        persistentVolumeClaim:\n          claimName: gitlab-pvc-logs\n      - name: gitlab-config\n        persistentVolumeClaim:\n          claimName: gitlab-pvc-config\n      - name: gitlab-data\n        persistentVolumeClaim:\n          claimName: gitlab-pvc-data\nstatus: {}\n\nEOF\nkubectl apply -f  gitlab-deploy.yaml\nkubectl get pod -n gitlab\n```\n\n### 创建svc\n\n```\ncat > gitlab-svc.yaml << \"EOF\"\napiVersion: v1\nkind: Service\nmetadata:\n  creationTimestamp: null\n  labels:\n    app: gitlab\n  name: gitlab\n  namespace: gitlab\nspec:\n  ports:\n  - name: 80-80\n    port: 80\n    protocol: TCP\n    targetPort: 80\n    nodePort: 30880\n  - name: 443-443\n    port: 443\n    protocol: TCP\n    targetPort: 443\n  - name: 22-22\n    port: 22\n    protocol: TCP\n    targetPort: 22\n  selector:\n    app: gitlab\n  type: NodePort\nstatus:\n  loadBalancer: {}\n\nEOF\nkubectl apply -f  gitlab-svc.yaml\nkubectl get svc -n gitlab\n```\n\n访问页面\n\n```\nhttp://192.168.48.200:30880/\n```\n\n![image-20240510211753542](../img/%E5%9F%BA%E4%BA%8EK8S%E7%9A%84CICD%E7%B3%BB%E7%BB%9F%E5%AE%9E%E7%8E%B0/969b19b798d53ed377c1c2b6ca9d0d2c697559838.png)\n\n### 页面测试\n\n#### 设置中文\n\n![sp20240920_184829_245](../img/%E5%9F%BA%E4%BA%8EK8S%E7%9A%84CICD%E7%B3%BB%E7%BB%9F%E5%AE%9E%E7%8E%B0/e040569c710147601f16d05900f35bcc697559838.png)\n\n\n\n#### 创建项目\n\n![image-20240920185232410](../img/%E5%9F%BA%E4%BA%8EK8S%E7%9A%84CICD%E7%B3%BB%E7%BB%9F%E5%AE%9E%E7%8E%B0/c79d7f3b59233ef180d9a4651917e311697559838.png)\n\n![image-20240920185329957](../img/%E5%9F%BA%E4%BA%8EK8S%E7%9A%84CICD%E7%B3%BB%E7%BB%9F%E5%AE%9E%E7%8E%B0/f487ee08b53753e3839e9650926bd7eb697559838.png)\n\n#### 项目推送\n\n操作节点:[master1]\n\n```\nyum install -y git\nmkdir /root/cicd/\ncd /root/cicd/\nmkdir chatgpt && cd chatgpt/\n```\n\n上传Chatgpt镜像站源码\n\n项目地址：[ChatGPTNextWeb](https://github.com/ChatGPTNextWeb/ChatGPT-Next-Web)\n\n```\ncd /root/cicd/chatgpt/\nwget https://github.com/ChatGPTNextWeb/ChatGPT-Next-Web/archive/refs/heads/main.zip\n```\n\n```\n[root@master1 chatgpt]# ls main.zip\n```\n\n解压源代码压缩包\n\n```\nunzip /root/cicd/chatgpt/main.zip\nmv ChatGPT-Next-Web-main/* ./\nrm -rf ChatGPT-Next-Web-main main.zip\n```\n\nGit全局设置\n\n```\ngit config --global user.name \"Administrator\"\ngit config --global user.email \"XiaooHu2002@163.com\"\n```\n\n添加版本库\n\n```\ncd /root/cicd/chatgpt/\ngit init\n```\n\n添加远程仓库\n\n要注意是哪个主分支哦！这里的是main\n\n![image-20240920192141173](../img/%E5%9F%BA%E4%BA%8EK8S%E7%9A%84CICD%E7%B3%BB%E7%BB%9F%E5%AE%9E%E7%8E%B0/81d9c2fdd2282841face7bc23cbebb3f697559838.png)\n\n\n\n```bash\ngit remote add origin http://192.168.48.200:30880/root/chatgpt.git\n#跟踪所有改动过的文件\ngit add . \n#提交所有更新过的文件\ngit commit -m \"first commit\"\n#将代码推送到远程仓库（主分支main）\n#如果主分支是main则直接执行下一步\n#首先我本地的主分支是master，我需要切换，可以通过git branch查看\ngit branch -m master main\n#推送main分支\ngit push -u origin main\n\n#会提示你让你输入gitlab的账号密码\nUsername for 'http://192.168.48.200:30880': root\nPassword for 'http://root@192.168.48.200:30880':\n#密码是qianyios\n```\n\n![image-20240928221810920](../img/%E5%9F%BA%E4%BA%8EK8S%E7%9A%84CICD%E7%B3%BB%E7%BB%9F%E5%AE%9E%E7%8E%B0/d37dd6861d7882ee071e71ee2e8f332a697559838.png)\n\n![image-20240928221824375](../img/%E5%9F%BA%E4%BA%8EK8S%E7%9A%84CICD%E7%B3%BB%E7%BB%9F%E5%AE%9E%E7%8E%B0/d4aa005daac2902cfba88cc454ef488c697559838.png)\n\n## Jenkins对接gitlab\n\n### 创建gitlab Secret令牌\n\n进入gitlab创建Secret令牌\n\n![image-20240928232433171](../img/%E5%9F%BA%E4%BA%8EK8S%E7%9A%84CICD%E7%B3%BB%E7%BB%9F%E5%AE%9E%E7%8E%B0/a82a765978bcf39cb1997f6e6d9d28cd697559838.png)\n\n![image-20240928232523788](../img/%E5%9F%BA%E4%BA%8EK8S%E7%9A%84CICD%E7%B3%BB%E7%BB%9F%E5%AE%9E%E7%8E%B0/ba7d24a30096e859452519103d31bd9c697559838.png)\n\n创建成功Secret令牌，并复制令牌\n\n> 此令牌需要保存好，后面jenkins还需要用到\n>\n> glpat-vLZgV6Z1nbC_96yyZdyp\n\n![image-20240928232604113](../img/%E5%9F%BA%E4%BA%8EK8S%E7%9A%84CICD%E7%B3%BB%E7%BB%9F%E5%AE%9E%E7%8E%B0/862de2cc8598bac9f54951ff4d3c6fa6697559838.png)\n\n### Jenkins创建流水线\n\n点击新建任务，输入名称并选择为流水线，并点击确定\n\n![image-20240928232711976](../img/%E5%9F%BA%E4%BA%8EK8S%E7%9A%84CICD%E7%B3%BB%E7%BB%9F%E5%AE%9E%E7%8E%B0/67f45551ed6670814d2b93f0914baa20697559838.png)\n\n在general中找到Generic Webhook Trigger 并勾选且复制webhook链接\n\n> http://JENKINS_URL/generic-webhook-trigger/invoke\n\n![image-20240928232844592](../img/%E5%9F%BA%E4%BA%8EK8S%E7%9A%84CICD%E7%B3%BB%E7%BB%9F%E5%AE%9E%E7%8E%B0/65caaf702957698297fefe7b0a8c47d4697559838.png)\n\n添加gitlab凭据\n\n![image-20240928233042430](../img/%E5%9F%BA%E4%BA%8EK8S%E7%9A%84CICD%E7%B3%BB%E7%BB%9F%E5%AE%9E%E7%8E%B0/6c0891a031bd660647e2bd36bc72036d697559838.png)\n\n![image-20240928233233174](../img/%E5%9F%BA%E4%BA%8EK8S%E7%9A%84CICD%E7%B3%BB%E7%BB%9F%E5%AE%9E%E7%8E%B0/a05a08721f9d77983116845433f6a86a697559838.png)\n\n![image-20240928233322636](../img/%E5%9F%BA%E4%BA%8EK8S%E7%9A%84CICD%E7%B3%BB%E7%BB%9F%E5%AE%9E%E7%8E%B0/61ae798e294383757346bb23d86fb8d8697559838.png)\n\n#### 配置Webhook\n\n配置允许Webhook和服务对本地网络的请求\n\n进入管理员-设置-网络\n\n![image-20240928233445339](../img/%E5%9F%BA%E4%BA%8EK8S%E7%9A%84CICD%E7%B3%BB%E7%BB%9F%E5%AE%9E%E7%8E%B0/73d1d1479e2f5b73d8c2d1b31dcd88c0697559838.png)\n\n勾选允许来自 webhooks 和集成对本地网络的请求并保存更改即可\n\n![image-20240928233549420](../img/%E5%9F%BA%E4%BA%8EK8S%E7%9A%84CICD%E7%B3%BB%E7%BB%9F%E5%AE%9E%E7%8E%B0/131fa8a88fe4f5fd7fa4a77cebe3a22a697559838.png)\n\n接下来配置webhooks\n\n进入到项目中\n\n![image-20240928233715393](../img/%E5%9F%BA%E4%BA%8EK8S%E7%9A%84CICD%E7%B3%BB%E7%BB%9F%E5%AE%9E%E7%8E%B0/a44c0ad8409ea4f5ba76072c9ada0c91697559838.png)\n\n填写相关信息\n\n> 网址：就是刚才jenkins创建项目的时候复制的链接，这里只是对其进行修改了，因为jenkins和gitlab都是部署在同一个k8s集群中我这里将域名修改成了service的地址\n>\n> 原地址：http://JENKINS_URL/generic-webhook-trigger/invoke\n>\n> 修改后的地址:http://jenkins-service.jenkins:8080/generic-webhook-trigger/invoke\n>\n> - **`jenkins-service`**：这是服务的名称，它在 Kubernetes 集群内部用于标识 Jenkins 服务。\n> - **`.jenkins`**：这是 Jenkins 服务所在的命名空间（namespace）。在 Kubernetes 中，服务的 DNS 名称会包含其命名空间。\n> - **`:8080`**：这是服务暴露的端口号，Jenkins 默认使用 8080 端口提供 Web 服务。\n>\n> `自己可以根据自己的deployment去修改`\n>\n> Secret 令牌：就是刚创建的个人令牌\n>\n> 推送事件：指定只有推送到某个仓库时才触发，留空则全部分支\n\n先看更改地址，这一步不需要操作什么，看清楚，替换了啥JENKINS_URL➡️jenkins-service.jenkins:8080\n\n![image-20240928234842712](../img/%E5%9F%BA%E4%BA%8EK8S%E7%9A%84CICD%E7%B3%BB%E7%BB%9F%E5%AE%9E%E7%8E%B0/3b4750bf2bc83def18803dc94f5833e0697559838.png)\n\n部署webhook\n\n![image-20240928235008407](../img/%E5%9F%BA%E4%BA%8EK8S%E7%9A%84CICD%E7%B3%BB%E7%BB%9F%E5%AE%9E%E7%8E%B0/49d0585b109c99ac2e4f7bbcbbc75a17697559838.png)\n\n![image-20240928234156662](../img/%E5%9F%BA%E4%BA%8EK8S%E7%9A%84CICD%E7%B3%BB%E7%BB%9F%E5%AE%9E%E7%8E%B0/f0dde55be4a78a5e03ab6998ade02c23697559838.png)\n\n然后添加webhook即可，然后测试推送事件\n\n![image-20240928235306092](../img/%E5%9F%BA%E4%BA%8EK8S%E7%9A%84CICD%E7%B3%BB%E7%BB%9F%E5%AE%9E%E7%8E%B0/31c356b4b6ac9022eb25d7caf142b444697559838.png)\n\n### 配置jenkins流水线\n\n#### 添加harbor用户\n\n![image-20240928235427264](../img/%E5%9F%BA%E4%BA%8EK8S%E7%9A%84CICD%E7%B3%BB%E7%BB%9F%E5%AE%9E%E7%8E%B0/3fda7a4b1043d4eba49619872d48cd5f697559838.png)\n\n![image-20240928235449242](../img/%E5%9F%BA%E4%BA%8EK8S%E7%9A%84CICD%E7%B3%BB%E7%BB%9F%E5%AE%9E%E7%8E%B0/dfd2d67aec2724ec510c8e0df619d957697559838.png)\n\n输入相关信息并点击create创建\n\n> 类型选择Username with password\n>\n> 范围选择全局\n>\n> 用户名为Harbor仓库用户名\n>\n> 密码为Harbor仓库用户密码\n>\n> 描述为此凭据的名称\n\n![image-20240928235632916](../img/%E5%9F%BA%E4%BA%8EK8S%E7%9A%84CICD%E7%B3%BB%E7%BB%9F%E5%AE%9E%E7%8E%B0/f414413c293dd15bb9ab3553f49ede43697559838.png)\n\n![image-20240928235646179](../img/%E5%9F%BA%E4%BA%8EK8S%E7%9A%84CICD%E7%B3%BB%E7%BB%9F%E5%AE%9E%E7%8E%B0/e9948bdccb4263609f078117a3ca72b4697559838.png)\n\n创建好后，接下来配置流水线\n\n先获取项目仓库地址\n\n![image-20240929000356404](../img/%E5%9F%BA%E4%BA%8EK8S%E7%9A%84CICD%E7%B3%BB%E7%BB%9F%E5%AE%9E%E7%8E%B0/e8aa9cfc053f08e019a4f526f0e1d1c7697559838.png)\n\n但是我们要对其中的地址改一下，改成\n\n> http://gitlab.gitlab/root/chatgpt.git\n\n回到jenkins任务\n\n点击Dashboard->ChatGPT->设置->并点击流水线\n\n![image-20240928235754557](../img/%E5%9F%BA%E4%BA%8EK8S%E7%9A%84CICD%E7%B3%BB%E7%BB%9F%E5%AE%9E%E7%8E%B0/f0306952bcd18ffa427235deca6af3f1697559838.png)\n\n![image-20240929002051798](../img/%E5%9F%BA%E4%BA%8EK8S%E7%9A%84CICD%E7%B3%BB%E7%BB%9F%E5%AE%9E%E7%8E%B0/8330554bf1e3c1fed45cfc5879951ddf697559838.png)\n\n点击添加凭据\n\n> Domain 选择全局凭据\n>\n> 类型选择Username with password\n>\n> 范围选择全局\n>\n> 用户名即是gitlab账号\n>\n> 密码即是gitlab账号密码\n>\n> 描述为此凭据的名称\n\n![image-20240929002313733](../img/%E5%9F%BA%E4%BA%8EK8S%E7%9A%84CICD%E7%B3%BB%E7%BB%9F%E5%AE%9E%E7%8E%B0/fedfa1d6622d973dda0b1c7e0f7d05f9697559838.png)\n\n往下滑\n\n![image-20240929002527605](../img/%E5%9F%BA%E4%BA%8EK8S%E7%9A%84CICD%E7%B3%BB%E7%BB%9F%E5%AE%9E%E7%8E%B0/c810fe11e41ce90a1f52eb5aa66af647697559838.png)\n\n保存即可\n\n#### harbor新建项目\n\n输入相关信息并点击确定\n\n> 用于存放业务镜像\n>\n> 访问级别设置成公开\n>\n> 存储容量为-1即代表不限制存储容量\n\n![image-20240929002628378](../img/%E5%9F%BA%E4%BA%8EK8S%E7%9A%84CICD%E7%B3%BB%E7%BB%9F%E5%AE%9E%E7%8E%B0/1c9300e55119c68fcdcd887228087659697559838.png)\n\n#### 项目镜像准备\n\n```\ndocker pull node:18-alpine\n#如果下载不了可以用我的\ndocker pull registry.cn-hangzhou.aliyuncs.com/qianyios/node:18-alpine\ndocker tag registry.cn-hangzhou.aliyuncs.com/qianyios/node:18-alpine 192.168.48.100/library/node:18-alpine\ndocker push 192.168.48.100/library/node:18-alpine\n```\n\n#### 编写业务部署清单\n\n```\n[root@master1 ~]# echo -n \"https://xiaoai.plus\" | base64\naHR0cHM6Ly94aWFvYWkucGx1cw==\n\n[root@master1 ~]# echo -n \"sk-K19c1kSqZZ92sXp13d042aD4E2B74a60B749E717Ed69449e\" | base64\n\nc2stSzE5YzFrU3FaWjkyc1hwMTNkMDQyYUQ0RTJCNzRhNjBCNzQ5RTcxN0VkNjk0NDll\n```\n\nkey是ChatGPTkey，这里已经对其base64加密\n\nbaseurl是chatgpt第三方服务商提供的代理地址，这里已经对其base64加密\n\n```\ncd /root/cicd/chatgpt\nkubectl create deploy chatgpt --image=chatgpt-next-web --dry-run=client -oyaml\nkubectl create svc nodeport  chatgpt --tcp=3000:3000 --dry-run=client -oyaml >> deploy.yaml\nvim deploy.yaml\n```\n\n```\napiVersion: v1\ndata:\n  key: c2stSzE5YzFrU3FaWjkyc1hwMTNkMDQyYUQ0RTJCNzRhNjBCNzQ5RTcxN0VkNjk0NDll\n  baseurl: aHR0cHM6Ly94aWFvYWkucGx1cw==\nkind: Secret\nmetadata:\n  creationTimestamp: null\n  name: chat-config\n\n---\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  creationTimestamp: null\n  labels:\n    app: chatgpt\n  name: chatgpt\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: chatgpt\n  strategy: {}\n  template:\n    metadata:\n      creationTimestamp: null\n      labels:\n        app: chatgpt\n    spec:\n      containers:\n      - image: chatgpt-next-web\n        name: chatgpt\n        ports:\n        - containerPort: 3000\n        imagePullPolicy: IfNotPresent\n        env:\n        - name: OPENAI_API_KEY\n          valueFrom:\n            secretKeyRef:\n              name: chat-config\n              key: key\n        - name: BASE_URL\n          valueFrom:\n            secretKeyRef:\n              name: chat-config\n              key: baseurl\n---\napiVersion: v1\nkind: Service\nmetadata:\n  creationTimestamp: null\n  labels:\n    app: chatgpt\n  name: chatgpt\nspec:\n  ports:\n  - name: 3000-3000\n    port: 3000\n    protocol: TCP\n    targetPort: 3000\n  selector:\n    app: chatgpt\n  type: NodePort\nstatus:\n  loadBalancer: {}\n```\n\n#### 编写镜像构建文件\n\n```\ncd /root/cicd/chatgpt\nsed -i 's|https://registry.yarnpkg.com/|https://registry.npmmirror.com/|g' yarn.lock\ncat > Dockerfile <<\"EOF\"\n# 基础镜像\nFROM 192.168.48.100/library/node:18-alpine AS base\n\n\n# 设置国内镜像源\nRUN sed -i 's/dl-cdn.alpinelinux.org/mirrors.ustc.edu.cn/g' /etc/apk/repositories\nRUN apk add --no-cache libc6-compat proxychains-ng\n\nWORKDIR /app\n\n# 依赖阶段\nCOPY package.json yarn.lock ./\nRUN npm config set registry https://registry.npmmirror.com\nRUN yarn config set registry https://registry.npmmirror.com --global\n\n# 替换 yarn.lock 文件中的源地址\nRUN sed -i 's|https://registry.yarnpkg.com/|https://registry.npmmirror.com/|g' yarn.lock\nRUN sed -i 's|https://registry.npmjs.org/|https://registry.npmmirror.com/|g' yarn.lock\n\n# 清除缓存并安装依赖\nRUN yarn config list  # 查看当前的 Yarn 配置\nRUN yarn install\n\n# 更新 caniuse-lite\nRUN npx update-browserslist-db@latest\n\n# 构建阶段\nFROM base AS builder\nRUN apk update && apk add --no-cache git\nENV OPENAI_API_KEY=\"\"\nENV BASE_URL=\"\"\n\nWORKDIR /app\nCOPY . .\nRUN yarn add @svgr/webpack@latest --frozen-lockfile\nRUN yarn add sharp  # 添加 sharp 包\nRUN yarn build\n\n# 运行阶段\nFROM base AS runner\nWORKDIR /app\nRUN apk add proxychains-ng\n\nENV PROXY_URL=\"\"\nENV OPENAI_API_KEY=\"\"\nENV BASE_URL=\"\"\n\nCOPY --from=builder /app/public ./public\nCOPY --from=builder /app/.next/standalone ./\nCOPY --from=builder /app/.next/static ./.next/static\nCOPY --from=builder /app/.next/server ./.next/server\n\nEXPOSE 3000\n\nCMD if [ -n \"$PROXY_URL\" ]; then \\\n        export HOSTNAME=\"127.0.0.1\"; \\\n        protocol=$(echo $PROXY_URL | cut -d: -f1); \\\n        host=$(echo $PROXY_URL | cut -d/ -f3 | cut -d: -f1); \\\n        port=$(echo $PROXY_URL | cut -d: -f3); \\\n        conf=/etc/proxychains.conf; \\\n        echo \"strict_chain\" > $conf; \\\n        echo \"proxy_dns\" >> $conf; \\\n        echo \"remote_dns_subnet 224\" >> $conf; \\\n        echo \"tcp_read_time_out 15000\" >> $conf; \\\n        echo \"tcp_connect_time_out 8000\" >> $conf; \\\n        echo \"localnet 127.0.0.0/255.0.0.0\" >> $conf; \\\n        echo \"localnet ::1/128\" >> $conf; \\\n        echo \"[ProxyList]\" >> $conf; \\\n        echo \"$protocol $host $port\" >> $conf; \\\n        cat /etc/proxychains.conf; \\\n        proxychains -f $conf node server.js; \\\n    else \\\n        node server.js; \\\n    fi\nEOF\n```\n\n#### 编写流水线脚本\n\n> `withCredentials` 块来引用一个名为 `my-credentials` 的凭据，该凭据的类型是用户名密码。`usernameVariable` 和 `passwordVariable` 参数分别指定了在代码块中使用凭据时的变量名。\n>\n> 在 `withCredentials` 块内部，你可以执行需要使用凭据的操作，比如在 Shell 脚本中使用用户名和密码进行身份验证。\n>\n> 请注意，`credentialsId` 参数需要指定你在 Jenkins 中创建的凭据的 ID。确保凭据 ID 正确，并且具有访问该凭据的权限。\n>\n> 使用 `withCredentials` 块可以确保凭据的安全性，因为凭据的值不会明文显示在日志中，而是以变量的形式传递给代码块中的操作。这样可以避免凭据泄露的风险。\n>\n> 以下内容，自行修改，对照，每一行都去看\n>\n> Harbor-passwd是jenkins创建的harbor的用户凭据\n\n```\ncd /root/cicd/chatgpt\ncat > Jenkinsfile<<\"EOF\"\npipeline{\n    agent {\n        kubernetes {\n            inheritFrom \"jenkins-slave\"\n            yaml '''\napiVersion: v1\nkind: Pod\nmetadata:\n  name: jenkins-slave\nspec:\n  securityContext:\n    fsGroup: 0\n    runAsUser: 0\n  nodeSelector:\n    k8s-type: master\n  containers:\n  - name: jnlp\n    image: \"192.168.48.100/library/inbound-agent:latest\"\n    imagePullPolicy: IfNotPresent\n    volumeMounts:\n    - name: kubectl\n      mountPath: /usr/bin/kubectl\n    - name: kube-config\n      mountPath: /root/.kube\n    - name: docker\n      mountPath: /usr/bin/docker\n    - name: docker-sock\n      mountPath: /var/run/docker.sock\n  volumes:\n  - name: kubectl\n    hostPath:\n      path: /usr/bin/kubectl\n  - name: kube-config\n    hostPath:\n      path: /root/.kube\n  - name: docker\n    hostPath:\n      path: /usr/bin/docker\n  - name: docker-sock\n    hostPath:\n      path: /var/run/docker.sock\n'''\n        }\n    }\n    environment {\n        NPM_REGISTRY = \"https://registry.npmmirror.com/\"\n        YARN_REGISTRY = \"https://registry.npmmirror.com/\"\n    }\n    stages{\n        stage('git clone') {\n            steps {\n                sh 'git version'\n            }\n        }\n        stage('image-build'){\n            steps{\n                withCredentials([usernamePassword(credentialsId: 'Harbor-passwd', usernameVariable: 'USERNAME', passwordVariable: 'PASSWORD')] {\n                    sh 'docker build -t 192.168.48.100/chatgpt/chatgpt:v1-$BUILD_NUMBER -f Dockerfile .'\n                    sh 'docker login 192.168.48.100 -u $USERNAME -p $PASSWORD'\n                    sh 'docker push 192.168.48.100/chatgpt/chatgpt:v1-$BUILD_NUMBER'\n                }\n            }\n        }\n        stage('cloud-deploy'){\n            steps{\n                sh 'sed -i \"s#chatgpt-next-web#192.168.48.100/chatgpt/chatgpt:v1-$BUILD_NUMBER#g\" deploy.yaml'\n                sh 'cat deploy.yaml'\n                sh 'kubectl get pod -A'\n                sh 'kubectl get secret,deploy,svc -A'\n                sh 'kubectl apply -f deploy.yaml'\n                sh 'kubectl get -f deploy.yaml'\n            }\n        }\n    }\n}\nEOF\n```\n\n#### 通过git上传代码\n\n```\ncd /root/cicd/chatgpt\ngit add .\ngit commit -m \"add Jenkinsfile Dockerfile and deploy.yaml\"\ngit push -u origin main\nUsername for 'http://192.168.48.200:30880': root\nPassword for 'http://root@192.168.48.200:30880':\n```\n\n![image-20240929010336567](../img/%E5%9F%BA%E4%BA%8EK8S%E7%9A%84CICD%E7%B3%BB%E7%BB%9F%E5%AE%9E%E7%8E%B0/8641cf25c809b82fa7a4f086be92b13155933597.png)\n\n![image-20241111191551671](../img/%E5%9F%BA%E4%BA%8EK8S%E7%9A%84CICD%E7%B3%BB%E7%BB%9F%E5%AE%9E%E7%8E%B0/8d570ba3605ce1e3cf7233f1b99c6d8255933597.png)\n\n## 测试\n\n通过刚刚的上传deploy.yaml，流水线已经开始执行\n\n进入jenkins页面可以看到jenkins建的项目正在执行，并且可以看到右下角有一个jenkins代理，说明新建了一个jenkins代理执行\n\n![image-20241111191226574](../img/%E5%9F%BA%E4%BA%8EK8S%E7%9A%84CICD%E7%B3%BB%E7%BB%9F%E5%AE%9E%E7%8E%B0/13986a41cf360dcad0b1575bd025080d55933597.png)\n\n![image-20241111191618626](../img/%E5%9F%BA%E4%BA%8EK8S%E7%9A%84CICD%E7%B3%BB%E7%BB%9F%E5%AE%9E%E7%8E%B0/23687c5d5c1a9fdf736d50a183e851f955933597.png)\n\nHarbor仓库也有构建好的镜像\n\n![image-20241111191702364](../img/%E5%9F%BA%E4%BA%8EK8S%E7%9A%84CICD%E7%B3%BB%E7%BB%9F%E5%AE%9E%E7%8E%B0/22dcd97b43b316bcdb3946b07ad6800955933597.png)\n\n测试项目部署成功\n\n![image-20241111191752588](../img/%E5%9F%BA%E4%BA%8EK8S%E7%9A%84CICD%E7%B3%BB%E7%BB%9F%E5%AE%9E%E7%8E%B0/223a7c5e6db6f6ae554840983e30777155933597.png)\n\njenkins部署日志也显示成功\n\n![image-20241111191840330](../img/%E5%9F%BA%E4%BA%8EK8S%E7%9A%84CICD%E7%B3%BB%E7%BB%9F%E5%AE%9E%E7%8E%B0/image-20241111191840330.png)\n\n<div class=\"tbsm\" style=\"margin-top:54px;\">\n<div class=\"tbsm-top\"><span><svg t=\"1674654360507\" class=\"icon\" viewBox=\"0 0 1024 1024\" version=\"1.1\" xmlns=\"http://www.w3.org/2000/svg\" p-id=\"987\" data-spm-anchor-id=\"a313x.7781069.0.i0\" width=\"35\" height=\"35\"><path d=\"M410.49 97.74H155.08a56.74 56.74 0 0 0-56.84 56.73V410a56.84 56.84 0 0 0 56.84 56.84h255.41A56.83 56.83 0 0 0 467.32 410V154.58a56.83 56.83 0 0 0-56.83-56.84zM410.49 558.74H155.08a56.74 56.74 0 0 0-56.84 56.73V871a56.84 56.84 0 0 0 56.84 56.84h255.41A56.83 56.83 0 0 0 467.32 871V615.58a56.83 56.83 0 0 0-56.83-56.84zM871.49 558.74H616.08a56.74 56.74 0 0 0-56.84 56.73V871a56.84 56.84 0 0 0 56.84 56.84h255.41A56.83 56.83 0 0 0 928.32 871V615.58a56.83 56.83 0 0 0-56.83-56.84z\" fill=\"#66EEFF\" p-id=\"988\"></path><path d=\"M410.49 558.74h-4.14A475 475 0 0 0 299.52 859.6a481.16 481.16 0 0 0 4.84 68.22h106.13A56.83 56.83 0 0 0 467.32 871V615.58a56.83 56.83 0 0 0-56.83-56.84zM871.49 558.74H616.08a56.74 56.74 0 0 0-56.84 56.73V871a56.84 56.84 0 0 0 56.84 56.84h255.41A56.83 56.83 0 0 0 928.32 871V615.58a56.83 56.83 0 0 0-56.83-56.84z\" fill=\"#C2F8FF\" p-id=\"989\"></path></svg></span><span style=\"font-size:30px;\"> 特别声明</span></div>\n<div class=\"tbsm-wz\">千屹博客旗下的所有文章，是通过本人课堂学习和课外自学所精心整理的知识巨著<br/>难免会有出错的地方<br/>如果细心的你发现了小失误，可以在下方评论区告诉我，或者私信我！<br />非常感谢大家的热烈支持！</div>\n</div>\n","tags":["Ceph","OpenEuler","Harbor","K8s","Jenkins","Gitlab"],"categories":["云原生"]},{"title":"Harbor共享存储高可用","url":"/posts/40301/","content":"\n<meta name=\"referrer\" content=\"no-referrer\"/>\n\n# Harbor共享存储高可用\n\n## 主机拓扑\n\n| 角色                                | 主机名         | ip             | 系统              | 资源最低要求                            |\n| ----------------------------------- | -------------- | -------------- | ----------------- | --------------------------------------- |\n| Harbor1<br />nginx<br />Keepalived1 | harbor1        | 192.168.48.106 | OpenEuler22.03LTS | CPU：4核 <br />内存：2G <br />硬盘：40G |\n| Harbor2<br />nginx<br />Keepalived2 | harbor2        | 192.168.48.107 | OpenEuler22.03LTS | CPU：4核 <br />内存：2G <br />硬盘：40G |\n| postgresql<br />Redis<br />NFS共享  | zujian         | 192.168.48.108 | OpenEuler22.03LTS | CPU：4核 <br />内存：2G <br />硬盘：40G |\n| 高可用ip                            | 192.168.48.100 |                |                   |                                         |\n\n`系统架构图`\n\n![image-20240430185108978](../img/Harbor%E5%85%B1%E4%BA%AB%E5%AD%98%E5%82%A8%E9%AB%98%E5%8F%AF%E7%94%A8/bbbf97d46f5255a4d83e886388f87b33697559838.png)\n\n## 基本配置\n\n操作节点：[harbor1，harbour2，zujian]\n\n```\nvi jichu_init.sh\n```\n\n将以下脚本内容添加进去\n\n```\n\n#!/bin/bash\nif [ $# -eq 2 ];then\n  echo \"设置主机名为：$1\"\n  echo \"ens160设置IP地址为：192.168.48.$2\"\nelse\n  echo  \"使用方法：sh $0 主机名 主机位\"\n  exit 2\nfi\n\necho \"--------------------------------------\"\necho \"1.正在设置主机名：$1\"\nhostnamectl set-hostname $1\n\necho \"2.正在关闭firewalld、dnsmasq、selinux\"\nsystemctl disable firewalld &> /dev/null\nsystemctl disable dnsmasq &> /dev/null\nsystemctl stop firewalld\nsystemctl stop dnsmasq\nsed -i \"s#SELINUX=enforcing#SELINUX=disabled#g\" /etc/selinux/config\nsetenforce 0\n\n\necho \"3.正在设置ens160：192.168.48.$2\"\ncat > /etc/sysconfig/network-scripts/ifcfg-ens160 <<EOF\nTYPE=Ethernet\nPROXY_METHOD=none\nBROWSER_ONLY=no\nBOOTPROTO=static\nDEFROUTE=yes\nIPV4_FAILURE_FATAL=no\nIPV6INIT=yes\nIPV6_AUTOCONF=yes\nIPV6_DEFROUTE=yes\nIPV6_FAILURE_FATAL=no\nNAME=ens160\nUUID=53b402ff-5865-47dd-a853-7afcd6521738\nDEVICE=ens160\nONBOOT=yes\nIPADDR=192.168.48.$2\nGATEWAY=192.168.48.2\nPREFIX=24\nDNS1=192.168.48.2\nDNS2=114.114.114.114\n\nnmcli c reload\nnmcli c up ens 160\n\necho \"4.优化ssh\"\nsed -i \"s#\\#UseDNS yes#UseDNS no#g\" /etc/ssh/sshd_config\nsed -i \"s#GSSAPIAuthentication yes#GSSAPIAuthentication no#g\" /etc/ssh/sshd_config\nsystemctl restart sshd\n\necho \"5.更改欧拉源为华为云源，速度快一点\"\nsed -i 's/\\$basearch/x86_64/g' /etc/yum.repos.d/openEuler.repo\nsed -i 's/http\\:\\/\\/repo.openeuler.org/https\\:\\/\\/mirrors.huaweicloud.com\\/openeuler/g' /etc/yum.repos.d/openEuler.repo\n\n\necho \"6.更新yum源软件包缓存\"\nyum clean all && yum makecache\ndnf update -y\n\necho \"7.修改history格式及记录数\"\nsed -i \"s#HISTSIZE=1000##g\" /etc/profile\ncat >> /etc/profile <<EOF\nshopt -s histappend\nUSER_IP=`who -u am i 2>/dev/null| awk '{print $NF}'|sed -e 's/[()]//g'`\nexport HISTFILE=~/.commandline_warrior\nexport HISTTIMEFORMAT=\"%Y-%m-%d %H:%M:%S  `whoami`@${USER_IP}: \"\nexport HISTSIZE=200000\nexport HISTFILESIZE=1000000\nexport PROMPT_COMMAND=\"history -a\"\nEOF\nsource /etc/profile\n\n\necho \"8.添加hosts解析\"\ncat > /etc/hosts <<EOF\n127.0.0.1   localhost localhost.localdomain localhost4 localhost4.localdomain4\n::1         localhost localhost.localdomain localhost6 localhost6.localdomain6\n192.168.48.106 harbor1\n192.168.48.107 harbor2\n192.168.48.108 zujian\nEOF\n\n\necho \"10.安装chrony服务，并同步时间\"\ndnf install chrony -y\nsystemctl start chronyd\nsystemctl enable chronyd\nchronyc sources\nchronyc sources\n\necho \"11、安装依赖包\"\ndnf install -y cmake gcc gcc-c++ perl readline readline-devel openssl openssl-devel zlib zlib-devel ncurses-devel readline readline-devel zlib zlib-devel\n\nreboot\n```\n\n\n\n```\n执行脚本命令格式：sh jichu_init.sh 主机名 主机位\n[harbor1] sh jichu_init.sh harbor1 106\n\n[harbor2] sh jichu_init.sh harbor2 107\n\n[zujian] sh jichu_init.sh zujian 108\n\n```\n\n配置ssh免密\n\n操作节点：[harbor1，harbour2，zujian]\n\n```\ndnf install -y sshpass \ncat > sshmianmi.sh << \"EOF\"\n#!/bin/bash\n# 目标主机列表\nhosts=(\"harbor1\" \"harbor2\" \"zujian\")\n# 密码\npassword=\"Lj201840.\"\n# 生成 SSH 密钥对\nssh-keygen -t rsa -N \"\" -f ~/.ssh/id_rsa\n\n# 循环遍历目标主机\nfor host in \"${hosts[@]}\"\ndo\n    # 复制公钥到目标主机\n    sshpass -p \"$password\" ssh-copy-id -o StrictHostKeyChecking=no \"$host\"\n    \n    # 验证免密登录\n    sshpass -p \"$password\" ssh -o StrictHostKeyChecking=no \"$host\" \"echo '免密登录成功'\"\ndone\nEOF\n\nsh sshmianmi.sh\n```\n\n## 安装高可用组件\n\n操作节点:[harbor1，harbour2]\n\n```\ndnf install -y keepalived nginx\n```\n\n### 安装nginx\n\n操作节点:[harbor1，harbour2]\n\n```\ncat > /etc/nginx/nginx.conf <<\"EOF\"\nuser nginx;\nworker_processes auto;\nerror_log /var/log/nginx/error.log notice;\npid /run/nginx.pid;\ninclude /usr/share/nginx/modules/*.conf;\nevents {\n    worker_connections 1024;\n}\nstream {\n    log_format  main  '$remote_addr $upstream_addr - [$time_local] $status $upstream_bytes_sent';\n    access_log  /var/log/nginx/harbor-access.log  main;\n    upstream harbor{\n       server 192.168.48.106:8081;   #harbor1\n       server 192.168.48.107:8081;   #harbor2\n    }\n    server {\n       listen  80;\n       proxy_pass harbor;\n    }\n}\nhttp {\n    log_format  main  '$remote_addr - $remote_user [$time_local] \"$request\" '\n                      '$status $body_bytes_sent \"$http_referer\" '\n                      '\"$http_user_agent\" \"$http_x_forwarded_for\"';\n    access_log  /var/log/nginx/access.log  main;\n    sendfile            on;\n    tcp_nopush          on;\n    keepalive_timeout   65;\n    types_hash_max_size 4096;\n    include             /etc/nginx/mime.types;\n    default_type        application/octet-stream;\n    \n    include /etc/nginx/conf.d/*.conf;\n    server {\n        listen       8888 default_server;\n        server_name  _;\n        location / {\n        }\n    }\n}\nEOF\nsystemctl enable --now nginx\nnginx -s reload\n```\n\n\n\n### 安装安装keepalived\n\n操作节点:[harbor1]\n\n```\ncat >/etc/keepalived/keepalived.conf << \"EOF\"\n! Configuration File for keepalived\n\nglobal_defs {\n   notification_email {\n     qianyios@qq.com\n   }\n   router_id harbor1\n}\n\nvrrp_instance zh {\n    state MASTER\n    interface ens160\n    mcast_src_ip 192.168.48.106\n    virtual_router_id 107\n    priority 100\n    advert_int 1\n    nopreempt\n    authentication {\n        auth_type PASS\n        auth_pass 1111\n    }\n    virtual_ipaddress {\n        192.168.48.100/24\n    }\n    track_script {\n        chk_nginx\n    }\n}\nvrrp_script chk_nginx {\n    script \"/etc/keepalived/check_nginx.sh\"\n    interval 2\n    weight -20\n}\nEOF\n```\n\n\n\n操作节点:[harbor2]\n\n```\ncat >/etc/keepalived/keepalived.conf << \"EOF\"\n! Configuration File for keepalived\n\nglobal_defs {\n   notification_email {\n     qianyios@qq.com\n   }\n   router_id harbor2\n}\n\nvrrp_instance zh {\n    state BACKUP\n    interface ens160\n    mcast_src_ip 192.168.48.107\n    virtual_router_id 107\n    priority 99\n    advert_int 1\n    nopreempt\n    authentication {\n        auth_type PASS\n        auth_pass 1111\n    }\n    virtual_ipaddress {\n        192.168.48.100/24\n    }\n    track_script {\n        chk_nginx\n    }\n}\nvrrp_script chk_nginx {\n    script \"/etc/keepalived/check_nginx.sh\"\n    interval 2\n    weight -20\n}\nEOF\n```\n\n\n\n配置检查脚本\n\n操作节点:[harbor1，harbour2]\n\n```\ncat >/etc/keepalived/check_nginx.sh <<\"EOF\"\n#!/bin/bash\ncounter=`ps -C nginx --no-header | wc -l`\nif [ $counter -eq 0 ]; then\n    systemctl start nginx\n    sleep 2\n    counter=`ps -C nginx --no-header | wc -l`\n    if [ $counter -eq 0 ]; then\n        systemctl stop keepalived\n    fi\nfi\n\nEOF\n```\n\n启动服务\n\n```\nsystemctl enable --now nginx keepalived\nnginx -s reload\n```\n\n查看VIP虚拟ip\n\n```\n[root@harbor1 ~]# ip a\n.............\n2: ens160: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc mq state UP group default qlen 1000\n    link/ether 00:0c:29:af:76:8c brd ff:ff:ff:ff:ff:ff\n    inet 192.168.48.106/24 brd 192.168.48.255 scope global noprefixroute ens160\n       valid_lft forever preferred_lft forever\n    inet 192.168.48.100/24 scope global secondary ens160   ###192.168.48.100/24就是刚刚设置的高可用ip\n       valid_lft forever preferred_lft forever\n    inet6 fe80::20c:29ff:feaf:768c/64 scope link noprefixroute\n       valid_lft forever preferred_lft forever\n\n```\n\n## 安装postgresql\n\n操作节点：[zujian]\n\n### 安装\n\n```\n#创建postgres用户\nuseradd postgres\npasswd postgres\n#设置密码123456\n\n\n#编译安装postgresql\nwget https://ftp.postgresql.org/pub/source/v16.2/postgresql-16.2.tar.gz\ntar zxvf postgresql-16.2.tar.gz -C /usr/local/bin/\ncd /usr/local/bin/postgresql-16.2/\n./configure --prefix=/usr/local/postgresql\nmake && make install\n\n#建立数据目录\nmkdir -p /data/postgresql/data\n#创建日志目录\nmkdir -p /data/postgresql/log\n#创建socket目录\nmkdir -p /data/postgresql/tmp\n#授权\nchown -R postgres:postgres /usr/local/postgresql/\nchown -R postgres:postgres /data/postgresql\n\n#设置postgres环境\nsu - postgres\ncd\ncat << \"EOF\" >> ~/.bash_profile\nPGHOME=/usr/local/postgresql\nexport PGHOME\nPGDATA=/data/postgresql/data\nexport PGDATA\nPATH=$PATH:$HOME/bin:$HOME/.local/bin:$PGHOME/bin\nexport PATH\nEOF\nsource ~/.bash_profile\npsql -V\n\n#初始化数据库\ninitdb --username=postgres -D /data/postgresql/data\n#会有Success. You can now start the database server using:      #表示初始化成功\n\n\n#修改初始化的配置文件\ncat > /data/postgresql/data/postgresql.conf << \"EOF\"\nmax_connections = 100                   # 允许最大连接数\nshared_buffers = 128MB                  # 内存大小\ndynamic_shared_memory_type = posix      # the default is usually the first option\nmax_wal_size = 1GB\nmin_wal_size = 80MB\nlog_timezone = 'Asia/Shanghai'\ndatestyle = 'iso, mdy'\ntimezone = 'Asia/Shanghai'\nlc_messages = 'en_US.UTF-8'             # locale for system error message\nlc_monetary = 'en_US.UTF-8'             # locale for monetary formatting\nlc_numeric = 'en_US.UTF-8'              # locale for number formatting\nlc_time = 'en_US.UTF-8'                 # locale for time formatting\ndefault_text_search_config = 'pg_catalog.english'\nlisten_addresses = '*' #监听所有地址\ndata_directory = '/data/postgresql/data'  # 数据目录指定\nport = 5432\nunix_socket_directories = '/data/postgresql/tmp'\nunix_socket_group = ''\nunix_socket_permissions = 0777\nlogging_collector = on\nlog_directory = '/data/postgresql/log'\nlog_rotation_size = 1GB\nlog_timezone = 'Asia/Shanghai'\nlog_min_duration_statement = 100\n\nEOF\n#设置远程连接\ncat >> /data/postgresql/data/pg_hba.conf << EOF\nlocal   all             all                                     trust\nhost    all             all             0.0.0.0/0               password\nhost    all             all             ::1/128                 password\nhost    all             postgres             0.0.0.0/0           trust\nEOF\n\n\n#启动PostgreSQL\npg_ctl -D /data/postgresql/data -l logfile start\n\n```\n\n### 进入数据库\n\n```\npsql -h 127.0.0.1 -p 5432 -U postgres\n\npostgres=# \\password\nEnter new password for user \"postgres\":\nEnter it again:\n#输入密码123456\npostgres=# exit\n\n#重新启动\npg_ctl -D /data/postgresql/data -l /data/postgresql/data/postgresql.log restart\n\n#提示一下信息成功（不是命令哈，不要去运行）\npg_ctl: old server process (PID: 25461) seems to be gone\nstarting server anyway\nwaiting for server to start.... done\nserver started\n\npsql -h 127.0.0.1 -p 5432 -U postgres\n#输入密码123456\n\nCREATE DATABASE registry;\nCREATE DATABASE notary_signer;\nCREATE DATABASE notary_servers;\n\\l\ncreate user server with password '123456';\ncreate user signer with password '123456';\n\\du\nGRANT ALL PRIVILEGES ON DATABASE registry to postgres;   \nGRANT ALL PRIVILEGES ON DATABASE notary_signer to postgres;   \nGRANT ALL PRIVILEGES ON DATABASE notary_servers to postgres;   \nexit\n```\n\n![image-20240421010122073](../img/Harbor%E5%85%B1%E4%BA%AB%E5%AD%98%E5%82%A8%E9%AB%98%E5%8F%AF%E7%94%A8/7c0a0a771ab21ffe0c5347b8e7bc0739697559838.png)\n\n![image-20240421010045648](../img/Harbor%E5%85%B1%E4%BA%AB%E5%AD%98%E5%82%A8%E9%AB%98%E5%8F%AF%E7%94%A8/9716f9bd02ccfaf957d1da80f1ed6b71697559838.png)\n\n### 设置启动服务\n\n操作节点[zujian]\n\n```\n#回到root用户下执行\nsu - root\ncat >/etc/init.d/PG-start.sh<< \"EOF\"\nsudo -u postgres /usr/local/postgresql/bin/pg_ctl -D /data/postgresql/data start\nEOF\n\ncat >/etc/init.d/PG-stop.sh<< \"EOF\"\nsudo -u postgres /usr/local/postgresql/bin/pg_ctl -D /data/postgresql/data stop\nEOF\n\ncat >/etc/init.d/PG-restart.sh<<\"EOF\"\nsudo -u postgres /usr/local/postgresql/bin/pg_ctl -D /data/postgresql/data restart\nEOF\n\nsudo chmod +x /etc/init.d/PG-start.sh\nsudo chmod +x /etc/init.d/PG-stop.sh\nsudo chmod +x /etc/init.d/PG-restart.sh\n\ncat >/etc/systemd/system/postgresql.service << \"EOF\"\n[Unit]\nDescription=postgresql Service\n\n[Service]\nType=oneshot\nuser=root\nRemainAfterExit=true\nExecStart=/usr/bin/sudo /etc/init.d/PG-start.sh\nExecStop=/usr/bin/sudo /etc/init.d/PG-stop.sh\nExecRestart=/usr/bin/sudo /etc/init.d/PG-restart.sh\n\n[Install]\nWantedBy=multi-user.target\nEOF\nsystemctl daemon-reload\nsystemctl enable --now postgresql\n\n```\n\n错误积累\n\n```\n#每次我启动pgsql的时候就有这个东西\n\n2024-09-14 14:34:03.196 CST [17746] HINT:  Is another postmaster (PID 16042) running in data directory \"/data/postgresql/data\"?\n stopped waiting\npg_ctl: could not start server\n\n#意思是有个pid进程在运行，杀掉它就行了\nsudo kill -9 16042\n```\n\n## 安装redis\n\n操作节点：[zujian]\n\n### 安装redis\n\n```\nwget https://download.redis.io/releases/redis-7.2.4.tar.gz\ntar zxvf redis-7.2.4.tar.gz \nmv redis-7.2.4 /usr/local/bin/\ncd /usr/local/bin/redis-7.2.4\nmake && make install\n```\n\n### 修改配置文件\n\n```\nvi /usr/local/bin/redis-7.2.4/redis.conf\n\n#bind 127.0.0.1 -::1  #注释掉bind的行，允许任何主机连接；\ndaemonize yes       #将no修改为yes，使redis可以使用守护进程方式启动；\nrequirepass 123456   #添加这行，设置redis连接的auth密码（123456）\nprotected-mode no  #禁用保护模式\n\n以下是一步到位将以上四个命令全部实现\nsed -i 's/^bind 127.0.0.1 -::1/#bind 127.0.0.1 -::1/' /usr/local/bin/redis-7.2.4/redis.conf\nsed -i 's/^daemonize no/daemonize yes/' /usr/local/bin/redis-7.2.4/redis.conf\necho -e \"\\nrequirepass 123456\" >> /usr/local/bin/redis-7.2.4/redis.conf\nsed -i 's/^protected-mode yes/protected-mode no/' /usr/local/bin/redis-7.2.4/redis.conf\n\n```\n\n### 启动服务\n\n```\nredis-server redis.conf\n```\n\n```\n[root@zujian redis-7.2.4]# redis-server redis.conf\n2226:C 20 Apr 2024 17:10:45.039 # WARNING Memory overcommit must be enabled! Without it, a background save or replication may fail under low memory condition. Being disabled, it can also cause failures without low memory condition, see https://github.com/jemalloc/jemalloc/issues/1328. To fix this issue add 'vm.overcommit_memory = 1' to /etc/sysctl.conf and then reboot or run the command 'sysctl vm.overcommit_memory=1' for this to take effect.\n```\n\nRedis在启动时可能会出现这样的日志：在分析这个问题之前， 首先要弄清楚什么是overcommit？ `Linux操作系统对大部分申请内存的请求都回复yes`，` 以便能运行更多的程序`。 因为申请内存后， 并不会马上使用内存， 这种技术叫做`overcommit`。如果Redis在启动时有上面的日志， 说明vm.overcommit_memory=0， Redis提示把它设置为1。\nvm.overcommit_memory用来设置内存分配策略， 有三个可选值， 如表：可用内存代表物理内存与swap之和\n\n![image-20240420171525086](../img/Harbor%E5%85%B1%E4%BA%AB%E5%AD%98%E5%82%A8%E9%AB%98%E5%8F%AF%E7%94%A8/de0356ab6f8115130d1a379524ade373697559838.png)\n\n解决办法：\n\n```\necho \"vm.overcommit_memory=1\" >> /etc/sysctl.conf\nsysctl vm.overcommit_memory=1\nredis-server redis.conf\n```\n\n再重新启动就可以查看版本和端口号了\n\n```shell\n[root@zujian redis-7.2.4]# redis-cli -v\nredis-cli 7.2.4\n[root@zujian redis-7.2.4]# ps aux |grep 6379\nroot        2227  0.0  0.3  68412 10888 ?        Ssl  17:10   0:00 redis-server *:6379\nroot        5427  0.0  0.0  22096  2300 pts/0    S+   17:19   0:00 grep --color=auto 6379\n#redis-server有这个就行\n```\n\n关闭服务（只是普及知识，测试可用，不要随意关闭）\n\n```\nredis-cli shutdown\n```\n\n### 客户端连接redis\n\n操作节点：[zujian]\n\n将redis-cli的工具复制到Harbor1，harbor2\n\n查看redis-cli工具位置\n\n```\n[root@zujian]# which redis-cli\n/usr/local/bin/redis-cli\n```\n\n复制\n\n```\nwhich redis-cli\nscp /usr/local/bin/redis-cli harbor1:/usr/local/bin/\nscp /usr/local/bin/redis-cli harbor2:/usr/local/bin/\n```\n\n操作节点：[harbor1,harbor2]\n\n```\nredis-cli -h 192.168.48.108 -p 6379 -a 123456\n```\n\n![image-20240420232245510](../img/Harbor%E5%85%B1%E4%BA%AB%E5%AD%98%E5%82%A8%E9%AB%98%E5%8F%AF%E7%94%A8/f6e078d51551d5805c25eaf9282418c9697559838.png)\n\n![image-20240420232257725](../img/Harbor%E5%85%B1%E4%BA%AB%E5%AD%98%E5%82%A8%E9%AB%98%E5%8F%AF%E7%94%A8/b51dc2d41ba515a7cbe4b11f86158148697559838.png)\n\n到此redis安装成功\n\n### 设置启动服务\n\n```\ncat >/etc/init.d/redis-start.sh<< \"EOF\"\n/usr/local/bin/redis-server /usr/local/bin/redis-7.2.4/redis.conf\nEOF\ncat >/etc/init.d/redis-stop.sh<< \"EOF\"\n/usr/local/bin/redis-cli -a 123456 shutdown\nEOF\n\nsudo chmod +x /etc/init.d/redis-start.sh\nsudo chmod +x /etc/init.d/redis-stop.sh\n\ncat >/etc/systemd/system/redis.service << \"EOF\"\n[Unit]\nDescription=redis Service\n\n[Service]\nType=oneshot\nuser=root\nRemainAfterExit=true\nExecStart=/usr/bin/sudo /etc/init.d/redis-start.sh\nExecStop=/usr/bin/sudo /etc/init.d/redis-stop.sh\n[Install]\nWantedBy=multi-user.target\nEOF\nsystemctl daemon-reload\nsystemctl enable --now redis\n```\n\n## NFS共享存储安装\n\n操作节点：[zujian]\n\n```\ndnf install -y nfs-utils\nsystemctl enable --now nfs\n#创建远程共享目录\nmkdir -p /data/harbor_data\n\ncat >> /etc/exports << \"EOF\"\n/data/harbor_data 192.168.48.0/24(rw,no_root_squash)\nEOF\n#使配置生效\nexportfs -arv\n\n#生效结果\n[root@zujian ~]# showmount -e\nExport list for zujian:\n/data/harbor_data 192.168.48.0/24\n\n```\n\n操作节点：[harbor1,harbor2]\n\nHarbor1、harbor2机器上安装nfs-utils客户端并挂载共享存储\n\n```\ndnf install -y nfs-utils\nsystemctl enable --now nfs\nmkdir -p /data/harbor_data\ncat >>/etc/fstab<<\"EOF\"\n192.168.48.108:/data/harbor_data /data/harbor_data nfs defaults 0 0\nEOF\nmount -a\ndf -h | grep harbor\n#以下是挂载成功\n[root@harbor1 ~]# df -h | grep harbor\n192.168.48.108:/data/harbor_data   63G  3.0G   57G   6% /data/harbor_data\n\n[root@harbor2 ~]# df -h | grep harbor\n192.168.48.108:/data/harbor_data   63G  3.0G   57G   6% /data/harbor_data\n\n```\n\n## harbor仓库安装\n\n操作节点：[harbor1,harbor2]\n\n### 安装docker\n\n```\nwget https://download.docker.com/linux/static/stable/x86_64/docker-26.0.1.tgz\ntar xf docker-*.tgz\ncp docker/* /usr/bin/\n#创建containerd的service文件,并且启动\ncat >/etc/systemd/system/containerd.service <<EOF\n[Unit]\nDescription=containerd container runtime\nDocumentation=https://containerd.io\nAfter=network.target local-fs.target\n[Service]\nExecStartPre=-/sbin/modprobe overlay\nExecStart=/usr/bin/containerd\nType=notify\nDelegate=yes\nKillMode=process\nRestart=always\nRestartSec=5\nLimitNPROC=infinity\nLimitCORE=infinity\nLimitNOFILE=1048576\nTasksMax=infinity\nOOMScoreAdjust=-999\n[Install]\nWantedBy=multi-user.target\nEOF\nsystemctl enable --now containerd.service\n\n#准备docker的service文件\n\ncat > /etc/systemd/system/docker.service <<EOF\n[Unit]\nDescription=Docker Application Container Engine\nDocumentation=https://docs.docker.com\nAfter=network-online.target firewalld.service containerd.service\nWants=network-online.target\nRequires=docker.socket containerd.service\n[Service]\nType=notify\nExecStart=/usr/bin/dockerd -H fd:// --containerd=/run/containerd/containerd.sock\nExecReload=/bin/kill -s HUP $MAINPID\nTimeoutSec=0\nRestartSec=2\nRestart=always\nStartLimitBurst=3\nStartLimitInterval=60s\nLimitNOFILE=infinity\nLimitNPROC=infinity\nLimitCORE=infinity\nTasksMax=infinity\nDelegate=yes\nKillMode=process\nOOMScoreAdjust=-500\n[Install]\nWantedBy=multi-user.target\nEOF\n\n\n#准备docker的socket文件\n\ncat > /etc/systemd/system/docker.socket <<EOF\n[Unit]\nDescription=Docker Socket for the API\n[Socket]\nListenStream=/var/run/docker.sock\nSocketMode=0660\nSocketUser=root\nSocketGroup=docker\n[Install]\nWantedBy=sockets.target\nEOF\ngroupadd docker\n\nsystemctl enable --now docker.socket  && systemctl enable --now docker.service\n\n\n#验证\nmkdir /etc/docker\ncat >/etc/docker/daemon.json <<EOF\n{\n  \"exec-opts\": [\"native.cgroupdriver=systemd\"],\n  \"registry-mirrors\": [\n    \"https://docker.mirrors.ustc.edu.cn\",\n    \"http://hub-mirror.c.163.com\",\n    \"https://pw860av8.mirror.aliyuncs.com\"\n  ],\n  \"max-concurrent-downloads\": 10,\n  \"log-driver\": \"json-file\",\n  \"log-level\": \"warn\",\n  \"log-opts\": {\n    \"max-size\": \"500m\",\n    \"max-file\": \"3\"\n    },\n  \"data-root\": \"/var/lib/docker\"\n}\nEOF\nsystemctl restart docker\ndocker -v\n\n```\n\n### 安装docker-compose\n\n操作节点：[harbor1,harbor2]\n\n```\nwget https://github.com/docker/compose/releases/download/v2.26.1/docker-compose-linux-x86_64\nmv docker-compose-linux-x86_64 /usr/local/bin/docker-compose\nchmod +x /usr/local/bin/docker-compose\ndocker-compose version\n```\n\n### 配置内核参数并使之生效\n\n操作节点：[harbor1,harbor2]\n\n```\nmodprobe br_netfilter\ncat >> /etc/sysctl.conf <<EOF\nnet.bridge.bridge-nf-call-ip6tables = 1\nnet.bridge.bridge-nf-call-iptables = 1\nnet.ipv4.ip_forward = 1 #路由转发\nEOF\nsysctl -p\n```\n\n### 下载harbor包并配置文件\n\n操作节点：[harbor1,harbor2]\n\n下载离线包offline字样\n\n```\nwget https://github.com/goharbor/harbor/releases/download/v2.9.4/harbor-offline-installer-v2.9.4.tgz\ntar zxvf harbor-offline-installer-v2.9.4.tgz\nmv harbor /var/\ncd /var/harbor/\n\n[root@harbor1 harbor]# ls\ncommon.sh  harbor.v2.9.4.tar.gz  harbor.yml.tmpl  install.sh  LICENSE  prepare\n\ncp harbor.yml.tmpl harbor.yml\n```\n\n配置harbor文件\n\n<font color='red'>操作节点：[harbor1]</font>\n\n```\nvi /var/harbor/harbor.yml\n```\n\n```yml\nhostname: 192.168.48.106  #harbor1\nhttp:\n  port: 8081\n  \n#https:       #先注释https协议，后面再实现\n # port: 443\n # certificate: /your/certificate/path\n # private_key: /your/private/key/path\n\n## 启用外部代理，启用后hostname将不再使用\nexternal_url: https://192.168.48.100\n\n#harbor页面密码\nharbor_admin_password: Harbor12345\n\n\n#配置NFS共享存储\ndata_volume: /data/harbor_data\n_version: 2.9.0\n#配置数据库\nexternal_database:\n  harbor:\n    host: 192.168.48.108  # 数据库主机地址\n    port: 5432              # 数据库端口\n    db_name: registry    # 数据库名称\n    username: postgres        # 连接该数据库的用户名\n    password: 123456    # 连接数据库的密码\n    ssl_mode: disable\n    max_idle_conns: 50\n    max_open_conns: 100\n  notary_server:\n    host: 192.168.48.108\n    port: 5432\n    db_name: notary_server\n    username: postgres\n    password: 123456\n    ssl_mode: disable\n  notary_signer:\n    host: 192.168.48.108\n    port: 5432\n    db_name: notary_signer\n    username: postgres\n    password: 123456\n    ssl_mode: disable \n#配置redis\nexternal_redis:\n  host: 192.168.48.108:6379 #redis服务IP地址和端口号\n  password: 123456   #连接外部redis服务的密码\n  registry_db_index: 1  \n  jobservice_db_index: 2 #job服务的数据库索引\n  chartmuseum_db_index: 3  #chartmuseum插件的Redis索引\n  trivy_db_index: 5   #Trivy扫描器的数据索引\n  idle_timeout_seconds: 30  #超时时间\n\n#启用metrics数据采集插件\nmetric:\n  enabled: false\n  port: 9090\n  path: /metrics\n\ntrivy:\n  ignore_unfixed: false\n  skip_update: false\n  skip_java_db_update: false\n  offline_scan: false\n  security_check: vuln\n  insecure: false\njobservice:\n  max_job_workers: 10\n  job_loggers:\n    - STD_OUTPUT\n    - FILE\n  logger_sweeper_duration: 1 #days\nnotification:\n  webhook_job_max_retry: 3\n  webhook_job_http_client_timeout: 3 #seconds\nlog:\n  level: info\n  local:\n    rotate_count: 50\n    rotate_size: 200M\n    location: /var/log/harbor\nproxy:\n  http_proxy:\n  https_proxy:\n  no_proxy:\n  components:\n    - core\n    - jobservice\n    - trivy\nupload_purging:\n  enabled: true\n  age: 168h\n  interval: 24h\n  dryrun: false\ncache:\n  enabled: false\n  expire_hours: 24\n```\n\n<font color='red'>操作节点：[harbor2]</font>\n\n```\nvi /var/harbor/harbor.yml\n```\n\n```yaml\nhostname: 192.168.48.107  #harbor2\nhttp:\n  port: 8081\n  \n#https:       #先注释https协议，后面再实现\n # port: 443\n # certificate: /your/certificate/path\n # private_key: /your/private/key/path\n\n## 启用外部代理，启用后hostname将不再使用\nexternal_url: https://192.168.48.100\n\n#harbor页面密码\nharbor_admin_password: Harbor12345\n\n#配置NFS共享存储\ndata_volume: /data/harbor_data\n_version: 2.9.0\n#配置数据库\nexternal_database:\n  harbor:\n    host: 192.168.48.108  # 数据库主机地址\n    port: 5432              # 数据库端口\n    db_name: registry    # 数据库名称\n    username: postgres        # 连接该数据库的用户名\n    password: 123456    # 连接数据库的密码\n    ssl_mode: disable\n    max_idle_conns: 2\n    max_open_conns: 0\nnotary_server:\n  host: 192.168.48.108\n  port: 5432\n  db_name: notary_server\n  username: postgres\n  password: 123456\n  ssl_mode: disable\nnotary_signer:\n  host: 192.168.48.108\n  port: 5432\n  db_name: notary_signer\n  username: postgres\n  password: 123456\n  ssl_mode: disable \n#配置redis\nexternal_redis:\n  host: 192.168.48.108:6379 #redis服务IP地址和端口号\n  password: 123456   #连接外部redis服务的密码\n  registry_db_index: 1  \n  jobservice_db_index: 2 #job服务的数据库索引\n  chartmuseum_db_index: 3  #chartmuseum插件的Redis索引\n  trivy_db_index: 5   #Trivy扫描器的数据索引\n  idle_timeout_seconds: 30  #超时时间\n\n#启用metrics数据采集插件\nmetric:\n  enabled: false\n  port: 9090\n  path: /metrics\n\ntrivy:\n  ignore_unfixed: false\n  skip_update: false\n  skip_java_db_update: false\n  offline_scan: false\n  security_check: vuln\n  insecure: false\njobservice:\n  max_job_workers: 10\n  job_loggers:\n    - STD_OUTPUT\n    - FILE\n  logger_sweeper_duration: 1 #days\nnotification:\n  webhook_job_max_retry: 3\n  webhook_job_http_client_timeout: 3 #seconds\nlog:\n  level: info\n  local:\n    rotate_count: 50\n    rotate_size: 200M\n    location: /var/log/harbor\nproxy:\n  http_proxy:\n  https_proxy:\n  no_proxy:\n  components:\n    - core\n    - jobservice\n    - trivy\nupload_purging:\n  enabled: true\n  age: 168h\n  interval: 24h\n  dryrun: false\ncache:\n  enabled: false\n  expire_hours: 24\n```\n\n### 将配置文件注入到各级件中并安装\n\n先提前下载镜像吧，这里用博主构建的镜像速度会快一点\n\n```\ndocker pull registry.cn-hangzhou.aliyuncs.com/qianyios/prepare:v2.9.4\ndocker tag registry.cn-hangzhou.aliyuncs.com/qianyios/prepare:v2.9.4 goharbor/prepare:v2.9.4\n```\n\n开始注入\n\n```\ncd /var/harbor/\n./prepare\n```\n\n![image-20240420230001756](../img/Harbor%E5%85%B1%E4%BA%AB%E5%AD%98%E5%82%A8%E9%AB%98%E5%8F%AF%E7%94%A8/a93d124f3f2f71fe2c608ef2859ee748697559838.png)\n\n开始安装\n\n```\ncd /var/harbor/\n./install.sh\n```\n\n![image-20240420230138644](../img/Harbor%E5%85%B1%E4%BA%AB%E5%AD%98%E5%82%A8%E9%AB%98%E5%8F%AF%E7%94%A8/7f5f1281ed43826bd2b9f0176373f41d697559838.png)\n\n### 配置自启动\n\n```\ncat >/usr/lib/systemd/system/harbor.service << \"EOF\"\n[Unit]\nDescription=Harbor\nAfter=docker.service systemd-networkd.service systemd-resolved.service nfs-server.service\nRequires=docker.service\nDocumentation=http://github.com/vmware/harbor\n[Service]\nType=simple\nRestart=on-failure\nRestartSec=5\nExecStart=/usr/local/bin/docker-compose -f /var/harbor/docker-compose.yml up\nExecStop=/usr/local/bin/docker-compose -f /var/harbor/docker-compose.yml down\n[Install]\nWantedBy=multi-user.target\nEOF\nsystemctl daemon-reload\nsystemctl enable harbor --now\n```\n\n`大坑来了，之前找了两个星期都没解决的`\n\n到此，harbor安装完成，`但是你在网页可能会出现不能用admin登入，会显示密码错误`你需要进行下一步安装证书\n\n原因：首先pg数据库在安装harbor时创建的admin是用sha256协议加密的\n\n![image-20240430182121148](../img/Harbor%E5%85%B1%E4%BA%AB%E5%AD%98%E5%82%A8%E9%AB%98%E5%8F%AF%E7%94%A8/cfdab591f116133f0e3db41a0992bd9f697559838.png)\n\n而在我们harbor页面，我们并没有配置ssl证书，是http方式访问并没有sha256加密协议，意味着harbor再登入的时候，会出现密码错误，就是：网页登入验证`===/===`pg数据库验证，配置openssl证书，可以解决此问题,openssl包含sha256协议，这样就可以登入了。\n\nOpenSSL是一个`强大的加密库`，广泛应用于互联网的各个角落，用于保护数据传输的安全。它实现了SSL和TLS协议，这些协议是现代网络安全的基石。\n\n## 配置ssl证书\n\n操作节点：[harbor1,harbor2]\n\n### 生成ca证书\n\n创建一个放置证书相关的目录，并使用cd进入该目录\n\n```\nmkdir /var/harbor/cert&& cd  /var/harbor/cert\n## 1. 生成CA证书私钥\nopenssl genrsa -out ca.key 4096\n## 2. 生成CA证书，可调整 -subj 选项来表明域名名称等信息\nopenssl req -x509 -new -nodes -sha512 -days 3650 \\\n -subj \"/C=CN/ST=Beijing/L=Beijing/O=example/OU=Personal/CN=192.168.48.100\" \\\n -key ca.key \\\n -out ca.crt\n```\n\n### 生成服务器证书\n\n认证证书通常包含证书请求`.csr`文件、签名证书`.crt`文件及私钥`.key`文件，我这里harbor配置的hostname是192.168.48.100，所以最终需要生成`192.168.48.100.crt、192.168.48.100.csr、192.168.48.100.key`三个文件。\n\n- key：证书私钥，一般利用rsa等算法生成\n- csr：证书请求文件，利用证书私钥生成证书请求文件，该文件包含了服务器和地址等信息，申请人将该文件提交给CA机构，CA机构会根据该文件所携带的私钥信息来进行签名生成证书\n- crt：证书文件\n\n```\n## 1. 生成私钥\nopenssl genrsa -out 192.168.48.100.key 4096\n## 2. 生成csr文件\nopenssl req -sha512 -new \\\n    -subj \"/C=CN/ST=Beijing/L=Beijing/O=example/OU=Personal/CN=192.168.48.100\" \\\n    -key 192.168.48.100.key \\\n    -out 192.168.48.100.csr\n## 3. 生成ssl匹配多域名文，例如既想使用域名又需要通过127.0.0.1本地地址登陆测试，可使用subjectAltName参数来进行配置\ncat > v3.ext <<-EOF\nauthorityKeyIdentifier=keyid,issuer\nbasicConstraints=CA:FALSE\nkeyUsage = digitalSignature, nonRepudiation, keyEncipherment, dataEncipherment\nextendedKeyUsage = serverAuth\nsubjectAltName = @alt_names\n\n[alt_names]\nDNS.1=192.168.48.100\nDNS.2=127.0.0.1\nIP.1=192.168.48.100\nEOF\n## 4. 根据v3.ext及csr文件请求生成crt证书文件\nopenssl x509 -req -sha512 -days 3650 \\\n    -extfile v3.ext \\\n    -CA ca.crt -CAkey ca.key -CAcreateserial \\\n    -in 192.168.48.100.csr \\\n    -out 192.168.48.100.crt\n```\n\n### 修改harbor配置文件\n\n```yaml\ncat >> /var/harbor/harbor.yml << \"EOF\"\nhttps:\n  port: 443\n  certificate: /var/harbor/cert/192.168.48.100.crt\n  private_key: /var/harbor/cert/192.168.48.100.key\nEOF\n```\n\n重新启动\n\n```\ncd /var/harbor\ndocker-compose down -v\n./prepare\ndocker-compose up -d\n```\n\n## 镜像上传及拉取测试\n\n操作节点：[harbor1,harbor2,zujian,qianyios（测试客户端）]\n\n找一台客户端装好`docker`进行测试\n\n```\n[root@qianyios ~]# docker -v\nDocker version 26.0.1, build d260a54\n```\n\n### 新建私有镜像仓库\n\n![image-20240429225926063](../img/Harbor%E5%85%B1%E4%BA%AB%E5%AD%98%E5%82%A8%E9%AB%98%E5%8F%AF%E7%94%A8/4fb7f4c6485f304c8148230cdd17cb5e697559838.png)\n\n### 客户端免https登陆\n\n```bash\n# 此时直接使用docker login登陆到harbor中，会报错，下面hostname和port是harbor的配置文件中设置的名称及端口\n#以下是格式\n[root@xxxx harbor]# docker login [hostname]:[port]\n\n可能会出现以下情况\n#192.168.48.100是高可用vip\n[root@harbor1 ~]# docker login 192.168.48.100\nUsername: admin\nPassword:\nError response from daemon: Get \"https://192.168.48.100/v2/\": tls: failed to verify certificate: x509: certificate signed by unknown authority\n\n[root@qianyios ~]# docker login 192.168.48.106:8081\nUsername: admin\nPassword:\nError response from daemon: Get \"https://192.168.48.106:8081/v2/\": http: server gave HTTP response to HTTPS client\n[root@qianyios ~]#\n\n# 客户端默认使用的是https协议，所以需要对docker做以下修改,在文件末尾添加insecure-registries\n[root@qianyios ~]# vim /etc/docker/daemon.json\n{\n   ................\n  \"registry-mirrors\": [],#无关紧要，不用看,\n  \"insecure-registries\": [ \"192.168.48.100\" ],#重要加这行，别忘了如果他不是最后一行一定要在末尾加逗号\n ................\n}\n\n# 修改后，重启docker使其生效\nsystemctl daemon-reload\nsystemctl restart docker\n\n# 利用docker info查看是否添加上\n[root@qianyios ~]# docker info\nContainers: 10\n Running: 1\n Paused: 0\n Stopped: 9\nImages: 37\n...\n Experimental: false\n Insecure Registries:\n  192.168.48.100   ###要确保有这个才行\n  127.0.0.0/8\n Registry Mirrors:\n\n\n```\n\n### 扩展知识-containerd私有仓库配置（可略过）\n\n在今后的K8s版本可能也会用containerd做为k8s的容器运行时，那么配置私有仓库也是一个头疼的事情。\n\n在/etc/containerd/config.toml会有以下两个信息，可以定位\n\n```\n[plugins.\"io.containerd.grpc.v1.cri\".registry.configs]\n[plugins.\"io.containerd.grpc.v1.cri\".registry.mirrors]\n```\n\n要在以上两个信息下配置东西如下：（理解，我下面有一步到位命令，不用手动加）\n\n```\n[plugins.\"io.containerd.grpc.v1.cri\".registry.configs]\n  [plugins.\"io.containerd.grpc.v1.cri\".registry.configs.\"192.168.48.100\".tls]\n    insecure_skip_verify = true  # 是否跳过安全认证\n  [plugins.\"io.containerd.grpc.v1.cri\".registry.configs.\"192.168.48.100\".auth]\n    username = \"admin\"\n    password = \"Harbor12345\"\n\n[plugins.\"io.containerd.grpc.v1.cri\".registry.mirrors]\n  [plugins.\"io.containerd.grpc.v1.cri\".registry.mirrors.\"docker.io\"]\n    endpoint = [\"https://registry-1.docker.io\"]\n  [plugins.\"io.containerd.grpc.v1.cri\".registry.mirrors.\"192.168.48.100\"]\n    endpoint = [\"http://192.168.48.100\"]\n```\n\n![image-20241009163343160](../img/Harbor%E5%85%B1%E4%BA%AB%E5%AD%98%E5%82%A8%E9%AB%98%E5%8F%AF%E7%94%A8/e7d8228511bde2282b1d458025a5170f697559838.png)\n\n添加Harbor信息\n\n```bash\nsed -i '/\\[plugins.\"io.containerd.grpc.v1.cri\".registry.configs\\]/a \\\n        [plugins.\"io.containerd.grpc.v1.cri\".registry.configs.\"192.168.48.100\".tls]\\\n          insecure_skip_verify = true  # 是否跳过安全认证\\\n        [plugins.\"io.containerd.grpc.v1.cri\".registry.configs.\"192.168.48.100\".auth]\\\n          username = \"admin\"\\\n          password = \"Harbor12345\"' /etc/containerd/config.toml\nsed -i '/\\[plugins.\"io.containerd.grpc.v1.cri\".registry.mirrors\\]/a \\\n        [plugins.\"io.containerd.grpc.v1.cri\".registry.mirrors.\"docker.io\"]\\\n          endpoint = [\"https://registry-1.docker.io\"]\\\n        [plugins.\"io.containerd.grpc.v1.cri\".registry.mirrors.\"192.168.48.100\"]\\\n          endpoint = [\"http://192.168.48.100\"]' /etc/containerd/config.toml\n```\n\n最后尝试下载镜像\n\n```\ncrictl pull 192.168.48.100/cicd/jenkins:latest\n```\n\n这个是我自己上传的镜像，已经在harbor仓库了，我现在在有containerd的客户端进行拉取看看能不能成功\n\n![image-20241009164535687](../img/Harbor%E5%85%B1%E4%BA%AB%E5%AD%98%E5%82%A8%E9%AB%98%E5%8F%AF%E7%94%A8/d2038f19baeadc7ad16d1028310d4b5f697559838.png)\n\n显然已经成功\n\n### 进行登入测试\n\n```bash\ndocker login 192.168.48.100\n\n[root@harbor1 ~]# docker login 192.168.48.100\nUsername: admin\nPassword:\nWARNING! Your password will be stored unencrypted in /root/.docker/config.json.\nConfigure a credential helper to remove this warning. See\nhttps://docs.docker.com/engine/reference/commandline/login/#credentials-store\n\nLogin Succeeded\n\n[root@qianyios ~]# docker login 192.168.48.100\nUsername: admin\nPassword:\nWARNING! Your password will be stored unencrypted in /root/.docker/config.json.\nConfigure a credential helper to remove this warning. See\nhttps://docs.docker.com/engine/reference/commandline/login/#credentials-store\n\nLogin Succeeded\n\n##经过测试，通过添加\"insecure-registries\": [ \"192.168.48.100\" ]可以免除https登入\n\n```\n\n### 上传镜像测试\n\n```bash\n#下载一个nginx镜像，然后tag，再上传\n[root@qianyios ~]# docker pull nginx\nUsing default tag: latest\nlatest: Pulling from library/nginx\na2abf6c4d29d: Pull complete\na9edb18cadd1: Pull complete\n589b7251471a: Pull complete\n186b1aaa4aa6: Pull complete\nb4df32aa5a72: Pull complete\na0bcbecc962e: Pull complete\nDigest: sha256:0d17b565c37bcbd895e9d92315a05c1c3c9a29f762b011a10c54a66cd53c9b31\nStatus: Downloaded newer image for nginx:latest\ndocker.io/library/nginx:latest\n#在此下载了最新版的nginx镜像tag为lastest\n```\n\n我们进入当刚刚创建的仓库，点推送指令\n\n```\n#推送镜像命令格式\n#docker tag 源镜像名[:TAG] 192.168.48.100/qianyios/新镜像名[:TAG]\ndocker tag SOURCE_IMAGE[:TAG] 192.168.48.100/qianyios/REPOSITORY[:TAG]\n```\n\n![image-20240430180549537](../img/Harbor%E5%85%B1%E4%BA%AB%E5%AD%98%E5%82%A8%E9%AB%98%E5%8F%AF%E7%94%A8/c1a6a7b6fecf5f740f5be385ab2efc19697559838.png)\n\n```\n#我们将nginx镜像打上tag   \n[root@qianyios ~]# docker images\nREPOSITORY   TAG       IMAGE ID       CREATED       SIZE\nnginx        latest    605c77e624dd   2 years ago   141MB\n#605的意思是镜像id的前三位数字，我们指定为V1标签，相当于版本号。\n[root@qianyios ~]# docker tag 605 192.168.48.100/qianyios/nginx:V1\n[root@qianyios ~]# docker images\nREPOSITORY                      TAG       IMAGE ID       CREATED       SIZE\n192.168.48.100/qianyios/nginx   V1        605c77e624dd   2 years ago   141MB\nnginx                           latest    605c77e624dd   2 years ago   141MB\n#开始上传\n[root@qianyios ~]# docker push 192.168.48.100/qianyios/nginx:V1\nThe push refers to repository [192.168.48.100/qianyios/nginx]\nd874fd2bc83b: Pushed\n32ce5f6a5106: Pushed\nf1db227348d0: Pushed\nb8d6e692a25e: Pushed\ne379e8aedd4d: Pushed\n2edcec3590a4: Pushed\nV1: digest: sha256:ee89b00528ff4f02f2405e4ee221743ebc3f8e8dd0bfd5c4c20a2fa2aaa7ede3 size: 1570\n#去页面查看\n```\n\n![image-20240430181509733](../img/Harbor%E5%85%B1%E4%BA%AB%E5%AD%98%E5%82%A8%E9%AB%98%E5%8F%AF%E7%94%A8/b1a7eca729d06f4371d5234181428e20697559838.png)\n\n![image-20240430181528902](../img/Harbor%E5%85%B1%E4%BA%AB%E5%AD%98%E5%82%A8%E9%AB%98%E5%8F%AF%E7%94%A8/d161a1df048d0256c3c33f9b5289ac05697559838.png)\n\n我们去harbor1测试拉取镜像，会发现下载数变成了`1`\n\n```\n[root@harbor1 ~]# docker pull 192.168.48.100/qianyios/nginx:V1\nV1: Pulling from qianyios/nginx\na2abf6c4d29d: Pull complete\na9edb18cadd1: Pull complete\n589b7251471a: Pull complete\n186b1aaa4aa6: Pull complete\nb4df32aa5a72: Pull complete\na0bcbecc962e: Pull complete\nDigest: sha256:ee89b00528ff4f02f2405e4ee221743ebc3f8e8dd0bfd5c4c20a2fa2aaa7ede3\nStatus: Downloaded newer image for 192.168.48.100/qianyios/nginx:V1\n192.168.48.100/qianyios/nginx:V1\n[root@harbor1 ~]#\n```\n\n![image-20240430181626605](../img/Harbor%E5%85%B1%E4%BA%AB%E5%AD%98%E5%82%A8%E9%AB%98%E5%8F%AF%E7%94%A8/fc75695e91827f976cf7cc6c74abeabe697559838.png)\n\n<div class=\"tbsm\" style=\"margin-top:54px;\">\n<div class=\"tbsm-top\"><span><svg t=\"1674654360507\" class=\"icon\" viewBox=\"0 0 1024 1024\" version=\"1.1\" xmlns=\"http://www.w3.org/2000/svg\" p-id=\"987\" data-spm-anchor-id=\"a313x.7781069.0.i0\" width=\"35\" height=\"35\"><path d=\"M410.49 97.74H155.08a56.74 56.74 0 0 0-56.84 56.73V410a56.84 56.84 0 0 0 56.84 56.84h255.41A56.83 56.83 0 0 0 467.32 410V154.58a56.83 56.83 0 0 0-56.83-56.84zM410.49 558.74H155.08a56.74 56.74 0 0 0-56.84 56.73V871a56.84 56.84 0 0 0 56.84 56.84h255.41A56.83 56.83 0 0 0 467.32 871V615.58a56.83 56.83 0 0 0-56.83-56.84zM871.49 558.74H616.08a56.74 56.74 0 0 0-56.84 56.73V871a56.84 56.84 0 0 0 56.84 56.84h255.41A56.83 56.83 0 0 0 928.32 871V615.58a56.83 56.83 0 0 0-56.83-56.84z\" fill=\"#66EEFF\" p-id=\"988\"></path><path d=\"M410.49 558.74h-4.14A475 475 0 0 0 299.52 859.6a481.16 481.16 0 0 0 4.84 68.22h106.13A56.83 56.83 0 0 0 467.32 871V615.58a56.83 56.83 0 0 0-56.83-56.84zM871.49 558.74H616.08a56.74 56.74 0 0 0-56.84 56.73V871a56.84 56.84 0 0 0 56.84 56.84h255.41A56.83 56.83 0 0 0 928.32 871V615.58a56.83 56.83 0 0 0-56.83-56.84z\" fill=\"#C2F8FF\" p-id=\"989\"></path></svg></span><span style=\"font-size:30px;\"> 特别声明</span></div>\n<div class=\"tbsm-wz\">千屹博客旗下的所有文章，是通过本人课堂学习和课外自学所精心整理的知识巨著<br/>难免会有出错的地方<br/>如果细心的你发现了小失误，可以在下方评论区告诉我，或者私信我！<br />非常感谢大家的热烈支持！</div>\n</div>\n","tags":["OpenEuler","Harbor"],"categories":["云原生"]},{"title":"OpenEuler-K8S高可用集群（内部etcd）","url":"/posts/62904/","content":"\n<meta name=\"referrer\" content=\"no-referrer\"/>\n\n# OpenEuler-部署K8S高可用集群（内部etcd）\n\n## 主机拓扑\n\n| 主机名  | ip1（NAT）     | 系统                | 磁盘 | 内存 |\n| ------- | -------------- | ------------------- | ---- | ---- |\n| master1 | 192.168.48.101 | OpenEuler-22.03-LTS | 100G | 4G   |\n| master2 | 192.168.48.102 | OpenEuler-22.03-LTS | 100G | 4G   |\n| master3 | 192.168.48.103 | OpenEuler-22.03-LTS | 100G | 4G   |\n| node01  | 192.168.48.104 | OpenEuler-22.03-LTS | 100G | 8G   |\n\n镜像下载地址：[OpenEuler-22.03-LTS](https://mirrors.nju.edu.cn/openeuler/openEuler-22.03-LTS-SP4/ISO/x86_64/)\n\n下载名为openEuler-22.03-LTS-SP4-x86_64-dvd.iso\n\n## 基础配置\n\nOpeneuler通过单独安装，非克隆。安装完后进行基本环境的配置，配置一下几个方面：\n\n1. 设置主机名\n2. 关闭firewalld、dnsmasq、selinux\n3. 设置ens33\n6. 备份并新增、docker-ce源、k8s源\n7. 更新yum源软件包缓存\n9. 添加hosts解析\n10. 关闭swap分区\n11. 安装chrony服务，并同步时间\n12. 配置limits.conf\n13. 安装必备工具\n14. 升级系统并重启\n\n操作主机：[master1,master2,master3,node01]\n\n```\n#将以下脚本内容添加进去\nvi k8s_system_init.sh\n```\n\n```\n#!/bin/bash\nif [ $# -eq 2 ];then\n  echo \"设置主机名为：$1\"\n  echo \"ens33设置IP地址为：192.168.48.$2\"\nelse\n  echo  \"使用方法：sh $0 主机名 主机位\"\n  exit 2\nfi\n\necho \"--------------------------------------\"\necho \"1.正在设置主机名：$1\"\nhostnamectl set-hostname $1\n\necho \"2.正在关闭firewalld、dnsmasq、selinux\"\nsystemctl disable firewalld &> /dev/null\nsystemctl disable dnsmasq &> /dev/null\nsystemctl stop firewalld\nsystemctl stop dnsmasq\nsed -i \"s#SELINUX=enforcing#SELINUX=disabled#g\" /etc/selinux/config\nsetenforce 0\n\n\necho \"3.正在设置ens33：192.168.48.$2\"\ncat > /etc/sysconfig/network-scripts/ifcfg-ens33 <<EOF\nTYPE=Ethernet\nPROXY_METHOD=none\nBROWSER_ONLY=no\nBOOTPROTO=static\nDEFROUTE=yes\nIPV4_FAILURE_FATAL=no\nIPV6INIT=yes\nIPV6_AUTOCONF=yes\nIPV6_DEFROUTE=yes\nIPV6_FAILURE_FATAL=no\nNAME=ens33\nUUID=53b402ff-5865-47dd-a853-7afcd6521738\nDEVICE=ens33\nONBOOT=yes\nIPADDR=192.168.48.$2\nGATEWAY=192.168.48.2\nPREFIX=24\nDNS1=192.168.48.2\nDNS2=114.114.114.114\nEOF\nnmcli c reload\nnmcli c up ens33\n\n\necho \"4.新增docker-ce源、k8s源\"\nmkdir /etc/yum.repos.d/bak/\ncp /etc/yum.repos.d/* /etc/yum.repos.d/bak/\nsleep 3\ncat > /etc/yum.repos.d/kubernetes.repo <<EOF\n[kubernetes]\nname=Kubernetes\nbaseurl=https://mirrors.aliyun.com/kubernetes/yum/repos/kubernetes-el7-x86_64/\nenabled=1\ngpgcheck=0\nrepo_gpgcheck=0\ngpgkey=https://mirrors.aliyun.com/kubernetes/yum/doc/yum-key.gpg \nEOF\n#切换为华为云，下载速度更快\nsed -i 's/\\$basearch/x86_64/g' /etc/yum.repos.d/openEuler.repo\nsed -i 's/http\\:\\/\\/repo.openeuler.org/https\\:\\/\\/mirrors.huaweicloud.com\\/openeuler/g' /etc/yum.repos.d/openEuler.repo\n\ncurl -o /etc/yum.repos.d/docker-ce.repo https://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo\nsed -i 's/\\$releasever/7/g' /etc/yum.repos.d/docker-ce.repo\n\necho \"5.更新yum源软件包缓存\"\n yum clean all && yum makecache\n\necho \"6.添加hosts解析\"\ncat > /etc/hosts <<EOF\n127.0.0.1   localhost localhost.localdomain localhost4 localhost4.localdomain4\n::1         localhost localhost.localdomain localhost6 localhost6.localdomain6\n192.168.48.101 master1\n192.168.48.102 master2\n192.168.48.103 master3\n192.168.48.104 node01\n192.168.48.105 node02\nEOF\n\n\necho \"7.关闭swap分区\"\nswapoff -a && sysctl -w vm.swappiness=0 &> /dev/null\nsed -ri '/^[^#]*swap/s@^@#@' /etc/fstab\n\n\necho \"8.安装chrony服务，并同步时间\"\nyum install chrony -y\nsystemctl start chronyd\nsystemctl enable chronyd\nchronyc sources\nchronyc sources\n\necho \"9.配置limits.conf\"\nulimit -SHn 65535\ncat >> /etc/security/limits.conf <<EOF\n* soft nofile 65536\n* hard nofile 131072\n* soft nproc 65535\n* hard nproc 655350\n* soft memlock unlimited\n* hard memlock unlimited\nEOF\n\n\necho \"10.必备工具安装\"\nyum install wget psmisc vim net-tools telnet device-mapper-persistent-data lvm2 git -y\n\n\necho \"11.重启\"\nreboot\n\n```\n\n```\nsh k8s_system_init.sh 主机名  主机位\n[master1] sh k8s_system_init.sh master1 101\n\n[master2] sh k8s_system_init.sh master2 102\n\n[master3] sh k8s_system_init.sh master3 103\n\n[node01] sh k8s_system_init.sh node01 104\n\n```\n\n### 配置ssh免密\n\n操作节点[master1]\n\n```\nyum install -y sshpass \ncat > sshmianmi.sh << \"EOF\"\n#!/bin/bash\n# 目标主机列表\nhosts=(\"master1\" \"master2\" \"master3\" \"node01\")\n# 密码\npassword=\"Lj201840.\"\n# 生成 SSH 密钥对\nssh-keygen -t rsa -N \"\" -f ~/.ssh/id_rsa\n\n# 循环遍历目标主机\nfor host in \"${hosts[@]}\"\ndo\n    # 复制公钥到目标主机\n    sshpass -p \"$password\" ssh-copy-id -o StrictHostKeyChecking=no \"$host\"\n    \n    # 验证免密登录\n    sshpass -p \"$password\" ssh -o StrictHostKeyChecking=no \"$host\" \"echo '免密登录成功'\"\ndone\nEOF\n\nsh sshmianmi.sh\n```\n\n## 内核及ipvs模块配置\n\n此步骤是配置ipvs模块，开启一些k8s集群中必须的内核参数。配置一下几个方面：\n\n1. 更改内核启动顺序\n2. 安装ipvsadm\n3. 配置ipvs模块\n4. 开启k8s集群必须的内核参数\n5. 配置完内核，重启服务器\n\n操作主机：[master1,master2,master3,node01]\n\n```\nvi kernel_update.sh\n```\n\n```\n#!/bin/bash\n\necho \"1.更改内核启动顺序\"\ngrub2-set-default  0 && grub2-mkconfig -o /etc/grub2.cfg\ngrubby --args=\"user_namespace.enable=1\" --update-kernel=\"$(grubby --default-kernel)\"\n\necho \"2.安装ipvsadm\"\nyum install ipvsadm ipset sysstat conntrack libseccomp -y &> /dev/null\n\n\necho \"3.配置ipvs模块\"\nmodprobe -- ip_vs\nmodprobe -- ip_vs_rr\nmodprobe -- ip_vs_wrr\nmodprobe -- ip_vs_sh\nmodprobe -- nf_conntrack\n\ncat >> /etc/modules-load.d/ipvs.conf <<EOF\nip_vs\nip_vs_lc\nip_vs_wlc\nip_vs_rr\nip_vs_wrr\nip_vs_lblc\nip_vs_lblcr\nip_vs_dh\nip_vs_sh\nip_vs_fo\nip_vs_nq\nip_vs_sed\nip_vs_ftp\nip_vs_sh\nnf_conntrack\nip_tables\nip_set\nxt_set\nipt_set\nipt_rpfilter\nipt_REJECT\nipip\nEOF\nsystemctl enable --now systemd-modules-load.service &> /dev/null\n\n\necho \"4.开启k8s集群必须的内核参数\"\ncat <<EOF > /etc/sysctl.d/k8s.conf\nnet.ipv4.ip_nonlocal_bind = 1 \nnet.ipv4.ip_forward = 1\nnet.bridge.bridge-nf-call-iptables = 1\nnet.bridge.bridge-nf-call-ip6tables = 1\nfs.may_detach_mounts = 1\nnet.ipv4.conf.all.route_localnet = 1\nvm.overcommit_memory=1\nvm.panic_on_oom=0\nfs.inotify.max_user_watches=89100\nfs.file-max=52706963\nfs.nr_open=52706963\nnet.netfilter.nf_conntrack_max=2310720\nnet.ipv4.tcp_keepalive_time = 600\nnet.ipv4.tcp_keepalive_probes = 3\nnet.ipv4.tcp_keepalive_intvl =15\nnet.ipv4.tcp_max_tw_buckets = 36000\nnet.ipv4.tcp_tw_reuse = 1\nnet.ipv4.tcp_max_orphans = 327680\nnet.ipv4.tcp_orphan_retries = 3\nnet.ipv4.tcp_syncookies = 1\nnet.ipv4.tcp_max_syn_backlog = 16384\nnet.ipv4.ip_conntrack_max = 65536\nnet.ipv4.tcp_max_syn_backlog = 16384\nnet.ipv4.tcp_timestamps = 0\nnet.core.somaxconn = 16384\nEOF\nsysctl --system\n\n\necho \"5.配置完内核，重启服务器！\"\nreboot\n\n```\n\n```\nsh kernel_update.sh\n```\n\n## 检查ipvs加载、内核版本验证\n\n```\nlsmod | grep --color=auto -e ip_vs -e nf_conntrack\nuname -a\n```\n\n![image-20231201233238841](../img/OpenEuler-K8S%E9%AB%98%E5%8F%AF%E7%94%A8%E9%9B%86%E7%BE%A4%EF%BC%88%E5%86%85%E9%83%A8etcd%EF%BC%89/1325a5766ef497cc896d29b1ef00b5de697559838.png)\n\n##  高可用组件安装\n\n### haproxy配置\n\n操作节点：[master1，master2,master3]\n\n```\nyum install keepalived haproxy -y\n```\n\n所有Master节点配置HAProxy，所有Master节点的HAProxy配置相同。\n\n```yaml\n操作节点：[master1，master2，master3]\ncat > /etc/haproxy/haproxy.cfg <<\"EOF\"\n\nglobal\n  maxconn  2000\n  ulimit-n  16384\n  log  127.0.0.1 local0 err\n  stats timeout 30s\n\ndefaults\n  log global\n  mode  http\n  option  httplog\n  timeout connect 5000\n  timeout client  50000\n  timeout server  50000\n  timeout http-request 15s\n  timeout http-keep-alive 15s\n\nfrontend monitor-in\n  bind *:33305\n  mode http\n  option httplog\n  monitor-uri /monitor\n\nfrontend k8s-master\n  bind 0.0.0.0:16443\n  bind 127.0.0.1:16443\n  mode tcp\n  option tcplog\n  tcp-request inspect-delay 5s\n  default_backend k8s-master\n\nbackend k8s-master\n  mode tcp\n  option tcplog\n  option tcp-check\n  balance roundrobin\n  default-server inter 10s downinter 5s rise 2 fall 2 slowstart 60s maxconn 250 maxqueue 256 weight 100\n  server master1   192.168.48.101:6443  check\n  server master2   192.168.48.102:6443  check\n  server master3   192.168.48.103:6443  check\nEOF\n```\n\n### Keepalived配置\n\n操作节点：[master1，master2,master3]\n\n所有Master节点配置Keepalived，以下三个Master节点配置注意ip和网卡。\n\n```\ncat > /etc/keepalived/keepalived.conf << \"EOF\"\n\n! Configuration File for keepalived\nglobal_defs {\n    router_id LVS_DEVEL\n    script_user root\n    enable_script_security\n}\n\nvrrp_script chk_apiserver {\n    script \"/etc/keepalived/check_apiserver.sh\"\n    interval 5\n    weight -5\n    fall 2\n    rise 1\n}\n\nvrrp_instance VI_1 {\n    state MASTER\n    interface ens33\n    mcast_src_ip 192.168.48.101\n    virtual_router_id 51\n    priority 201\n    advert_int 2\n    authentication {\n        auth_type PASS\n        auth_pass 1111 # 限制在8个字符以内\n    }\n    virtual_ipaddress {\n        192.168.48.200\n    }\n    track_script {\n        chk_apiserver\n    }\n}\nEOF\n```\n\n```\ncat > /etc/keepalived/keepalived.conf << \"EOF\"\n\n! Configuration File for keepalived\nglobal_defs {\n    router_id LVS_DEVEL\n    script_user root\n    enable_script_security\n}\n\nvrrp_script chk_apiserver {\n    script \"/etc/keepalived/check_apiserver.sh\"\n    interval 5\n    weight -5\n    fall 2\n    rise 1\n}\n\nvrrp_instance VI_1 {\n    state BACKUP\n    interface ens33\n    mcast_src_ip 192.168.48.102\n    virtual_router_id 51\n    priority 150\n    advert_int 2\n    authentication {\n        auth_type PASS\n        auth_pass 1111 # 限制在8个字符以内\n    }\n    virtual_ipaddress {\n        192.168.48.200\n    }\n    track_script {\n        chk_apiserver\n    }\n}\nEOF\n```\n\n```\ncat > /etc/keepalived/keepalived.conf << \"EOF\"\n\n! Configuration File for keepalived\nglobal_defs {\n    router_id LVS_DEVEL\n    script_user root\n    enable_script_security\n}\n\nvrrp_script chk_apiserver {\n    script \"/etc/keepalived/check_apiserver.sh\"\n    interval 5\n    weight -5\n    fall 2\n    rise 1\n}\n\nvrrp_instance VI_1 {\n    state BACKUP\n    interface ens33\n    mcast_src_ip 192.168.48.103\n    virtual_router_id 51\n    priority 99\n    advert_int 2\n    authentication {\n        auth_type PASS\n        auth_pass 1111 # 限制在8个字符以内\n    }\n    virtual_ipaddress {\n        192.168.48.200\n    }\n    track_script {\n        chk_apiserver\n    }\n}\nEOF\n```\n\n### 配置Keepalived健康检查文件\n\n操作节点：[master1，master2,master3]\n\n```\ncat > /etc/keepalived/check_apiserver.sh << \"EOF\"\n#!/bin/bash\n\nerr=0\nfor k in \\$(seq 1 3)\ndo\n    check_code=\\$(pgrep haproxy)\n    if [[ \\$check_code == \"\" ]]; then\n        err=\\$(expr \\$err + 1)\n        sleep 1\n        continue\n    else\n        err=0\n        break\n    fi\ndone\n\nif [[ \\$err != \"0\" ]]; then\n    echo \"Stopping keepalived due to haproxy failure.\"\n    /usr/bin/systemctl stop keepalived\n    exit 1\nelse\n    exit 0\nfi\nEOF\n\nchmod +x /etc/keepalived/check_apiserver.sh\n```\n\n### 启动haproxy和keepalived\n\n```\n操作节点：[master，master2,master3]\nsystemctl daemon-reload\nsystemctl enable --now haproxy\nsystemctl enable --now keepalived\nsystemctl restart haproxy keepalived\n```\n\n### 测试集群负载均衡高可用\n\n查看master1的vip\n\n```\nip a\n```\n\n![image-20231109232708584](../img/OpenEuler-K8S%E9%AB%98%E5%8F%AF%E7%94%A8%E9%9B%86%E7%BE%A4%EF%BC%88%E5%86%85%E9%83%A8etcd%EF%BC%89/d419111a4b7e1cecb92fe4c934c15324697559838.png)\n\n模拟master1的宕机测试，看看vip会不会漂移到master2去\n\n```\n[master1] poweroff\n```\n\n![image-20231109232803276](../img/OpenEuler-K8S%E9%AB%98%E5%8F%AF%E7%94%A8%E9%9B%86%E7%BE%A4%EF%BC%88%E5%86%85%E9%83%A8etcd%EF%BC%89/fde8cea0a4bc27255f880d21601fdb8c697559838.png)\n\n这时候查看master2的ip列表\n\n```\n[master2] ip a\n```\n\n![image-20231109232825999](../img/OpenEuler-K8S%E9%AB%98%E5%8F%AF%E7%94%A8%E9%9B%86%E7%BE%A4%EF%BC%88%E5%86%85%E9%83%A8etcd%EF%BC%89/d4019c6f8cdc38d93404b9c6277c7369697559838.png)\n\n结论：这时可以知道，负载均衡集群成功，当master1出现宕机情况，vip会从master1漂移到master2\n\n## docker安装\n\n### 安装docker\n\n操作节点[master1，master2，master3,node01]\n\n```\nwget https://download.docker.com/linux/static/stable/x86_64/docker-24.0.7.tgz\ntar xf docker-*.tgz\ncp -rf docker/* /usr/bin/\n#创建containerd的service文件,并且启动\ncat >/etc/systemd/system/containerd.service <<EOF\n[Unit]\nDescription=containerd container runtime\nDocumentation=https://containerd.io\nAfter=network.target local-fs.target\n[Service]\nExecStartPre=-/sbin/modprobe overlay\nExecStart=/usr/bin/containerd\nType=notify\nDelegate=yes\nKillMode=process\nRestart=always\nRestartSec=5\nLimitNPROC=infinity\nLimitCORE=infinity\nLimitNOFILE=1048576\nTasksMax=infinity\nOOMScoreAdjust=-999\n[Install]\nWantedBy=multi-user.target\nEOF\nsystemctl enable --now containerd.service\n\n#准备docker的service文件\n\ncat > /etc/systemd/system/docker.service <<EOF\n[Unit]\nDescription=Docker Application Container Engine\nDocumentation=https://docs.docker.com\nAfter=network-online.target firewalld.service containerd.service\nWants=network-online.target\nRequires=docker.socket containerd.service\n[Service]\nType=notify\nExecStart=/usr/bin/dockerd --config-file=/etc/docker/daemon.json -H fd://\ncontainerd=/run/containerd/containerd.sock\nExecReload=/bin/kill -s HUP $MAINPID\nTimeoutSec=0\nRestartSec=2\nRestart=always\nStartLimitBurst=3\nStartLimitInterval=60s\nLimitNOFILE=infinity\nLimitNPROC=infinity\nLimitCORE=infinity\nTasksMax=infinity\nDelegate=yes\nKillMode=process\nOOMScoreAdjust=-500\n[Install]\nWantedBy=multi-user.target\nEOF\n\n\n#准备docker的socket文件\n\ncat > /etc/systemd/system/docker.socket <<EOF\n[Unit]\nDescription=Docker Socket for the API\n[Socket]\nListenStream=/var/run/docker.sock\nSocketMode=0660\nSocketUser=root\nSocketGroup=docker\n[Install]\nWantedBy=sockets.target\nEOF\ngroupadd docker\n\nsystemctl enable --now docker.socket  && systemctl enable --now docker.service\n\n\n#验证\nmkdir /etc/docker\nsudo tee /etc/docker/daemon.json > /dev/null <<'EOF'\n{\n  \"registry-mirrors\": [\n    \"https://docker.xuanyuan.me\",\n    \"https://docker.m.daocloud.io\",\n    \"https://docker.1ms.run\",\n    \"https://docker.1panel.live\",\n    \"https://registry.cn-hangzhou.aliyuncs.com\",\n\t\t\"https://docker.qianyios.top\"\n  ],\n  \"max-concurrent-downloads\": 10,\n  \"log-driver\": \"json-file\",\n  \"log-level\": \"warn\",\n  \"log-opts\": {\n    \"max-size\": \"10m\",\n    \"max-file\": \"3\"\n  },\n  \"data-root\": \"/var/lib/docker\"\n}\nEOF\nsystemctl daemon-reload\nsystemctl restart docker\n```\n\n### 安装cri-docker\n\n操作节点[master1，master2，master3,node01]\n\n```\nwget https://github.com/Mirantis/cri-dockerd/releases/download/v0.3.12/cri-dockerd-0.3.12.amd64.tgz\n\ntar -zxvf cri-dockerd-0.3.*.amd64.tgz\ncp cri-dockerd/cri-dockerd  /usr/bin/\nchmod +x /usr/bin/cri-dockerd\n\n\n#写入启动配置文件\ncat >  /usr/lib/systemd/system/cri-docker.service <<EOF\n[Unit]\nDescription=CRI Interface for Docker Application Container Engine\nDocumentation=https://docs.mirantis.com\nAfter=network-online.target firewalld.service docker.service\nWants=network-online.target\nRequires=cri-docker.socket\n \n[Service]\nType=notify\nExecStart=/usr/bin/cri-dockerd --network-plugin=cni --pod-infra-container-image=registry.aliyuncs.com/google_containers/pause:3.9\nExecReload=/bin/kill -s HUP $MAINPID\nTimeoutSec=0\nRestartSec=2\nRestart=always\n \nStartLimitBurst=3\n \nStartLimitInterval=60s\n \nLimitNOFILE=infinity\nLimitNPROC=infinity\nLimitCORE=infinity\n \nTasksMax=infinity\nDelegate=yes\nKillMode=process\n \n[Install]\nWantedBy=multi-user.target\nEOF\n\n\n#写入socket配置文件\ncat > /usr/lib/systemd/system/cri-docker.socket <<EOF\n[Unit]\nDescription=CRI Docker Socket for the API\nPartOf=cri-docker.service\n \n[Socket]\nListenStream=%t/cri-dockerd.sock\nSocketMode=0660\nSocketUser=root\nSocketGroup=docker\n \n[Install]\nWantedBy=sockets.target\nEOF\n\nsystemctl daemon-reload && systemctl enable cri-docker --now\n```\n\n## K8S集群安装\n\n### 安装k8s所需的工具\n\n```\n操作节点[master1，master2，master3,node01]\n\nyum -y install  kubeadm kubelet kubectl\n\n#为了实现docker使用的cgroupdriver与kubelet使用的cgroup的一致性，配置如下：\nsed -i 's/^KUBELET_EXTRA_ARGS=/KUBELET_EXTRA_ARGS=\"--cgroup-driver=systemd\"/g' /etc/sysconfig/kubelet\n\n#设置kubelet为开机自启动即可，由于没有生成配置文件，集群初始化后自动启动\nsystemctl enable kubelet\nsystemctl enable kubelet.service\n```\n\n### 集群初始化\n\n```\n操作节点[master1,master2,master3]\n\ncat > kubeadm-config.yaml << EOF\napiVersion: kubeadm.k8s.io/v1beta3\nbootstrapTokens:\n- groups:\n  - system:bootstrappers:kubeadm:default-node-token\n  token: abcdef.0123456789abcdef\n  ttl: 24h0m0s\n  usages:\n  - signing\n  - authentication\nkind: InitConfiguration\nlocalAPIEndpoint:\n  advertiseAddress: 192.168.48.101\n  bindPort: 6443\nnodeRegistration:\n  criSocket: unix:///var/run/cri-dockerd.sock\n  imagePullPolicy: IfNotPresent\n  taints: null\n---\napiServer:\n  timeoutForControlPlane: 4m0s\napiVersion: kubeadm.k8s.io/v1beta3\ncertificatesDir: /etc/kubernetes/pki\nclusterName: kubernetes\ncontrollerManager: {}\ndns: {}\netcd:\n  local:\n    dataDir: /var/lib/etcd\nimageRepository: registry.aliyuncs.com/google_containers\nkind: ClusterConfiguration\nkubernetesVersion: 1.28.2\nnetworking:\n  dnsDomain: cluster.local\n  podSubnet: 10.244.0.0/16\n  serviceSubnet: 10.96.0.0/12\nscheduler: {}\ncontrolPlaneEndpoint: \"192.168.48.200:16443\"\n---\napiVersion: kubeproxy.config.k8s.io/v1alpha1\nbindAddress: 0.0.0.0\nbindAddressHardFail: false\nclientConnection:\n  acceptContentTypes: \"\"\n  burst: 0\n  contentType: \"\"\n  kubeconfig: /var/lib/kube-proxy/kubeconfig.conf\n  qps: 0\nclusterCIDR: \"\"\nconfigSyncPeriod: 0s\nconntrack:\n  maxPerCore: null\n  min: null\n  tcpCloseWaitTimeout: null\n  tcpEstablishedTimeout: null\ndetectLocal:\n  bridgeInterface: \"\"\n  interfaceNamePrefix: \"\"\ndetectLocalMode: \"\"\nenableProfiling: false\nhealthzBindAddress: \"\"\nhostnameOverride: \"\"\niptables:\n  localhostNodePorts: null\n  masqueradeAll: false\n  masqueradeBit: null\n  minSyncPeriod: 0s\n  syncPeriod: 0s\nipvs:\n  excludeCIDRs: null\n  minSyncPeriod: 0s\n  scheduler: \"\"\n  strictARP: false\n  syncPeriod: 0s\n  tcpFinTimeout: 0s\n  tcpTimeout: 0s\n  udpTimeout: 0s\nkind: KubeProxyConfiguration\nlogging:\n  flushFrequency: 0\n  options:\n    json:\n      infoBufferSize: \"0\"\n  verbosity: 0\nmetricsBindAddress: \"\"\nmode: \"\"\nnodePortAddresses: null\noomScoreAdj: null\nportRange: \"\"\nshowHiddenMetricsForVersion: \"\"\nwinkernel:\n  enableDSR: false\n  forwardHealthCheckVip: false\n  networkName: \"\"\n  rootHnsEndpointName: \"\"\n  sourceVip: \"\"\n---\napiVersion: kubelet.config.k8s.io/v1beta1\nauthentication:\n  anonymous:\n    enabled: false\n  webhook:\n    cacheTTL: 0s\n    enabled: true\n  x509:\n    clientCAFile: /etc/kubernetes/pki/ca.crt\nauthorization:\n  mode: Webhook\n  webhook:\n    cacheAuthorizedTTL: 0s\n    cacheUnauthorizedTTL: 0s\ncgroupDriver: systemd\nclusterDNS:\n- 10.96.0.10\nclusterDomain: cluster.local\ncontainerRuntimeEndpoint: \"\"\ncpuManagerReconcilePeriod: 0s\nevictionPressureTransitionPeriod: 0s\nfileCheckFrequency: 0s\nhealthzBindAddress: 127.0.0.1\nhealthzPort: 10248\nhttpCheckFrequency: 0s\nimageMinimumGCAge: 0s\nkind: KubeletConfiguration\nlogging:\n  flushFrequency: 0\n  options:\n    json:\n      infoBufferSize: \"0\"\n  verbosity: 0\nmemorySwap: {}\nnodeStatusReportFrequency: 0s\nnodeStatusUpdateFrequency: 0s\nrotateCertificates: true\nruntimeRequestTimeout: 0s\nshutdownGracePeriod: 0s\nshutdownGracePeriodCriticalPods: 0s\nstaticPodPath: /etc/kubernetes/manifests\nstreamingConnectionIdleTimeout: 0s\nsyncFrequency: 0s\nvolumeStatsAggPeriod: 0s\n\nEOF\n\nkubeadm config migrate --old-config kubeadm-config.yaml --new-config new.yaml\n\n```\n\n### 准备k8s所需的镜像\n\n```\n操作节点[master1,master2,master3]\n\nkubeadm config images pull --config /root/new.yaml \n```\n\n![image-20231110100341121](../img/OpenEuler-K8S%E9%AB%98%E5%8F%AF%E7%94%A8%E9%9B%86%E7%BE%A4%EF%BC%88%E5%86%85%E9%83%A8etcd%EF%BC%89/15d685625b3cf3eb0b5ec8f67347f298697559838.png)\n\n### master1节点初始化\n\n操作节点[master1]\n\n```\nkubeadm init --config /root/new.yaml  --upload-certs\n```\n\n会生成信息\n\n![image-20231110175843902](../img/OpenEuler-K8S%E9%AB%98%E5%8F%AF%E7%94%A8%E9%9B%86%E7%BE%A4%EF%BC%88%E5%86%85%E9%83%A8etcd%EF%BC%89/845bd1bac6bcf6ef286522b7c49f1672697559838.png)\n\n记录信息后面会用到\n\n初始化成功以后，会产生Token值，用于其他节点加入时使用，因此要记录下初始化成功生成的token值（令牌值），**有效期24小时，后续需要操作可以重新生成Token**\n\n操作节点[master1]\n\n```\nkubeadm join 192.168.48.200:16443 --token abcdef.0123456789abcdef \\\n        --discovery-token-ca-cert-hash sha256:fd91b75286ce9d50c840f380117e25961ad743a8962f3a9f2c80d74c928e1497 \\\n        --control-plane --certificate-key 0dfa57d943f4a2b8b55840d17f67de731b137e11ca4720f7bf9bfd75d8247e22\n\nkubeadm join 192.168.48.200:16443 --token abcdef.0123456789abcdef \\\n        --discovery-token-ca-cert-hash sha256:fd91b75286ce9d50c840f380117e25961ad743a8962f3a9f2c80d74c928e1497\n```\n\n`操作kubect报错：`\n\n![image-20231110180035297](../img/OpenEuler-K8S%E9%AB%98%E5%8F%AF%E7%94%A8%E9%9B%86%E7%BE%A4%EF%BC%88%E5%86%85%E9%83%A8etcd%EF%BC%89/f7e9c2c31bb5f7dab653a744542e5f95697559838.png)\n\n此时通过kubectl操作，会出现失败，因为还没有将集群的\"钥匙\"交给root用户。`/etc/kubernetes/admin.conf` 文件是 Kubernetes（K8s）集群中的管理员配置文件，它包含了用于管理集群的身份验证和访问信息。所以下面进行配置环境变量，用于访问Kubernetes集群：\n\n`添加环境变量`\n\n操作节点[master1]\n\n```\nmkdir -p $HOME/.kube\nsudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config\nsudo chown $(id -u):$(id -g) $HOME/.kube/config\n```\n\n### 添加其他master节点至集群中\n\n操作节点[master2,master3]\n\n```\n操作节点[master2,master3]\nkubeadm join 192.168.48.200:16443 --token abcdef.0123456789abcdef \\\n        --discovery-token-ca-cert-hash sha256:fd91b75286ce9d50c840f380117e25961ad743a8962f3a9f2c80d74c928e1497 \\\n        --control-plane --certificate-key 0dfa57d943f4a2b8b55840d17f67de731b137e11ca4720f7bf9bfd75d8247e22 \\\n        --cri-socket unix:///var/run/cri-dockerd.sock \n```\n\n注意：这里末尾添加了`--cri-socket unix:///var/run/cri-dockerd.sock `\n\n接着给`master2`添加环境变量\n\n```\n操作节点[master2,master3]\nmkdir -p $HOME/.kube\nsudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config\nsudo chown $(id -u):$(id -g) $HOME/.kube/config\n```\n\n![image-20231110180919008](../img/OpenEuler-K8S%E9%AB%98%E5%8F%AF%E7%94%A8%E9%9B%86%E7%BE%A4%EF%BC%88%E5%86%85%E9%83%A8etcd%EF%BC%89/069369188589ae7cde679b64eb6cf342697559838.png)\n\n这里没有展示master3的图片，但是步骤一样的\n\n### 模拟Token过期重新生成并加入Node节点\n\n假设加入集群的token过期了。node01无法加入了，这里就模拟一下这种情况\n\n1. Token过期后生成新的token：\n\n```bash\nkubeadm token create --print-join-command\n```\n\n```\n[root@master1 ~]# kubeadm token create --print-join-command\nkubeadm join 192.168.48.200:16443 --token tn5q1b.7w1jj77ewup7k2in --discovery-token-ca-cert-hash sha256:cc5427e0e133d95250ab0aa90976fea2c383278b6345fd7e8c28702ac8dfc61f\n\n```\n\n其中，`192.168.48.200:16443` 是你的 Kubernetes API 服务器的地址和端口，`tn5q1b.7w1jj77ewup7k2in` 是新的令牌，`sha256:cc5427e0e133d95250ab0aa90976fea2c383278b6345fd7e8c28702ac8dfc61f` 是令牌的 CA 证书哈希值。\n\n2. Master需要生成--certificate-key：\n\n```bash\nkubeadm init phase upload-certs --upload-certs\n```\n\n```\n[root@master1 ~]# kubeadm init phase upload-certs --upload-certs\nW1110 18:12:03.426245   10185 version.go:104] could not fetch a Kubernetes version from the internet: unable to get URL \"https://dl.k8s.io/release/stable-1.txt\": Get \"https://dl.k8s.io/release/stable-1.txt\": context deadline exceeded (Client.Timeout exceeded while awaiting headers)\nW1110 18:12:03.426320   10185 version.go:105] falling back to the local client version: v1.28.2\n[upload-certs] Storing the certificates in Secret \"kubeadm-certs\" in the \"kube-system\" Namespace\n[upload-certs] Using certificate key:\n5d3706028d5e569324a4c456c81ae0f5551ece88b3132f03917668c6b0605128\n```\n\n其中，`5d3706028d5e569324a4c456c81ae0f5551ece88b3132f03917668c6b0605128` 是证书密钥。\n\n3. 生成新的Token用于集群添加新Node节点\n\n操作节点[node01]\n\n```\nkubeadm join 192.168.48.200:16443 --token tn5q1b.7w1jj77ewup7k2in --discovery-token-ca-cert-hash sha256:cc5427e0e133d95250ab0aa90976fea2c383278b6345fd7e8c28702ac8dfc61f  \\\n        --cri-socket unix:///var/run/cri-dockerd.sock \n```\n\n注意：这里末尾添加了`--cri-socket unix:///var/run/cri-dockerd.sock `\n\n![image-20231110181623386](../img/OpenEuler-K8S%E9%AB%98%E5%8F%AF%E7%94%A8%E9%9B%86%E7%BE%A4%EF%BC%88%E5%86%85%E9%83%A8etcd%EF%BC%89/cf859df3d82366d7f606598d038aa610697559838.png)\n\n这时在master查看node状态（显示为notready不影响）\n\n![image-20231111145807000](../img/OpenEuler-K8S%E9%AB%98%E5%8F%AF%E7%94%A8%E9%9B%86%E7%BE%A4%EF%BC%88%E5%86%85%E9%83%A8etcd%EF%BC%89/7b38ac6fd6804d8cb1ee144e43fbad45697559838.png)\n\n### 模拟新加master节点的加入K8S集群中\n\n假设我们新加master节点的话，就拼接token，`从刚刚生成的token拼接`\n\n```\n[root@master1 ~]# kubeadm token create --print-join-command\nkubeadm join 192.168.48.200:16443 --token tn5q1b.7w1jj77ewup7k2in --discovery-token-ca-cert-hash sha256:cc5427e0e133d95250ab0aa90976fea2c383278b6345fd7e8c28702ac8dfc61f\n```\n\n这里提取信息1\n\n```\nkubeadm join 192.168.48.200:16443 --token tn5q1b.7w1jj77ewup7k2in --discovery-token-ca-cert-hash sha256:cc5427e0e133d95250ab0aa90976fea2c383278b6345fd7e8c28702ac8dfc61f\n```\n\n接着\n\n```\n[root@master1 ~]# kubeadm init phase upload-certs --upload-certs\nW1110 18:12:03.426245   10185 version.go:104] could not fetch a Kubernetes version from the internet: unable to get URL \"https://dl.k8s.io/release/stable-1.txt\": Get \"https://dl.k8s.io/release/stable-1.txt\": context deadline exceeded (Client.Timeout exceeded while awaiting headers)\nW1110 18:12:03.426320   10185 version.go:105] falling back to the local client version: v1.28.2\n[upload-certs] Storing the certificates in Secret \"kubeadm-certs\" in the \"kube-system\" Namespace\n[upload-certs] Using certificate key:\n5d3706028d5e569324a4c456c81ae0f5551ece88b3132f03917668c6b0605128\n```\n\n这里提取信息2：这里前面要加上`--control-plane --certificate-key`\n\n```\n--control-plane --certificate-key 5d3706028d5e569324a4c456c81ae0f5551ece88b3132f03917668c6b0605128\n```\n\n合成\n\n```\nkubeadm join 192.168.48.200:16443 --token tn5q1b.7w1jj77ewup7k2in \\\n        --discovery-token-ca-cert-hash sha256:cc5427e0e133d95250ab0aa90976fea2c383278b6345fd7e8c28702ac8dfc61f  \\\n        --control-plane --certificate-key 5d3706028d5e569324a4c456c81ae0f5551ece88b3132f03917668c6b0605128 \\\n        --cri-socket unix:///var/run/cri-dockerd.sock\n        \n        \nkubeadm join 192.168.48.200:16443 --token lnkno8.u4v1l8n9pahzf0kj \\\n        --discovery-token-ca-cert-hash sha256:cc5427e0e133d95250ab0aa90976fea2c383278b6345fd7e8c28702ac8dfc61f \\\n        --control-plane --certificate-key 41e441fe56cb4bdfcc2fc0291958e6b1da54d01f4649b6651471c07583f85cdf \\\n        --cri-socket unix:///var/run/cri-dockerd.sock\n\n\n```\n\n注意：这里末尾添加了`--cri-socket unix:///var/run/cri-dockerd.sock `\n\n图示\n\n![image-20231110182741430](../img/OpenEuler-K8S%E9%AB%98%E5%8F%AF%E7%94%A8%E9%9B%86%E7%BE%A4%EF%BC%88%E5%86%85%E9%83%A8etcd%EF%BC%89/9b12e9d1b72ed9ed9378712e1d5ca792697559838.png)\n\n## 安装calico网络插件\n\n操作节点[master1]\n\n添加解析记录，否则无法访问\n\n```\necho '185.199.108.133 raw.githubusercontent.com' >> /etc/hosts\n```\n\n### 应用operator资源清单文件\n\n网络组件有很多种，只需要部署其中一个即可，推荐Calico。 \nCalico是一个纯三层的数据中心网络方案，Calico支持广泛的平台，包括Kubernetes、OpenStack等。 \nCalico 在每一个计算节点利用 Linux Kernel 实现了一个高效的虚拟路由器（ vRouter） 来负责数据转发，而每个 vRouter 通过 BGP 协议负责把自己上运行的 workload 的路由信息向整个 Calico 网络内传播。 \n此外，Calico 项目还实现了 Kubernetes 网络策略，提供ACL功能。\n\n```\ncurl https://raw.githubusercontent.com/projectcalico/calico/v3.25.1/manifests/calico.yaml -O\n```\n\n```yaml\n[root@master1 ~]# vim calico.yaml\n#参考信息\n - name: WAIT_FOR_DATASTORE\n  value: \"true\"\n#添加以下两行\n- name: IP_AUTODETECTION_METHOD\n  value: interface=ens33\n\n#ens33是你的网卡\n```\n\n![image-20231110183944854](../img/OpenEuler-K8S%E9%AB%98%E5%8F%AF%E7%94%A8%E9%9B%86%E7%BE%A4%EF%BC%88%E5%86%85%E9%83%A8etcd%EF%BC%89/ce136d73e7af87b3d00f77d5eb9572cb697559838.png)\n\n```\nsed -i 's| docker.io/calico/| registry.cn-hangzhou.aliyuncs.com/qianyios/|' calico.yaml\nkubectl apply -f calico.yaml\n```\n\n![image-20231110184031455](../img/OpenEuler-K8S%E9%AB%98%E5%8F%AF%E7%94%A8%E9%9B%86%E7%BE%A4%EF%BC%88%E5%86%85%E9%83%A8etcd%EF%BC%89/ce8e8fec52aa29431e7cb6dd10bb987c697559838.png)\n\n### 监视kube-system命名空间中pod运行情况\n\n等待估计20分钟左右吧(确保全部running)\n\n```\nkubectl get pods -n kube-system\n```\n\n![image-20231110193921266](../img/OpenEuler-K8S%E9%AB%98%E5%8F%AF%E7%94%A8%E9%9B%86%E7%BE%A4%EF%BC%88%E5%86%85%E9%83%A8etcd%EF%BC%89/8f8108ea428f175038feb979c1915446697559838.png)\n\n### 拿掉master节点的污点\n\n节点 master1 和 master2 都有一个名为 `node-role.kubernetes.io/control-plane:NoSchedule` 的污点。这个污点的作用是阻止普通的 Pod 被调度到这些节点上，只允许特定的控制平面组件（如 kube-apiserver、kube-controller-manager 和 kube-scheduler）在这些节点上运行。\n\n这种设置有助于确保控制平面节点专门用于运行 Kubernetes 的核心组件，而不会被普通的工作负载占用。通过将污点添加到节点上，可以确保只有被授权的控制平面组件才能在这些节点上运行。\n\n```\nkubectl describe node master1 | grep -i taint\nkubectl describe node master2 | grep -i taint\nkubectl describe node master3 | grep -i taint\n```\n\n![image-20231111152324023](../img/OpenEuler-K8S%E9%AB%98%E5%8F%AF%E7%94%A8%E9%9B%86%E7%BE%A4%EF%BC%88%E5%86%85%E9%83%A8etcd%EF%BC%89/8b8acf56d0f0a8e48e0818575a12568b697559838.png)\n\n去除污点\n\n```\nkubectl taint node master1 node-role.kubernetes.io/control-plane:NoSchedule-\nkubectl taint node master2 node-role.kubernetes.io/control-plane:NoSchedule-\nkubectl taint node master3 node-role.kubernetes.io/control-plane:NoSchedule-\n```\n\n![image-20231111152342956](../img/OpenEuler-K8S%E9%AB%98%E5%8F%AF%E7%94%A8%E9%9B%86%E7%BE%A4%EF%BC%88%E5%86%85%E9%83%A8etcd%EF%BC%89/4505f1906390d4d0c6092eed8db765f9697559838.png)\n\n## 安装dashboard\n\n操作节点[master1]\n\n下载文件\n\nhttps://github.com/kubernetes/dashboard/releases/tag/v2.7.0\n\n目前最新版本v2.7.0 \n\n```\nwget https://raw.githubusercontent.com/kubernetes/dashboard/v2.7.0/aio/deploy/recommended.yaml\nsed -i 's/kubernetesui\\/dashboard:v2.7.0/registry.cn-hangzhou.aliyuncs.com\\/qianyios\\/dashboard:v2.7.0/g' recommended.yaml\nsed -i 's/kubernetesui\\/metrics-scraper:v1.0.8/registry.cn-hangzhou.aliyuncs.com\\/qianyios\\/metrics-scraper:v1.0.8/g' recommended.yaml\n```\n\n![image-20231014174400992](../img/OpenEuler-K8S%E9%AB%98%E5%8F%AF%E7%94%A8%E9%9B%86%E7%BE%A4%EF%BC%88%E5%86%85%E9%83%A8etcd%EF%BC%89/e5b7e6cd0c2a3d031b42e3471e220bbf697559838.png)\n\n修改配置文件\n\n```yaml\nvim recommended.yaml\n---\nkind: Service\napiVersion: v1\nmetadata:\n  labels:\n    app: kubernetes-dashboard\n  name: kubernetes-dashboard\n  namespace: kubernetes-dashboard\nspec:\n  ports:\n    - port: 443\n      targetPort: 8443\n      nodePort: 30001\n  type: NodePort\n  selector:\n    app: kubernetes-dashboard\n\n---\n```\n\n![image-20231014174511047](../img/OpenEuler-K8S%E9%AB%98%E5%8F%AF%E7%94%A8%E9%9B%86%E7%BE%A4%EF%BC%88%E5%86%85%E9%83%A8etcd%EF%BC%89/3327017a27ffdc97149d004b33a692a7697559838.png)\n\n运行dashboard\n\n```\nkubectl apply -f recommended.yaml\n```\n\n![image-20231014174622344](../img/OpenEuler-K8S%E9%AB%98%E5%8F%AF%E7%94%A8%E9%9B%86%E7%BE%A4%EF%BC%88%E5%86%85%E9%83%A8etcd%EF%BC%89/b1237cb08df67405f40a6670c3e1f80c697559838.png)\n\n检查运行状态\n\n```\nkubectl get pods -n kubernetes-dashboard\nkubectl get pod,svc -o wide -n kubernetes-dashboard\n```\n\n![image-20231111025752605](../img/OpenEuler-K8S%E9%AB%98%E5%8F%AF%E7%94%A8%E9%9B%86%E7%BE%A4%EF%BC%88%E5%86%85%E9%83%A8etcd%EF%BC%89/941f9c38bede63a9ac31ad12ebef40d5697559838.png)\n\n### 创建cluster-admin用户\n\n```\n创建service account并绑定默认cluster-admin管理员群角色\n#创建用户\nkubectl create serviceaccount dashboard-admin -n kubernetes-dashboard\n#用户授权\nkubectl create clusterrolebinding dashboard-admin --clusterrole=cluster-admin --serviceaccount=kubernetes-dashboard:dashboard-admin\n#获取用户Token\nkubectl create token dashboard-admin -n kubernetes-dashboard\n```\n\n![image-20231111025817854](../img/OpenEuler-K8S%E9%AB%98%E5%8F%AF%E7%94%A8%E9%9B%86%E7%BE%A4%EF%BC%88%E5%86%85%E9%83%A8etcd%EF%BC%89/f47b22eb887a88cef935bd76a21af939697559838.png)\n\n记录token\n\n```\neyJhbGciOiJSUzI1NiIsImtpZCI6IjJxb21sRTZSckhEZ09FMnlvWU5IY3dfTTRIWDEzRUpsQ000MThhSWxYNDgifQ.eyJhdWQiOlsiaHR0cHM6Ly9rdWJlcm5ldGVzLmRlZmF1bHQuc3ZjLmNsdXN0ZXIubG9jYWwiXSwiZXhwIjoxNjk5NjQ2Mjg3LCJpYXQiOjE2OTk2NDI2ODcsImlzcyI6Imh0dHBzOi8va3ViZXJuZXRlcy5kZWZhdWx0LnN2Yy5jbHVzdGVyLmxvY2FsIiwia3ViZXJuZXRlcy5pbyI6eyJuYW1lc3BhY2UiOiJrdWJlcm5ldGVzLWRhc2hib2FyZCIsInNlcnZpY2VhY2NvdW50Ijp7Im5hbWUiOiJkYXNoYm9hcmQtYWRtaW4iLCJ1aWQiOiIyNTBhNTQ2MS03MGJlLTRhZTItOWY2Yi1hMDQwOWE1NWJhMTMifX0sIm5iZiI6MTY5OTY0MjY4Nywic3ViIjoic3lzdGVtOnNlcnZpY2VhY2NvdW50Omt1YmVybmV0ZXMtZGFzaGJvYXJkOmRhc2hib2FyZC1hZG1pbiJ9.U-lH9_sRU4TVrpAznqS60INNSev9NxHu61igGUTzTBoaWo7WjPG7vzTnpZYhvsoglTzMEKhfranJkkkn95pe-prkvSasaAL6kXHw0jQjlSMzcYiF7DoLdkOtDJSukuALEubidf9eIwZXFZ-sezZdZHm4hnk5nWme5YtdOmYOJPh5sv1dzRvM1XuOHknJPTA1BbdZuVAtSGHSjkhwx-wl-41uuQoROW5GjJs0bz4zLBFn1w_pWaSMCn7pjGJNcbr6IuDV41km_etpwwxacWyfAcxNykzCtIiE1abJj7m-e944GvAn_eqxz3wCZD6Bgt41FWRzyMHjrppJfDjk7FaHNw\n\n```\n\n### 登录浏览器访问\n\n```\nhttps://192.168.48.200:30001\n\n输入token：\n----\neyJhbGciOiJSUzI1NiIsImtpZCI6IjJxb21sRTZSckhEZ09FMnlvWU5IY3dfTTRIWDEzRUpsQ000MThhSWxYNDgifQ.eyJhdWQiOlsiaHR0cHM6Ly9rdWJlcm5ldGVzLmRlZmF1bHQuc3ZjLmNsdXN0ZXIubG9jYWwiXSwiZXhwIjoxNjk5NjQ2Mjg3LCJpYXQiOjE2OTk2NDI2ODcsImlzcyI6Imh0dHBzOi8va3ViZXJuZXRlcy5kZWZhdWx0LnN2Yy5jbHVzdGVyLmxvY2FsIiwia3ViZXJuZXRlcy5pbyI6eyJuYW1lc3BhY2UiOiJrdWJlcm5ldGVzLWRhc2hib2FyZCIsInNlcnZpY2VhY2NvdW50Ijp7Im5hbWUiOiJkYXNoYm9hcmQtYWRtaW4iLCJ1aWQiOiIyNTBhNTQ2MS03MGJlLTRhZTItOWY2Yi1hMDQwOWE1NWJhMTMifX0sIm5iZiI6MTY5OTY0MjY4Nywic3ViIjoic3lzdGVtOnNlcnZpY2VhY2NvdW50Omt1YmVybmV0ZXMtZGFzaGJvYXJkOmRhc2hib2FyZC1hZG1pbiJ9.U-lH9_sRU4TVrpAznqS60INNSev9NxHu61igGUTzTBoaWo7WjPG7vzTnpZYhvsoglTzMEKhfranJkkkn95pe-prkvSasaAL6kXHw0jQjlSMzcYiF7DoLdkOtDJSukuALEubidf9eIwZXFZ-sezZdZHm4hnk5nWme5YtdOmYOJPh5sv1dzRvM1XuOHknJPTA1BbdZuVAtSGHSjkhwx-wl-41uuQoROW5GjJs0bz4zLBFn1w_pWaSMCn7pjGJNcbr6IuDV41km_etpwwxacWyfAcxNykzCtIiE1abJj7m-e944GvAn_eqxz3wCZD6Bgt41FWRzyMHjrppJfDjk7FaHNw\n\n----\n\n```\n\n![image-20231111025910110](../img/OpenEuler-K8S%E9%AB%98%E5%8F%AF%E7%94%A8%E9%9B%86%E7%BE%A4%EF%BC%88%E5%86%85%E9%83%A8etcd%EF%BC%89/0a7bbc42f311f76a92caaaf48e6c5328697559838.png)\n\n### 部署一个nginx测试\n\n操作节点[master1]\n\n```yaml\nvim web.yaml\n\nkind: Deployment\n#apiVersion: extensions/v1beta1\napiVersion: apps/v1\nmetadata:\n  labels:\n    app: web-deployment-label\n  name: web-deployment\n  namespace: default\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: web-selector\n  template:\n    metadata:\n      labels:\n        app: web-selector\n    spec:\n      containers:\n      - name: web-container\n        image: nginx:latest\n        imagePullPolicy: Always\n        ports:\n        - containerPort: 80\n          protocol: TCP\n          name: http\n        - containerPort: 443\n          protocol: TCP\n          name: https\n\n---\nkind: Service\napiVersion: v1\nmetadata:\n  labels:\n    app: web-service-label\n  name: web-service\n  namespace: default\nspec:\n  type: NodePort\n  ports:\n  - name: http\n    port: 80\n    protocol: TCP\n    targetPort: 80\n    nodePort: 30080\n  - name: https\n    port: 443\n    protocol: TCP\n    targetPort: 443\n    nodePort: 30443\n  selector:\n    app: web-selector\n    \nkubectl apply -f web.yaml \n```\n\n![image-20231014180923818](../img/OpenEuler-K8S%E9%AB%98%E5%8F%AF%E7%94%A8%E9%9B%86%E7%BE%A4%EF%BC%88%E5%86%85%E9%83%A8etcd%EF%BC%89/f23a00d645442660869b7e461fa8909b697559838.png)\n\n```\n### 查看nginx的pod 的详细信息\nkubectl get deploy,svc,pod -o wide\n```\n\n![image-20231016203536987](../img/OpenEuler-K8S%E9%AB%98%E5%8F%AF%E7%94%A8%E9%9B%86%E7%BE%A4%EF%BC%88%E5%86%85%E9%83%A8etcd%EF%BC%89/188449aa6759f72c7a7bdb9843828ba3697559838.png)\n\n访问nginx网站\n\n```\nhttp://192.168.48.200:30080\n```\n\n![image-20231111030413487](../img/OpenEuler-K8S%E9%AB%98%E5%8F%AF%E7%94%A8%E9%9B%86%E7%BE%A4%EF%BC%88%E5%86%85%E9%83%A8etcd%EF%BC%89/b3740a04d81e31f25f486291feea4944697559838.png)\n\n<div class=\"tbsm\" style=\"margin-top:54px;\">\n<div class=\"tbsm-top\"><span><svg t=\"1674654360507\" class=\"icon\" viewBox=\"0 0 1024 1024\" version=\"1.1\" xmlns=\"http://www.w3.org/2000/svg\" p-id=\"987\" data-spm-anchor-id=\"a313x.7781069.0.i0\" width=\"35\" height=\"35\"><path d=\"M410.49 97.74H155.08a56.74 56.74 0 0 0-56.84 56.73V410a56.84 56.84 0 0 0 56.84 56.84h255.41A56.83 56.83 0 0 0 467.32 410V154.58a56.83 56.83 0 0 0-56.83-56.84zM410.49 558.74H155.08a56.74 56.74 0 0 0-56.84 56.73V871a56.84 56.84 0 0 0 56.84 56.84h255.41A56.83 56.83 0 0 0 467.32 871V615.58a56.83 56.83 0 0 0-56.83-56.84zM871.49 558.74H616.08a56.74 56.74 0 0 0-56.84 56.73V871a56.84 56.84 0 0 0 56.84 56.84h255.41A56.83 56.83 0 0 0 928.32 871V615.58a56.83 56.83 0 0 0-56.83-56.84z\" fill=\"#66EEFF\" p-id=\"988\"></path><path d=\"M410.49 558.74h-4.14A475 475 0 0 0 299.52 859.6a481.16 481.16 0 0 0 4.84 68.22h106.13A56.83 56.83 0 0 0 467.32 871V615.58a56.83 56.83 0 0 0-56.83-56.84zM871.49 558.74H616.08a56.74 56.74 0 0 0-56.84 56.73V871a56.84 56.84 0 0 0 56.84 56.84h255.41A56.83 56.83 0 0 0 928.32 871V615.58a56.83 56.83 0 0 0-56.83-56.84z\" fill=\"#C2F8FF\" p-id=\"989\"></path></svg></span><span style=\"font-size:30px;\"> 特别声明</span></div>\n<div class=\"tbsm-wz\">千屹博客旗下的所有文章，是通过本人课堂学习和课外自学所精心整理的知识巨著<br/>难免会有出错的地方<br/>如果细心的你发现了小失误，可以在下方评论区告诉我，或者私信我！<br />非常感谢大家的热烈支持！</div>\n</div>","tags":["OpenEuler","K8s"],"categories":["云原生"]},{"title":"OpenEuler-K8S高可用集群（外部etcd）","url":"/posts/2459/","content":"\n<meta name=\"referrer\" content=\"no-referrer\"/>\n\n# OpenEuler-部署K8S高可用集群（外部etcd）\n\n## 主机拓扑\n\n| 主机名  | ip1（NAT）     | 系统                | 磁盘 | 内存 |\n| ------- | -------------- | ------------------- | ---- | ---- |\n| master1 | 192.168.48.101 | OpenEuler-22.03-LTS | 100G | 4G   |\n| master2 | 192.168.48.102 | OpenEuler-22.03-LTS | 100G | 4G   |\n| master3 | 192.168.48.103 | OpenEuler-22.03-LTS | 100G | 4G   |\n| node01  | 192.168.48.104 | OpenEuler-22.03-LTS | 100G | 8G   |\n\n镜像下载地址：[OpenEuler-22.03-LTS](https://mirrors.nju.edu.cn/openeuler/openEuler-22.03-LTS-SP4/ISO/x86_64/)\n\n下载名为openEuler-22.03-LTS-SP4-x86_64-dvd.iso\n\n## 基础配置\n\nOpeneuler通过单独安装，非克隆。安装完后进行基本环境的配置，配置一下几个方面：\n\n1. 设置主机名\n2. 关闭firewalld、dnsmasq、selinux\n3. 设置ens33\n4. 备份并新增、docker-ce源、k8s源\n5. 更新yum源软件包缓存\n6. 添加hosts解析\n7. 关闭swap分区\n8. 安装chrony服务，并同步时间\n9. 配置limits.conf\n10. 安装必备工具\n11. 升级系统并重启\n\n操作主机：[master1,master2,master3,node01]\n\n```\n#将以下脚本内容添加进去\nvi k8s_system_init.sh\n```\n\n```\n#!/bin/bash\nif [ $# -eq 2 ];then\n  echo \"设置主机名为：$1\"\n  echo \"ens33设置IP地址为：192.168.48.$2\"\nelse\n  echo  \"使用方法：sh $0 主机名 主机位\"\n  exit 2\nfi\n\necho \"--------------------------------------\"\necho \"1.正在设置主机名：$1\"\nhostnamectl set-hostname $1\n\necho \"2.正在关闭firewalld、dnsmasq、selinux\"\nsystemctl disable firewalld &> /dev/null\nsystemctl disable dnsmasq &> /dev/null\nsystemctl stop firewalld\nsystemctl stop dnsmasq\nsed -i \"s#SELINUX=enforcing#SELINUX=disabled#g\" /etc/selinux/config\nsetenforce 0\n\n\necho \"3.正在设置ens33：192.168.48.$2\"\ncat > /etc/sysconfig/network-scripts/ifcfg-ens33 <<EOF\nTYPE=Ethernet\nPROXY_METHOD=none\nBROWSER_ONLY=no\nBOOTPROTO=static\nDEFROUTE=yes\nIPV4_FAILURE_FATAL=no\nIPV6INIT=yes\nIPV6_AUTOCONF=yes\nIPV6_DEFROUTE=yes\nIPV6_FAILURE_FATAL=no\nNAME=ens33\nUUID=53b402ff-5865-47dd-a853-7afcd6521738\nDEVICE=ens33\nONBOOT=yes\nIPADDR=192.168.48.$2\nGATEWAY=192.168.48.2\nPREFIX=24\nDNS1=192.168.48.2\nDNS2=114.114.114.114\nEOF\nnmcli c reload\nnmcli c up ens33\n\n\necho \"4.新增docker-ce源、k8s源\"\nmkdir /etc/yum.repos.d/bak/\ncp /etc/yum.repos.d/* /etc/yum.repos.d/bak/\nsleep 3\ncat > /etc/yum.repos.d/kubernetes.repo <<EOF\n[kubernetes]\nname=Kubernetes\nbaseurl=https://mirrors.aliyun.com/kubernetes/yum/repos/kubernetes-el7-x86_64/\nenabled=1\ngpgcheck=0\nrepo_gpgcheck=0\ngpgkey=https://mirrors.aliyun.com/kubernetes/yum/doc/yum-key.gpg \nEOF\n#切换为华为云，下载速度更快\nsed -i 's/\\$basearch/x86_64/g' /etc/yum.repos.d/openEuler.repo\nsed -i 's/http\\:\\/\\/repo.openeuler.org/https\\:\\/\\/mirrors.huaweicloud.com\\/openeuler/g' /etc/yum.repos.d/openEuler.repo\n\ncurl -o /etc/yum.repos.d/docker-ce.repo https://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo\nsed -i 's/\\$releasever/7/g' /etc/yum.repos.d/docker-ce.repo\n\necho \"5.更新yum源软件包缓存\"\n yum clean all && yum makecache\n\necho \"6.添加hosts解析\"\ncat > /etc/hosts <<EOF\n127.0.0.1   localhost localhost.localdomain localhost4 localhost4.localdomain4\n::1         localhost localhost.localdomain localhost6 localhost6.localdomain6\n192.168.48.101 master1\n192.168.48.102 master2\n192.168.48.103 master3\n192.168.48.104 node01\n192.168.48.105 node02\nEOF\n\n\necho \"7.关闭swap分区\"\nswapoff -a && sysctl -w vm.swappiness=0 &> /dev/null\nsed -ri '/^[^#]*swap/s@^@#@' /etc/fstab\n\n\necho \"8.安装chrony服务，并同步时间\"\nyum install chrony -y\nsystemctl start chronyd\nsystemctl enable chronyd\nchronyc sources\nchronyc sources\n\necho \"9.配置limits.conf\"\nulimit -SHn 65535\ncat >> /etc/security/limits.conf <<EOF\n* soft nofile 65536\n* hard nofile 131072\n* soft nproc 65535\n* hard nproc 655350\n* soft memlock unlimited\n* hard memlock unlimited\nEOF\n\n\necho \"10.必备工具安装\"\nyum install wget psmisc vim net-tools telnet device-mapper-persistent-data lvm2 git -y\n\n\necho \"11.重启\"\nreboot\n```\n\n```\nsh k8s_system_init.sh 主机名  主机位\n[master1] sh k8s_system_init.sh master1 101\n\n[master2] sh k8s_system_init.sh master2 102\n\n[master3] sh k8s_system_init.sh master3 103\n\n[node01] sh k8s_system_init.sh node01 104\n\n```\n\n### 配置ssh免密\n\n操作节点[master1]\n\n```\nyum install -y sshpass \ncat > sshmianmi.sh << \"EOF\"\n#!/bin/bash\n# 目标主机列表\nhosts=(\"master1\" \"master2\" \"master3\" \"node01\")\n# 密码\npassword=\"Lj201840.\"\n# 生成 SSH 密钥对\nssh-keygen -t rsa -N \"\" -f ~/.ssh/id_rsa\n\n# 循环遍历目标主机\nfor host in \"${hosts[@]}\"\ndo\n    # 复制公钥到目标主机\n    sshpass -p \"$password\" ssh-copy-id -o StrictHostKeyChecking=no \"$host\"\n    \n    # 验证免密登录\n    sshpass -p \"$password\" ssh -o StrictHostKeyChecking=no \"$host\" \"echo '免密登录成功'\"\ndone\nEOF\n\nsh sshmianmi.sh\n```\n\n## 内核及ipvs模块配置\n\n此步骤是配置ipvs模块，开启一些k8s集群中必须的内核参数。配置一下几个方面：\n\n1. 更改内核启动顺序\n2. 安装ipvsadm\n3. 配置ipvs模块\n4. 开启k8s集群必须的内核参数\n5. 配置完内核，重启服务器\n\n操作主机：[master1,master2,master3,node01]\n\n```\nvi kernel_update.sh\n```\n\n```\n#!/bin/bash\n\necho \"1.更改内核启动顺序\"\ngrub2-set-default  0 && grub2-mkconfig -o /etc/grub2.cfg\ngrubby --args=\"user_namespace.enable=1\" --update-kernel=\"$(grubby --default-kernel)\"\n\necho \"2.安装ipvsadm\"\nyum install ipvsadm ipset sysstat conntrack libseccomp -y &> /dev/null\n\n\necho \"3.配置ipvs模块\"\nmodprobe -- ip_vs\nmodprobe -- ip_vs_rr\nmodprobe -- ip_vs_wrr\nmodprobe -- ip_vs_sh\nmodprobe -- nf_conntrack\n\ncat >> /etc/modules-load.d/ipvs.conf <<EOF\nip_vs\nip_vs_lc\nip_vs_wlc\nip_vs_rr\nip_vs_wrr\nip_vs_lblc\nip_vs_lblcr\nip_vs_dh\nip_vs_sh\nip_vs_fo\nip_vs_nq\nip_vs_sed\nip_vs_ftp\nip_vs_sh\nnf_conntrack\nip_tables\nip_set\nxt_set\nipt_set\nipt_rpfilter\nipt_REJECT\nipip\nEOF\nsystemctl enable --now systemd-modules-load.service &> /dev/null\n\n\necho \"4.开启k8s集群必须的内核参数\"\ncat <<EOF > /etc/sysctl.d/k8s.conf\nnet.ipv4.ip_nonlocal_bind = 1 \nnet.ipv4.ip_forward = 1\nnet.bridge.bridge-nf-call-iptables = 1\nnet.bridge.bridge-nf-call-ip6tables = 1\nfs.may_detach_mounts = 1\nnet.ipv4.conf.all.route_localnet = 1\nvm.overcommit_memory=1\nvm.panic_on_oom=0\nfs.inotify.max_user_watches=89100\nfs.file-max=52706963\nfs.nr_open=52706963\nnet.netfilter.nf_conntrack_max=2310720\nnet.ipv4.tcp_keepalive_time = 600\nnet.ipv4.tcp_keepalive_probes = 3\nnet.ipv4.tcp_keepalive_intvl =15\nnet.ipv4.tcp_max_tw_buckets = 36000\nnet.ipv4.tcp_tw_reuse = 1\nnet.ipv4.tcp_max_orphans = 327680\nnet.ipv4.tcp_orphan_retries = 3\nnet.ipv4.tcp_syncookies = 1\nnet.ipv4.tcp_max_syn_backlog = 16384\nnet.ipv4.ip_conntrack_max = 65536\nnet.ipv4.tcp_max_syn_backlog = 16384\nnet.ipv4.tcp_timestamps = 0\nnet.core.somaxconn = 16384\nEOF\nsysctl --system\n\n\necho \"5.配置完内核，重启服务器！\"\nreboot\n\n```\n\n```\nsh kernel_update.sh\n```\n\n## 检查ipvs加载、内核版本验证\n\n```\nlsmod | grep --color=auto -e ip_vs -e nf_conntrack\nuname -a\n```\n\n![image-20231201233238841](../img/OpenEuler-%E9%83%A8%E7%BD%B2K8S%E9%AB%98%E5%8F%AF%E7%94%A8%E9%9B%86%E7%BE%A4%EF%BC%88%E5%A4%96%E9%83%A8etcd%EF%BC%89/172c341f6eb660349513110db6396f8a697559838.png)\n\n## 部署ETCD集群\n\n本次在master1、master2、master3上进行etcd集群部署\n\n### 安装etcd\n\n#### 下载安装包\n\n```\nwget https://github.com/etcd-io/etcd/releases/download/v3.5.13/etcd-v3.5.13-linux-amd64.tar.gz\n```\n\n![image-20240415172117528](../img/OpenEuler-%E9%83%A8%E7%BD%B2K8S%E9%AB%98%E5%8F%AF%E7%94%A8%E9%9B%86%E7%BE%A4%EF%BC%88%E5%A4%96%E9%83%A8etcd%EF%BC%89/11286bc829bf03be81ded0fad06d517c697559838.png)\n\n#### 解压\n\n```\ntar xf etcd-v3.5.13-linux-amd64.tar.gz\nmv etcd-v3.5.13-linux-amd64 /tmp/etcd\ncp /tmp/etcd/etcd* /usr/local/bin/\n```\n\n![image-20240415172055623](../img/OpenEuler-%E9%83%A8%E7%BD%B2K8S%E9%AB%98%E5%8F%AF%E7%94%A8%E9%9B%86%E7%BE%A4%EF%BC%88%E5%A4%96%E9%83%A8etcd%EF%BC%89/2f7ad631cf19c2667d0705ebe99592d0697559838.png)\n\n#### 添加环境变量\n\n将文件夹中**etcd**和**etcdctl**两个文件添加到环境变量中\n\n```\nmkdir -p /var/lib/etcd/\nmkdir -p /etc/etcd/\nchmod 700 /var/lib/etcd\n```\n\n![image-20231015012808701](../img/OpenEuler-%E9%83%A8%E7%BD%B2K8S%E9%AB%98%E5%8F%AF%E7%94%A8%E9%9B%86%E7%BE%A4%EF%BC%88%E5%A4%96%E9%83%A8etcd%EF%BC%89/a4a8fc0d3df4db52ff269165d72b3d2a697559838.png)\n\n#### 创建默认配置文件\n\n```\ncat <<EOF | sudo tee /etc/etcd/etcd.conf\n#节点名称\nETCD_NAME=$(hostname -s)\n#数据存放位置\nETCD_DATA_DIR=/var/lib/etcd\nEOF\n```\n\n![image-20231015012819394](../img/OpenEuler-%E9%83%A8%E7%BD%B2K8S%E9%AB%98%E5%8F%AF%E7%94%A8%E9%9B%86%E7%BE%A4%EF%BC%88%E5%A4%96%E9%83%A8etcd%EF%BC%89/8f2cb9b53e68cac0cf269016f0cbee01697559838.png)\n\n#### 创建etcd服务\n\n```\ncat <<EOF | sudo tee /etc/systemd/system/etcd.service\n \n[Unit]\nDescription=Etcd Server\nDocumentation=https://github.com/coreos/etcd\nAfter=network.target\n \n[Service]\nUser=root\nType=notify\nEnvironmentFile=-/etc/etcd/etcd.conf\nExecStart=/usr/local/bin/etcd\nRestart=on-failure\nRestartSec=10s\nLimitNOFILE=40000\n \n[Install]\nWantedBy=multi-user.target\nEOF\n```\n\n![image-20231015012847141](../img/OpenEuler-%E9%83%A8%E7%BD%B2K8S%E9%AB%98%E5%8F%AF%E7%94%A8%E9%9B%86%E7%BE%A4%EF%BC%88%E5%A4%96%E9%83%A8etcd%EF%BC%89/5641c565bdf99103532207244fcf0c14697559838.png)\n\n#### 开启服务\n\n```\nsystemctl daemon-reload && systemctl enable etcd && systemctl start etcd\n```\n\n![image-20231015012901227](../img/OpenEuler-%E9%83%A8%E7%BD%B2K8S%E9%AB%98%E5%8F%AF%E7%94%A8%E9%9B%86%E7%BE%A4%EF%BC%88%E5%A4%96%E9%83%A8etcd%EF%BC%89/055cf2ac1363668a505d2a1e70d0adbb697559838.png)\n\n#### **查看版本信息**\n\n```\netcd -version\n```\n\n![image-20231201234123720](../img/OpenEuler-%E9%83%A8%E7%BD%B2K8S%E9%AB%98%E5%8F%AF%E7%94%A8%E9%9B%86%E7%BE%A4%EF%BC%88%E5%A4%96%E9%83%A8etcd%EF%BC%89/c4e6dc2a872878b201e356076ed65799697559838.png)\n\n### 在<font color='red'>master1</font>节点上生成etcd配置文件\n\n```\nvim etcd_install.sh\n```\n\n```\netcd1=192.168.48.101\netcd2=192.168.48.102\netcd3=192.168.48.103\n\nTOKEN=smartgo\nETCDHOSTS=($etcd1 $etcd2 $etcd3)\nNAMES=(\"master1\" \"master2\" \"master3\")\nfor i in \"${!ETCDHOSTS[@]}\"; do\nHOST=${ETCDHOSTS[$i]}\nNAME=${NAMES[$i]}\ncat << EOF > /tmp/$NAME.conf\n# [member]\nETCD_NAME=$NAME\nETCD_DATA_DIR=\"/var/lib/etcd/default.etcd\"\nETCD_LISTEN_PEER_URLS=\"http://$HOST:2380\"\nETCD_LISTEN_CLIENT_URLS=\"http://$HOST:2379,http://127.0.0.1:2379\"\n#[cluster]\nETCD_INITIAL_ADVERTISE_PEER_URLS=\"http://$HOST:2380\"\nETCD_INITIAL_CLUSTER=\"${NAMES[0]}=http://${ETCDHOSTS[0]}:2380,${NAMES[1]}=http://${ETCDHOSTS[1]}:2380,${NAMES[2]}=http://${ETCDHOSTS[2]}:2380\"\nETCD_INITIAL_CLUSTER_STATE=\"new\"\nETCD_INITIAL_CLUSTER_TOKEN=\"$TOKEN\"\nETCD_ADVERTISE_CLIENT_URLS=\"http://$HOST:2379\"\nEOF\ndone\nls /tmp/master*\nscp /tmp/master2.conf $etcd2:/etc/etcd/etcd.conf\nscp /tmp/master3.conf $etcd3:/etc/etcd/etcd.conf\ncp /tmp/master1.conf /etc/etcd/etcd.conf\nrm -f /tmp/master*.conf\n```\n\n![image-20231014195615912](../img/OpenEuler-%E9%83%A8%E7%BD%B2K8S%E9%AB%98%E5%8F%AF%E7%94%A8%E9%9B%86%E7%BE%A4%EF%BC%88%E5%A4%96%E9%83%A8etcd%EF%BC%89/7897e265466dc29664ceeca604116fc2697559838.png)\n\n```\nsh etcd_install.sh\n```\n\n![image-20231014195602840](../img/OpenEuler-%E9%83%A8%E7%BD%B2K8S%E9%AB%98%E5%8F%AF%E7%94%A8%E9%9B%86%E7%BE%A4%EF%BC%88%E5%A4%96%E9%83%A8etcd%EF%BC%89/0cae78bd52f7275854186f864d3f7387697559838.png)\n\n### 在k8s集群master节点上启动etcd\n\n```\nsystemctl restart etcd\nsystemctl enable --now etcd\n```\n\n![image-20231014195712942](../img/OpenEuler-%E9%83%A8%E7%BD%B2K8S%E9%AB%98%E5%8F%AF%E7%94%A8%E9%9B%86%E7%BE%A4%EF%BC%88%E5%A4%96%E9%83%A8etcd%EF%BC%89/9ef822be06209ae69f5e0c898e2a321c697559838.png)\n\n### 检查etcd集群是否正常\n\n```\netcdctl member list\netcdctl endpoint health\n```\n\n![image-20231015013040955](../img/OpenEuler-%E9%83%A8%E7%BD%B2K8S%E9%AB%98%E5%8F%AF%E7%94%A8%E9%9B%86%E7%BE%A4%EF%BC%88%E5%A4%96%E9%83%A8etcd%EF%BC%89/165629df49d6688aaa227ead76653327697559838.png)\n\n![image-20231015013053386](../img/OpenEuler-%E9%83%A8%E7%BD%B2K8S%E9%AB%98%E5%8F%AF%E7%94%A8%E9%9B%86%E7%BE%A4%EF%BC%88%E5%A4%96%E9%83%A8etcd%EF%BC%89/7f3a5409aa09bd3ece2b527e05c623ba697559838.png)\n\n![image-20231015013100578](../img/OpenEuler-%E9%83%A8%E7%BD%B2K8S%E9%AB%98%E5%8F%AF%E7%94%A8%E9%9B%86%E7%BE%A4%EF%BC%88%E5%A4%96%E9%83%A8etcd%EF%BC%89/4aaef3d61e5580590a0e0d148136a2ec697559838.png)\n\n##  高可用组件安装\n\n### haproxy配置\n\n操作节点：[master1，master2,master3]\n\n```\nyum install keepalived haproxy -y\n```\n\n所有Master节点配置HAProxy，所有Master节点的HAProxy配置相同。\n\n```yaml\n操作节点：[master1，master2, master3]\ncat > /etc/haproxy/haproxy.cfg <<\"EOF\"\n\nglobal\n  maxconn  2000\n  ulimit-n  16384\n  log  127.0.0.1 local0 err\n  stats timeout 30s\n\ndefaults\n  log global\n  mode  http\n  option  httplog\n  timeout connect 5000\n  timeout client  50000\n  timeout server  50000\n  timeout http-request 15s\n  timeout http-keep-alive 15s\n\nfrontend monitor-in\n  bind *:33305\n  mode http\n  option httplog\n  monitor-uri /monitor\n\nfrontend k8s-master\n  bind 0.0.0.0:16443\n  bind 127.0.0.1:16443\n  mode tcp\n  option tcplog\n  tcp-request inspect-delay 5s\n  default_backend k8s-master\n\nbackend k8s-master\n  mode tcp\n  option tcplog\n  option tcp-check\n  balance roundrobin\n  default-server inter 10s downinter 5s rise 2 fall 2 slowstart 60s maxconn 250 maxqueue 256 weight 100\n  server master1   192.168.48.101:6443  check\n  server master2   192.168.48.102:6443  check\n  server master3   192.168.48.103:6443  check\nEOF\n```\n\n### Keepalived配置\n\n操作节点：[master1，master2,master3]\n\n所有Master节点配置Keepalived，以下三个Master节点配置注意ip和网卡。\n\n```\n操作节点：[master1]\n\ncat >/etc/keepalived/keepalived.conf  <<\"EOF\"\n\n! Configuration File for keepalived\nglobal_defs {\n    router_id LVS_DEVEL\nscript_user root\n    enable_script_security\n}\nvrrp_script chk_apiserver {\n    script \"/etc/keepalived/check_apiserver.sh\"\n    interval 5\n    weight -5\n    fall 2  \nrise 1\n}\nvrrp_instance VI_1 {\n    state MASTER\n    interface ens33\n    mcast_src_ip 192.168.48.101\n    virtual_router_id 51\n    priority 101\n    advert_int 2\n    authentication {\n        auth_type PASS\n        auth_pass K8SHA_KA_AUTH\n    }\n    virtual_ipaddress {\n        192.168.48.200\n    }\n    track_script {\n       chk_apiserver\n    }\n}\nEOF\n```\n\n```\n操作节点：[master2]\ncat >/etc/keepalived/keepalived.conf  <<\"EOF\"\n\n! Configuration File for keepalived\nglobal_defs {\n    router_id LVS_DEVEL\nscript_user root\n    enable_script_security\n}\nvrrp_script chk_apiserver {\n    script \"/etc/keepalived/check_apiserver.sh\"\n    interval 5\n    weight -5\n    fall 2  \nrise 1\n}\nvrrp_instance VI_1 {\n    state BACKUP\n    interface ens33\n    mcast_src_ip 192.168.48.102\n    virtual_router_id 51\n    priority 100\n    advert_int 2\n    authentication {\n        auth_type PASS\n        auth_pass K8SHA_KA_AUTH\n    }\n    virtual_ipaddress {\n        192.168.48.200\n    }\n    track_script {\n       chk_apiserver\n    }\n}\nEOF\n```\n\n```\n操作节点：[master3]\ncat >/etc/keepalived/keepalived.conf  <<\"EOF\"\n\n! Configuration File for keepalived\nglobal_defs {\n    router_id LVS_DEVEL\nscript_user root\n    enable_script_security\n}\nvrrp_script chk_apiserver {\n    script \"/etc/keepalived/check_apiserver.sh\"\n    interval 5\n    weight -5\n    fall 2  \nrise 1\n}\nvrrp_instance VI_1 {\n    state BACKUP\n    interface ens33\n    mcast_src_ip 192.168.48.103\n    virtual_router_id 51\n    priority 99\n    advert_int 2\n    authentication {\n        auth_type PASS\n        auth_pass K8SHA_KA_AUTH\n    }\n    virtual_ipaddress {\n        192.168.48.200\n    }\n    track_script {\n       chk_apiserver\n    }\n}\nEOF\n```\n\n### 配置Keepalived健康检查文件\n\n操作节点：[master1，master2,master3]\n\n```\ncat > /etc/keepalived/check_apiserver.sh <<\"EOF\"\n #!/bin/bash\n err=0\n for k in $(seq 1 3)\n do\n    check_code=$(pgrep haproxy)\n    if [[ $check_code == \"\" ]]; then\n        err=$(expr $err + 1)\n        sleep 1\n        continue\n    else\n        err=0\n        break\n    fi\n done\n \n if [[ $err != \"0\" ]]; then\n    echo \"systemctl stop keepalived\"\n    /usr/bin/systemctl stop keepalived\n    exit 1\n else\n    exit 0\n fi\nEOF\n\nchmod +x /etc/keepalived/check_apiserver.sh\n```\n\n### 启动haproxy和keepalived\n\n```\n操作节点：[master，master2,master3]\nsystemctl daemon-reload\nsystemctl enable --now haproxy\nsystemctl enable --now keepalived\n```\n\n### 测试集群负载均衡高可用\n\n查看master1的vip\n\n```\nip a\n```\n\n![image-20231109232708584](../img/OpenEuler-%E9%83%A8%E7%BD%B2K8S%E9%AB%98%E5%8F%AF%E7%94%A8%E9%9B%86%E7%BE%A4%EF%BC%88%E5%A4%96%E9%83%A8etcd%EF%BC%89/c056fd53ea94319afdcbfd30f2bd32bf697559838.png)\n\n模拟master1的宕机测试，看看vip会不会漂移到master2去\n\n```\n[master1] poweroff\n```\n\n![image-20231109232803276](../img/OpenEuler-%E9%83%A8%E7%BD%B2K8S%E9%AB%98%E5%8F%AF%E7%94%A8%E9%9B%86%E7%BE%A4%EF%BC%88%E5%A4%96%E9%83%A8etcd%EF%BC%89/e38cdfec8d2832c3b0cc5fda8a1dfa47697559838.png)\n\n这时候查看master2的ip列表\n\n```\n[master2] ip a\n```\n\n![image-20231109232825999](../img/OpenEuler-%E9%83%A8%E7%BD%B2K8S%E9%AB%98%E5%8F%AF%E7%94%A8%E9%9B%86%E7%BE%A4%EF%BC%88%E5%A4%96%E9%83%A8etcd%EF%BC%89/cfbcf94ba4e1a5ee2b56eedfd315202d697559838.png)\n\n结论：这时可以知道，负载均衡集群成功，当master1出现宕机情况，vip会从master1漂移到master2\n\n## docker安装\n\n### 安装docker\n\n操作节点[master1，master2，master3,node01]\n\n```\nwget https://download.docker.com/linux/static/stable/x86_64/docker-24.0.7.tgz\ntar xf docker-*.tgz\ncp -rf docker/* /usr/bin/\n#创建containerd的service文件,并且启动\ncat >/etc/systemd/system/containerd.service <<EOF\n[Unit]\nDescription=containerd container runtime\nDocumentation=https://containerd.io\nAfter=network.target local-fs.target\n[Service]\nExecStartPre=-/sbin/modprobe overlay\nExecStart=/usr/bin/containerd\nType=notify\nDelegate=yes\nKillMode=process\nRestart=always\nRestartSec=5\nLimitNPROC=infinity\nLimitCORE=infinity\nLimitNOFILE=1048576\nTasksMax=infinity\nOOMScoreAdjust=-999\n[Install]\nWantedBy=multi-user.target\nEOF\nsystemctl enable --now containerd.service\n\n#准备docker的service文件\n\ncat > /etc/systemd/system/docker.service <<EOF\n[Unit]\nDescription=Docker Application Container Engine\nDocumentation=https://docs.docker.com\nAfter=network-online.target firewalld.service containerd.service\nWants=network-online.target\nRequires=docker.socket containerd.service\n[Service]\nType=notify\nExecStart=/usr/bin/dockerd --config-file=/etc/docker/daemon.json -H fd://\ncontainerd=/run/containerd/containerd.sock\nExecReload=/bin/kill -s HUP $MAINPID\nTimeoutSec=0\nRestartSec=2\nRestart=always\nStartLimitBurst=3\nStartLimitInterval=60s\nLimitNOFILE=infinity\nLimitNPROC=infinity\nLimitCORE=infinity\nTasksMax=infinity\nDelegate=yes\nKillMode=process\nOOMScoreAdjust=-500\n[Install]\nWantedBy=multi-user.target\nEOF\n\n\n#准备docker的socket文件\n\ncat > /etc/systemd/system/docker.socket <<EOF\n[Unit]\nDescription=Docker Socket for the API\n[Socket]\nListenStream=/var/run/docker.sock\nSocketMode=0660\nSocketUser=root\nSocketGroup=docker\n[Install]\nWantedBy=sockets.target\nEOF\ngroupadd docker\n\nsystemctl enable --now docker.socket  && systemctl enable --now docker.service\n\n\n#验证\nmkdir /etc/docker\nsudo tee /etc/docker/daemon.json > /dev/null <<'EOF'\n{\n  \"registry-mirrors\": [\n    \"https://docker.xuanyuan.me\",\n    \"https://docker.m.daocloud.io\",\n    \"https://docker.1ms.run\",\n    \"https://docker.1panel.live\",\n    \"https://registry.cn-hangzhou.aliyuncs.com\",\n\t\t\"https://docker.qianyios.top\"\n  ],\n  \"max-concurrent-downloads\": 10,\n  \"log-driver\": \"json-file\",\n  \"log-level\": \"warn\",\n  \"log-opts\": {\n    \"max-size\": \"10m\",\n    \"max-file\": \"3\"\n  },\n  \"data-root\": \"/var/lib/docker\"\n}\nEOF\nsystemctl daemon-reload\nsystemctl restart docker\n```\n\n### 安装cri-docker\n\n操作节点[master1，master2，master3,node01]\n\n```\nwget https://github.com/Mirantis/cri-dockerd/releases/download/v0.3.12/cri-dockerd-0.3.12.amd64.tgz\n\ntar -zxvf cri-dockerd-0.3.12.amd64.tgz\ncp cri-dockerd/cri-dockerd  /usr/bin/\nchmod +x /usr/bin/cri-dockerd\n\n\n#写入启动配置文件\ncat >  /usr/lib/systemd/system/cri-docker.service <<EOF\n[Unit]\nDescription=CRI Interface for Docker Application Container Engine\nDocumentation=https://docs.mirantis.com\nAfter=network-online.target firewalld.service docker.service\nWants=network-online.target\nRequires=cri-docker.socket\n \n[Service]\nType=notify\nExecStart=/usr/bin/cri-dockerd --network-plugin=cni --pod-infra-container-image=registry.aliyuncs.com/google_containers/pause:3.9\nExecReload=/bin/kill -s HUP $MAINPID\nTimeoutSec=0\nRestartSec=2\nRestart=always\n \nStartLimitBurst=3\n \nStartLimitInterval=60s\n \nLimitNOFILE=infinity\nLimitNPROC=infinity\nLimitCORE=infinity\n \nTasksMax=infinity\nDelegate=yes\nKillMode=process\n \n[Install]\nWantedBy=multi-user.target\nEOF\n\n\n#写入socket配置文件\ncat > /usr/lib/systemd/system/cri-docker.socket <<EOF\n[Unit]\nDescription=CRI Docker Socket for the API\nPartOf=cri-docker.service\n \n[Socket]\nListenStream=%t/cri-dockerd.sock\nSocketMode=0660\nSocketUser=root\nSocketGroup=docker\n \n[Install]\nWantedBy=sockets.target\nEOF\n\nsystemctl daemon-reload && systemctl enable cri-docker --now\n```\n\n## K8S集群安装\n\n### 安装k8s所需的工具\n\n```\n操作节点[master1，master2，master3,node01]\n\nyum -y install  kubeadm kubelet kubectl\n\n#为了实现docker使用的cgroupdriver与kubelet使用的cgroup的一致性，配置如下：\nsed -i 's/^KUBELET_EXTRA_ARGS=/KUBELET_EXTRA_ARGS=\"--cgroup-driver=systemd\"/g' /etc/sysconfig/kubelet\n\n#设置kubelet为开机自启动即可，由于没有生成配置文件，集群初始化后自动启动\nsystemctl enable kubelet\nsystemctl enable kubelet.service\n```\n\n### 初始化集群\n\n```\ncat > kubeadm-config.yaml << EOF\n---\napiVersion: kubeadm.k8s.io/v1beta3\nbootstrapTokens:\n- groups:\n  - system:bootstrappers:kubeadm:default-node-token\n  token: abcdef.0123456789abcdef\n  ttl: 24h0m0s\n  usages:\n  - signing\n  - authentication\nkind: InitConfiguration\nlocalAPIEndpoint:\n  advertiseAddress: 192.168.48.101\n  bindPort: 6443\nnodeRegistration:\n  criSocket: unix:///var/run/cri-dockerd.sock\n---\napiVersion: kubeadm.k8s.io/v1beta3\nkind: ClusterConfiguration\nkubernetesVersion: 1.28.2\nimageRepository: registry.aliyuncs.com/google_containers\nnetworking:\n  dnsDomain: cluster.local\n  podSubnet: 10.244.0.0/16\n  serviceSubnet: 10.96.0.0/12\nscheduler: {}\napiServerCertSANs:\n- 192.168.48.200\ncontrolPlaneEndpoint: \"192.168.48.200:16443\"\netcd:\n  external:\n    endpoints:\n      - http://192.168.48.101:2379\n      - http://192.168.48.102:2379\n      - http://192.168.48.103:2379\n---\napiVersion: kubeproxy.config.k8s.io/v1alpha1\nkind: KubeProxyConfiguration\nfeatureGates:\n  # SupportIPVSProxyMode: false\nmode: ipvs\n---\napiVersion: kubelet.config.k8s.io/v1beta1\nauthentication:\n  anonymous:\n    enabled: false\n  webhook:\n    cacheTTL: 0s\n    enabled: true\n  x509:\n    clientCAFile: /etc/kubernetes/pki/ca.crt\nauthorization:\n  mode: Webhook\n  webhook:\n    cacheAuthorizedTTL: 0s\n    cacheUnauthorizedTTL: 0s\ncgroupDriver: systemd\nclusterDNS:\n- 10.96.0.10\nclusterDomain: cluster.local\ncpuManagerReconcilePeriod: 0s\nevictionPressureTransitionPeriod: 0s\nfileCheckFrequency: 0s\nhealthzBindAddress: 127.0.0.1\nhealthzPort: 10248\nhttpCheckFrequency: 0s\nimageMinimumGCAge: 0s\nkind: KubeletConfiguration\nlogging:\n  flushFrequency: 0\n  options:\n    json:\n      infoBufferSize: \"0\"\n  verbosity: 0\nmemorySwap: {}\nnodeStatusReportFrequency: 0s\nnodeStatusUpdateFrequency: 0s\nrotateCertificates: true\nruntimeRequestTimeout: 0s\nshutdownGracePeriod: 0s\nshutdownGracePeriodCriticalPods: 0s\nstaticPodPath: /etc/kubernetes/manifests\nstreamingConnectionIdleTimeout: 0s\nsyncFrequency: 0s\nvolumeStatsAggPeriod: 0s\nEOF\n\n```\n\n### 准备k8s所需的镜像\n\n```\n操作节点[master1]\n\nkubeadm config images pull --config kubeadm-config.yaml\n```\n\n![image-20231202000515399](../img/OpenEuler-%E9%83%A8%E7%BD%B2K8S%E9%AB%98%E5%8F%AF%E7%94%A8%E9%9B%86%E7%BE%A4%EF%BC%88%E5%A4%96%E9%83%A8etcd%EF%BC%89/9fedff61048258078e518d11118b9251697559838.png)\n\n### master1节点初始化\n\n操作节点[master1]\n\n```\nkubeadm init --config kubeadm-config.yaml --upload-certs --v=9\n```\n\n会生成信息\n\n![image-20231202000611013](../img/OpenEuler-%E9%83%A8%E7%BD%B2K8S%E9%AB%98%E5%8F%AF%E7%94%A8%E9%9B%86%E7%BE%A4%EF%BC%88%E5%A4%96%E9%83%A8etcd%EF%BC%89/5829c27c107b54a0d91955190139d113697559838.png)\n\n记录信息后面会用到\n\n初始化成功以后，会产生Token值，用于其他节点加入时使用，因此要记录下初始化成功生成的token值（令牌值），**有效期24小时，后续需要操作可以重新生成Token**\n\n操作节点[master1]\n\n```\nkubeadm join 192.168.48.200:16443 --token abcdef.0123456789abcdef \\\n        --discovery-token-ca-cert-hash sha256:bc27d821932d27bb4b49c187ddd412569ead01b14009e03b6d03aa3ea54e4612 \\\n        --control-plane --certificate-key 37b1370abd3584c354517603bf97e10c795e3367e05e5ff3f2f6ca14288d8054\n\n\nkubeadm join 192.168.48.200:16443 --token abcdef.0123456789abcdef \\\n        --discovery-token-ca-cert-hash sha256:bc27d821932d27bb4b49c187ddd412569ead01b14009e03b6d03aa3ea54e4612\n```\n\n`操作kubect报错：`\n\n![image-20231110180035297](../img/OpenEuler-%E9%83%A8%E7%BD%B2K8S%E9%AB%98%E5%8F%AF%E7%94%A8%E9%9B%86%E7%BE%A4%EF%BC%88%E5%A4%96%E9%83%A8etcd%EF%BC%89/fefa374e5d13878092f01fb03ed253a6697559838.png)\n\n此时通过kubectl操作，会出现失败，因为还没有将集群的\"钥匙\"交给root用户。`/etc/kubernetes/admin.conf` 文件是 Kubernetes（K8s）集群中的管理员配置文件，它包含了用于管理集群的身份验证和访问信息。所以下面进行配置环境变量，用于访问Kubernetes集群：\n\n`添加环境变量`\n\n操作节点[master1]\n\n```\nmkdir -p $HOME/.kube\nsudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config\nsudo chown $(id -u):$(id -g) $HOME/.kube/config\n```\n\n### 添加其他master节点至集群中\n\n操作节点[master2,master3]\n\n```\n操作节点[master2,master3]\nkubeadm join 192.168.48.200:16443 --token abcdef.0123456789abcdef \\\n        --discovery-token-ca-cert-hash sha256:bc27d821932d27bb4b49c187ddd412569ead01b14009e03b6d03aa3ea54e4612 \\\n        --control-plane --certificate-key 37b1370abd3584c354517603bf97e10c795e3367e05e5ff3f2f6ca14288d8054 \\\n        --cri-socket unix:///var/run/cri-dockerd.sock \n```\n\n注意：这里末尾添加了`--cri-socket unix:///var/run/cri-dockerd.sock `\n\n接着给`master2`添加环境变量\n\n```\n操作节点[master2,master3]\nmkdir -p $HOME/.kube\nsudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config\nsudo chown $(id -u):$(id -g) $HOME/.kube/config\n```\n\n![image-20231110180919008](../img/OpenEuler-%E9%83%A8%E7%BD%B2K8S%E9%AB%98%E5%8F%AF%E7%94%A8%E9%9B%86%E7%BE%A4%EF%BC%88%E5%A4%96%E9%83%A8etcd%EF%BC%89/f28981c217fe0f91573bcac90ed8e152697559838.png)\n\n这里没有展示master3的图片，但是步骤一样的\n\n### 模拟Token过期重新生成并加入Node节点\n\n假设加入集群的token过期了。node01无法加入了，这里就模拟一下这种情况\n\n1. Token过期后生成新的token：\n\n```bash\nkubeadm token create --print-join-command\n```\n\n```\n[root@master1 ~]# kubeadm token create --print-join-command\nkubeadm join 192.168.48.200:16443 --token ke773y.6hv9utk33to4vwfy --discovery-token-ca-cert-hash sha256:bc27d821932d27bb4b49c187ddd412569ead01b14009e03b6d03aa3ea54e4612\n[root@master1 ~]#\n\n```\n\n其中，`192.168.48.200:16443` 是你的 Kubernetes API 服务器的地址和端口，`ke773y.6hv9utk33to4vwfy` 是新的令牌，`sha256:bc27d821932d27bb4b49c187ddd412569ead01b14009e03b6d03aa3ea54e4612` 是令牌的 CA 证书哈希值。\n\n2. Master需要生成--certificate-key：\n\n```bash\nkubeadm init phase upload-certs --upload-certs\n```\n\n```\n[root@master1 ~]# kubeadm init phase upload-certs --upload-certs\nW1110 18:12:03.426245   10185 version.go:104] could not fetch a Kubernetes version from the internet: unable to get URL \"https://dl.k8s.io/release/stable-1.txt\": Get \"https://dl.k8s.io/release/stable-1.txt\": context deadline exceeded (Client.Timeout exceeded while awaiting headers)\nW1110 18:12:03.426320   10185 version.go:105] falling back to the local client version: v1.28.2\n[upload-certs] Storing the certificates in Secret \"kubeadm-certs\" in the \"kube-system\" Namespace\n[upload-certs] Using certificate key:\n5d3706028d5e569324a4c456c81ae0f5551ece88b3132f03917668c6b0605128\n```\n\n其中，`5d3706028d5e569324a4c456c81ae0f5551ece88b3132f03917668c6b0605128` 是证书密钥。\n\n3. 生成新的Token用于集群添加新Node节点\n\n操作节点[node01]\n\n```\nkubeadm join 192.168.48.200:16443 \\\n        --token ke773y.6hv9utk33to4vwfy \\\n        --discovery-token-ca-cert-hash sha256:bc27d821932d27bb4b49c187ddd412569ead01b14009e03b6d03aa3ea54e4612  \\\n        --cri-socket unix:///var/run/cri-dockerd.sock \n```\n\n注意：这里末尾添加了`--cri-socket unix:///var/run/cri-dockerd.sock `\n\n![image-20231110181623386](../img/OpenEuler-%E9%83%A8%E7%BD%B2K8S%E9%AB%98%E5%8F%AF%E7%94%A8%E9%9B%86%E7%BE%A4%EF%BC%88%E5%A4%96%E9%83%A8etcd%EF%BC%89/0a11667e5c9aa7d99b42b680cf28ef43697559838.png)\n\n这时在master查看node状态（显示为notready不影响）\n\n![image-20231111145807000](../img/OpenEuler-%E9%83%A8%E7%BD%B2K8S%E9%AB%98%E5%8F%AF%E7%94%A8%E9%9B%86%E7%BE%A4%EF%BC%88%E5%A4%96%E9%83%A8etcd%EF%BC%89/fd5c8370fdba5ace21ff70b1bd7a623d697559838.png)\n\n### 模拟新加master节点的加入K8S集群中\n\n假设我们新加master节点的话，就拼接token，`从刚刚生成的token拼接`\n\n```\n[root@master1 ~]# kubeadm token create --print-join-command\nkubeadm join 192.168.48.200:16443 --token tn5q1b.7w1jj77ewup7k2in --discovery-token-ca-cert-hash sha256:cc5427e0e133d95250ab0aa90976fea2c383278b6345fd7e8c28702ac8dfc61f\n```\n\n这里提取信息1\n\n```\nkubeadm join 192.168.48.200:16443 --token tn5q1b.7w1jj77ewup7k2in --discovery-token-ca-cert-hash sha256:cc5427e0e133d95250ab0aa90976fea2c383278b6345fd7e8c28702ac8dfc61f\n```\n\n接着\n\n```\n[root@master1 ~]# kubeadm init phase upload-certs --upload-certs\nW1110 18:12:03.426245   10185 version.go:104] could not fetch a Kubernetes version from the internet: unable to get URL \"https://dl.k8s.io/release/stable-1.txt\": Get \"https://dl.k8s.io/release/stable-1.txt\": context deadline exceeded (Client.Timeout exceeded while awaiting headers)\nW1110 18:12:03.426320   10185 version.go:105] falling back to the local client version: v1.28.2\n[upload-certs] Storing the certificates in Secret \"kubeadm-certs\" in the \"kube-system\" Namespace\n[upload-certs] Using certificate key:\n5d3706028d5e569324a4c456c81ae0f5551ece88b3132f03917668c6b0605128\n```\n\n这里提取信息2：这里前面要加上`--control-plane --certificate-key`\n\n```\n--control-plane --certificate-key 5d3706028d5e569324a4c456c81ae0f5551ece88b3132f03917668c6b0605128\n```\n\n合成\n\n```\nkubeadm join 192.168.48.200:16443 --token tn5q1b.7w1jj77ewup7k2in \\\n        --discovery-token-ca-cert-hash sha256:cc5427e0e133d95250ab0aa90976fea2c383278b6345fd7e8c28702ac8dfc61f  \\\n        --control-plane --certificate-key 5d3706028d5e569324a4c456c81ae0f5551ece88b3132f03917668c6b0605128 \\\n        --cri-socket unix:///var/run/cri-dockerd.sock\n        \n        \nkubeadm join 192.168.48.200:16443 --token lnkno8.u4v1l8n9pahzf0kj \\\n        --discovery-token-ca-cert-hash sha256:cc5427e0e133d95250ab0aa90976fea2c383278b6345fd7e8c28702ac8dfc61f \\\n        --control-plane --certificate-key 41e441fe56cb4bdfcc2fc0291958e6b1da54d01f4649b6651471c07583f85cdf \\\n        --cri-socket unix:///var/run/cri-dockerd.sock\n\n\n```\n\n注意：这里末尾添加了`--cri-socket unix:///var/run/cri-dockerd.sock `\n\n图示\n\n![image-20231110182741430](../img/OpenEuler-%E9%83%A8%E7%BD%B2K8S%E9%AB%98%E5%8F%AF%E7%94%A8%E9%9B%86%E7%BE%A4%EF%BC%88%E5%A4%96%E9%83%A8etcd%EF%BC%89/4a97b357d8fcf1ab20396d46fa4207e7697559838.png)\n\n## 安装calico网络插件\n\n操作节点[master1]\n\n添加解析记录，否则无法访问\n\n```\necho '185.199.108.133 raw.githubusercontent.com' >> /etc/hosts\n```\n\n### 应用operator资源清单文件\n\n网络组件有很多种，只需要部署其中一个即可，推荐Calico。 \nCalico是一个纯三层的数据中心网络方案，Calico支持广泛的平台，包括Kubernetes、OpenStack等。 \nCalico 在每一个计算节点利用 Linux Kernel 实现了一个高效的虚拟路由器（ vRouter） 来负责数据转发，而每个 vRouter 通过 BGP 协议负责把自己上运行的 workload 的路由信息向整个 Calico 网络内传播。 \n此外，Calico 项目还实现了 Kubernetes 网络策略，提供ACL功能。\n\n```\ncurl https://raw.githubusercontent.com/projectcalico/calico/v3.25.1/manifests/calico.yaml -O\n```\n\n```yaml\n[root@master1 ~]# vim calico.yaml\n。。。。。\n- name: WAIT_FOR_DATASTORE\n  value: \"true\"\n  #添加以下两行\n- name: IP_AUTODETECTION_METHOD\n  value: interface=ens33\n#ens33是你的网卡\n```\n\n![image-20231110183944854](../img/OpenEuler-%E9%83%A8%E7%BD%B2K8S%E9%AB%98%E5%8F%AF%E7%94%A8%E9%9B%86%E7%BE%A4%EF%BC%88%E5%A4%96%E9%83%A8etcd%EF%BC%89/7d33aa399268a12dfbb757f1436c6a8a697559838.png)\n\n```\nsed -i 's| docker.io/calico/| registry.cn-hangzhou.aliyuncs.com/qianyios/|' calico.yaml\nkubectl apply -f calico.yaml\n```\n\n![image-20231110184031455](../img/OpenEuler-%E9%83%A8%E7%BD%B2K8S%E9%AB%98%E5%8F%AF%E7%94%A8%E9%9B%86%E7%BE%A4%EF%BC%88%E5%A4%96%E9%83%A8etcd%EF%BC%89/5deef971f2349641bcbd972ecb01be1a697559838.png)\n\n### 监视kube-system命名空间中pod运行情况\n\n等待估计20分钟左右吧(确保全部running)\n\n```\nkubectl get pods -n kube-system\n```\n\n![image-20231110193921266](../img/OpenEuler-%E9%83%A8%E7%BD%B2K8S%E9%AB%98%E5%8F%AF%E7%94%A8%E9%9B%86%E7%BE%A4%EF%BC%88%E5%A4%96%E9%83%A8etcd%EF%BC%89/3a877ccea193177ddf12995dd591ac1a697559838.png)\n\n### 拿掉master节点的污点\n\n节点 master1 和 master2 都有一个名为 `node-role.kubernetes.io/control-plane:NoSchedule` 的污点。这个污点的作用是阻止普通的 Pod 被调度到这些节点上，只允许特定的控制平面组件（如 kube-apiserver、kube-controller-manager 和 kube-scheduler）在这些节点上运行。\n\n这种设置有助于确保控制平面节点专门用于运行 Kubernetes 的核心组件，而不会被普通的工作负载占用。通过将污点添加到节点上，可以确保只有被授权的控制平面组件才能在这些节点上运行。\n\n```\nkubectl describe node master1 | grep -i taint\nkubectl describe node master2 | grep -i taint\nkubectl describe node master3 | grep -i taint\n```\n\n![image-20231111152324023](../img/OpenEuler-%E9%83%A8%E7%BD%B2K8S%E9%AB%98%E5%8F%AF%E7%94%A8%E9%9B%86%E7%BE%A4%EF%BC%88%E5%A4%96%E9%83%A8etcd%EF%BC%89/df8eab00f259e7857b7376580c10e265697559838.png)\n\n去除污点\n\n```\nkubectl taint node master1 node-role.kubernetes.io/control-plane:NoSchedule-\nkubectl taint node master2 node-role.kubernetes.io/control-plane:NoSchedule-\nkubectl taint node master3 node-role.kubernetes.io/control-plane:NoSchedule-\n```\n\n![image-20231111152342956](../img/OpenEuler-%E9%83%A8%E7%BD%B2K8S%E9%AB%98%E5%8F%AF%E7%94%A8%E9%9B%86%E7%BE%A4%EF%BC%88%E5%A4%96%E9%83%A8etcd%EF%BC%89/440c55180b12cc13c70889f569e6df2a697559838.png)\n\n## 安装dashboard\n\n操作节点[master1]\n\n下载文件\n\nhttps://github.com/kubernetes/dashboard/releases/tag/v2.7.0\n\n目前最新版本v2.7.0 \n\n```\nwget https://raw.githubusercontent.com/kubernetes/dashboard/v2.7.0/aio/deploy/recommended.yaml\nsed -i 's/kubernetesui\\/dashboard:v2.7.0/registry.cn-hangzhou.aliyuncs.com\\/qianyios\\/dashboard:v2.7.0/g' recommended.yaml\nsed -i 's/kubernetesui\\/metrics-scraper:v1.0.8/registry.cn-hangzhou.aliyuncs.com\\/qianyios\\/metrics-scraper:v1.0.8/g' recommended.yaml\n```\n\n![image-20231014174400992](../img/OpenEuler-%E9%83%A8%E7%BD%B2K8S%E9%AB%98%E5%8F%AF%E7%94%A8%E9%9B%86%E7%BE%A4%EF%BC%88%E5%A4%96%E9%83%A8etcd%EF%BC%89/dc94aa0b268990ba35b69f63ee1e4425697559838.png)\n\n修改配置文件\n\n```yaml\nvim recommended.yaml\n---\nkind: Service\napiVersion: v1\nmetadata:\n  labels:\n    app: kubernetes-dashboard\n  name: kubernetes-dashboard\n  namespace: kubernetes-dashboard\nspec:\n  ports:\n    - port: 443\n      targetPort: 8443\n      nodePort: 30001\n  type: NodePort\n  selector:\n    app: kubernetes-dashboard\n\n---\n```\n\n![image-20231014174511047](../img/OpenEuler-%E9%83%A8%E7%BD%B2K8S%E9%AB%98%E5%8F%AF%E7%94%A8%E9%9B%86%E7%BE%A4%EF%BC%88%E5%A4%96%E9%83%A8etcd%EF%BC%89/106f6e666e0fe6147ee3804ee807d094697559838.png)\n\n运行dashboard\n\n```\nkubectl apply -f recommended.yaml\n```\n\n![image-20231014174622344](../img/OpenEuler-%E9%83%A8%E7%BD%B2K8S%E9%AB%98%E5%8F%AF%E7%94%A8%E9%9B%86%E7%BE%A4%EF%BC%88%E5%A4%96%E9%83%A8etcd%EF%BC%89/8c81fcb3a5858585b3e3d399896be60c697559838.png)\n\n检查运行状态\n\n```\nkubectl get pods -n kubernetes-dashboard\nkubectl get pod,svc -o wide -n kubernetes-dashboard\n```\n\n![image-20231111025752605](../img/OpenEuler-%E9%83%A8%E7%BD%B2K8S%E9%AB%98%E5%8F%AF%E7%94%A8%E9%9B%86%E7%BE%A4%EF%BC%88%E5%A4%96%E9%83%A8etcd%EF%BC%89/e1ca8cd9e0b98706124877b8da192bc8697559838.png)\n\n### 创建cluster-admin用户\n\n```\n创建service account并绑定默认cluster-admin管理员群角色\n#创建用户\nkubectl create serviceaccount dashboard-admin -n kubernetes-dashboard\n#用户授权\nkubectl create clusterrolebinding dashboard-admin --clusterrole=cluster-admin --serviceaccount=kubernetes-dashboard:dashboard-admin\n#获取用户Token\nkubectl create token dashboard-admin -n kubernetes-dashboard\n```\n\n![image-20231111025817854](../img/OpenEuler-%E9%83%A8%E7%BD%B2K8S%E9%AB%98%E5%8F%AF%E7%94%A8%E9%9B%86%E7%BE%A4%EF%BC%88%E5%A4%96%E9%83%A8etcd%EF%BC%89/ed6bc492c9fe47747ad7dd31483e4262697559838.png)\n\n记录token\n\n```\neyJhbGciOiJSUzI1NiIsImtpZCI6IjJxb21sRTZSckhEZ09FMnlvWU5IY3dfTTRIWDEzRUpsQ000MThhSWxYNDgifQ.eyJhdWQiOlsiaHR0cHM6Ly9rdWJlcm5ldGVzLmRlZmF1bHQuc3ZjLmNsdXN0ZXIubG9jYWwiXSwiZXhwIjoxNjk5NjQ2Mjg3LCJpYXQiOjE2OTk2NDI2ODcsImlzcyI6Imh0dHBzOi8va3ViZXJuZXRlcy5kZWZhdWx0LnN2Yy5jbHVzdGVyLmxvY2FsIiwia3ViZXJuZXRlcy5pbyI6eyJuYW1lc3BhY2UiOiJrdWJlcm5ldGVzLWRhc2hib2FyZCIsInNlcnZpY2VhY2NvdW50Ijp7Im5hbWUiOiJkYXNoYm9hcmQtYWRtaW4iLCJ1aWQiOiIyNTBhNTQ2MS03MGJlLTRhZTItOWY2Yi1hMDQwOWE1NWJhMTMifX0sIm5iZiI6MTY5OTY0MjY4Nywic3ViIjoic3lzdGVtOnNlcnZpY2VhY2NvdW50Omt1YmVybmV0ZXMtZGFzaGJvYXJkOmRhc2hib2FyZC1hZG1pbiJ9.U-lH9_sRU4TVrpAznqS60INNSev9NxHu61igGUTzTBoaWo7WjPG7vzTnpZYhvsoglTzMEKhfranJkkkn95pe-prkvSasaAL6kXHw0jQjlSMzcYiF7DoLdkOtDJSukuALEubidf9eIwZXFZ-sezZdZHm4hnk5nWme5YtdOmYOJPh5sv1dzRvM1XuOHknJPTA1BbdZuVAtSGHSjkhwx-wl-41uuQoROW5GjJs0bz4zLBFn1w_pWaSMCn7pjGJNcbr6IuDV41km_etpwwxacWyfAcxNykzCtIiE1abJj7m-e944GvAn_eqxz3wCZD6Bgt41FWRzyMHjrppJfDjk7FaHNw\n\n```\n\n### 登录浏览器访问\n\n```\nhttps://192.168.48.200:30001\n\n输入token：\n----\neyJhbGciOiJSUzI1NiIsImtpZCI6IjJxb21sRTZSckhEZ09FMnlvWU5IY3dfTTRIWDEzRUpsQ000MThhSWxYNDgifQ.eyJhdWQiOlsiaHR0cHM6Ly9rdWJlcm5ldGVzLmRlZmF1bHQuc3ZjLmNsdXN0ZXIubG9jYWwiXSwiZXhwIjoxNjk5NjQ2Mjg3LCJpYXQiOjE2OTk2NDI2ODcsImlzcyI6Imh0dHBzOi8va3ViZXJuZXRlcy5kZWZhdWx0LnN2Yy5jbHVzdGVyLmxvY2FsIiwia3ViZXJuZXRlcy5pbyI6eyJuYW1lc3BhY2UiOiJrdWJlcm5ldGVzLWRhc2hib2FyZCIsInNlcnZpY2VhY2NvdW50Ijp7Im5hbWUiOiJkYXNoYm9hcmQtYWRtaW4iLCJ1aWQiOiIyNTBhNTQ2MS03MGJlLTRhZTItOWY2Yi1hMDQwOWE1NWJhMTMifX0sIm5iZiI6MTY5OTY0MjY4Nywic3ViIjoic3lzdGVtOnNlcnZpY2VhY2NvdW50Omt1YmVybmV0ZXMtZGFzaGJvYXJkOmRhc2hib2FyZC1hZG1pbiJ9.U-lH9_sRU4TVrpAznqS60INNSev9NxHu61igGUTzTBoaWo7WjPG7vzTnpZYhvsoglTzMEKhfranJkkkn95pe-prkvSasaAL6kXHw0jQjlSMzcYiF7DoLdkOtDJSukuALEubidf9eIwZXFZ-sezZdZHm4hnk5nWme5YtdOmYOJPh5sv1dzRvM1XuOHknJPTA1BbdZuVAtSGHSjkhwx-wl-41uuQoROW5GjJs0bz4zLBFn1w_pWaSMCn7pjGJNcbr6IuDV41km_etpwwxacWyfAcxNykzCtIiE1abJj7m-e944GvAn_eqxz3wCZD6Bgt41FWRzyMHjrppJfDjk7FaHNw\n\n----\n\n```\n\n![image-20231111025910110](../img/OpenEuler-%E9%83%A8%E7%BD%B2K8S%E9%AB%98%E5%8F%AF%E7%94%A8%E9%9B%86%E7%BE%A4%EF%BC%88%E5%A4%96%E9%83%A8etcd%EF%BC%89/7b34dc0f898a641c9ab933bed917ef3a697559838.png)\n\n### 部署一个nginx测试\n\n操作节点[master1]\n\n```yaml\nvim web.yaml\n\nkind: Deployment\n#apiVersion: extensions/v1beta1\napiVersion: apps/v1\nmetadata:\n  labels:\n    app: web-deployment-label\n  name: web-deployment\n  namespace: default\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: web-selector\n  template:\n    metadata:\n      labels:\n        app: web-selector\n    spec:\n      containers:\n      - name: web-container\n        image: nginx:latest\n        imagePullPolicy: Always\n        ports:\n        - containerPort: 80\n          protocol: TCP\n          name: http\n        - containerPort: 443\n          protocol: TCP\n          name: https\n\n---\nkind: Service\napiVersion: v1\nmetadata:\n  labels:\n    app: web-service-label\n  name: web-service\n  namespace: default\nspec:\n  type: NodePort\n  ports:\n  - name: http\n    port: 80\n    protocol: TCP\n    targetPort: 80\n    nodePort: 30080\n  - name: https\n    port: 443\n    protocol: TCP\n    targetPort: 443\n    nodePort: 30443\n  selector:\n    app: web-selector\n    \nkubectl apply -f web.yaml \n```\n\n![image-20231014180923818](../img/OpenEuler-%E9%83%A8%E7%BD%B2K8S%E9%AB%98%E5%8F%AF%E7%94%A8%E9%9B%86%E7%BE%A4%EF%BC%88%E5%A4%96%E9%83%A8etcd%EF%BC%89/5181d6f7aaaf9bceb00fa35640993309697559838.png)\n\n```\n### 查看nginx的pod 的详细信息\nkubectl get deploy,svc,pod -o wide\n```\n\n![image-20231016203536987](../img/OpenEuler-%E9%83%A8%E7%BD%B2K8S%E9%AB%98%E5%8F%AF%E7%94%A8%E9%9B%86%E7%BE%A4%EF%BC%88%E5%A4%96%E9%83%A8etcd%EF%BC%89/302a4487890e97870530cc9b18b6d9f2697559838.png)\n\n访问nginx网站\n\n```\nhttp://192.168.48.200:30080\n```\n\n![image-20231111030413487](../img/OpenEuler-%E9%83%A8%E7%BD%B2K8S%E9%AB%98%E5%8F%AF%E7%94%A8%E9%9B%86%E7%BE%A4%EF%BC%88%E5%A4%96%E9%83%A8etcd%EF%BC%89/b5a25165b9ac41398207d34177a4860a697559838.png)\n\n<div class=\"tbsm\" style=\"margin-top:54px;\">\n<div class=\"tbsm-top\"><span><svg t=\"1674654360507\" class=\"icon\" viewBox=\"0 0 1024 1024\" version=\"1.1\" xmlns=\"http://www.w3.org/2000/svg\" p-id=\"987\" data-spm-anchor-id=\"a313x.7781069.0.i0\" width=\"35\" height=\"35\"><path d=\"M410.49 97.74H155.08a56.74 56.74 0 0 0-56.84 56.73V410a56.84 56.84 0 0 0 56.84 56.84h255.41A56.83 56.83 0 0 0 467.32 410V154.58a56.83 56.83 0 0 0-56.83-56.84zM410.49 558.74H155.08a56.74 56.74 0 0 0-56.84 56.73V871a56.84 56.84 0 0 0 56.84 56.84h255.41A56.83 56.83 0 0 0 467.32 871V615.58a56.83 56.83 0 0 0-56.83-56.84zM871.49 558.74H616.08a56.74 56.74 0 0 0-56.84 56.73V871a56.84 56.84 0 0 0 56.84 56.84h255.41A56.83 56.83 0 0 0 928.32 871V615.58a56.83 56.83 0 0 0-56.83-56.84z\" fill=\"#66EEFF\" p-id=\"988\"></path><path d=\"M410.49 558.74h-4.14A475 475 0 0 0 299.52 859.6a481.16 481.16 0 0 0 4.84 68.22h106.13A56.83 56.83 0 0 0 467.32 871V615.58a56.83 56.83 0 0 0-56.83-56.84zM871.49 558.74H616.08a56.74 56.74 0 0 0-56.84 56.73V871a56.84 56.84 0 0 0 56.84 56.84h255.41A56.83 56.83 0 0 0 928.32 871V615.58a56.83 56.83 0 0 0-56.83-56.84z\" fill=\"#C2F8FF\" p-id=\"989\"></path></svg></span><span style=\"font-size:30px;\"> 特别声明</span></div>\n<div class=\"tbsm-wz\">千屹博客旗下的所有文章，是通过本人课堂学习和课外自学所精心整理的知识巨著<br/>难免会有出错的地方<br/>如果细心的你发现了小失误，可以在下方评论区告诉我，或者私信我！<br />非常感谢大家的热烈支持！</div>\n</div>\n","tags":["OpenEuler","K8s"],"categories":["云原生"]},{"title":"Nginx1.22实现内网自签证书","url":"/posts/10165/","content":"\n<meta name=\"referrer\" content=\"no-referrer\"/>\n\n# Nginx1.22实现内网自签证书\n\nHTTPS（全称：HyperText Transfer Protocol Secure）是HTTP（超文本传输协议）的安全版本。本质上，HTTPS在HTTP的基础上，通过SSL/TLS协议提供了数据加密、完整性保护和身份验证，以确保网络数据传输的安全性。HTTPS被广泛用于互联网上的安全通信，特别是在线交易和处理敏感信息时，本文以Nginx为例部署自签发https证书。\n\n## 前情提要\n\n本次实验仅仅用于实验测试有ssl需求的实验，生产环境建议不要用\n\n本次实验环境是Rocky8.9（和centos 8 stream 大差不差）\n\n## 安装nginx\n\n```\ndnf update -y\ndnf module list nginx\ndnf remove @nginx\ndnf module reset nginx\ndnf module install nginx:1.22 -y\nsystemctl enable --now nginx\nnginx -V\n```\n\n查看是否有`--with-http_ssl_module`\n\n`--with-http_ssl_module` 是 Nginx 配置选项之一，用于启用 Nginx 的 SSL 功能模块。当 Nginx 编译时包含了 `--with-http_ssl_module` 选项时，表示 Nginx 将支持处理 HTTPS 请求，即通过 SSL/TLS 加密协议保护数据传输。\n\n![image-20240406194001867](../img/Nginx1.22%E5%AE%9E%E7%8E%B0%E5%86%85%E7%BD%91%E8%87%AA%E7%AD%BE%E8%AF%81%E4%B9%A6.assets/image-20240406194001867.png)\n\n## 安装openssl\n\nOpenSSL 是一个开放源代码的加密库，广泛用于安全通信、加密和解密数据。它提供了一组功能丰富的工具和库，用于处理安全通信所需的各种加密操作。\n\n```\ndnf install openssl\ndnf install openssl-devel\n```\n\n## 生成证书\n\n```\n#没有就创建sslkey文件夹\ncd /etc/nginx/sslkey\n\n#创建本地私有密钥\nopenssl genrsa -out ssl.key 2048\n \n#按提示输入即可\nopenssl req -new -key ssl.key -out ssl.csr\n\n ----------------------------------------------------------------\n 国家名称(2字母代码)[XX]:CN\nCountry Name (2 letter code) [XX]:CN\n\n州或省名(全称)[]:Guangdong\nState or Province Name (full name) []:Guangdong\n\n地区名称(如城市)[默认城市]:广州\nLocality Name (eg, city) [Default City]:Guangzhou\n\n组织机构名称(如公司)【默认公司有限公司】:qianyios\nOrganization Name (eg, company) [Default Company Ltd]:qianyios\n\n组织单位名称(如section) []:NONE\nOrganizational Unit Name (eg, section) []:NONE\n\n通用名称(例如，您的名字或服务器主机名)[]:qianyios\nCommon Name (eg, your name or your server's hostname) []:qianyios\n\n邮箱地址[]:abc@qq.com\nEmail Address []:abc@qq.com\n\n请输入以下“额外”属性\nPlease enter the following 'extra' attributes\n\n与您的证书请求一起发送\nto be sent with your certificate request\n\n挑战密码[]:123456\nA challenge password []:123456\n\n可选的公司名称[]:NONE\nAn optional company name []:NONE\n\n ----------------------------------------------------------------\n\n#创建证书crt\nopenssl x509 -req -days 1460 -in ssl.csr -signkey ssl.key -out ssl.crt\n \n#创建证书pem\nopenssl dhparam -out ssl.pem 2048\n```\n\n## Nginx配置\n\n```\nvi /etc/nginx/nginx.conf\n\n...........\ninclude /etc/nginx/sslkey/*.conf;\n...........\n\n保存退出\n```\n\n在nginx默认配置下加上`include /etc/nginx/sslkey/*.conf;`\n\n![image-20240406194859367](../img/Nginx1.22%E5%AE%9E%E7%8E%B0%E5%86%85%E7%BD%91%E8%87%AA%E7%AD%BE%E8%AF%81%E4%B9%A6.assets/image-20240406194859367.png)\n\n给ssl证书单独生成一个conf。\n\n```\ncat >> /etc/nginx/sslkey/ssl.conf <<\"EOF\"\nserver {\n    listen 443   ssl;\n    ssl_certificate                          /etc/nginx/sslkey/ssl.crt;\n    ssl_certificate_key                        /etc/nginx/sslkey/ssl.key;\n    ssl_session_timeout 5m;\n    ssl_protocols TLSv1.2;\n    ssl_ciphers EECDH+AESGCM:EDH+AESGCM:AES256+EECDH:AES256+EDH:!aNULL:!eNULL:!EXPORT:!DES:!RC4:!MD5:!PSK:!KRB5:!aECDH:!EDH+3DES;\n    add_header Strict-Transport-Security \"max-age=31536000; includeSubDomains\";\n}\nEOF\n```\n\n<font color='red'>重点！！！</font>\n\n在你需要的网站配置加入重定向至https，因为我们默认访问nginx页面的时候是http的，所以要重定向。现在我们模拟访问80端口的默认网页\n\n```\nvi /etc/nginx/nginx.conf\n\n\n    include /etc/nginx/conf.d/*.conf;\n    include /etc/nginx/sslkey/*.conf;\n    server {\n        listen       80;\n        listen       [::]:80;\n        return 301 https://$host$request_uri;   #就加这一句\n        server_name  _;\n        root         /usr/share/nginx/html;\n\n\n```\n\n\n\n![image-20240406195448828](../img/Nginx1.22%E5%AE%9E%E7%8E%B0%E5%86%85%E7%BD%91%E8%87%AA%E7%AD%BE%E8%AF%81%E4%B9%A6.assets/image-20240406195448828.png)\n\n\n\n重启nginx\n\n```\nnginx -t\nnginx -s reload\n```\n\n\n\n这时候访问80网页，自签证书已经好了，只是不受信任而已\n\n![image-20240406195703184](../img/Nginx1.22%E5%AE%9E%E7%8E%B0%E5%86%85%E7%BD%91%E8%87%AA%E7%AD%BE%E8%AF%81%E4%B9%A6.assets/image-20240406195703184.png)\n\n<div class=\"tbsm\" style=\"margin-top:54px;\">\n<div class=\"tbsm-top\"><span><svg t=\"1674654360507\" class=\"icon\" viewBox=\"0 0 1024 1024\" version=\"1.1\" xmlns=\"http://www.w3.org/2000/svg\" p-id=\"987\" data-spm-anchor-id=\"a313x.7781069.0.i0\" width=\"35\" height=\"35\"><path d=\"M410.49 97.74H155.08a56.74 56.74 0 0 0-56.84 56.73V410a56.84 56.84 0 0 0 56.84 56.84h255.41A56.83 56.83 0 0 0 467.32 410V154.58a56.83 56.83 0 0 0-56.83-56.84zM410.49 558.74H155.08a56.74 56.74 0 0 0-56.84 56.73V871a56.84 56.84 0 0 0 56.84 56.84h255.41A56.83 56.83 0 0 0 467.32 871V615.58a56.83 56.83 0 0 0-56.83-56.84zM871.49 558.74H616.08a56.74 56.74 0 0 0-56.84 56.73V871a56.84 56.84 0 0 0 56.84 56.84h255.41A56.83 56.83 0 0 0 928.32 871V615.58a56.83 56.83 0 0 0-56.83-56.84z\" fill=\"#66EEFF\" p-id=\"988\"></path><path d=\"M410.49 558.74h-4.14A475 475 0 0 0 299.52 859.6a481.16 481.16 0 0 0 4.84 68.22h106.13A56.83 56.83 0 0 0 467.32 871V615.58a56.83 56.83 0 0 0-56.83-56.84zM871.49 558.74H616.08a56.74 56.74 0 0 0-56.84 56.73V871a56.84 56.84 0 0 0 56.84 56.84h255.41A56.83 56.83 0 0 0 928.32 871V615.58a56.83 56.83 0 0 0-56.83-56.84z\" fill=\"#C2F8FF\" p-id=\"989\"></path></svg></span><span style=\"font-size:30px;\"> 特别声明</span></div>\n<div class=\"tbsm-wz\">千屹博客旗下的所有文章，是通过本人课堂学习和课外自学所精心整理的知识巨著<br/>难免会有出错的地方<br/>如果细心的你发现了小失误，可以在下方评论区告诉我，或者私信我！<br />非常感谢大家的热烈支持！</div>\n</div>\n","tags":["Rocky 8","Nginx"],"categories":["运维"]},{"title":"广州商学院课程作业导航","url":"/posts/548777d4/","content":"\n<meta name=\"referrer\" content=\"no-referrer\"/>\n\n# 广州商学院课程作业导航\n\n<a href=\"https://blog.qianyios.top/posts/d721e715/\"><img src=\"https://i0.hdslb.com/bfs/article/daddec263720c95dfc5b4f53b45a96fd55933597.png\"/></a>\n\n\n<a href=\"https://blog.qianyios.top/posts/f5e08620/\"><img src=\"https://i0.hdslb.com/bfs/article/225c076d72b0942a26654c2f37dace8a55933597.png\"/></a>\n\n<a href=\"https://blog.qianyios.top/posts/f8bb3dfe/\"><img src=\"https://blog.qianyios.top/img/%E5%8D%8E%E4%B8%BAensp%E6%A8%A1%E6%8B%9F%E5%99%A8%E5%AE%89%E8%A3%85%E6%95%99%E7%A8%8B/1.webp\"/></a>\n\n<div class=\"tbsm\" style=\"margin-top:54px;\">\n<div class=\"tbsm-top\"><span><svg t=\"1674654360507\" class=\"icon\" viewBox=\"0 0 1024 1024\" version=\"1.1\" xmlns=\"http://www.w3.org/2000/svg\" p-id=\"987\" data-spm-anchor-id=\"a313x.7781069.0.i0\" width=\"35\" height=\"35\"><path d=\"M410.49 97.74H155.08a56.74 56.74 0 0 0-56.84 56.73V410a56.84 56.84 0 0 0 56.84 56.84h255.41A56.83 56.83 0 0 0 467.32 410V154.58a56.83 56.83 0 0 0-56.83-56.84zM410.49 558.74H155.08a56.74 56.74 0 0 0-56.84 56.73V871a56.84 56.84 0 0 0 56.84 56.84h255.41A56.83 56.83 0 0 0 467.32 871V615.58a56.83 56.83 0 0 0-56.83-56.84zM871.49 558.74H616.08a56.74 56.74 0 0 0-56.84 56.73V871a56.84 56.84 0 0 0 56.84 56.84h255.41A56.83 56.83 0 0 0 928.32 871V615.58a56.83 56.83 0 0 0-56.83-56.84z\" fill=\"#66EEFF\" p-id=\"988\"></path><path d=\"M410.49 558.74h-4.14A475 475 0 0 0 299.52 859.6a481.16 481.16 0 0 0 4.84 68.22h106.13A56.83 56.83 0 0 0 467.32 871V615.58a56.83 56.83 0 0 0-56.83-56.84zM871.49 558.74H616.08a56.74 56.74 0 0 0-56.84 56.73V871a56.84 56.84 0 0 0 56.84 56.84h255.41A56.83 56.83 0 0 0 928.32 871V615.58a56.83 56.83 0 0 0-56.83-56.84z\" fill=\"#C2F8FF\" p-id=\"989\"></path></svg></span><span style=\"font-size:30px;\"> 特别声明</span></div>\n<div class=\"tbsm-wz\">千屹博客旗下的所有文章，是通过本人课堂学习和课外自学所精心整理的知识巨著<br/>难免会有出错的地方<br/>如果细心的你发现了小失误，可以在下方评论区告诉我，或者私信我！<br />非常感谢大家的热烈支持！</div>\n</div>\n\n"},{"title":"工学云自动签到","url":"/posts/53959/","content":"\n<meta name=\"referrer\" content=\"no-referrer\"/>\n\n# 工学云自动签到\n\n## 前情提要\n\n原作者项目：[Rockytkg/AutoMoGuDingCheckIn: 工学云自动打卡，支持多用户、自定义地区、周报、日报、月报，支持免服务器运行](https://github.com/Rockytkg/AutoMoGuDingCheckIn)\n\n<font color='red'>帮作者点一下右上角的star（星星）</font>\n\n![image-20250110160405637](https://i0.hdslb.com/bfs/article/43659ea6071cbbf958d28bc8637048be697559838.png)\n\n**仅供学习交流测试！您必须在下载或Fork此源码的24小时内删除所有内容！！**\n\n**1、请务必认真阅读此文档后继续！**\n\n**2、本项目开源&免费，所有开发均仅限于学习交流，禁止用于任何商业用途。**\n\n**3、如基于或参考此项目进行二次开发，请注明原作者并使用GPL2.0许可证开源**\n\n**4、使用本项目对自己账号有一定的风险，在这里本站不承担任何责任和后果，所有危险后果自负，一切由使用者本人负责<font color='red'>（到这里如果介意了可以退出本站，不用继续看了）</font>**\n\n\n\n<p style=\"text-align:center;font-size:22px\" >\n  <font color='red'>效果呈现</font></font>\n</p>\n\n\n\n\n\n![image-20250111194827314](https://i0.hdslb.com/bfs/article/2eb104532fa15e60bc34067404b21942697559838.png)\n\n\n\n## 使用教程\n\n环境\n\n- Python 3.10+\n- pip（Python 包管理器）\n\n### 服务器部署（可以先用虚拟机测试）\n\n测试机centos，openeuler\n\n```bash\n#设置pip国内镜像源\nmkdir ~/.pip\ncat >~/.pip/pip.conf << \"EOF\"\n[global]\nindex-url = http://mirrors.aliyun.com/pypi/simple/ \n[install]\ntrusted-host=mirrors.aliyun.com\nEOF\n#安装python3\nyum install -y python3.11 python3.11-pip\nsudo rm /usr/bin/python\nsudo ln -s /usr/bin/python3.11 /usr/bin/python\npython3 -m pip install --upgrade pip\n```\n\n拉取代码\n\n```bash\n#安装git \nyum install -y git\n#在root目录下执行\ncd /root\n#拉取代码(这个拉取不了就用下面国内镜像拉取)\ngit clone https://github.com/Rockytkg/AutoMoGuDingCheckIn.git AutoMoGuDingCheckIn\n#国内镜像拉取\ngit clone https://github.site/Rockytkg/AutoMoGuDingCheckIn.git AutoMoGuDingCheckIn\n```\n\n配置个人信息\n\n```\nvim AutoMoGuDingCheckIn/user/example.json\n```\n\n设置个人信息\n\n![image-20250110161544065](https://i0.hdslb.com/bfs/article/8a567f1c0a9ac4133f7196605f96657a697559838.png)\n\n设置邮箱发送\n\n![image-20250110161622840](https://i0.hdslb.com/bfs/article/6c41f010375e15386564f651dd2751d5697559838.png)\n\n> `收件邮箱一定要是QQ邮箱`\n\n```\n例子：我用的发件邮箱是网易的，收件邮箱一定要是QQ邮箱\n不然最后的微信邮件提醒，你操作不了\n{\n    \"type\": \"SMTP\",\n    \"enabled\": true,\n    \"host\": \"Smtp.163.com\",\n    \"port\": 465,\n    \"username\": \"xxxxxx@163.com\",  \n    \"password\": \"网易授权码，按照下面教程获取\",\n    \"from\": \"严千屹\",\n    \"to\": \"xxxxx@qq.com\"   #一定要是qq邮箱\n}\n```\n\n那个smtp密码是授权码，不是邮箱密码，我用的是网易的\n\n[网易邮箱（126/163）：授权码获取攻略_网易邮箱授权码-CSDN博客](https://blog.csdn.net/kissradish/article/details/108447972)\n\n自行获取就行了\n\n`发件邮箱`要是`想用其他邮箱`类似操作获取授权码就行，但是`收件邮箱一定要是QQ邮箱`\n\n\n\n填好之后，这就是一个人的信息了\n\n`多用户配置,有多个人，你就看下面，没有就略过`\n\n下载这个配置文件：[example.json](https://github.com/Rockytkg/AutoMoGuDingCheckIn/blob/main/user/example.json)\n\n修改信息之后，更改文件名（随意），任何运行脚本即可。\n\n![image-20250223203047997](https://i0.hdslb.com/bfs/article/922af5289e629ea1d083e78831e01b0c55933597.png)\n\n最后再运行代码，会帮你自动设置计划任务，自动打卡\n\n``` bash\ncd /root/AutoMoGuDingCheckIn/ && chmod +x setup.sh\nbash setup.sh\n```\n\n按照他的指示操作，进行设置打卡时间就行了，这样他会按照你的时间，每天进行打卡，比如说你设置的事实8,17  那么他就会每天早上8点（上班），下午17点（下班）进行打卡\n\n![image-20250110170721599](https://i0.hdslb.com/bfs/article/1aab7b0214711c034b608419ede3c382697559838.png)\n\n### 无服务器部署\n\nGithub 工作流（免服务器部署）\n\n参见 [Wiki](https://github.com/Rockytkg/AutoMoGuDingCheckIn/wiki/Github-工作流部署)\n\n\n\n**切记不要将配置文件上传到公开仓库，否则会造成信息泄露。请使用环境变量！！！，已经泄露请立刻修改工学云密码！！！**\n\n\n\n### 微信邮件推送\n\n微信搜索QQ邮件提醒\n\n![e6284406623e269cebcf96d30c7ff800](https://i0.hdslb.com/bfs/article/b44a32b138c5a3826769b616a05d5140697559838.jpg)\n\n绑定好邮箱\n\n![image-20250111194024741](https://i0.hdslb.com/bfs/article/c1fc27efbc8af3f05ebf55ffbebd4a31697559838.png)\n\n这样，等每一次打卡之后，就会邮件推送，然后就是下面这样的\n\n![b5b38eddcc2602876628686581eb8231](https://i0.hdslb.com/bfs/article/96ba18890ef5ff01f91876e070c38e96697559838.jpg)\n\n\n\n<div class=\"tbsm\" style=\"margin-top:54px;\">\n<div class=\"tbsm-top\"><span><svg t=\"1674654360507\" class=\"icon\" viewBox=\"0 0 1024 1024\" version=\"1.1\" xmlns=\"http://www.w3.org/2000/svg\" p-id=\"987\" data-spm-anchor-id=\"a313x.7781069.0.i0\" width=\"35\" height=\"35\"><path d=\"M410.49 97.74H155.08a56.74 56.74 0 0 0-56.84 56.73V410a56.84 56.84 0 0 0 56.84 56.84h255.41A56.83 56.83 0 0 0 467.32 410V154.58a56.83 56.83 0 0 0-56.83-56.84zM410.49 558.74H155.08a56.74 56.74 0 0 0-56.84 56.73V871a56.84 56.84 0 0 0 56.84 56.84h255.41A56.83 56.83 0 0 0 467.32 871V615.58a56.83 56.83 0 0 0-56.83-56.84zM871.49 558.74H616.08a56.74 56.74 0 0 0-56.84 56.73V871a56.84 56.84 0 0 0 56.84 56.84h255.41A56.83 56.83 0 0 0 928.32 871V615.58a56.83 56.83 0 0 0-56.83-56.84z\" fill=\"#66EEFF\" p-id=\"988\"></path><path d=\"M410.49 558.74h-4.14A475 475 0 0 0 299.52 859.6a481.16 481.16 0 0 0 4.84 68.22h106.13A56.83 56.83 0 0 0 467.32 871V615.58a56.83 56.83 0 0 0-56.83-56.84zM871.49 558.74H616.08a56.74 56.74 0 0 0-56.84 56.73V871a56.84 56.84 0 0 0 56.84 56.84h255.41A56.83 56.83 0 0 0 928.32 871V615.58a56.83 56.83 0 0 0-56.83-56.84z\" fill=\"#C2F8FF\" p-id=\"989\"></path></svg></span><span style=\"font-size:30px;\"> 特别声明</span></div>\n<div class=\"tbsm-wz\">千屹博客旗下的所有文章，是通过本人课堂学习和课外自学所精心整理的知识巨著<br/>难免会有出错的地方<br/>如果细心的你发现了小失误，可以在下方评论区告诉我，或者私信我！<br />非常感谢大家的热烈支持！</div>\n</div>\n\n","tags":["工学云"]},{"title":"OpenStack-Train-三节点部署","url":"/posts/26892/","content":"\n<meta name=\"referrer\" content=\"no-referrer\"/>\n\n# OpenStack-Train-三节点部署\n\n## 主机拓扑\n\n| 主机名       | ens33（NAT）   | ens36(仅主机)   | 内存 | 硬盘1 | 硬盘2 | os        |\n| ------------ | -------------- | --------------- | ---- | ----- | ----- | --------- |\n| controller-1 | 192.168.48.101 | 192.168.148.101 | 8G   | 100G  |       | Centos7.9 |\n| computer-2   | 192.168.48.102 | 192.168.148.102 | 3G   | 100G  | 100G  | Centos7.9 |\n| computer-3   | 192.168.48.103 | 192.168.148.103 | 3G   | 100G  | 100G  | Centos7.9 |\n\n具体安装的服务如下：\n\n| 节点名称   | OpenStack 服务                                               |\n| ---------- | ------------------------------------------------------------ |\n| 控制节点   | MariaDB RabbitMQ Memcache Etcd Keystone Placement Glance Nova Neutron Cinder Horizon Heat |\n| 计算节点   | Nova Neutron                                                 |\n| 块存储节点 | Cinder Swift                                                 |\n\n三台节点的配置如下图\n\n![image-20240107003616013](../img/OpenStack-Train-%E4%B8%89%E8%8A%82%E7%82%B9%E9%83%A8%E7%BD%B2.assets/3e7313ef3a188b5fcf69a37024a6afab697559838.png)\n\n![image-20240107003516583](../img/OpenStack-Train-%E4%B8%89%E8%8A%82%E7%82%B9%E9%83%A8%E7%BD%B2.assets/286f41907c7aa2488dc965030d91add1697559838.png)\n\n![image-20240107003313362](../img/OpenStack-Train-%E4%B8%89%E8%8A%82%E7%82%B9%E9%83%A8%E7%BD%B2.assets/6043b98af224a9c97503d350f935369e697559838.png)\n\nVMware网络设置如下图\n\n![image-20240107003708588](../img/OpenStack-Train-%E4%B8%89%E8%8A%82%E7%82%B9%E9%83%A8%E7%BD%B2.assets/972f5f1f095069468b1c8fdc0d5e3149697559838.png)\n\n## 安全性\n\n### 物理节点关闭顺序\n\n给每台机都加上两个脚本\n\n```\ncat >> stop.sh << EOF\n#!/bin/bash\n# 关闭所有 OpenStack 节点\n# 依次关闭计算节点、网络节点、控制节点\nfor server in \\$(openstack server list -f value -c ID); do\n    openstack server stop \\$server\ndone\n# 关闭计算节点\necho \"Stopping compute services...\"\nsystemctl stop openstack-nova-compute.service\nsystemctl stop libvirtd.service\n# 关闭网络节点\necho \"Stopping network services...\"\nsystemctl stop openvswitch.service\nsystemctl stop neutron-server.service\nsystemctl stop neutron-linuxbridge-agent.service\nsystemctl stop neutron-dhcp-agent.service\nsystemctl stop neutron-metadata-agent.service\nsystemctl stop neutron-l3-agent.service\n# 关闭控制节点\necho \"Stopping control services...\"\nsystemctl stop mariadb.service\nsystemctl stop rabbitmq-server.service\nsystemctl stop memcached.service\nsystemctl stop httpd.service\nsystemctl stop openstack-glance-api.service\nsystemctl stop openstack-glance-registry.service\nsystemctl stop openstack-cinder-api.service\nsystemctl stop openstack-cinder-scheduler.service\nsystemctl stop openstack-cinder-volume.service\nsystemctl stop openstack-nova-api.service\nsystemctl stop openstack-nova-scheduler.service\nsystemctl stop openstack-nova-conductor.service\nsystemctl stop openstack-nova-novncproxy.service\nsystemctl stop openstack-nova-consoleauth.service\nsystemctl stop openstack-keystone.service\nsystemctl stop openstack-heat-api.service\nsystemctl stop openstack-heat-api-cfn.service\nsystemctl stop openstack-heat-engine.service\nsystemctl stop openstack-swift-proxy.service\nsystemctl stop openstack-swift-account.service\nsystemctl stop openstack-swift-container.service\nsystemctl stop openstack-swift-object.service\necho \"Stopping all services...\"\nsystemctl stop --all\n# 关闭电源\necho \"Shutting down the system...\"\npoweroff\nEOF\n\ncat >> start.sh << EOF\n#!/bin/bash\n# 重新启动 OpenStack 服务\n# 依次启动控制节点、网络节点、计算节点\n# 启动控制节点\necho \"Starting control services...\"\nsystemctl start mariadb.service\nsystemctl start rabbitmq-server.service\nsystemctl start memcached.service\nsystemctl start httpd.service\nsystemctl start openstack-glance-api.service\nsystemctl start openstack-glance-registry.service\nsystemctl start openstack-cinder-api.service\nsystemctl start openstack-cinder-scheduler.service\nsystemctl start openstack-cinder-volume.service\nsystemctl start openstack-nova-api.service\nsystemctl start openstack-nova-scheduler.service\nsystemctl start openstack-nova-conductor.service\nsystemctl start openstack-nova-novncproxy.service\nsystemctl start openstack-nova-consoleauth.service\nsystemctl start openstack-keystone.service\nsystemctl start openstack-heat-api.service\nsystemctl start openstack-heat-api-cfn.service\nsystemctl start openstack-heat-engine.service\nsystemctl start openstack-swift-proxy.service\nsystemctl start openstack-swift-account.service\nsystemctl start openstack-swift-container.service\nsystemctl start openstack-swift-object.service\n# 启动网络节点\necho \"Starting network services...\"\nsystemctl start openvswitch.service\nsystemctl start neutron-server.service\nsystemctl start neutron-linuxbridge-agent.service\nsystemctl start neutron-dhcp-agent.service\nsystemctl start neutron-metadata-agent.service\nsystemctl start neutron-l3-agent.service\n# 启动计算节点\necho \"Starting compute services...\"\nsystemctl start libvirtd.service\nsystemctl start openstack-nova-compute.service\nEOF\n```\n\n<font color='red'>（先给两个计算节点执行-最后等计算节点完全关闭，再给控制节点执行）</font>\n\n```\n关闭物理机的时候运行\nsh stop.sh\n(运行的时候可能会提示你有些服务找不到，报错，这个没关系，但是要是告诉你有些服务起不来，要你自己去找报错了)一般情况下是没问题的\n```\n\n### 物理节点开启顺序\n\n> <font color='red'>先开controller-1再开剩下的计算节点</font>\n\n### 基本用户信息\n\nOpenStack 各组件都需要在控制节点数据库中注册专属账户以存放数据信息，故需要设置密码，强烈建议各组件的密码以及宿主机密码各不相同。\n\n|    OpenStack 组件     |         密码          |\n| :-------------------: | :-------------------: |\n|     控制节点 root     |        123456         |\n|     计算节点 root     |        123456         |\n|  Metadata 元数据密钥  |    METADATA_SECRET    |\n|   Mariadb root 账户   |     MARIADB_PASS      |\n|     RabbitMQ 服务     |      RABBIT_PASS      |\n|    OpenStack admin    |      ADMIN_PASS       |\n|    Placement 服务     |    PLACEMENT_PASS     |\n|    Keystone 数据库    |    KEYSTONE_DBPASS    |\n|      Glance 服务      |      GLANCE_PASS      |\n|     Glance 数据库     |     GLANCE_DBPASS     |\n|       Nova 服务       |       NOVA_PASS       |\n|      Nova 数据库      |      NOVA_DBPASS      |\n|     Neutron 服务      |     NEUTRON_PASS      |\n|    Neutron 数据库     |    NEUTRON_DBPASS     |\n|      Cinder 服务      |      CINDER_PASS      |\n|     Cinder 数据库     |     CINDER_DBPASS     |\n|    Horizon 数据库     |      DASH_DBPASS      |\n|       Swift服务       |      SWIFT_PASS       |\n|       Heat服务        |       HEAT_PASS       |\n|    Heat数据库服务     |      HEAT_DBPASS      |\n| heat_domain_admin用户 | HEAT_DOMAIN_USER_PASS |\n\n### 测试用户\n\n| 用户    | 密码   |\n| ------- | ------ |\n| admin   | 123456 |\n| use_dog | 123456 |\n\n### 身份验证\n\n控制节点管理 OpenStack 服务时需要进行身份认证，可将认证信息导入到控制节点环境变量中，方便后续安装配置使用。\nadmin-openrc文件需提前编写并放入控制节点中，后续安装将不再说明由来\n\n```\n#配置管理员和测试用户账号（很重要）\ncat > /root/admin-openrc <<\"EOF\"\nexport OS_USERNAME=admin\nexport OS_PASSWORD=123456\nexport OS_PROJECT_NAME=admin\nexport OS_USER_DOMAIN_NAME=Default\nexport OS_PROJECT_DOMAIN_NAME=Default\nexport OS_AUTH_URL=http://controller-1:5000/v3\nexport OS_IDENTITY_API_VERSION=3\nEOF\n\ncat >user_dog-openrc << EOF\nexport OS_USERNAME=user_dog\nexport OS_PASSWORD=123456\nexport OS_PROJECT_NAME=Train\nexport OS_USER_DOMAIN_NAME=RegionOne\nexport OS_PROJECT_DOMAIN_NAME=RegionOne\nexport OS_AUTH_URL=http://controller-1:5000/v3\nexport OS_IDENTITY_API_VERSION=3\nEOF\n\n# OS_USERNAME  登录 OpenStack 服务的用户名\n# OS_PASSWORD  登录 OpenStack 服务的用户密码\n# OS_PROJECT_NAME 登录时进入的项目名\n# OS_USER_DOMAIN_NAME  登录时进入的域名\n# OS_PROJECT_DOMAIN_NAME  登录时进入的项目域名\n# OS_AUTH_URL 指定 Keystone（身份认证服务）的 URL  \n# 如未部署 DNS 服务器，则需要在 hosts中指定 controller-1 映射，或将 controller-1 用控制节点 IP 替代\n# OS_IDENTITY_API_VERSION 身份认证服务的 API 版本号 \n```\n\n## 基础配置\n\n### 网卡配置\n\n<font color='red'>操作节点[controller-1，computer-2，computer-3]</font>\n\n```\n【ens33】注意主机名，这里只展示要修改和添加的部分\n[root@controller-1 ~]# cat /etc/sysconfig/network-scripts/ifcfg-ens33\nBOOTPROTO=static\nONBOOT=yes\nIPADDR=192.168.48.101\nPREFIX=24\nGATEWAY=192.168.48.2\nDNS1=192.168.48.2\nDNS2=114.114.114.114\n[root@computer-2 ~]# cat /etc/sysconfig/network-scripts/ifcfg-ens33\nBOOTPROTO=static\nONBOOT=yes\nIPADDR=192.168.48.102\nPREFIX=24\nGATEWAY=192.168.48.2\nDNS1=192.168.48.2\nDNS2=114.114.114.114\n[root@computer-3 ~]# cat /etc/sysconfig/network-scripts/ifcfg-ens33\nBOOTPROTO=static\nONBOOT=yes\nIPADDR=192.168.48.103\nPREFIX=24\nGATEWAY=192.168.48.2\nDNS1=192.168.48.2\nDNS2=114.114.114.114\n\n【ens36】注意主机名，这里只展示要修改和添加的部分\n[root@controller-1 ~]# cat /etc/sysconfig/network-scripts/ifcfg-ens36\nBOOTPROTO=static\nONBOOT=yes\nIPADDR=192.168.148.101\nPREFIX=24\n[root@computer-2 ~]# cat /etc/sysconfig/network-scripts/ifcfg-ens36\nBOOTPROTO=static\nONBOOT=yes\nIPADDR=192.168.148.102\nPREFIX=24\n[root@computer-3 ~]# cat /etc/sysconfig/network-scripts/ifcfg-ens36\nBOOTPROTO=static\nONBOOT=yes\nIPADDR=192.168.148.103\nPREFIX=24\n```\n\n### 配置主机名\n\n<font color='red'>操作节点[controller-1]</font>\n\n```\nhostnamectl set-hostname controller-1 && bash\n```\n\n<font color='red'>操作节点[computer-2]</font>\n\n```\nhostnamectl set-hostname computer-2 && bash\n```\n\n<font color='red'>操作节点[computer-3]</font>\n\n```\nhostnamectl set-hostname computer-3 && bash\n```\n\n### 基础配置\n\n<font color='red'>操作节点[所有节点]</font>\n\n```\n#设置hosts\ncat >> /etc/hosts << EOF\n192.168.148.101 controller-1\n192.168.148.102 computer-2\n192.168.148.103 computer-3\nEOF\n#安装openstack-train\nyum install centos-release-openstack-train -y\nyum install python-openstackclient openstack-selinux -y\n#关闭防火墙和关闭selinux\nsystemctl disable firewalld --now\nsed -i \"s#SELINUX=enforcing#SELINUX=disabled#g\" /etc/selinux/config\nsetenforce 0\n#配置时间同步\nyum install chrony -y\nsystemctl enable chronyd --now\nchronyc sources\n\nreboot\n```\n\n### 配置免密\n\n<font color='red'>操作节点[controller-1]</font>\n\n```\n#各节点\nyum install -y sshpass \ncat > sshmianmi.sh << \"EOF\"\n#!/bin/bash\n# 目标主机列表\nhosts=(\"controller-1\" \"computer-2\" \"computer-3\")\n# 密码（注意修改）\npassword=\"123456\"\n# 生成 SSH 密钥对\nssh-keygen -t rsa -N \"\" -f ~/.ssh/id_rsa\n\n# 循环遍历目标主机\nfor host in \"${hosts[@]}\"\ndo\n    # 复制公钥到目标主机\n    sshpass -p \"$password\" ssh-copy-id -o StrictHostKeyChecking=no \"$host\"\n    \n    # 验证免密登录\n    sshpass -p \"$password\" ssh -o StrictHostKeyChecking=no \"$host\" \"echo '免密登录成功'\"\ndone\nEOF\n\nsh sshmianmi.sh\n```\n\n## 依赖组件\n\n<font color='red'>操作节点[controller-1]</font>\n\n### Mariadb数据库\n\n```\nyum install mariadb mariadb-server python2-PyMySQL -y\ncat >>/etc/my.cnf.d/openstack.cnf<<EOF\n[mysqld]\nbind-address =0.0.0.0\ndefault-storage-engine = innodb\ninnodb_file_per_table = on\nmax_connections =4096\ncollation-server = utf8_general_ci\ncharacter-set-server = utf8\nEOF\nsystemctl enable mariadb --now\nmysql_secure_installation\nEnter current password for root (enter for none): 回车\nSet root password? [Y/n] y\n# 将要求输入数据库 root 账户密码 MARIADB_PASS\nRemove anonymous users? [Y/n] y\nDisallow root login remotely? [Y/n] n\nRemove test database and access to it? [Y/n] y\nReload privilege tables now? [Y/n] y\n# 验证\nmysql -u root -pMARIADB_PASS\n```\n\n### Rabbitmq\n\n```\nyum install rabbitmq-server -y\nsystemctl enable rabbitmq-server.service --now\nrabbitmqctl add_user openstack RABBIT_PASS\nrabbitmqctl set_permissions openstack \".*\" \".*\" \".*\"\n```\n\n### Memcached\n\n```\nyum install memcached python-memcached -y\nsed -i \"s/OPTIONS=\\\"-l 127.0.0.1,::1\\\"/OPTIONS=\\\"-l 127.0.0.1,::1,controller-1\\\"/g\" /etc/sysconfig/memcached\nsed -i 's/^CACHESIZE=\"64\"$/CACHESIZE=\"1024\"/' /etc/sysconfig/memcached\n#增加 Memcached 服务器的缓存大小\nsystemctl enable memcached --now\n```\n\n注意这里的-l 127.0.0.1,::1,controller-1中controller-1是你的主机名，后续不做解释\n\n## keystone（身份验证服务）\n\n<font color='red'>操作节点[controller-1]</font>\n\n```\nmysql -u root -pMARIADB_PASS\nCREATE DATABASE keystone;\nGRANT ALL PRIVILEGES ON keystone.* TO 'keystone'@'localhost' IDENTIFIED BY 'KEYSTONE_DBPASS';\nGRANT ALL PRIVILEGES ON keystone.* TO 'keystone'@'%' IDENTIFIED BY 'KEYSTONE_DBPASS';\nflush privileges;\nexit\n\nyum install yum-utils openstack-keystone httpd mod_wsgi -y\nmv /etc/keystone/keystone.conf{,.bak}\ncat> /etc/keystone/keystone.conf << EOF\n[database]\nconnection = mysql+pymysql://keystone:KEYSTONE_DBPASS@controller-1/keystone\n[token]\nprovider = fernet\nEOF\n#同步服务器\nsu -s /bin/sh -c \"keystone-manage db_sync\" keystone\n#查看是否成功\nmysql -u keystone -p\"KEYSTONE_DBPASS\"\nuse keystone;\nshow tables;\nexit\n#有表就行\n\nkeystone-manage fernet_setup --keystone-user keystone --keystone-group keystone\nkeystone-manage credential_setup --keystone-user keystone --keystone-group keystone\nkeystone-manage bootstrap --bootstrap-password 123456 \\\n  --bootstrap-admin-url http://controller-1:5000/v3/ \\\n  --bootstrap-internal-url http://controller-1:5000/v3/ \\\n  --bootstrap-public-url http://controller-1:5000/v3/ \\\n  --bootstrap-region-id RegionOne\n  \ncp /etc/httpd/conf/httpd.conf{,.bak}\nsed -i \"s/#ServerName www.example.com:80/ServerName controller-1/g\" /etc/httpd/conf/httpd.conf\nln -s /usr/share/keystone/wsgi-keystone.conf /etc/httpd/conf.d/\nsystemctl enable httpd  --now\n\n#配置管理员和测试用户账号（很重要）\ncat > /root/admin-openrc <<\"EOF\"\nexport OS_USERNAME=admin\nexport OS_PASSWORD=123456\nexport OS_PROJECT_NAME=admin\nexport OS_USER_DOMAIN_NAME=Default\nexport OS_PROJECT_DOMAIN_NAME=Default\nexport OS_AUTH_URL=http://controller-1:5000/v3\nexport OS_IDENTITY_API_VERSION=3\nEOF\n\ncat >user_dog-openrc << EOF\nexport OS_USERNAME=user_dog\nexport OS_PASSWORD=123456\nexport OS_PROJECT_NAME=Train\nexport OS_USER_DOMAIN_NAME=RegionOne\nexport OS_PROJECT_DOMAIN_NAME=RegionOne\nexport OS_AUTH_URL=http://controller-1:5000/v3\nexport OS_IDENTITY_API_VERSION=3\nEOF\n\nsource admin-openrc\n\n#创建域、项目、用户、角色\n# 创建一个 RegionOne 域名作为后续云实例创建域名\nopenstack domain create --description \"RegionOne Domain\" RegionOne\n# service 项目 创建在 default 用于 OpenStack 服务\nopenstack project create --domain default \\\n  --description \"Service Project\" service\n# 在 RegionOne 域中创建一个 Train 项目\nopenstack project create --domain RegionOne \\\n  --description \"Train Project\" Train\n  \n# 在 RegionOne 域中创建普通用户 user_dog \nopenstack user create --domain RegionOne \\\n  --password 123456 user_dog\n# 创建普通用户 user_dog  的规则 user_dog_role\nopenstack role create user_dog_role\n# 将规则与用户绑定\nopenstack role add --project Train --user user_dog user_dog_role\n# 注：可以重复上边步骤以创建更多项目、用户及规则\n\n\n# 验证服务可用性\n# 卸载 admin 用户的环境\nunset OS_AUTH_URL OS_PASSWORD\n# 验证 admin 用户可用性\nopenstack --os-auth-url http://controller-1:5000/v3 \\\n  --os-project-domain-name Default --os-user-domain-name Default --os-project-name admin --os-username admin token issue\n# 输入后将要求输入 管理员 admin 的密码\n# 返回  token 信息则服务正常\n\n# 验证 user_dog 用户可用性\nopenstack --os-auth-url http://controller-1:5000/v3 \\\n  --os-project-domain-name RegionOne --os-user-domain-name RegionOne --os-project-name Train --os-username user_dog token issue\n\nsource admin-openrc\n# 列举当前所有域名\nopenstack domain list\n[root@controller-1 ~]# openstack domain list\n+----------------------------------+-----------+---------+--------------------+\n| ID                               | Name      | Enabled | Description        |\n+----------------------------------+-----------+---------+--------------------+\n| 4b4ebbd4e4054ed3a7be6414787c8514 | RegionOne | True    | RegionOne Domain   |\n| default                          | Default   | True    | The default domain |\n+----------------------------------+-----------+---------+--------------------+\n[root@controller-1 ~]#\n\n```\n\n## Glance（镜像服务）\n\n<font color='red'>操作节点[controller-1]</font>\n\n```\n#控制节点\nmysql -u root -pMARIADB_PASS\nCREATE DATABASE glance;\nGRANT ALL PRIVILEGES ON glance.* TO 'glance'@'localhost' \\\n  IDENTIFIED BY 'GLANCE_DBPASS';\nGRANT ALL PRIVILEGES ON glance.* TO 'glance'@'%' \\\n  IDENTIFIED BY 'GLANCE_DBPASS';\nflush privileges;\nexit\n#将 GLANCE_DBPASS 替换为 glance数据库服务的密码\nsource admin-openrc\n#创建用户服务和api端点\nopenstack user create --domain default --password GLANCE_PASS glance\n#GLANCE_PASS 为 glance 服务的密码\n\n# 为 Glance 用户添加 admin 规则到系统项目 service\nopenstack role add --project service --user glance admin\n# 没有输出内容\n\n# 为 Glance 添加管理镜像的服务\nopenstack service create --name glance \\\n  --description \"OpenStack Image\" image\n\n# 为 RegionOne 域名添加服务接口\nopenstack endpoint create --region RegionOne \\\n  image public http://controller-1:9292\n\nopenstack endpoint create --region RegionOne \\\n  image internal http://controller-1:9292\n\nopenstack endpoint create --region RegionOne \\\n  image admin http://controller-1:9292\n\n#安装glance服务\nyum install openstack-glance -y\nmv /etc/glance/glance-api.conf{,.bak}\ncat >/etc/glance/glance-api.conf << EOF\n[DEFAULT]\nuse_keystone_quotas = True\nlog_file = /var/log/glance/glance.log\n[database]\nconnection = mysql+pymysql://glance:GLANCE_DBPASS@controller-1/glance\n# GLANCE_DBPASS 为 Glance 服务的数据库账户密码\n[keystone_authtoken]\nwww_authenticate_uri  = http://controller-1:5000\nauth_url = http://controller-1:5000\nmemcached_servers = controller-1:11211\nauth_type = password\nproject_domain_name = Default\nuser_domain_name = Default\nproject_name = service\nusername = glance\npassword = GLANCE_PASS\nservice_token_roles_required = true\n# GLANCE_PASS 为 Glance 服务的数据库账户密码\n[paste_deploy]\nflavor = keystone\n[glance_store]\nstores = file,http\ndefault_store = file\ndefault_backend = {'store_one': 'http', 'store_two': 'file'}\nfilesystem_store_datadir = /var/lib/glance/images/\nEOF\n# 同步 Glance 数据到数据库\nsu -s /bin/sh -c \"glance-manage db_sync\" glance\nsystemctl enable openstack-glance-api  --now\n# 验证服务可用性\nsource admin-openrc\nwget https://download.cirros-cloud.net/0.6.2/cirros-0.6.2-x86_64-disk.img\n#可能会下载不到，可以复制链接到浏览器下载，然后移到/root/目录下\nglance image-create --name \"cirros\" \\\n  --file cirros-0.6.2-x86_64-disk.img \\\n  --disk-format qcow2 --container-format bare \\\n  --visibility=public\n\nopenstack image list\n\n[root@controller-1 ~]# openstack image list\n+--------------------------------------+--------+--------+\n| ID                                   | Name   | Status |\n+--------------------------------------+--------+--------+\n| 627761da-7f8c-4780-842a-e50e62f5c464 | cirros | active |\n+--------------------------------------+--------+--------+\n\n```\n\n## Placement（资源调度）\n\n<font color='red'>操作节点[controller-1]</font>\n\n```\nmysql -u root -pMARIADB_PASS\nCREATE DATABASE placement;\nGRANT ALL PRIVILEGES ON placement.* TO 'placement'@'localhost'  IDENTIFIED BY 'PLACEMENT_DBPASS';\nGRANT ALL PRIVILEGES ON placement.* TO 'placement'@'%' IDENTIFIED BY 'PLACEMENT_DBPASS';\nflush privileges;\nexit\n\n#PLACEMENT_DBPASS 为 placement 服务的密码\nsource admin-openrc\nopenstack user create --domain default --password PLACEMENT_PASS placement\nopenstack role add --project service --user placement admin\nopenstack service create --name placement \\\n  --description \"Placement API\" placement\nopenstack endpoint create --region RegionOne \\\n  placement public http://controller-1:8778\nopenstack endpoint create --region RegionOne \\\n  placement internal http://controller-1:8778\nopenstack endpoint create --region RegionOne \\\n  placement admin http://controller-1:8778\nyum install openstack-placement-api -y\nmv /etc/placement/placement.conf{,.bak}\ncat > /etc/placement/placement.conf << EOF\n[placement_database]\nconnection = mysql+pymysql://placement:PLACEMENT_DBPASS@controller-1/placement\n# PLACEMENT_DBPASS 为 placement 服务的数据库账户密码\n[api]\nauth_strategy = keystone\n[keystone_authtoken]\nauth_url = http://controller-1:5000/v3\nmemcached_servers = controller-1:11211\nauth_type = password\nproject_domain_name = Default\nuser_domain_name = Default\nproject_name = service\nusername = placement\npassword = PLACEMENT_PASS\n# PLACEMENT_PASS 为 placement 服务的密码\nEOF\n\n#同步数据库\nsu -s /bin/sh -c \"placement-manage db sync\" placement\ncp /etc/httpd/conf.d/00-placement-api.conf{,.bak}\ncat >> /etc/httpd/conf.d/00-placement-api.conf << EOF\n#在#SSLCertificateKeyFile ...下添加\n<Directory /usr/bin>\n<IfVersion >= 2.4>\n\tRequire all granted\n</IfVersion>\n<IfVersion < 2.4>\n\tOrder allow,deny\t\n\tAllow from all\n</IfVersion>\n</Directory>\nEOF\nsystemctl restart httpd\n\n# 验证服务\nsource admin-openrc\nplacement-status upgrade check\n#安装pip osc组件验证资源\nyum install epel-release -y\nyum install python-pip -y\npip install osc-placement==2.2.0\nsystemctl restart httpd\n\n# 验证\nopenstack --os-placement-api-version 1.2 resource class list --sort-column name\n# +----------------------------------------+\n# | name                                   |\n# +----------------------------------------+\n# | DISK_GB                                |\n......\n\nopenstack --os-placement-api-version 1.6 trait list --sort-column name\n+---------------------------------------+\n| name                                  |\n+---------------------------------------+\n| COMPUTE_DEVICE_TAGGING                |\n| COMPUTE_GRAPHICS_MODEL_CIRRUS         |\n\n```\n\n## Nova（计算服务）\n\n### <font color='red'>操作节点[controller-1]</font>\n\n```\n#控制节点controller-1\nmysql -u root -pMARIADB_PASS\nCREATE DATABASE nova_api;\nCREATE DATABASE nova;\nCREATE DATABASE nova_cell0;\nGRANT ALL PRIVILEGES ON nova_api.* TO 'nova'@'localhost' \\\n  IDENTIFIED BY 'NOVA_DBPASS';\nGRANT ALL PRIVILEGES ON nova_api.* TO 'nova'@'%' \\\n  IDENTIFIED BY 'NOVA_DBPASS';\nGRANT ALL PRIVILEGES ON nova.* TO 'nova'@'localhost' \\\n  IDENTIFIED BY 'NOVA_DBPASS';\nGRANT ALL PRIVILEGES ON nova.* TO 'nova'@'%' \\\n  IDENTIFIED BY 'NOVA_DBPASS';\nGRANT ALL PRIVILEGES ON nova_cell0.* TO 'nova'@'localhost' \\\n  IDENTIFIED BY 'NOVA_DBPASS';\nGRANT ALL PRIVILEGES ON nova_cell0.* TO 'nova'@'%' \\\n  IDENTIFIED BY 'NOVA_DBPASS';\nflush privileges;\nexit\n\n# NOVA_DBPASS 为 nova 服务的密码\n\nsource admin-openrc\nopenstack user create --domain default --password NOVA_PASS nova\nopenstack role add --project service --user nova admin\nopenstack service create --name nova \\\n  --description \"OpenStack Compute\" compute\nopenstack endpoint create --region RegionOne \\\n  compute public http://controller-1:8774/v2.1\nopenstack endpoint create --region RegionOne \\\n  compute internal http://controller-1:8774/v2.1\nopenstack endpoint create --region RegionOne \\\n  compute admin http://controller-1:8774/v2.1\nmv /etc/yum.repos.d/epel.repo{,.bak} \nyum install -y \\\n    openstack-nova-api \\\n    openstack-nova-scheduler \\\n    openstack-nova-conductor \\\n    openstack-nova-novncproxy\n#mv /etc/yum.repos.d/epel.repo{.bak,} \nmv /etc/nova/nova.conf{,.bak}\ncat > /etc/nova/nova.conf <<EOF\n[DEFAULT]\nenabled_apis = osapi_compute,metadata\ntransport_url = rabbit://openstack:RABBIT_PASS@controller-1:5672/\n# RABBIT_PASS为 rabbitmq 密码\nmy_ip = 192.168.148.101\n# 控制节点管理网络的 IP\nlog_file = /var/log/nova/nova-controller.log\nrootwrap_config = /etc/nova/rootwrap.conf\n[api_database]\nconnection = mysql+pymysql://nova:NOVA_DBPASS@controller-1/nova_api\n# NOVA_DBPASS 为数据库 Nova 账户密码\n[database]\nconnection = mysql+pymysql://nova:NOVA_DBPASS@controller-1/nova\n# NOVA_DBPASS 为数据库 Nova 账户密码\n[api]\nauth_strategy = keystone\n[keystone_authtoken]\nwww_authenticate_uri = http://controller-1:5000/\nauth_url = http://controller-1:5000/\nmemcached_servers = controller-1:11211\nauth_type = password\nproject_domain_name = Default\nuser_domain_name = Default\nproject_name = service\nusername = nova\npassword =NOVA_PASS\n# NOVA_PASS 为 Nova 服务的密码\n[vnc]\nenabled = true\nserver_listen = \\$my_ip\nserver_proxyclient_address = \\$my_ip\n[glance]\napi_servers = http://controller-1:9292\n[oslo_concurrency]\nlock_path = /var/run/nova\n[placement]\nregion_name = RegionOne\nproject_domain_name = Default\nproject_name = service\nauth_type = password\nuser_domain_name = Default\nauth_url = http://controller-1:5000/v3\nusername = placement\npassword = PLACEMENT_PASS\n# PLACEMENT_PASS 为 placement 服务的密码\nEOF\nsu -s /bin/sh -c \"nova-manage api_db sync\" nova\nsu -s /bin/sh -c \"nova-manage cell_v2 map_cell0\" nova\nsu -s /bin/sh -c \"nova-manage cell_v2 create_cell --name=cell1 --verbose\" nova\nsu -s /bin/sh -c \"nova-manage db sync\" nova\n\n# 验证\n\nsu -s /bin/sh -c \"nova-manage cell_v2 list_cells\" nova\n\nsystemctl enable --now \\\n    openstack-nova-api.service \\\n    openstack-nova-scheduler.service \\\n    openstack-nova-conductor.service \\\n    openstack-nova-novncproxy.service\n    \nsystemctl status \\\n    openstack-nova-api.service \\\n    openstack-nova-scheduler.service \\\n    openstack-nova-conductor.service \\\n    openstack-nova-novncproxy.service\n    \n```\n\n### <font color='red'>操作节点[computer-2]</font>\n\n```\n##computer-2计算节点\nyum install openstack-nova-compute -y\nmv /etc/nova/nova.conf{,.bak}\ncat > /etc/nova/nova.conf <<EOF\n[DEFAULT]\nenabled_apis = osapi_compute,metadata\ntransport_url = rabbit://openstack:RABBIT_PASS@controller-1\nmy_ip = 192.168.148.102\ncompute_driver=libvirt.LibvirtDriver\nlog_file = /var/log/nova/nova-compute.log\n# 192.168.148.102替换为 计算节点管理网络 IP 地址\n[api]\nauth_strategy = keystone\n[keystone_authtoken]\nwww_authenticate_uri = http://controller-1:5000/\nauth_url = http://controller-1:5000/\nmemcached_servers = controller-1:11211\nauth_type = password\nproject_domain_name = Default\nuser_domain_name = Default\nproject_name = service\nusername = nova\npassword = NOVA_PASS\n#NOVA_PASS为nova服务密码\n[vnc]\nenabled = true\nserver_listen = 0.0.0.0\nserver_proxyclient_address = \\$my_ip\nnovncproxy_base_url = http://192.168.48.101:6080/vnc_auto.html\n# 将 192.168.48.101修改为控制节点的外部网络 IP （ens33）,不是ens36\n[glance]\napi_servers = http://controller-1:9292\n[oslo_concurrency]\nlock_path = /var/lib/nova/tmp\n[placement]\nregion_name = RegionOne\nproject_domain_name = Default\nproject_name = service\nauth_type = password\nuser_domain_name = Default\nauth_url = http://controller-1:5000/v3\nusername = placement\npassword = PLACEMENT_PASS\n#PLACEMENT_PASS 为 Placement 服务密码\nEOF\n\negrep -c '(vmx|svm)' /proc/cpuinfo\n---------------------------------------------------------------------------------\n# 如果返回值大于 1 则说明已经开启硬件虚拟化，无需配置 qemu\n# 如等于 0 ，则需要配置 qemu 以代替默认的 kvm\nvi /etc/nova/nova.conf\n[libvirt]\n# ...\nvirt_type = qemu\n\n# 以上配置仅当 egrep -c '(vmx|svm)' /proc/cpuinfo 结果为 0 时才进行配置\n---------------------------------------------------------------------------------\nsystemctl enable libvirtd.service openstack-nova-compute.service --now\nsystemctl status libvirtd.service openstack-nova-compute.service \n```\n\n### <font color='red'>操作节点[computer-3]</font>\n\n```\nyum install openstack-nova-compute -y\nmv /etc/nova/nova.conf{,.bak}\ncat > /etc/nova/nova.conf <<EOF\n[DEFAULT]\nenabled_apis = osapi_compute,metadata\ntransport_url = rabbit://openstack:RABBIT_PASS@controller-1\nmy_ip = 192.168.148.103\ncompute_driver=libvirt.LibvirtDriver\nlog_file = /var/log/nova/nova-compute.log\n# 192.168.148.103替换为 计算节点管理网络 IP 地址\n[api]\nauth_strategy = keystone\n[keystone_authtoken]\nwww_authenticate_uri = http://controller-1:5000/\nauth_url = http://controller-1:5000/\nmemcached_servers = controller-1:11211\nauth_type = password\nproject_domain_name = Default\nuser_domain_name = Default\nproject_name = service\nusername = nova\npassword = NOVA_PASS\n#NOVA_PASS为nova服务密码\n[vnc]\nenabled = true\nserver_listen = 0.0.0.0\nserver_proxyclient_address = \\$my_ip\nnovncproxy_base_url = http://192.168.48.101:6080/vnc_auto.html\n# 将 192.168.48.101修改为控制节点的外部网络 IP （ens33）,不是ens36\n[glance]\napi_servers = http://controller-1:9292\n[oslo_concurrency]\nlock_path = /var/lib/nova/tmp\n[placement]\nregion_name = RegionOne\nproject_domain_name = Default\nproject_name = service\nauth_type = password\nuser_domain_name = Default\nauth_url = http://controller-1:5000/v3\nusername = placement\npassword = PLACEMENT_PASS\n#PLACEMENT_PASS 为 Placement 服务密码\nEOF\n\negrep -c '(vmx|svm)' /proc/cpuinfo\n---------------------------------------------------------------------------------\n# 如果返回值大于 1 则说明已经开启硬件虚拟化，无需配置 qemu\n# 如等于 0 ，则需要配置 qemu 以代替默认的 kvm\nvi /etc/nova/nova.conf\n[libvirt]\n# ...\nvirt_type = qemu\n\n# 以上配置仅当 egrep -c '(vmx|svm)' /proc/cpuinfo 结果为 0 时才进行配置\n---------------------------------------------------------------------------------\n\nsystemctl enable libvirtd.service openstack-nova-compute.service --now\nsystemctl status libvirtd.service openstack-nova-compute.service \n```\n\n### 验证\n\n操作节点[controller-1]\n\n```\nsource admin-openrc\nopenstack compute service list --service nova-compute\n\n[root@controller-1 ~]# openstack compute service list --service nova-compute\n+----+--------------+------------+------+---------+-------+----------------------------+\n| ID | Binary       | Host       | Zone | Status  | State | Updated At                 |\n+----+--------------+------------+------+---------+-------+----------------------------+\n|  9 | nova-compute | computer-2 | nova | enabled | up    | 2024-01-04T17:00:00.000000 |\n| 10 | nova-compute | computer-3 | nova | enabled | up    | 2024-01-04T17:00:06.000000 |\n+----+--------------+------------+------+---------+-------+----------------------------+\n\n# 在控制节点执行验证\nsu -s /bin/sh -c \"nova-manage cell_v2 discover_hosts --verbose\" nova\n[root@controller-1 ~]# su -s /bin/sh -c \"nova-manage cell_v2 discover_hosts --verbose\" nova\nFound 2 cell mappings.\nSkipping cell0 since it does not contain hosts.\nGetting computes from cell 'cell1': a1cc1ff2-388b-46c3-b8ea-b92c1182fbc8\nChecking host mapping for compute host 'computer-2': cddb3327-9712-411d-8592-eb39a5eb240e\nCreating host mapping for compute host 'computer-2': cddb3327-9712-411d-8592-eb39a5eb240e\nChecking host mapping for compute host 'computer-3': fb280b19-efde-4e26-972a-0ba060be847e\nCreating host mapping for compute host 'computer-3': fb280b19-efde-4e26-972a-0ba060be847e\n\n#追加在末尾\ncat >>/etc/nova/nova.conf << EOF\n[scheduler]\ndiscover_hosts_in_cells_interval = 300\nEOF\ndiscover_hosts_in_cells_interval 参数指定了调度器发现主机的间隔时间，单位为秒。默认值为 300 秒（即 5 分钟）。这意味着调度器每隔 5 分钟会检查并发现新的主机。\n```\n\n## Neutron（网络服务）\n\n### <font color='red'>操作节点[controller-1]</font>\n\n```\n##控制节点controller-1\nmysql -u root -pMARIADB_PASS\nCREATE DATABASE neutron;\nGRANT ALL PRIVILEGES ON neutron.* TO 'neutron'@'localhost' \\\n  IDENTIFIED BY 'NEUTRON_DBPASS';\nGRANT ALL PRIVILEGES ON neutron.* TO 'neutron'@'%' \\\n  IDENTIFIED BY 'NEUTRON_DBPASS';\nflush privileges;\nexit\nsource admin-openrc\nopenstack user create --domain default --password NEUTRON_PASS neutron\nopenstack role add --project service --user neutron admin\nopenstack service create --name neutron \\\n  --description \"OpenStack Networking\" network\nopenstack endpoint create --region RegionOne \\\n  network public http://controller-1:9696\nopenstack endpoint create --region RegionOne \\\n  network internal http://controller-1:9696\nopenstack endpoint create --region RegionOne \\\n  network admin http://controller-1:9696\n# 选择安装 大二层 网络\nyum install openstack-neutron openstack-neutron-ml2 \\\n  openstack-neutron-linuxbridge ebtables -y\n\nmv /etc/neutron/neutron.conf{,.bak}\ncat > /etc/neutron/neutron.conf <<EOF\n\n[database]\nconnection = mysql+pymysql://neutron:NEUTRON_DBPASS@controller-1/neutron\n#NEUTRON_DBPASS为 数据库 neutron 账户密码\n[DEFAULT]\ncore_plugin = ml2\nservice_plugins = router\nallow_overlapping_ips = true\ntransport_url = rabbit://openstack:RABBIT_PASS@controller-1\nauth_strategy = keystone\nnotify_nova_on_port_status_changes = true\nnotify_nova_on_port_data_changes = true\n# RABBIT_PASS 为 消息队列密码\n[keystone_authtoken]\nwww_authenticate_uri = http://controller-1:5000\nauth_url = http://controller-1:5000\nmemcached_servers = controller-1:11211\nauth_type = password\nproject_domain_name = default\nuser_domain_name = default\nproject_name = service\nusername = neutron\npassword = NEUTRON_PASS\n# NEUTRON_PASS为 neutron 服务密码\n[nova]\nauth_url = http://controller-1:5000\nauth_type = password\nproject_domain_name = default\nuser_domain_name = default\nregion_name = RegionOne\nproject_name = service\nusername = nova\npassword = NOVA_PASS\n# [nova]  没有则添加\n# NOVA_PASS为 Nova 服务密码\n[oslo_concurrency]\nlock_path = /var/lib/neutron/tmp\nEOF\n\nmv /etc/neutron/plugins/ml2/ml2_conf.ini{,.bak}\ncat > /etc/neutron/plugins/ml2/ml2_conf.ini << EOF\n\n[ml2]\ntype_drivers = flat,vlan,vxlan\ntenant_network_types = vxlan\nmechanism_drivers = linuxbridge,l2population\nextension_drivers = port_security\n[ml2_type_flat]\nflat_networks = provider\n[ml2_type_vxlan]\nvni_ranges = 1:1000\n[securitygroup]\nenable_ipset = true\nEOF\n\nmv /etc/neutron/plugins/ml2/linuxbridge_agent.ini{,.bak}\ncat > /etc/neutron/plugins/ml2/linuxbridge_agent.ini <<EOF\n\n[linux_bridge]\nphysical_interface_mappings = provider:ens36\n# ens36 为第二块网卡名称\n[vxlan]\nenable_vxlan = true\nlocal_ip = 192.168.148.101\nl2_population = true\n# 192.168.148.101 为管理网络 控制节点的 IP  即 controller-1 IP\n[securitygroup]\nenable_security_group = true\nfirewall_driver = neutron.agent.linux.iptables_firewall.IptablesFirewallDriver\nEOF\n\nmv /etc/neutron/l3_agent.ini{,.bak}\ncat > /etc/neutron/l3_agent.ini << EOF\n\n[DEFAULT]\ninterface_driver = linuxbridge\nEOF\n\nmv /etc/neutron/dhcp_agent.ini{,.bak}\ncat > /etc/neutron/dhcp_agent.ini << EOF\n\n[DEFAULT]\ninterface_driver = linuxbridge\ndhcp_driver = neutron.agent.linux.dhcp.Dnsmasq\nenable_isolated_metadata = true\nEOF\n\n----------------------\n\nmodprobe br_netfilter\ncat >>/etc/rc.sysinit<<EOF\n\n#!/bin/bash\nfor file in /etc/sysconfig/modules/*.modules ; do\n[ -x $file ] && $file\ndone\nEOF\necho \"modprobe br_netfilter\" >/etc/sysconfig/modules/br_netfilter.modules\nchmod 755 /etc/sysconfig/modules/br_netfilter.modules\nsysctl -a | grep net.bridge.bridge-nf-call\n----------------------\n\nmv /etc/neutron/metadata_agent.ini{,.bak}\ncat >> /etc/neutron/metadata_agent.ini << EOF\n\n[DEFAULT]\nnova_metadata_host = controller-1\nmetadata_proxy_shared_secret = METADATA_SECRET\n# METADATA_SECRET 为 元数据 的密钥\nEOF\n\ncat >> /etc/nova/nova.conf << EOF\n\n#追加在末尾\n[neutron]\nauth_url = http://controller-1:5000\nauth_type = password\nproject_domain_name = default\nuser_domain_name = default\nregion_name = RegionOne\nproject_name = service\nusername = neutron\npassword = NEUTRON_PASS\nservice_metadata_proxy = true\nmetadata_proxy_shared_secret = METADATA_SECRET\n#NEUTRON_PASS  为 neutron 服务的密码\n#METADATA_SECRET 为上边设置的元数据密钥\nEOF\n\n-------------------\n\nln -s /etc/neutron/plugins/ml2/ml2_conf.ini /etc/neutron/plugin.ini\n\nsu -s /bin/sh -c \"neutron-db-manage --config-file /etc/neutron/neutron.conf --config-file /etc/neutron/plugins/ml2/ml2_conf.ini upgrade head\" neutron\n\nsystemctl restart openstack-nova-api.service\n\nsystemctl enable --now neutron-server.service neutron-linuxbridge-agent.service neutron-dhcp-agent.service neutron-metadata-agent.service neutron-l3-agent.service\n\nsystemctl status neutron-server.service  neutron-linuxbridge-agent.service neutron-dhcp-agent.service   neutron-metadata-agent.service  neutron-l3-agent.service\n\n```\n\n### <font color='red'>操作节点[computer-2]</font>\n\n```\n###compute计算节点\nyum install openstack-neutron-linuxbridge ebtables ipset -y \n\nmv /etc/neutron/neutron.conf{,.bak}\ncat > /etc/neutron/neutron.conf << EOF\n[DEFAULT]\ntransport_url = rabbit://openstack:RABBIT_PASS@controller-1\n#RABBIT_PASS为 控制节点 消息队列 密码\nauth_strategy = keystone\n[keystone_authtoken]\nwww_authenticate_uri = http://controller-1:5000\nauth_url = http://controller-1:5000\nmemcached_servers = controller-1:11211\nauth_type = password\nproject_domain_name = default\nuser_domain_name = default\nproject_name = service\nusername = neutron\npassword = NEUTRON_PASS\n# NEUTRON_PASS  为控制节点 neutron 服务密码\n[oslo_concurrency]\nlock_path = /var/lib/neutron/tmp\nEOF\n\nmv /etc/neutron/plugins/ml2/linuxbridge_agent.ini{,.bak}\ncat >> /etc/neutron/plugins/ml2/linuxbridge_agent.ini <<EOF\n[linux_bridge]\nphysical_interface_mappings = provider:ens36\n# ens36 为 第二块网卡名字\n[vxlan]\nenable_vxlan = true\nlocal_ip = 192.168.148.102\nl2_population = true\n# 192.168.148.102  为 computer-2 管理网络的 IP 地址\n[securitygroup]\nenable_security_group = true\nfirewall_driver = neutron.agent.linux.iptables_firewall.IptablesFirewallDriver\nEOF\n\ncat >> /etc/nova/nova.conf << EOF\n[neutron]\nauth_url = http://controller-1:5000\nauth_type = password\nproject_domain_name = default\nuser_domain_name = default\nregion_name = RegionOne\nproject_name = service\nusername = neutron\npassword = NEUTRON_PASS\nservice_metadata_proxy = true\nmetadata_proxy_shared_secret = METADATA_SECRET\n# NEUTRON_PASS  为 neutron 服务的密码\n# METADATA_SECRET 为上边设置的元数据密钥\n\nEOF\n-------------------\nmodprobe br_netfilter\ncat >>/etc/rc.sysinit<<EOF\n#!/bin/bash\nfor file in /etc/sysconfig/modules/*.modules ; do\n[ -x $file ] && $file\ndone\nEOF\necho \"modprobe br_netfilter\" >/etc/sysconfig/modules/br_netfilter.modules\nchmod 755 /etc/sysconfig/modules/br_netfilter.modules\nsysctl -a | grep net.bridge.bridrge-nf-call\n-------------------\nsystemctl enable neutron-linuxbridge-agent.service --now\nsystemctl restart openstack-nova-compute.service neutron-linuxbridge-agent.service\nsystemctl status neutron-linuxbridge-agent.service\n\n```\n\n### <font color='red'>操作节点[computer-3]</font>\n\n```\n###compute计算节点\nyum install openstack-neutron-linuxbridge ebtables ipset -y \n\nmv /etc/neutron/neutron.conf{,.bak}\ncat > /etc/neutron/neutron.conf << EOF\n[DEFAULT]\ntransport_url = rabbit://openstack:RABBIT_PASS@controller-1\n#RABBIT_PASS为 控制节点 消息队列 密码\nauth_strategy = keystone\n[keystone_authtoken]\nwww_authenticate_uri = http://controller-1:5000\nauth_url = http://controller-1:5000\nmemcached_servers = controller-1:11211\nauth_type = password\nproject_domain_name = default\nuser_domain_name = default\nproject_name = service\nusername = neutron\npassword = NEUTRON_PASS\n# NEUTRON_PASS  为控制节点 neutron 服务密码\n[oslo_concurrency]\nlock_path = /var/lib/neutron/tmp\nEOF\n\nmv /etc/neutron/plugins/ml2/linuxbridge_agent.ini{,.bak}\ncat >> /etc/neutron/plugins/ml2/linuxbridge_agent.ini <<EOF\n[linux_bridge]\nphysical_interface_mappings = provider:ens36\n# ens36 为 第二块网卡名字\n[vxlan]\nenable_vxlan = true\nlocal_ip = 192.168.148.103\nl2_population = true\n# 192.168.148.103  为 computer-3 管理网络的 IP 地址\n[securitygroup]\nenable_security_group = true\nfirewall_driver = neutron.agent.linux.iptables_firewall.IptablesFirewallDriver\nEOF\n\ncat >> /etc/nova/nova.conf << EOF\n[neutron]\nauth_url = http://controller-1:5000\nauth_type = password\nproject_domain_name = default\nuser_domain_name = default\nregion_name = RegionOne\nproject_name = service\nusername = neutron\npassword = NEUTRON_PASS\nservice_metadata_proxy = true\nmetadata_proxy_shared_secret = METADATA_SECRET\n# NEUTRON_PASS  为 neutron 服务的密码\n# METADATA_SECRET 为上边设置的元数据密钥\n\nEOF\n-------------------\nmodprobe br_netfilter\ncat >>/etc/rc.sysinit<<EOF\n#!/bin/bash\nfor file in /etc/sysconfig/modules/*.modules ; do\n[ -x $file ] && $file\ndone\nEOF\necho \"modprobe br_netfilter\" >/etc/sysconfig/modules/br_netfilter.modules\nchmod 755 /etc/sysconfig/modules/br_netfilter.modules\nsysctl -a | grep net.bridge.bridrge-nf-call\n-------------------\nsystemctl enable neutron-linuxbridge-agent.service --now\nsystemctl restart openstack-nova-compute.service neutron-linuxbridge-agent.service\nsystemctl status neutron-linuxbridge-agent.service\n\n```\n\n### 验证\n\n<font color='red'>操作节点[controller-1]</font>\n\n```\nsource admin-openrc\nopenstack network agent list\n#确保六个都是up在做下一步\n[root@controller-1 ~]# openstack network agent list\n+--------------------------------------+--------------------+--------------+-------------------+-------+-------+---------------------------+\n| ID                                   | Agent Type         | Host         | Availability Zone | Alive | State | Binary                    |\n+--------------------------------------+--------------------+--------------+-------------------+-------+-------+---------------------------+\n| 33e3f611-c4e6-4f0c-abe0-ba22afaa7fba | Linux bridge agent | computer-2   | None              | :-)   | UP    | neutron-linuxbridge-agent |\n| 485af228-87fd-4270-8e35-cca6562910ce | L3 agent           | controller-1 | nova              | :-)   | UP    | neutron-l3-agent          |\n| 68c8b1e7-e75a-4adb-9c92-6ceea4983b65 | Linux bridge agent | computer-3   | None              | :-)   | UP    | neutron-linuxbridge-agent |\n| 96db82bf-d658-474e-b44a-db270bf0d677 | DHCP agent         | controller-1 | nova              | :-)   | UP    | neutron-dhcp-agent        |\n| c6f55bf1-5140-43fe-a0b2-1d7248539f7e | Linux bridge agent | controller-1 | None              | :-)   | UP    | neutron-linuxbridge-agent |\n| f396cc24-9168-4fd0-aaba-869842315caf | Metadata agent     | controller-1 | None              | :-)   | UP    | neutron-metadata-agent    |\n+--------------------------------------+--------------------+--------------+-------------------+-------+-------+---------------------------+\n[root@controller-1 ~]#\n\n```\n\n## Horizon（界面服务）\n\n<font color='red'>操作节点[controller-1]</font>\n\n```\n###控制节点\nyum install openstack-dashboard -y\ncp /etc/openstack-dashboard/local_settings{,.bak}\n#注释以下信息\nsed -i 's/^ALLOWED_HOSTS/#&/' /etc/openstack-dashboard/local_settings\nsed -i 's/^OPENSTACK_HOST/#&/' /etc/openstack-dashboard/local_settings\nsed -i 's/^OPENSTACK_KEYSTONE_URL/#&/' /etc/openstack-dashboard/local_settings\nsed -i 's/^TIME_ZONE/#&/' /etc/openstack-dashboard/local_settings\n\n追加内容\ncat >> /etc/openstack-dashboard/local_settings <<EOF\nALLOWED_HOSTS = ['*']\nSESSION_ENGINE = 'django.contrib.sessions.backends.cache'\nCACHES = {\n    'default': {\n         'BACKEND': 'django.core.cache.backends.memcached.MemcachedCache',\n         'LOCATION': 'controller-1:11211',\n    }\n}\nOPENSTACK_HOST = \"controller-1\"\nOPENSTACK_KEYSTONE_URL = \"http://%s:5000/identity/v3\" % OPENSTACK_HOST\nOPENSTACK_KEYSTONE_MULTIDOMAIN_SUPPORT = True\nOPENSTACK_API_VERSIONS = {\n    \"identity\": 3,\n    \"image\": 2,\n    \"volume\": 3,\n}\nOPENSTACK_KEYSTONE_DEFAULT_DOMAIN = \"Default\"\nOPENSTACK_KEYSTONE_DEFAULT_ROLE = \"user\"\nTIME_ZONE = \"Asia/Shanghai\"\n# 有则修改没有则添加\nEOF\necho \"WEBROOT = '/dashboard'\" >> /etc/openstack-dashboard/local_settings\nsed -i \"s/'enable_distributed_router': False,/'enable_distributed_router': True,/g\" /etc/openstack-dashboard/local_settings\nsed -i \"s/'enable_ha_router': False,/'enable_ha_router': True,/g\" /etc/openstack-dashboard/local_settings\nsed -i \"/'enable_router': True,/a 'enable_lb': True,\" /etc/openstack-dashboard/local_settings\nsed -i \"/'enable_lb': True,/a 'enable_firewall': True,\" /etc/openstack-dashboard/local_settings\nsed -i \"/'enable_firewall': True,/a 'enable_vpn': True,\" /etc/openstack-dashboard/local_settings\n\ncp /etc/httpd/conf.d/openstack-dashboard.conf{,.bak}\ncat >> /etc/httpd/conf.d/openstack-dashboard.conf << EOF\nWSGIApplicationGroup %{GLOBAL}\nEOF\n\nsystemctl restart httpd memcached\nsystemctl status httpd memcached\n\n# 验证\n# 访问 http://192.168.48.101/dashboard  （控制节点ip）\n# 登录用户密码 可使用 admin 或 user_dog\n# 域名 使用 Default\n```\n\n## Cinder（块存储服务）\n\n### <font color='red'>操作节点[controller-1]</font>\n\n```\n###控制节点\nmysql -u root -pMARIADB_PASS\nCREATE DATABASE cinder;\nGRANT ALL PRIVILEGES ON cinder.* TO 'cinder'@'localhost' \\\n  IDENTIFIED BY 'CINDER_DBPASS';\nGRANT ALL PRIVILEGES ON cinder.* TO 'cinder'@'%' \\\n  IDENTIFIED BY 'CINDER_DBPASS';\nexit\n# CINDER_DBPASS 为 cinder 数据库账户密码\nsource admin-openrc\nopenstack user create --domain default --password CINDER_PASS cinder\nopenstack role add --project service --user cinder admin\n  openstack service create --name cinderv3 \\\n  --description \"OpenStack Block Storage\" volumev3\nopenstack endpoint create --region RegionOne \\\n  volumev3 public http://controller-1:8776/v3/%\\(project_id\\)s\nopenstack endpoint create --region RegionOne \\\n  volumev3 internal http://controller-1:8776/v3/%\\(project_id\\)s\nopenstack endpoint create --region RegionOne \\\n  volumev3 admin http://controller-1:8776/v3/%\\(project_id\\)s\n\nyum install openstack-cinder -y\nmv /etc/cinder/cinder.conf{,.bak}\ncat > /etc/cinder/cinder.conf << EOF\n[DEFAULT]\ntransport_url = rabbit://openstack:RABBIT_PASS@controller-1\nauth_strategy = keystone\nmy_ip = 192.168.148.101\n# 控制节点管理网络 IP\n[database]\nconnection = mysql+pymysql://cinder:CINDER_DBPASS@controller-1/cinder\n# CINDER_DBPASS 为数据库 Cinder 账户密码\n[keystone_authtoken]\nwww_authenticate_uri = http://controller-1:5000\nauth_url = http://controller-1:5000\nmemcached_servers = controller-1:11211\nauth_type = password\nproject_domain_name = default\nuser_domain_name = default\nproject_name = service\nusername = cinder\npassword = CINDER_PASS\n# CINDER_PASS 为 Cinder 服务密码\n[oslo_concurrency]\nlock_path = /var/lib/cinder/tmp\nEOF\n\nsu -s /bin/sh -c \"cinder-manage db sync\" cinder\n\nsystemctl restart openstack-nova-api.service\nsystemctl status openstack-nova-api.service\nsystemctl enable --now openstack-cinder-api.service openstack-cinder-scheduler.service\nsystemctl status openstack-cinder-api.service openstack-cinder-scheduler.service\n```\n\n###  添加物理磁盘\n\n 关闭所有节点(运行不了，请回开头，复制关闭顺序脚本)<font color='red'>（注意关闭顺序，这里不在说明，回头看）</font>\n\n<font color='red'>操作节点[所有节点]</font>\n\n```\nsh stop.sh\n```\n\n给computer-3添加一块100g的磁盘\n\n![image-20240105171301012](../img/OpenStack-Train-%E4%B8%89%E8%8A%82%E7%82%B9%E9%83%A8%E7%BD%B2.assets/c0a1e3c2ee116a980e5d0ad5d7926985697559838.png)\n\n在开机执行\n\n```\nsh start.sh\n```\n\n### <font color='red'>操作节点[computer-3]</font>\n\n```\n###computer-3节点\n\n添加一块物理磁盘\n[root@computer-3 ~]# lsblk\nNAME            MAJ:MIN RM  SIZE RO TYPE MOUNTPOINT\nsda               8:0    0  100G  0 disk\n├─sda1            8:1    0    1G  0 part /boot\n└─sda2            8:2    0   99G  0 part\n  ├─centos-root 253:0    0   50G  0 lvm  /\n  ├─centos-swap 253:1    0  3.6G  0 lvm  [SWAP]\n  └─centos-home 253:2    0 45.4G  0 lvm  /home\nsdb               8:16   0  100G  0 disk       #这个就是新添加的磁盘\nsr0              11:0    1 1024M  0 rom\n\nyum install lvm2 device-mapper-persistent-data -y\nsystemctl enable lvm2-lvmetad.service --now\n# 如显示不存在则说明系统默认安装了 lvm  以上步骤可忽略\n\n#创建/dev/sdb卷组\npvcreate /dev/sdb\n# Physical volume \"/dev/sdb\" successfully created.\n\nvgcreate cinder-volumes /dev/sdb\n# Volume group \"cinder-volumes\" successfully created\n# sdb 为划分给块存储使用的磁盘\n# 如有多个磁盘，则需重复以上两个命令\n\n\ncp /etc/lvm/lvm.conf{,.bak}\nsed -i '130 a\\filter = [ \"a/sdb/\",\"r/.*/\"]' /etc/lvm/lvm.conf\n#sdb是上面添加的新的物理磁盘\n# 如有多个磁盘，则将磁盘编号以固定格式添加到过滤设备中，例如有两个磁盘 sdb sdc ，则为 filter = [ \"a/sdb/\", \"a/sdc/\",\"r/.*/\"]\n\n\nyum install openstack-cinder targetcli python-keystone -y\nmv /etc/cinder/cinder.conf{,.bak}\ncat >> /etc/cinder/cinder.conf << EOF\n[DEFAULT]\ntransport_url = rabbit://openstack:RABBIT_PASS@controller-1\nauth_strategy = keystone\nmy_ip = 192.168.148.103\nenabled_backends = lvm\nglance_api_servers = http://controller-1:9292\n# 192.168.148.103  为块存储节点 computer-3管理网络 的接口IP\n[database]\nconnection = mysql+pymysql://cinder:CINDER_DBPASS@controller-1/cinder\n# CINDER_DBPASS 为数据库 Cinder 账户密码\n[keystone_authtoken]\nwww_authenticate_uri = http://controller-1:5000\nauth_url = http://controller-1:5000\nmemcached_servers = controller-1:11211\nauth_type = password\nproject_domain_name = default\nuser_domain_name = default\nproject_name = service\nusername = cinder\npassword = CINDER_PASS\n# CINDER_PASS 为 cinder 数据库账户密码\n[lvm]\nvolume_driver = cinder.volume.drivers.lvm.LVMVolumeDriver\nvolume_group = cinder-volumes\ntarget_protocol = iscsi\ntarget_helper = lioadm\n# [lvm]  没有则新建\n[oslo_concurrency]\nlock_path = /var/lib/cinder/tmp\nEOF\n\nsystemctl enable openstack-cinder-volume.service target.service --now\nsystemctl status openstack-cinder-volume.service target.service\n\n```\n\n### 验证\n\n<font color='red'>操作节点[controller-1]</font>\n\n```\nsource admin-openrc\nopenstack volume service list\nsystemctl restart httpd memcached\n\n[root@controller-1 ~]# openstack volume service list\n+------------------+----------------+------+---------+-------+----------------------------+\n| Binary           | Host           | Zone | Status  | State | Updated At                 |\n+------------------+----------------+------+---------+-------+----------------------------+\n| cinder-scheduler | controller-1   | nova | enabled | up    | 2024-01-05T09:27:48.000000 |\n| cinder-volume    | computer-3@lvm | nova | enabled | up    | 2024-01-05T09:27:44.000000 |\n+------------------+----------------+------+---------+-------+----------------------------+\n\n```\n\n## Swift（对象存储）\n\n<font color='red'>关闭所有节点，回头看物理关闭顺序</font>\n\n给<font color='red'>computer-3</font>添加4张硬盘，添加完之后就可以开机了\n\n![image-20240107001040770](../img/OpenStack-Train-%E4%B8%89%E8%8A%82%E7%82%B9%E9%83%A8%E7%BD%B2.assets/2737f3006c57c7583f0d05ef3da5951e697559838.png)\n\n### <font color='red'>操作节点[controller-1]</font>\n\n```\n###控制节点\nsource admin-openrc\nopenstack user create --domain default --password SWIFT_PASS swift\nopenstack role add --project service --user swift admin\n#创建swift服务实体：\nopenstack service create --name swift \\\n  --description \"OpenStack Object Storage\" object-store\n#创建swift服务实体：\nopenstack endpoint create --region RegionOne \\\nobject-store public http://controller-1:8080/v1/AUTH_%\\(project_id\\)s\n\nopenstack endpoint create --region RegionOne \\\nobject-store internal http://controller-1:8080/v1/AUTH_%\\(project_id\\)s\n\nopenstack endpoint create --region RegionOne \\\nobject-store admin http://controller-1:8080/v1\n\n#安装swift组件\nyum install -y openstack-swift-proxy python-swiftclient \\\n  python-keystoneclient python-keystonemiddleware \\\n  Memcached\n\nmv /etc/swift/proxy-server.conf{,.bak}\ncat> /etc/swift/proxy-server.conf<<EOF\n[DEFAULT]\nbind_ip = 0.0.0.0\nbind_port = 8080\nuser = swift\n[pipeline:main]\npipeline = catch_errors gatekeeper healthcheck proxy-logging cache container_sync bulk ratelimit authtoken keystoneauth container-quotas account-quotas slo dlo versioned_writes proxy-logging proxy-server\n[app:proxy-server]\nuse = egg:swift#proxy\nallow_account_management = true\naccount_autocreate = true\n#Keystone auth info\n[filter:authtoken]\npaste.filter_factory = keystonemiddleware.auth_token:filter_factory\nwww_authenticate_uri = http://controller-1:5000\nauth_url = http://controller-1:5000/v3\nmemcached_servers = controller-1:11211\nauth_type = password\nproject_domain_name = default\nuser_domain_name = default\nproject_name = service\nusername = swift\npassword = SWIFT_PASS\ndelay_auth_decision = true\nservice_token_roles_required = True\n[filter:keystoneauth]\nuse = egg:swift#keystoneauth\noperator_roles = admin,user\n[filter:healthcheck]\nuse = egg:swift#healthcheck\n[filter:cache]\nuse = egg:swift#memcache\nmemcache_servers = controller-1:11211\n[filter:ratelimit]\nuse = egg:swift#ratelimit\n[filter:domain_remap]\nuse = egg:swift#domain_remap\n[filter:catch_errors]\nuse = egg:swift#catch_errors\n[filter:cname_lookup]\nuse = egg:swift#cname_lookup\n[filter:staticweb]\nuse = egg:swift#staticweb\n[filter:tempurl]\nuse = egg:swift#tempurl\n[filter:formpost]\nuse = egg:swift#formpost\n[filter:name_check]\nuse = egg:swift#name_check\n[filter:list-endpoints]\nuse = egg:swift#list_endpoints\n[filter:proxy-logging]\nuse = egg:swift#proxy_logging\n[filter:bulk]\nuse = egg:swift#bulk\n[filter:slo]\nuse = egg:swift#slo\n[filter:dlo]\nuse = egg:swift#dlo\n[filter:container-quotas]\nuse = egg:swift#container_quotas\n[filter:account-quotas]\nuse = egg:swift#account_quotas\n[filter:gatekeeper]\nuse = egg:swift#gatekeeper\n[filter:container_sync]\nuse = egg:swift#container_sync\n[filter:xprofile]\nuse = egg:swift#xprofile\n[filter:versioned_writes]\nuse = egg:swift#versioned_writes\nEOF\n```\n\n### <font color='red'>操作节点[computer-3]</font>\n\n```\nlsblk\n```\n\n![image-20240107001422383](../img/OpenStack-Train-%E4%B8%89%E8%8A%82%E7%82%B9%E9%83%A8%E7%BD%B2.assets/b38a836ef849a8a2ae7a15f933687430697559838.png)\n\n```\n#conpute-3节点\nyum install xfsprogs rsync -y\n\nlsblk\n#将/dev/sdb和/dev/sdc设备格式化为XFS：\nmkfs.xfs /dev/sdc\nmkfs.xfs /dev/sdd\nmkfs.xfs /dev/sde\nmkfs.xfs /dev/sdf\n#创建安装点目录结构：\nmkdir -p /srv/node/sdc\nmkdir -p /srv/node/sdd\nmkdir -p /srv/node/sde\nmkdir -p /srv/node/sdf\n\ncat >> /etc/fstab << EOF\n/dev/sdc /srv/node/sdc xfs noatime,nodiratime,nobarrier,logbufs=8 0 2\n/dev/sdd /srv/node/sdd xfs noatime,nodiratime,nobarrier,logbufs=8 0 2\n/dev/sde /srv/node/sde xfs noatime,nodiratime,nobarrier,logbufs=8 0 2\n/dev/sdf /srv/node/sdf xfs noatime,nodiratime,nobarrier,logbufs=8 0 2\nEOF\n\n#安装设备\nmount /srv/node/sdc\nmount /srv/node/sdd\nmount /srv/node/sde\nmount /srv/node/sdf\n\ncat>/etc/rsyncd.conf<<EOF\nuid = swift\ngid = swift\nlog file = /var/log/rsyncd.log\npid file = /var/run/rsyncd.pid\naddress = 192.168.148.103\n#192.168.148.103为computer-3的管理网络ip\n[account]\nmax connections = 2\npath = /srv/node/\nread only = False\nlock file = /var/lock/account.lock\n\n[container]\nmax connections = 2\npath = /srv/node/\nread only = False\nlock file = /var/lock/container.lock\n\n[object]\nmax connections = 2\npath = /srv/node/\nread only = False\nlock file = /var/lock/object.lock\nEOF\n\n#重启服务\nsystemctl enable rsyncd.service\nsystemctl start rsyncd.service\n\n#安装swift组件\nyum install -y openstack-swift-account openstack-swift-container \\\n  openstack-swift-object\n  \nmv /etc/swift/account-server.conf{,.bak}\ncat> /etc/swift/account-server.conf<<EOF\n[DEFAULT]\nbind_ip = 192.168.148.103\nbind_port = 6202\nuser = swift\nswift_dir = /etc/swift\ndevices = /srv/node\nmount_check = true\n[pipeline:main]\npipeline = healthcheck recon account-server\n[app:account-server]\nuse = egg:swift#account\n[filter:healthcheck]\nuse = egg:swift#healthcheck\n[filter:recon]\nuse = egg:swift#recon\nrecon_cache_path = /var/cache/swift\n[account-replicator]\n[account-auditor]\n[account-reaper]\n[filter:xprofile]\nuse = egg:swift#xprofile\nEOF\n\nmv /etc/swift/container-server.conf{,.bak}\ncat> /etc/swift/container-server.conf<<EOF\n[DEFAULT]\nbind_ip = 192.168.148.103\nbind_port = 6201\nuser = swift\nswift_dir = /etc/swift\ndevices = /srv/node\nmount_check = true\n[pipeline:main]\npipeline = healthcheck recon container-server\n[app:container-server]\nuse = egg:swift#container\n[filter:healthcheck]\nuse = egg:swift#healthcheck\n[filter:recon]\nuse = egg:swift#recon\n[container-replicator]\n[container-updater]\n[container-auditor]\n[container-sync]\n[filter:xprofile]\nuse = egg:swift#xprofile\n[container-sharder]\nEOF\n\nmv /etc/swift/object-server.conf{,.bak}\ncat> /etc/swift/object-server.conf<<EOF\n[DEFAULT]\nbind_ip = 0.0.0.0\nbind_port = 6200\nuser = swift\nswift_dir = /etc/swift\ndevices = /srv/node\nmount_check = true\n[pipeline:main]\npipeline = healthcheck recon object-server\n[app:object-server]\nuse = egg:swift#object\nrecon_cache_path = /var/cache/swift\nrecon_lock_path = /var/lock\n[filter:healthcheck]\nuse = egg:swift#healthcheck\n[filter:recon]\nuse = egg:swift#recon\n[object-replicator]\n[object-reconstructor]\n[object-updater]\n[object-expirer]\n[filter:xprofile]\nuse = egg:swift#xprofile\n[object-relinker]\n[object-auditor]\nlog_name = object-auditor\nlog_facility = LOG_LOCAL0\nlog_level = INFO\nlog_address=/dev/log   \nEOF\n#确保对安装点目录结构拥有适当的所有权：\nchown -R swift:swift /srv/node\n\n#创建recon目录并确保对其拥有适当的所有权：\n mkdir -p /var/cache/swift\n chown -R root:swift /var/cache/swift\n chmod -R 775 /var/cache/swift\n \n# 在防火墙中启用必要的访问(实验忽略)\nfirewall-cmd --permanent --add-port=6200/tcp\nfirewall-cmd --permanent --add-port=6201/tcp\nfirewall-cmd --permanent --add-port=6202/tcp\n\n```\n\n### <font color='red'>操作节点[controller-1]</font>\n\n<font color='red'>创建和分发初始环</font>\n\n```\n#控制节点\n转到/etc/swift目录。(所以操作在此目录，执行)\n创建用户环account.builder文件：\ncd /etc/swift\n##第一部分（6202）创建用户环\nswift-ring-builder account.builder create 10 3 1\nswift-ring-builder account.builder add \\\n   --region 1 --zone 1 --ip 192.168.148.103 --port 6202 --device sdc --weight 100\nswift-ring-builder account.builder add \\\n   --region 1 --zone 1 --ip 192.168.148.103 --port 6202 --device sdd --weight 100\nswift-ring-builder account.builder add \\\n   --region 1 --zone 2 --ip 192.168.148.103 --port 6202 --device sde --weight 100\nswift-ring-builder account.builder add \\\n   --region 1 --zone 2 --ip 192.168.148.103 --port 6202 --device sdf --weight 100\nswift-ring-builder account.builder\n##重新平衡环且验证\nswift-ring-builder account.builder rebalance\nswift-ring-builder account.builder\n\n\n##第二部分（6201）创建容器环\nswift-ring-builder container.builder create 10 3 1\nswift-ring-builder container.builder add \\\n   --region 1 --zone 1 --ip 192.168.148.103 --port 6201 --device sdc --weight 100\nswift-ring-builder container.builder add \\\n   --region 1 --zone 1 --ip 192.168.148.103 --port 6201 --device sdd --weight 100\nswift-ring-builder container.builder add \\\n   --region 1 --zone 2 --ip 192.168.148.103 --port 6201 --device sde --weight 100\nswift-ring-builder container.builder add \\\n   --region 1 --zone 2 --ip 192.168.148.103 --port 6201 --device sdf --weight 100\nswift-ring-builder container.builder\nswift-ring-builder container.builder rebalance\n\n##第三部分（6200）创建对象环\nswift-ring-builder object.builder create 10 3 1\nswift-ring-builder object.builder add \\\n   --region 1 --zone 1 --ip 192.168.148.103 --port 6200 --device sdc --weight 100\nswift-ring-builder object.builder add \\\n   --region 1 --zone 1 --ip 192.168.148.103 --port 6200 --device sdd --weight 100\nswift-ring-builder object.builder add \\\n   --region 1 --zone 2 --ip 192.168.148.103 --port 6200 --device sde --weight 100\nswift-ring-builder object.builder add \\\n   --region 1 --zone 2 --ip 192.168.148.103 --port 6200 --device sdf --weight 100\nswift-ring-builder object.builder\nswift-ring-builder object.builder rebalance\n\n将swift目录下生成三个.gz文件复制到存储节点的swift目录下\nscp account.ring.gz container.ring.gz object.ring.gz 192.168.148.103:/etc/swift\n\n##完成安装 controller-1\nmv  /etc/swift/swift.conf{,.bak}\ncat> /etc/swift/swift.conf<<EOF\n[swift-hash]\nswift_hash_path_suffix = swift\nswift_hash_path_prefix = swift\n[storage-policy:0]\nname = Policy-0\ndefault = yes\nEOF\n-------------------------------------------------------------------------------------\n#将控制节点的swift配置文件复制到存储节点（computer-3）\nscp swift.conf 192.168.148.103:/etc/swift\n\nswift_hash_path_suffix和swift_hash_path_prefix作为哈希算法的一部分用于确定数据在集群中的位置。\n这些值应该保持机密，并且在部署集群之后不能更改丢失。可自定义\n-------------------------------------------------------------------------------------\n在所有节点确保对配置目录拥有适当的所有权：\n####存储节点与控制节点同时执行（注意！！！！两个节点同时执行）\n操作节点[controller-1，computer-3]\n\nchown -R root:swift /etc/swift \n\n在控制器节点和任何其他运行代理服务的节点上，启动对象存储代理服务及其相关性，并将它们配置为在系统启动时启动(存储节点无代理服务)\n-------------------------------------------------------------------------------------\n#重启服务(操作节点[controller-1]\nsystemctl enable openstack-swift-proxy.service memcached.service --now\nsystemctl restart openstack-swift-proxy.service memcached.service\n```\n\n### 计算节点\n\n```\n在存储节点启动所有服务\n systemctl enable openstack-swift-account.service openstack-swift-account-auditor.service \\\n  openstack-swift-account-reaper.service openstack-swift-account-replicator.service\n systemctl start openstack-swift-account.service openstack-swift-account-auditor.service \\\n  openstack-swift-account-reaper.service openstack-swift-account-replicator.service\n systemctl enable openstack-swift-container.service \\\n  openstack-swift-container-auditor.service openstack-swift-container-replicator.service \\\n  openstack-swift-container-updater.service\n systemctl start openstack-swift-container.service \\\n  openstack-swift-container-auditor.service openstack-swift-container-replicator.service \\\n  openstack-swift-container-updater.service\n systemctl enable openstack-swift-object.service openstack-swift-object-auditor.service \\\n  openstack-swift-object-replicator.service openstack-swift-object-updater.service\n systemctl start openstack-swift-object.service openstack-swift-object-auditor.service \\\n  openstack-swift-object-replicator.service openstack-swift-object-updater.service\n```\n\n### 验证\n\n<font color='red'>操作节点[controller-1]</font>\n\n```\ncd /etc/swift\nswift stat\n[root@controller-1 swift]# swift stat\n               Account: AUTH_07a1ce96dca54f1bb0d3b968f1343617\n            Containers: 0\n               Objects: 0\n                 Bytes: 0\n       X-Put-Timestamp: 1684919814.32783\n           X-Timestamp: 1684919814.32783\n            X-Trans-Id: txd6f3affa0140455b935ff-00646dd605\n          Content-Type: text/plain; charset=utf-8\nX-Openstack-Request-Id: txd6f3affa0140455b935ff-00646dd605\n\n#测试上传镜像\n[root@controller-1 swift]# cd\n[root@controller-1 ~]# swift upload demo cirros-0.6.2-x86_64-disk.img --object-name image\nimage\n\nsystemctl restart httpd memcached\nsystemctl status httpd memcached\n\n##重启nova服务\nsudo systemctl restart openstack-nova*\n\n```\n\n![image-20240107002628456](../img/OpenStack-Train-%E4%B8%89%E8%8A%82%E7%82%B9%E9%83%A8%E7%BD%B2.assets/1f2bbbaf1bed2cb9551ccf60f442e9a1697559838.png)\n\n## Heat（编排）\n\n### <font color='red'>操作节点[controller-1]</font>\n\n```\n#创建heat数据库和用户\nmysql -u root -pMARIADB_PASS\nCREATE DATABASE heat;\nGRANT ALL PRIVILEGES ON heat.* TO 'heat'@'localhost' \\\n  IDENTIFIED BY 'HEAT_DBPASS';\nGRANT ALL PRIVILEGES ON heat.* TO 'heat'@'%' \\\n  IDENTIFIED BY 'HEAT_DBPASS';\nflush privileges;\nexit\n\nsource admin-openrc\nopenstack user create --domain default --password HEAT_PASS heat\n#添加 admin 角色到 heat 用户上\nopenstack role add --project service --user heat admin\n##创建heat和 heat-cfn 服务实体\nopenstack service create --name heat \\\n  --description \"Orchestration\" orchestration\nopenstack service create --name heat-cfn \\\n  --description \"Orchestration\"  cloudformation  \n##创建 Orchestration 服务的 API 端点\nopenstack endpoint create --region RegionOne \\\n  orchestration public http://controller-1:8004/v1/%\\(tenant_id\\)s\nopenstack endpoint create --region RegionOne \\\n  orchestration internal http://controller-1:8004/v1/%\\(tenant_id\\)s\nopenstack endpoint create --region RegionOne \\\n  orchestration admin http://controller-1:8004/v1/%\\(tenant_id\\)s\n\nopenstack endpoint create --region RegionOne \\\n  cloudformation public http://controller-1:8000/v1\nopenstack endpoint create --region RegionOne \\\n  cloudformation internal http://controller-1:8000/v1\nopenstack endpoint create --region RegionOne \\\n  cloudformation admin http://controller-1:8000/v1\n```\n\n为了管理栈，在认证服务中Orchestration需要更多信息\n\n```\n#控制节点\n#为栈创建 heat 包含项目和用户的域\nopenstack domain create --description \"Stack projects and users\" heat\n\n#在 heat 域中创建管理项目和用户的heat_domain_admin用户：\nopenstack user create --domain heat --password=HEAT_DOMAIN_USER_PASS heat_domain_admin\n\n#)添加admin角色到 heat 域 中的heat_domain_admin用户，启用heat_domain_admin用户#管理栈的管理权限\nopenstack role add --domain heat --user-domain heat --user heat_domain_admin admin\n\n#为栈创建 heat 包含项目和用户的域\nopenstack role create heat_stack_owner\n\n#添加heat_stack_owner 角色到demo 项目和用户，启用demo 用户管理栈。\nopenstack role add --project demo --user demo heat_stack_owner\n#必须添加 heat_stack_owner 角色到每个管理栈的用户。\n\n#heat_stack_user 角色\nopenstack role create heat_stack_user\n\n```\n\n安装并配置Heat组件相关软件\n\n```\n#控制节点\nyum install openstack-heat-api openstack-heat-api-cfn \\\n  openstack-heat-engine -y\n\nmv /etc/heat/heat.conf{,.bak}\ncat > /etc/heat/heat.conf << EOF\n[database]\nconnection = mysql+pymysql://heat:HEAT_DBPASS@controller-1/heat  \n#HEAT_DBPASS是HEAT数据库密码\n[DEFAULT]\ntransport_url = rabbit://openstack:RABBIT_PASS@controller-1\n#RABBIT_PASS为Rabbitmq服务密码 用户名是openstack\n[keystone_authtoken]\nwww_authenticate_uri = http://controller-1:5000\nauth_url = http://controller-1:5000\nmemcached_servers = controller-1:11211\nauth_type = password\nproject_domain_name = default\nuser_domain_name = default\nproject_name = service\nusername = heat\npassword = HEAT_PASS\n#HEAT_PASS是heat用户密码\n[trustee]\nauth_type = password\nauth_url = http://controller-1:5000\nusername = heat\npassword = HEAT_PASS\n#HEAT_PASS是heat用户密码\nuser_domain_name = default\n[clients_keystone]\nauth_uri = http://controller-1:5000\n[DEFAULT]\nheat_metadata_server_url = http://controller-1:8000\nheat_waitcondition_server_url = http://controller-1:8000/v1/waitcondition\n[DEFAULT]\nstack_domain_admin = heat_domain_admin\nstack_domain_admin_password = HEAT_DOMAIN_USER_PASS\nstack_user_domain_name = heat\nEOF\n\nsu -s /bin/sh -c \"heat-manage db_sync\" heat\n##启动 Orchestration 编排服务heat组件并将其设置为随系统启动\nsystemctl enable openstack-heat-api.service \\\n  openstack-heat-api-cfn.service openstack-heat-engine.service\n\nsystemctl restart openstack-heat-api.service \\\n  openstack-heat-api-cfn.service openstack-heat-engine.service\n  \n```\n\n### 验证\n\n```\nsystemctl list-unit-files |grep openstack-heat*\n\n[root@controller-1 ~]# systemctl list-unit-files |grep openstack-heat*\nopenstack-heat-api-cfn.service                enabled\nopenstack-heat-api.service                    enabled\nopenstack-heat-engine.service                 enabled\n-------------------------------------------------------------------------------\ncd\nsource admin-openrc\nopenstack service list\nopenstack orchestration service list\n该输出显示表明在控制节点上有应该四个heat-engine组件。\n\n[root@controller-1 ~]# openstack orchestration service list\n+--------------+-------------+--------------------------------------+--------------+--------+----------------------------+--------+\n| Hostname     | Binary      | Engine ID                            | Host         | Topic  | Updated At                 | Status |\n+--------------+-------------+--------------------------------------+--------------+--------+----------------------------+--------+\n| controller-1 | heat-engine | a0f45441-3550-4b59-8b69-f57d668dfbf2 | controller-1 | engine | 2024-01-06T16:00:18.000000 | up     |\n| controller-1 | heat-engine | 8fade664-a171-4f1e-9bec-6410bd3add07 | controller-1 | engine | 2024-01-06T16:00:18.000000 | up     |\n| controller-1 | heat-engine | 8318df8d-1171-40ff-b70e-1be979e6ebcc | controller-1 | engine | 2024-01-06T16:00:18.000000 | up     |\n| controller-1 | heat-engine | c843e3c0-7884-4384-9873-a7d8788b77a0 | controller-1 | engine | 2024-01-06T16:00:18.000000 | up     |\n+--------------+-------------+--------------------------------------+--------------+--------+----------------------------+--------+\n\nsystemctl restart httpd memcached\nsystemctl status httpd memcached\n\n```\n\n\n\n## 创建实例\n\n### 创建实例类型\n\n左侧选择管理员，点击计算，点击实例类型，右侧点击创建实例类型。\n\n![image-20240106230035149](../img/OpenStack-Train-%E4%B8%89%E8%8A%82%E7%82%B9%E9%83%A8%E7%BD%B2.assets/55d5112b942c438d89818b728d7d3062697559838.png)\n\n根据以上图片步骤依次填入：实例名称、VCPU数量、内存大小、根磁盘大小，确认无误后点击创建实例类型。\n\n### 创建镜像\n\n测试镜像：https://download.cirros-cloud.net/0.6.2/cirros-0.6.2-x86_64-disk.img\n\n<font color='red'>有两种上传方式（二选一）！！！</font>\n\n<font color='red'>1.Windows上传镜像方式</font>\n\n左侧选择管理员，点击计算，点击镜像，右侧点击创建镜像。\n\nWindows下载到本地即可\n\n![image-20240106230649633](../img/OpenStack-Train-%E4%B8%89%E8%8A%82%E7%82%B9%E9%83%A8%E7%BD%B2.assets/f2ea42f3b57b4b7a5fb9bd242f78e526697559838.png)\n\n根据以上图片步骤依次填入：镜像名称、选择文件、镜像格式，确认无误后点击创建镜像。\n**注**：演示上传的 img 镜像格式需选用 QCOW2 - QEMU模拟器 才可正常加载。\n\n\n\n<font color='red'>2.Linux上传镜像方式</font>\n\n```\nsource admin-openrc\nwget https://download.cirros-cloud.net/0.6.2/cirros-0.6.2-x86_64-disk.img\n#可能会下载不到，可以复制链接到浏览器下载，然后移到/root/目录下\nglance image-create --name \"cirros\" \\\n  --file cirros-0.6.2-x86_64-disk.img \\\n  --disk-format qcow2 --container-format bare \\\n  --visibility=public\n\nopenstack image list\n\n[root@controller-1 ~]# openstack image list\n+--------------------------------------+--------+--------+\n| ID                                   | Name   | Status |\n+--------------------------------------+--------+--------+\n| 627761da-7f8c-4780-842a-e50e62f5c464 | cirros | active |\n+--------------------------------------+--------+--------+\n\n```\n\n### 创建内部网络\n\n左侧选择管理员，点击网络，点击网络，右侧点击创建网络。\n\n![image-20240106231124036](../img/OpenStack-Train-%E4%B8%89%E8%8A%82%E7%82%B9%E9%83%A8%E7%BD%B2.assets/cea509bcbba7395e7c5710616943c0bd697559838.png)\n\n![image-20240106231151367](../img/OpenStack-Train-%E4%B8%89%E8%8A%82%E7%82%B9%E9%83%A8%E7%BD%B2.assets/6bab28f65a2c56a624df71c4b9866347697559838.png)\n\n![image-20240106231323081](../img/OpenStack-Train-%E4%B8%89%E8%8A%82%E7%82%B9%E9%83%A8%E7%BD%B2.assets/0b1b24f8d99f5c3f49662532c68ac046697559838.png)\n\n### 创建外部网络\n\n左侧选择管理员，点击网络，点击网络，右侧点击创建网络。\n\n<font color='red'>如果你是按照本文档搭建的，就填provider</font>\n\n![image-20240106231633793](../img/OpenStack-Train-%E4%B8%89%E8%8A%82%E7%82%B9%E9%83%A8%E7%BD%B2.assets/5fbbf082bc66e60949bdd81825facd02697559838.png)\n\n![image-20240106231854446](../img/OpenStack-Train-%E4%B8%89%E8%8A%82%E7%82%B9%E9%83%A8%E7%BD%B2.assets/070d5393f9a1b8dd7dee9d2fea10086e697559838.png)\n\n![image-20240106232011057](../img/OpenStack-Train-%E4%B8%89%E8%8A%82%E7%82%B9%E9%83%A8%E7%BD%B2.assets/d0a471b28e40019c7fc79bc8918cda04697559838.png)\n\n### 创建路由\n\n左侧选择管理员，点击网络，点击路由，右侧点击创建路由。\n\n![image-20240106232138022](../img/OpenStack-Train-%E4%B8%89%E8%8A%82%E7%82%B9%E9%83%A8%E7%BD%B2.assets/31d170f9b1e99be47760fd014bb6809d697559838.png)\n\n\n\n![image-20240106232201129](../img/OpenStack-Train-%E4%B8%89%E8%8A%82%E7%82%B9%E9%83%A8%E7%BD%B2.assets/cb31565a3cfeb2dc853ac38cded0043e697559838.png)\n\n![image-20240106232242376](../img/OpenStack-Train-%E4%B8%89%E8%8A%82%E7%82%B9%E9%83%A8%E7%BD%B2.assets/ce7823ed963eca1a54ca8b97f14928e5697559838.png)\n\n### 添加安全组规则\n\n![image-20240106232342515](../img/OpenStack-Train-%E4%B8%89%E8%8A%82%E7%82%B9%E9%83%A8%E7%BD%B2.assets/757fee2ef006d00f258da6008163fe91697559838.png)\n\n![image-20240106232725982](../img/OpenStack-Train-%E4%B8%89%E8%8A%82%E7%82%B9%E9%83%A8%E7%BD%B2.assets/b99fadf3fe10a6ddba4ba221b3c2ff87697559838.png)\n\n最后效果长这样\n\n![image-20240106232758711](../img/OpenStack-Train-%E4%B8%89%E8%8A%82%E7%82%B9%E9%83%A8%E7%BD%B2.assets/485233affd839f8fbce7ea1c0ae2765d697559838.png)\n\n### 创建实例\n\n![image-20240106232939110](../img/OpenStack-Train-%E4%B8%89%E8%8A%82%E7%82%B9%E9%83%A8%E7%BD%B2.assets/0105c7af8682dc647d6cf79473cd9fbc697559838.png)\n\n![image-20240106233038731](../img/OpenStack-Train-%E4%B8%89%E8%8A%82%E7%82%B9%E9%83%A8%E7%BD%B2.assets/86ffdba6219b46e5a387f8b67fa5edf7697559838.png)\n\n![image-20240106233101509](../img/OpenStack-Train-%E4%B8%89%E8%8A%82%E7%82%B9%E9%83%A8%E7%BD%B2.assets/8bf413d2923a38d956d41f905d1a4f6b697559838.png)\n\n![image-20240106233129659](../img/OpenStack-Train-%E4%B8%89%E8%8A%82%E7%82%B9%E9%83%A8%E7%BD%B2.assets/3083c4669cd60df3c5a53b7b5f661629697559838.png)\n\n然后点击创建实例\n\n分配浮动ip\n\n![image-20240106233251169](../img/OpenStack-Train-%E4%B8%89%E8%8A%82%E7%82%B9%E9%83%A8%E7%BD%B2.assets/bfb7b78b90815059f8171048bcb0683b697559838.png)\n\n![image-20240106233418787](../img/OpenStack-Train-%E4%B8%89%E8%8A%82%E7%82%B9%E9%83%A8%E7%BD%B2.assets/f584f2ac4bb92bb8043c2c07c670dbf4697559838.png)\n\n<font color='red'>结论：创建实例成功</font>\n\n<div class=\"tbsm\" style=\"margin-top:54px;\">\n<div class=\"tbsm-top\"><span><svg t=\"1674654360507\" class=\"icon\" viewBox=\"0 0 1024 1024\" version=\"1.1\" xmlns=\"http://www.w3.org/2000/svg\" p-id=\"987\" data-spm-anchor-id=\"a313x.7781069.0.i0\" width=\"35\" height=\"35\"><path d=\"M410.49 97.74H155.08a56.74 56.74 0 0 0-56.84 56.73V410a56.84 56.84 0 0 0 56.84 56.84h255.41A56.83 56.83 0 0 0 467.32 410V154.58a56.83 56.83 0 0 0-56.83-56.84zM410.49 558.74H155.08a56.74 56.74 0 0 0-56.84 56.73V871a56.84 56.84 0 0 0 56.84 56.84h255.41A56.83 56.83 0 0 0 467.32 871V615.58a56.83 56.83 0 0 0-56.83-56.84zM871.49 558.74H616.08a56.74 56.74 0 0 0-56.84 56.73V871a56.84 56.84 0 0 0 56.84 56.84h255.41A56.83 56.83 0 0 0 928.32 871V615.58a56.83 56.83 0 0 0-56.83-56.84z\" fill=\"#66EEFF\" p-id=\"988\"></path><path d=\"M410.49 558.74h-4.14A475 475 0 0 0 299.52 859.6a481.16 481.16 0 0 0 4.84 68.22h106.13A56.83 56.83 0 0 0 467.32 871V615.58a56.83 56.83 0 0 0-56.83-56.84zM871.49 558.74H616.08a56.74 56.74 0 0 0-56.84 56.73V871a56.84 56.84 0 0 0 56.84 56.84h255.41A56.83 56.83 0 0 0 928.32 871V615.58a56.83 56.83 0 0 0-56.83-56.84z\" fill=\"#C2F8FF\" p-id=\"989\"></path></svg></span><span style=\"font-size:30px;\"> 特别声明</span></div>\n<div class=\"tbsm-wz\">千屹博客旗下的所有文章，是通过本人课堂学习和课外自学所精心整理的知识巨著<br/>难免会有出错的地方<br/>如果细心的你发现了小失误，可以在下方评论区告诉我，或者私信我！<br />非常感谢大家的热烈支持！</div>\n</div>\n","tags":["Centos 7","OpenStack"],"categories":["云原生"]},{"title":"k8s部署Prometheus+Grafana","url":"/posts/25424/","content":"\n<meta name=\"referrer\" content=\"no-referrer\"/>\n\n# k8s部署Prometheus+Grafana\n\n![image-20240107005039292](../img/k8s%E9%83%A8%E7%BD%B2Prometheus+Grafana.assets/99194bb5049ba5669d662e158dabf24c697559838.png)\n\n| 主机名  | ip1（NAT）     | 系统      | 磁盘 | 内存 |\n| ------- | -------------- | --------- | ---- | ---- |\n| master1 | 192.168.48.101 | Centos7.9 | 100G | 4G   |\n| master2 | 192.168.48.102 | Centos7.9 | 100G | 4G   |\n| master3 | 192.168.48.103 | Centos7.9 | 100G | 4G   |\n| node01  | 192.168.48.104 | Centos7.9 | 100G | 6G   |\n| node02  | 192.168.48.105 | Centos7.9 | 100G | 6G   |\n\n<font color='red'>做这个之前你要拥有一个k8s集群，参考以下教程</font>\n\n[K8S高可用集群（内部etcd） - 严千屹博客 (qianyios.top)](https://blog.qianyios.top/posts/7158/)\n\n[K8S高可用集群（外部etcd） - 严千屹博客 (qianyios.top)](https://blog.qianyios.top/posts/59349/)\n\n## 部署Prometheus\n\n创建命名空间\n\n<font color='red'>操作节点[master1]</font>\n\n```\nkubectl create namespace prometheus-work\n```\n\n部署Prometheus deploy\n\n<font color='red'>操作节点[master1]</font>\n\n```yaml\ncat >prome_deploy.yml<< \"EOF\"\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: prometheus\n  namespace: prometheus-work\n  labels:\n    app: prometheus\nspec:\n  selector:\n    matchLabels:\n      app: prometheus\n  template:\n    metadata:\n      labels:\n        app: prometheus\n    spec:\n      securityContext:                                   #指定运行的用户为root\n        runAsUser: 0\n      serviceAccountName: prometheus\n      containers:\n      - image: prom/prometheus:v2.30.2\n        name: prometheus\n        args:\n        - \"--config.file=/etc/prometheus/prometheus.yml\" #通过volume挂载prometheus.yml\n        - \"--storage.tsdb.path=/prometheus\"              #通过vlolume挂载目录/prometheus\n        - \"--storage.tsdb.retention.time=24h\"\n        - \"--web.enable-admin-api\"                       #控制对admin HTTP API的访问\n        - \"--web.enable-lifecycle\"                       #支持热更新，直接执行localhost:9090/-/reload立即生效\n        ports:\n        - containerPort: 9090\n          name: http\n        volumeMounts:\n        - mountPath: \"/etc/prometheus\"\n          name: config-volume\n        - mountPath: \"/prometheus\"\n          name: data\n        resources:\n          requests:\n            cpu: 100m\n            memory: 512Mi\n          limits:\n            cpu: 100m\n            memory: 512Mi\n      volumes:\n      - name: data\n        persistentVolumeClaim:\n          claimName: prometheus-data  #本地存储\n      - name: config-volume\n        configMap:\n          name: prometheus-config     #定义的prometeus.yaml\n\nEOF\nkubectl apply -f prome_deploy.yml\n\n```\n\n部署Prometheus service\n\n<font color='red'>操作节点[master1]</font>\n\n```yaml\ncat> prome_svc.yml<< \"EOF\"\napiVersion: v1\nkind: Service\nmetadata:\n  name: prometheus\n  namespace: prometheus-work\n  labels:\n    app: prometheus\nspec:\n  selector:\n    app: prometheus\n  type: NodePort\n  ports:\n    - name: web\n      port: 9090\n      targetPort: http\nEOF\nkubectl apply -f prome_svc.yml\n\n```\n\n部署configmap\n\n<font color='red'>操作节点[master1]</font>\n\n```yaml\ncat > prome_cfg.yml << \"EOF\"\napiVersion: v1\nkind: ConfigMap\nmetadata:\n  name: prometheus-config\n  namespace: prometheus-work\ndata:\n  prometheus.yml: |\n    global:\n      scrape_interval: 15s\n      scrape_timeout: 15s\n    scrape_configs:\n    - job_name: 'prometheus'\n      static_configs:\n      - targets: ['localhost:9090']\n\nEOF\n kubectl apply -f prome_cfg.yml\n\n```\n\n部署PV，PVC\n\n<font color='red'>操作节点[node01]</font>\n\n```\n#在node01节点上执行\nmkdir /data/k8s/prometheus -p\n```\n\n<font color='red'>操作节点[master1]</font>\n\n```yaml\ncat > prome_pvc.yml << \"EOF\"\napiVersion: v1\nkind: PersistentVolume\nmetadata:\n  name: prometheus-local\n  labels:\n    app: prometheus\nspec:\n  accessModes:\n  - ReadWriteOnce\n  capacity:\n    storage: 5Gi\n  storageClassName: local-storage\n  local:\n    path: /data/k8s/prometheus  #在node01节点创建此目录\n  nodeAffinity:\n    required:\n      nodeSelectorTerms:\n      - matchExpressions:\n        - key: kubernetes.io/hostname\n          operator: In\n          values:\n          - node01   #指定运行在node节点\n  persistentVolumeReclaimPolicy: Retain\n---\napiVersion: v1\nkind: PersistentVolumeClaim\nmetadata:\n  name: prometheus-data\n  namespace: prometheus-work\nspec:\n  selector:\n    matchLabels:\n      app: prometheus\n  accessModes:\n  - ReadWriteOnce\n  resources:\n    requests:\n      storage: 5Gi\n  storageClassName: local-storage\n\nEOF\nkubectl apply -f prome_pvc.yml\n\n```\n\n配置rabc\n\n<font color='red'>操作节点[master1]</font>\n\n```yaml\ncat > prome_rabc.yml << \"EOF\"\napiVersion: v1\nkind: ServiceAccount\nmetadata:\n  name: prometheus\n  namespace: prometheus-work\n---\napiVersion: rbac.authorization.k8s.io/v1\nkind: ClusterRole        #创建一个clusterrole\nmetadata:\n  name: prometheus\nrules:\n- apiGroups:\n  - \"\"\n  resources:\n  - nodes\n  - services\n  - endpoints\n  - pods\n  - nodes/proxy\n  verbs:\n  - get\n  - list\n  - watch\n- apiGroups:\n  - \"extensions\"\n  resources:\n    - ingresses\n  verbs:\n  - get\n  - list\n  - watch\n- apiGroups:\n  - \"\"\n  resources:\n  - configmaps\n  - nodes/metrics\n  verbs:\n  - get\n- nonResourceURLs:\n  - /metrics\n  verbs:\n  - get\n---\napiVersion: rbac.authorization.k8s.io/v1\nkind: ClusterRoleBinding\nmetadata:\n  name: prometheus\nroleRef:\n  apiGroup: rbac.authorization.k8s.io\n  kind: ClusterRole\n  name: prometheus\nsubjects:\n- kind: ServiceAccount\n  name: prometheus\n  namespace: prometheus-work\n\nEOF\nkubectl apply -f prome_rabc.yml\n\n```\n\n查看部署的Prometheus服务\n\n<font color='red'>操作节点[master1]</font>\n\n```bash\n[root@master1 ~]# kubectl get pod,svc,configmap,sa -n prometheus-work\nNAME                             READY   STATUS    RESTARTS   AGE\npod/prometheus-db4b5c549-6gb7d   1/1     Running   0          4m39s\n\nNAME                 TYPE       CLUSTER-IP      EXTERNAL-IP   PORT(S)          AGE\nservice/prometheus   NodePort   10.103.99.200   <none>        9090:30512/TCP   15m    #注意这个30512是后面要访问的端口\n\nNAME                          DATA   AGE\nconfigmap/kube-root-ca.crt    1      17m\nconfigmap/prometheus-config   1      14m\n\nNAME                        SECRETS   AGE\nserviceaccount/default      0         17m\nserviceaccount/prometheus   0         12m\n\n```\n\n在浏览器访问Prometheus\n访问地址是node节点IP加上service的nodeport端口\n\n```\n192.168.48.104:30512\n```\n\n![image-20240103162100215](../img/k8s%E9%83%A8%E7%BD%B2Prometheus+Grafana.assets/ff121d0cea6b3d700c126869c1ec57a6697559838.png)\n\n## 部署grafana\n\n部署deployment\n\n```yaml\ncat >grafana.yml <<\"EOF\"\nkind: Deployment\napiVersion: apps/v1\nmetadata:\n  labels:\n    app: grafana\n  name: grafana\n  namespace: prometheus-work\nspec:\n  replicas: 1\n  revisionHistoryLimit: 10\n  selector:\n    matchLabels:\n      app: grafana\n  template:\n    metadata:\n      labels:\n        app: grafana\n    spec:\n      securityContext:\n        runAsNonRoot: true\n        runAsUser: 10555\n        fsGroup: 10555\n      containers:\n        - name: grafana\n          image: grafana/grafana:8.4.4\n          imagePullPolicy: IfNotPresent\n          env:\n            - name: GF_AUTH_BASIC_ENABLED\n              value: \"true\"\n            - name: GF_AUTH_ANONYMOUS_ENABLED\n              value: \"false\"\n          readinessProbe:\n            httpGet:\n              path: /login\n              port: 3000\n          volumeMounts:\n            - mountPath: /var/lib/grafana\n              name: grafana-data-volume\n          ports:\n            - containerPort: 3000\n              protocol: TCP\n      volumes:\n        - name: grafana-data-volume\n          emptyDir: {}\n\nEOF\nkubectl apply -f grafana.yml\n```\n\n部署svc\n\n```\ncat >grafana_svc.yml<<\"EOF\"\nkind: Service\napiVersion: v1\nmetadata:\n  labels:\n    app: grafana\n  name: grafana-service\n  namespace: prometheus-work\nspec:\n  ports:\n    - port: 3000\n      targetPort: 3000\n  selector:\n    app: grafana\n  type: NodePort\n\nEOF\nkubectl apply -f grafana_svc.yml\n\n```\n\n查看服务\n\n```\n[root@master1 ~]# kubectl get pod,svc -n prometheus-work |grep grafana\npod/grafana-5d475d9d7-ctb2t      1/1     Running   0          5m18s\nservice/grafana-service   NodePort   10.99.157.212   <none>        3000:31163/TCP   5m12s\n#查看grafana的pod在哪个节点\n[root@master1 1]# kubectl describe pod -n prometheus-work grafana-5d475d9d7-ctb2t | grep Node:\nNode:             node02/192.168.48.105\n[root@master1 1]#\n```\n\n访问页面http://192.168.48.105:31163\n\n首次登录grafana，<font color='red'>用户名和密码都是admin</font>，登陆之后会要求修改admin的密码，也可以不修改\n\n![image-20240103163411877](../img/k8s%E9%83%A8%E7%BD%B2Prometheus+Grafana.assets/a7a86e95b368d4e4d5877738b9a0741f697559838.png)\n\n![image-20240103164006642](../img/k8s%E9%83%A8%E7%BD%B2Prometheus+Grafana.assets/6fa04500240fafe21391975276fc8e6f697559838.png)\n\n![image-20240103164054258](../img/k8s%E9%83%A8%E7%BD%B2Prometheus+Grafana.assets/164a86ddf205de933273884be556f56c697559838.png)\n\n![image-20240103164130946](../img/k8s%E9%83%A8%E7%BD%B2Prometheus+Grafana.assets/9c15d8da3655b36cfbf47d5f8e5c0f5a697559838.png)\n\n## 监控开始\n\n以下测试均已监控node01来做测试\n\n![image-20240107005309863](../img/k8s%E9%83%A8%E7%BD%B2Prometheus+Grafana.assets/3c8cba195ef369929b216e63061be620697559838.png)\n\n[GitHub - prometheus/node_exporter: Exporter for machine metrics](https://github.com/prometheus/node_exporter)\n\n### **监控linux服务器**\n\n主要监控指标：\n\n- CPU\n- 内存\n- 硬盘\n- 网络流量\n- 系统负载\n- 系统服务\n\n#### 安装采集器\n\n从上图得知监控linux需要使用<font color='red'>Node exporter</font>采集器\n\n下载Node exporter采集器\n\n![image-20240103164627575](../img/k8s%E9%83%A8%E7%BD%B2Prometheus+Grafana.assets/adadb2a4fdae2245309f74f48c037a2d697559838.png)\n\n操作节点[node01]\n\n```\nwget -P /usr/local/ https://github.com/prometheus/node_exporter/releases/download/v1.7.0/node_exporter-1.7.0.linux-amd64.tar.gz\n#也可以自己先下载上传到/usr/local/ 下\n```\n\n```\ncd /usr/local/\ntar -xvf node_exporter-1.7.0.linux-amd64.tar.gz\nmv node_exporter-1.7.0.linux-amd64 node_exporter\ncd /usr/local/node_exporter\n./node_exporter\n```\n\n出现以下没关系\n\n![image-20240103165243667](../img/k8s%E9%83%A8%E7%BD%B2Prometheus+Grafana.assets/78c7408333844d4be10795b9faaeb494697559838.png)\n\n访问采集器\n\n```\nhttp://192.168.48.104:9100/\n```\n\n![image-20240103165201596](../img/k8s%E9%83%A8%E7%BD%B2Prometheus+Grafana.assets/c2700241ef8440f353b2e2d68e84e832697559838.png)\n\n#### 设置采集器开机自启动\n\n**加入systemd管理**\n\n```\ncat > /usr/lib/systemd/system/node_exporter.service << \"EOF\"\n[Unit]\nDescription=node_exporter\n[Service]\n#ExecStart=/usr/local/node_exporter/node_exporter --web.config=/usr/local/node_exporter/config.yml\nExecStart=/usr/local/node_exporter/node_exporter\nExecReload=/bin/kill -HUP $MAINPID\nKillMode=process\nRestart=on-failure\n[Install]\nWantedBy=multi-user.target\nEOF\n# 重新加载\nsystemctl daemon-reload\n# 启动\nsystemctl start node_exporter\n# 加入开机自启\nsystemctl enable node_exporter\n```\n\n#### Prometheus配置\n\n**配置文件修改**\n\n<font color='red'>操作节点[master1]</font>\n\n```\n在Prometheus配置文件添加被监控端\ncat > prome_cfg.yml << \"EOF\"\napiVersion: v1\nkind: ConfigMap\nmetadata:\n  name: prometheus-config\n  namespace: prometheus-work\ndata:\n  prometheus.yml: |\n    global:\n      scrape_interval: 15s\n      scrape_timeout: 15s\n    scrape_configs:\n    - job_name: 'prometheus'\n      static_configs:\n      - targets: ['localhost:9090']\n    - job_name: 'test'\n      static_configs:\n      - targets: ['192.168.48.104:9100']\n\nEOF\nkubectl apply -f prome_cfg.yml\n```\n\n热加载更新\n\n<font color='red'>操作节点[node01]</font>加的是哪个节点就在哪个节点进行热加载\n\n```\n#实现Prometheus热更新\ncurl -X POST http://192.168.48.104:30512/-/reload\n```\n\n访问prometheus页面查看http://192.168.48.104:30512\n\n![image-20240103192048627](../img/k8s%E9%83%A8%E7%BD%B2Prometheus+Grafana.assets/0bc9c1e585fc8faa1024148d386db551697559838.png)\n\n可以看到有记录了\n\n#### Grafana展示\n\n展示数据需要配置仪表盘，仪表盘可以自己制作导入，也可以从官方下载使用。\n\n进入grafana  http://192.168.48.105:31163\n\n![image-20240103192229794](../img/k8s%E9%83%A8%E7%BD%B2Prometheus+Grafana.assets/68ce702e3a54fc010b5eed8a2f8a9445697559838.png)\n\n这里直接输入9276仪表盘id，然后点击load\n\n![image-20240103192353726](../img/k8s%E9%83%A8%E7%BD%B2Prometheus+Grafana.assets/bc89d64827561e2d817129c323b6135c697559838.png)\n\n![image-20240103192457219](../img/k8s%E9%83%A8%E7%BD%B2Prometheus+Grafana.assets/7e68cce07a77c185791f1a78e4d020de697559838.png)\n\n![image-20240103192553778](../img/k8s%E9%83%A8%E7%BD%B2Prometheus+Grafana.assets/e8173f303cf08d29d0c2cf67148a372c697559838.png)\n\n默认情况下网络这部分是没有数据的\n\n![image-20240103192648040](../img/k8s%E9%83%A8%E7%BD%B2Prometheus+Grafana.assets/6fb716206070e90ad7dbddb15fe7a439697559838.png)\n\n![image-20240103192728841](../img/k8s%E9%83%A8%E7%BD%B2Prometheus+Grafana.assets/f7a3d89ddccd5d543b1cc85c8c096b9f697559838.png)\n\n![image-20240103192904616](../img/k8s%E9%83%A8%E7%BD%B2Prometheus+Grafana.assets/7253c84bd73260228ace9c4eceeec130697559838.png)\n\n点击右上角的save保存\n\n![image-20240103193009248](../img/k8s%E9%83%A8%E7%BD%B2Prometheus+Grafana.assets/9a9b29f404b4e471832b80c35bea3094697559838.png)\n\n![image-20240103193028376](../img/k8s%E9%83%A8%E7%BD%B2Prometheus+Grafana.assets/3fe3b746ea84bb1e57106ed40bb8db6e697559838.png)\n\n![image-20240103193049630](../img/k8s%E9%83%A8%E7%BD%B2Prometheus+Grafana.assets/065c6e6e0252f22fe4190059064d58a9697559838.png)\n\n### 监控多台linux\n\n- **复制安装文件**\n\n远程复制到新增的机器\n\n<font color='red'>假设我还要监控node02</font>\n\n<font color='red'>操作节点[node01]</font>\n\n```\nscp -r /usr/local/node_exporter root@192.168.48.105:/usr/local/\nscp /usr/lib/systemd/system/node_exporter.service root@192.168.48.105:/usr/lib/systemd/system/\n```\n\n<font color='red'>操作节点[node02]</font>\n\n```\n# 重新加载\nsystemctl daemon-reload\n# 启动\nsystemctl start node_exporter\n# 加入开机自启\nsystemctl enable node_exporter\n```\n\n添加采集器信息\n\n<font color='red'>操作节点[master1]</font>\n\n```yaml\n在Prometheus配置文件添加被监控端\ncat > prome_cfg.yml << \"EOF\"\napiVersion: v1\nkind: ConfigMap\nmetadata:\n  name: prometheus-config\n  namespace: prometheus-work\ndata:\n  prometheus.yml: |\n    global:\n      scrape_interval: 15s\n      scrape_timeout: 15s\n    scrape_configs:\n    - job_name: 'prometheus'\n      static_configs:\n      - targets: ['localhost:9090']\n    - job_name: 'test'\n      static_configs:\n      - targets: ['192.168.48.104:9100','192.168.48.105:9100']\n#以逗号分割添加新的node02地址的采集器\nEOF\nkubectl apply -f prome_cfg.yml\n```\n\n热加载更新\n\n<font color='red'>操作节点[node02]</font>\n\n```\n#实现Prometheus热更新\ncurl -X POST http://192.168.48.104:30512/-/reload\n```\n\n![image-20240103195032856](../img/k8s%E9%83%A8%E7%BD%B2Prometheus+Grafana.assets/e128ae8ca854893d5824a025b0458b5d697559838.png)\n\n![image-20240103195105169](../img/k8s%E9%83%A8%E7%BD%B2Prometheus+Grafana.assets/e76669ac7347997d5111c26e452a98e9697559838.png)\n\n<div class=\"tbsm\" style=\"margin-top:54px;\">\n<div class=\"tbsm-top\"><span><svg t=\"1674654360507\" class=\"icon\" viewBox=\"0 0 1024 1024\" version=\"1.1\" xmlns=\"http://www.w3.org/2000/svg\" p-id=\"987\" data-spm-anchor-id=\"a313x.7781069.0.i0\" width=\"35\" height=\"35\"><path d=\"M410.49 97.74H155.08a56.74 56.74 0 0 0-56.84 56.73V410a56.84 56.84 0 0 0 56.84 56.84h255.41A56.83 56.83 0 0 0 467.32 410V154.58a56.83 56.83 0 0 0-56.83-56.84zM410.49 558.74H155.08a56.74 56.74 0 0 0-56.84 56.73V871a56.84 56.84 0 0 0 56.84 56.84h255.41A56.83 56.83 0 0 0 467.32 871V615.58a56.83 56.83 0 0 0-56.83-56.84zM871.49 558.74H616.08a56.74 56.74 0 0 0-56.84 56.73V871a56.84 56.84 0 0 0 56.84 56.84h255.41A56.83 56.83 0 0 0 928.32 871V615.58a56.83 56.83 0 0 0-56.83-56.84z\" fill=\"#66EEFF\" p-id=\"988\"></path><path d=\"M410.49 558.74h-4.14A475 475 0 0 0 299.52 859.6a481.16 481.16 0 0 0 4.84 68.22h106.13A56.83 56.83 0 0 0 467.32 871V615.58a56.83 56.83 0 0 0-56.83-56.84zM871.49 558.74H616.08a56.74 56.74 0 0 0-56.84 56.73V871a56.84 56.84 0 0 0 56.84 56.84h255.41A56.83 56.83 0 0 0 928.32 871V615.58a56.83 56.83 0 0 0-56.83-56.84z\" fill=\"#C2F8FF\" p-id=\"989\"></path></svg></span><span style=\"font-size:30px;\"> 特别声明</span></div>\n<div class=\"tbsm-wz\">千屹博客旗下的所有文章，是通过本人课堂学习和课外自学所精心整理的知识巨著<br/>难免会有出错的地方<br/>如果细心的你发现了小失误，可以在下方评论区告诉我，或者私信我！<br />非常感谢大家的热烈支持！</div>\n</div>\n","tags":["Centos 7","K8s","Prometheus","Grafana"],"categories":["云原生"]},{"title":"基于CentOS Stream 8一键安装OpenStack Yoga版本","url":"/posts/11354/","content":"\n<meta name=\"referrer\" content=\"no-referrer\"/>\n\n# 基于CentOS Stream 8一键安装OpenStack Yoga版本\n\n## 主机拓扑\n\n| 主机名    | ip             | 内存 | cpu  | 硬盘      | OS              |\n| --------- | -------------- | ---- | ---- | --------- | --------------- |\n| openstack | 192.168.48.100 | 8G   | 2v2c | 100G+100G | CentOS Stream 8 |\n\n![image-20231229212257188](../img/%E4%B8%80%E9%94%AE%E9%83%A8%E7%BD%B2%E5%8D%95%E8%8A%82%E7%82%B9openstack-Yoga.assets/image-20231229212257188.png)\n\n本机镜像可以进入这里下载[CentOS-Stream-8-x86_64-latest-boot.iso](https://mirrors.aliyun.com/centos-vault/8-stream/isos/x86_64/CentOS-Stream-8-20240603.0-x86_64-dvd1.iso)\n\n注意！Centos Stream 8已经停止更新了，此实验可以用作测试，不可用于生产\n\n## 网络配置\n\n```\n[root@localhost ~]# vi /etc/sysconfig/network-scripts/ifcfg-ens160\nTYPE=Ethernet\nPROXY_METHOD=none\nBROWSER_ONLY=no\nBOOTPROTO=static\nDEFROUTE=yes\nIPV4_FAILURE_FATAL=no\nIPV6INIT=yes\nIPV6_AUTOCONF=yes\nIPV6_DEFROUTE=yes\nIPV6_FAILURE_FATAL=no\nIPV6_ADDR_GEN_MODE=eui64\nNAME=ens160\nUUID=025bf07f-8fc9-41eb-b26e-13218b0d434b\nDEVICE=ens160\nONBOOT=yes\nIPADDR=192.168.48.100\nPREFIX=24\nGATEWAY=192.168.48.2\nDNS1=192.168.48.2\nDNS2=114.114.114.114\n```\n\n## 基础配置\n\n```\n#设置主机名\nhostnamectl set-hostname openstack && bash\n\n#添加本地名称解析\ncat >>/etc/hosts << \"EOF\"\n192.168.48.100 openstack \nEOF\n#关闭防火墙\nsystemctl disable firewalld --now\nsed -i \"s#SELINUX=enforcing#SELINUX=disabled#g\" /etc/selinux/config\nsetenforce 0\n\n#值得需要注意的是，openstack不允许使用NetworkManager，而是需要使用Network，所以我们还需要安装Network的服务。\ndnf install -y network-scripts \nsystemctl disable --now NetworkManager\nsystemctl restart network\nsystemctl enable --now network\n\n#启用powertools库\ndnf config-manager --enable powertools\n\n#重建以下缓存\ndnf clean all && dnf makecache \n\n#升级软件包\ndnf -y update\nreboot\n\n```\n\n## 安装openstack\n\n```\n[root@openstack ~]#  dnf search release-openstack\n........\ncentos-release-openstack-yoga.noarch : OpenStack from the CentOS Cloud SIG repo configs\n\n#安装最新的yoga版本\ndnf install -y centos-release-openstack-yoga.noarch\n\n#安装packstack软件包并生成应答文件\ndnf install -y openstack-packstack\npackstack --gen-answer-file /root/openstack-answer.txt\n\n#修改应答文件\n#一键替换，若有其他需要根据需要自行修改其中的值\nsed -i 's/CONFIG_HEAT_INSTALL=n/CONFIG_HEAT_INSTALL=y/g; s/CONFIG_PROVISION_DEMO=y/CONFIG_PROVISION_DEMO=n/g; s/CONFIG_NEUTRON_OVN_BRIDGE_IFACES=/CONFIG_NEUTRON_OVN_BRIDGE_IFACES=br-ex:ens160/g' /root/openstack-answer.txt\n\nsed -i 's/CONFIG_KEYSTONE_ADMIN_PW=.*/CONFIG_KEYSTONE_ADMIN_PW=admin/g' /root/openstack-answer.txt\n\n#也可以手动替换\nvi /root/openstack-answer.txt\n-------------------------\nCONFIG_HEAT_INSTALL=y           #安装heat模板服务\nCONFIG_PROVISION_DEMO=n         #我们不要提供的demo项目\nCONFIG_KEYSTONE_ADMIN_PW=admin  #设置登陆密码\nCONFIG_NEUTRON_OVN_BRIDGE_IFACES=br-ex:ens160            #OVN端口映射，就是云主机连接外网时通过那块网卡进行数据包的转发\n-------------------------\n\n#开始安装\npackstack --answer-file /root/openstack-answer.txt \n```\n\n然后你就可以通过http://192.168.48.100/dashboard访问页面了\n\n<div class=\"tbsm\" style=\"margin-top:54px;\">\n<div class=\"tbsm-top\"><span><svg t=\"1674654360507\" class=\"icon\" viewBox=\"0 0 1024 1024\" version=\"1.1\" xmlns=\"http://www.w3.org/2000/svg\" p-id=\"987\" data-spm-anchor-id=\"a313x.7781069.0.i0\" width=\"35\" height=\"35\"><path d=\"M410.49 97.74H155.08a56.74 56.74 0 0 0-56.84 56.73V410a56.84 56.84 0 0 0 56.84 56.84h255.41A56.83 56.83 0 0 0 467.32 410V154.58a56.83 56.83 0 0 0-56.83-56.84zM410.49 558.74H155.08a56.74 56.74 0 0 0-56.84 56.73V871a56.84 56.84 0 0 0 56.84 56.84h255.41A56.83 56.83 0 0 0 467.32 871V615.58a56.83 56.83 0 0 0-56.83-56.84zM871.49 558.74H616.08a56.74 56.74 0 0 0-56.84 56.73V871a56.84 56.84 0 0 0 56.84 56.84h255.41A56.83 56.83 0 0 0 928.32 871V615.58a56.83 56.83 0 0 0-56.83-56.84z\" fill=\"#66EEFF\" p-id=\"988\"></path><path d=\"M410.49 558.74h-4.14A475 475 0 0 0 299.52 859.6a481.16 481.16 0 0 0 4.84 68.22h106.13A56.83 56.83 0 0 0 467.32 871V615.58a56.83 56.83 0 0 0-56.83-56.84zM871.49 558.74H616.08a56.74 56.74 0 0 0-56.84 56.73V871a56.84 56.84 0 0 0 56.84 56.84h255.41A56.83 56.83 0 0 0 928.32 871V615.58a56.83 56.83 0 0 0-56.83-56.84z\" fill=\"#C2F8FF\" p-id=\"989\"></path></svg></span><span style=\"font-size:30px;\"> 特别声明</span></div>\n<div class=\"tbsm-wz\">千屹博客旗下的所有文章，是通过本人课堂学习和课外自学所精心整理的知识巨著<br/>难免会有出错的地方<br/>如果细心的你发现了小失误，可以在下方评论区告诉我，或者私信我！<br />非常感谢大家的热烈支持！</div>\n</div>\n","tags":["Centos 8 stream","OpenStack"],"categories":["云原生"]},{"title":"Ceph集群分布式集群","url":"/posts/43453/","content":"\n<meta name=\"referrer\" content=\"no-referrer\"/>\n\n# Ceph集群分布式集群\n\n本篇教程针对<font color='red'>外部</font>ceph集群介绍教程，如果是基于K8S<font color='red'>内部</font>ceph请前往[基于K8S1.28.2实验rook部署ceph - 严千屹博客 (qianyios.top)](https://blog.qianyios.top/posts/58032/)\n\n## 机器拓扑\n\n| 主机名 | ip             | 硬盘1 | 硬盘2 | 内存 | cpu  | 软件                                                      | OS              |\n| ------ | -------------- | ----- | ----- | ---- | ---- | --------------------------------------------------------- | --------------- |\n| ceph1  | 192.168.48.101 | 100G  | 100G  | 2G   | 1v   | Docker 24.0.7<br />epel最新版本<br />ceph（reef、18.2.0） | Centos stream 9 |\n| ceph2  | 192.168.48.102 | 100G  | 100G  | 2G   | 1v   | Docker 24.0.7<br />epel最新版本<br />ceph（reef、18.2.0） | Centos stream 9 |\n| ceph3  | 192.168.48.103 | 100G  | 100G  | 2G   | 1v   | Docker 24.0.7<br />epel最新版本<br />ceph（reef、18.2.0） | Centos stream 9 |\n\n已经<font color='red'>测试过</font>了，<font color='red'>最小配置</font>，可以满足<font color='red'>毕设</font>需求，后面可自行根据需要调整\n\n![image-20231222141636094](../img/Ceph集群分布式存储集群/ee4eca61c8df08d1a105e1140609e13f697559838.png)\n\n## 基础配置\n\n### 系统基础配置\n\n配置主机名\n\nceph1\n\n```\nhostnamectl set-hostname ceph1 && bash\n```\n\nceph2\n\n```\nhostnamectl set-hostname ceph2 && bash\n```\n\nceph3\n\n```\nhostnamectl set-hostname ceph3 && bash\n```\n\n<font color='red'>操作节点[所有节点]</font>\n\n```\n#关闭防火墙和selinux\nsed -i \"s#SELINUX=enforcing#SELINUX=disabled#g\" /etc/selinux/config\nsetenforce 0\nsystemctl disable --now firewalld\n\n#设置时间同步\nyum install chrony -y\nsystemctl start chronyd\nsystemctl enable chronyd\nchronyc sources\nchronyc sources\n\n#配置hosts\ncat << EOF > /etc/hosts\n127.0.0.1   localhost localhost.localdomain localhost4 localhost4.localdomain4\n::1         localhost localhost.localdomain localhost6 localhost6.localdomain6\n192.168.48.101 ceph1\n192.168.48.102 ceph2\n192.168.48.103 ceph3\nEOF\n\n#配置yum\nmkdir repo.bak\nmv /etc/yum.repos.d/* repo.bak/\ncat > /etc/yum.repos.d/centos9.repo<< \"EOF\"\n[BaseOS]\nname=Baseos\nbaseurl=https://mirrors.aliyun.com/centos-stream/9-stream/BaseOS/x86_64/os\ngpgcheck=0\nenabled=1\n\n[AppStream]\nname=AppStream\nbaseurl=https://mirrors.aliyun.com/centos-stream/9-stream/AppStream/x86_64/os/\ngpgcheck=0\nenabled=1\n\n[extras-common]\nname=extras-common\nbaseurl=https://mirrors.aliyun.com/centos-stream/SIGs/9-stream/extras/x86_64/extras-common/\ngpgcheck=0\nenabled=0\n\n[ceph-reef]\nname=ceph-reef\nbaseurl=https://mirrors.aliyun.com/ceph/rpm-reef/el9/x86_64/\ngpgcheck=0\nenabled=1\n\n[epel]\nname=epel\nbaseurl=https://mirrors.aliyun.com/epel/9/Everything/x86_64/\ngpgcheck=0\nenabled=1\n\n[ceph-reef-noarch]\nname=ceph-reef-noarch\nbaseurl=https://mirrors.aliyun.com/ceph/rpm-reef/el9/noarch/\ngpgcheck=0\nenabled=1\n\nEOF\n\n# 内核参数设置：开启IP转发，允许iptables对bridge的数据进行处理 \ncat << EOF > /etc/sysctl.conf \nnet.ipv4.ip_nonlocal_bind = 1\nnet.ipv4.ip_forward = 1\nEOF\n\ncat << EOF > /etc/sysctl.d/ceph.conf \nkernel.pid_max = 4194303 \nvm.swappiness = 0 \nEOF\n\nsysctl -p\n\n#更新yum源\ndnf clean all && dnf makecache\n\n#安装软件\ndnf install vim net-tools wget lsof python3 yum-utils device-mapper-persistent-data lvm2 -y\n```\n\n### 配置ssh免密\n\n<font color='red'>操作节点[ceph1]</font>\n\n```yaml\nyum install -y sshpass \ncat > sshmianmi.sh << \"EOF\"\n#!/bin/bash\n# 目标主机列表\nhosts=(\"ceph1\" \"ceph2\" \"ceph3\")  #就改这个\n# 主机密码\npassword=\"123456\"                    #就改这个\n# 生成 SSH 密钥对\nssh-keygen -t rsa -N \"\" -f ~/.ssh/id_rsa\n\n# 循环遍历目标主机\nfor host in \"${hosts[@]}\"\ndo\n    # 复制公钥到目标主机\n    sshpass -p \"$password\" ssh-copy-id -o StrictHostKeyChecking=no \"$host\"\n    \n    # 验证免密登录\n    sshpass -p \"$password\" ssh -o StrictHostKeyChecking=no \"$host\" \"echo '免密登录成功'\"\ndone\nEOF\n\nsh sshmianmi.sh\n```\n\n## 安装docker\n\n<font color='red'>操作节点[所有节点]</font>\n\n```\nyum-config-manager --add-repo https://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo\ndnf install -y docker-ce docker-ce-cli containerd.io docker-compose-plugin\nsystemctl enable --now docker\nmkdir -p /etc/docker\ntee /etc/docker/daemon.json <<-'EOF'\n{\n  \"registry-mirrors\": [\"https://pw860av8.mirror.aliyuncs.com\"]\n}\nEOF\nsystemctl daemon-reload\nsystemctl restart docker\ndocker info\n```\n\n## 安装cephadm\n\n<font color='red'>操作节点[所有节点]</font>\n\n```\ndnf install --assumeyes cephadm\nwhich cephadm\n```\n\n## 安装ceph集群\n\n### 启动一个集群\n\n<font color='red'>操作节点[ceph1]</font>\n\n在 ceph1 上启动 cephadm bootstrap\n\n```\ncephadm bootstrap --mon-ip 192.168.48.101\n```\n\n上述指令会为我们完成以下工作：\n\n- 创建mon\n- 创建ssh key并且添加到 /root/.ssh/authorized_keys 文件\n- 将集群间通信的最小配置写入/etc/ceph/ceph.conf\n- 将client.admin管理secret密钥的副本写入/etc/ceph/ceph.client.admin.keyring。\n- 将公用密钥的副本写入/etc/ceph/ceph.pub\n\n执行结果如下：\n\n框框中的是ceph页面的账号密码\n\n![image-20231222140050214](../img/Ceph集群分布式存储集群/452e9a762119d38b6bf2d09c4cf5871f697559838.png)\n\n<font color='red'>访问页面并用上面的账号密码登入，就会提示你修改密码，修改成你自己的密码</font>\n\n```\nhttps://192.168.48.101:8443/\n```\n\n![image-20231222140150112](../img/Ceph集群分布式存储集群/06d8cf6ce8eee0d48374ed664e384c67697559838.png)\n\n运行ceph查看集群健康状态\n\n```\n[root@ceph1 ~]# ceph -s\nbash: ceph: command not found\n```\n\n这里会显示<font color='red'>报错</font>，我们要在<font color='red'>所有节点</font>需要安装ceph-common\n\n<font color='red'>操作节点[所有节点]</font>\n\n```\ncephadm add-repo --release reef\ndnf install -y liburing\n# 安装ceph-common包\ndnf install -y librbd1 ceph-common\n# 查看ceph-common是否正常安装\nceph -v\n```\n\n再次在<font color='red'>ceph1</font>查看集群健康状况\n\n```\nceph -s\n```\n\n![image-20231222140331471](../img/Ceph集群分布式存储集群/1b57598993c2effa3fb0f3c7f30edb34697559838.png)\n\n这里有报错提示<font color='red'>HEALTH_WARN</font>暂时不用管\n\n### 添加ceph节点\n\n<font color='red'>操作节点[ceph1]</font>\n\n```bash\n#拷贝ceph1的Ceph 集群的公钥至其他节点，以便加入集群\nssh-copy-id -f -i /etc/ceph/ceph.pub root@ceph2\nssh-copy-id -f -i /etc/ceph/ceph.pub root@ceph3\n# 添加ceph节点\nceph orch host add ceph2 192.168.48.102\nceph orch host add ceph3 192.168.48.103\n\n删除可以用\nceph orch host rm ceph3\n# 查看现在的节点情况\nceph orch host ls\n# 添加label后可以允许该节点运行ceph cli（比如cephadm shell命令）\nceph orch host label add ceph2 _admin\nceph orch host label add ceph3 _admin\n# 设置 mon 节点\nceph orch apply mon 3\nceph orch apply mon ceph1,ceph2,ceph3\n# 查看 mon 详情\n[root@ceph1 ~]#  ceph mon dump\nepoch 3\nfsid 233c64c8-9e76-11ee-86fc-000c2965f5d0\nlast_changed 2023-12-19T14:13:02.000188+0000\ncreated 2023-12-19T13:56:10.829244+0000\nmin_mon_release 18 (reef)\nelection_strategy: 1\n0: [v2:192.168.48.101:3300/0,v1:192.168.48.101:6789/0] mon.ceph1\n1: [v2:192.168.48.103:3300/0,v1:192.168.48.103:6789/0] mon.ceph3\n2: [v2:192.168.48.102:3300/0,v1:192.168.48.102:6789/0] mon.ceph2\ndumped monmap epoch 3\n\n# 设置 mgr 节点\nceph orch apply mgr 3\nceph orch apply mgr ceph1,ceph2,ceph3\n[root@ceph1 ~]#  ceph -s\n  cluster:\n    id:     233c64c8-9e76-11ee-86fc-000c2965f5d0\n    health: HEALTH_WARN\n            OSD count 0 < osd_pool_default_size 3\n\n  services:\n    mon: 3 daemons, quorum ceph1,ceph3,ceph2 (age 7m)\n    mgr: ceph1.gtejkn(active, since 18m), standbys: ceph2.rvzimn, ceph3.pbajtu\n    osd: 0 osds: 0 up, 0 in\n\n  data:\n    pools:   0 pools, 0 pgs\n    objects: 0 objects, 0 B\n    usage:   0 B used, 0 B / 0 B avail\n    pgs:\n\n```\n\n### 添加OSD\n\n<font color='red'>操作节点[ceph1]</font>\n\n![image-20231222141243608](../img/Ceph集群分布式存储集群/4b77a3a2f519ba8c01195299653efa24697559838.png)\n\n```\nceph orch daemon add osd ceph1:/dev/nvme0n2\nceph orch daemon add osd ceph2:/dev/nvme0n2\nceph orch daemon add osd ceph3:/dev/nvme0n2\n```\n\n查看状态\n\n```bash\n[root@ceph1 ~]# ceph -s\n  cluster:\n    id:     233c64c8-9e76-11ee-86fc-000c2965f5d0\n    health: HEALTH_OK\n\n  services:\n    mon: 3 daemons, quorum ceph1,ceph3,ceph2 (age 25m)\n    mgr: ceph1.gtejkn(active, since 36m), standbys: ceph2.rvzimn, ceph3.pbajtu\n    osd: 3 osds: 3 up (since 20s), 3 in (since 33s)\n\n  data:\n    pools:   1 pools, 1 pgs\n    objects: 2 objects, 449 KiB\n    usage:   81 MiB used, 300 GiB / 300 GiB avail\n    pgs:     1 active+clean\n\n[root@ceph1 ~]#\n```\n\n<font color='green'>至此ceph集群部署成果</font>\n\n## ceph存储的使用\n\n| 存储类型           | 特征                                                         | 应用场景          | 典型设备  |\n| :----------------- | :----------------------------------------------------------- | :---------------- | :-------- |\n| 块存储（RBD）      | 存储速度较快 不支持共享存储 [**ReadWriteOnce**]              | 虚拟机硬盘        | 硬盘 Raid |\n| 文件存储（CephFS） | 存储速度慢（需经操作系统处理再转为块存储） 支持共享存储 [**ReadWriteMany**] | 文件共享          | FTP NFS   |\n| 对象存储（Object） | 具备块存储的读写性能和文件存储的共享特性 操作系统不能直接访问，只能通过应用程序级别的API访问 | 图片存储 视频存储 | OSS       |\n\n### 块存储(RBD)\n\n#### 配置rbd\n\n<font color='red'>操作节点[ceph1]</font>\n\n```bash\n------------------------------------------------------\n#创建名为qianyios-rbd的存储池pool\nceph osd pool create qianyios-rbd 128 128 \n\n[root@ceph1 ~]# ceph osd pool create qianyios-rbd 128 128\npool 'qianyios-rbd' created\n\n\n#删除pool用这个\nceph osd pool delete qianyios-rbd qianyios-rbd --yes-i-really-really-mean-it\n------------------------------------------------------\n#查看列表\nceph osd pool ls\n\n[root@ceph1 ~]# ceph osd pool ls\n.mgr\nqianyios-rbd\n------------------------------------------------------\n#将类型为存储池的pool（qianyios-rbd）转换为rbd类型\nceph osd pool application enable qianyios-rbd rbd\n\n[root@ceph1 ~]# ceph osd pool application enable qianyios-rbd rbd\nenabled application 'rbd' on pool 'qianyios-rbd'\n\n------------------------------------------------------\n#初始化qianyios-rbd存储池\nrbd pool init qianyios-rbd\n------------------------------------------------------\n#创建一个名为 \"qy-rbd-img\" 的 RBD 镜像，存储在 \"qianyios-rbd\" 存储池中，镜像的大小为 10GB。\nrbg create -p qianyios-rbd --image qy-rbd-img --size 10G\n或者（二选一）\nrbd create --size 10G qianyios-rbd/qy-rbd-img\n#删除镜像用这个\nrbd rm qianyios-rbd/qy-rbd-img\n\n------------------------------------------------------\n#查看创建状态\nrbd ls qianyios-rbd\n\nrbd info qianyios-rbd/qy-rbd-img\n\n[root@ceph1 ~]# rbd ls qianyios-rbd\nqy-rbd-img\n[root@ceph1 ~]# rbd info qianyios-rbd/qy-rbd-img\nrbd image 'qy-rbd-img':\n        size 10 GiB in 2560 objects\n        order 22 (4 MiB objects)\n        snapshot_count: 0\n        id: 8589e2720f1f\n        block_name_prefix: rbd_data.8589e2720f1f\n        format: 2\n        features: layering, exclusive-lock, object-map, fast-diff, deep-flatten\n        op_features:\n        flags:\n        create_timestamp: Thu Dec 21 23:09:33 2023\n        access_timestamp: Thu Dec 21 23:09:33 2023\n        modify_timestamp: Thu Dec 21 23:09:33 2023\n\n------------------------------------------------------\n# 创建rbd 用户key（验证文件）\n#创建一个名为 \"qianyios-user\" 的客户端，并为其授予读写qianyios-rbd存储池的权限\nceph auth get-or-create client.qianyios-user mon 'profile rbd' osd 'profile rbd pool=qianyios-rbd' mgr 'profile rbd pool=qianyios-rbd'\n# output会输出以下内容\n[client.qianyios-user]\n        key = AQDKVYRl1nZ8ARAAvhXZojmroyy+YIb9dnTGSw==\n\nceph auth get client.qianyios-user -o /root/ceph.client.qianyios-user.keyring\n\n[root@ceph1 ~]# cat /root/ceph.client.qianyios-user.keyring\n[client.qianyios-user]\n        key = AQDKVYRl1nZ8ARAAvhXZojmroyy+YIb9dnTGSw==\n        caps mgr = \"profile rbd pool=qianyios-rbd\"\n        caps mon = \"profile rbd\"\n        caps osd = \"profile rbd pool=qianyios-rbd\"\n------------------------------------------------------\n```\n\n<font color='red'>!讲解一下这个创建用户key（验证文件）</font>\n\n1. 讲解：通过这个命令，会创建一个用户，并分别指定这个用户对mon、osd、mgr的权限。如果不加pool=xxx，则这个用户能管理整个守护进程。\n\n2. mon的权限必须是mon 'profile rbd'，因为Mon服务本身就是只读的，你再限制一个只读权限，脱裤子放屁。 \n\n3. 假设你写了 osd 'profile rbd'，则用户能管理所有pool的osd设备。\n\n4. 假设你写了osd 'profile rbd pool=xxx'，则这个用户可以读写名叫xxx的pool的osd设备。\n\n5. 假设你写了osd 'profile rbd-read-only pool=xxx'，则这个用户只能读取名叫xxx的pool中的osd数据，不能写入。\n\n6. mgr同理，但是最好不要写mgr 'profile rbd'，否则A池的管理员能够关闭B池的librados接口，那就糟糕了。\n\n<font color='red'>举例：</font>\n\n1. 创建一个volumes用户，该用户对volumes池拥有读写权限\n\n```bash\nceph auth get-or-create client.volumes mon 'profile rbd' osd 'profile rbd pool=volumes' mgr 'profile rbd pool=volumes'\n```\n\n2. 创建一个volumes用户，该用户对volumes池拥有只读权限。\n\n```bash\nceph auth get-or-create client.volumes mon 'profile rbd' osd 'profile rbd-read-only pool=volumes' mgr 'profile rbd pool=volumes'\n```\n\n#### 客户端挂载\n\n这里新开一台客户机centos stream 9，这个客户端可以是你的任何一台机要挂载的机子\n\n##### 添加yum\n\n<font color='red'>操作节点[test]测试机</font>\n\n```\nmkdir repo.bak\nmv /etc/yum.repos.d/* repo.bak/\ncat > /etc/yum.repos.d/centos9.repo<< \"EOF\"\n[BaseOS]\nname=Baseos\nbaseurl=https://mirrors.aliyun.com/centos-stream/9-stream/BaseOS/x86_64/os\ngpgcheck=0\nenabled=1\n\n[AppStream]\nname=AppStream\nbaseurl=https://mirrors.aliyun.com/centos-stream/9-stream/AppStream/x86_64/os/\ngpgcheck=0\nenabled=1\n\n[extras-common]\nname=extras-common\nbaseurl=https://mirrors.aliyun.com/centos-stream/SIGs/9-stream/extras/x86_64/extras-common/\ngpgcheck=0\nenabled=0\n\n[ceph-reef]\nname=ceph-reef\nbaseurl=https://mirrors.aliyun.com/ceph/rpm-reef/el9/x86_64/\ngpgcheck=0\nenabled=1\n\n[epel]\nname=epel\nbaseurl=https://mirrors.aliyun.com/epel/9/Everything/x86_64/\ngpgcheck=0\nenabled=1\n\n[ceph-reef-noarch]\nname=ceph-reef-noarch\nbaseurl=https://mirrors.aliyun.com/ceph/rpm-reef/el9/noarch/\ngpgcheck=0\nenabled=1\n\nEOF\ndnf clean all && dnf makecache\n```\n\n##### 客户端安装cephadm和ceph-common\n\n<font color='red'>操作节点[test]测试机</font>\n\n```\ndnf install -y cephadm ceph-common\n```\n\n##### 拷贝ceph1的证书至客户端\n\n把ceph1创建的`ceph.client.qianyios-user.keyring `和`ceph.conf`复制到客户端（192.168.48.128）\n\n```\nscp /root/ceph.client.qianyios-user.keyring /etc/ceph/ceph.conf 192.168.48.128:/etc/ceph/\n```\n\n![image-20231221234526458](../img/Ceph集群分布式存储集群/8dfd15373ce9782a78fce4cd6c6fab04697559838.png)\n\n```\n[root@test ~]# ll /etc/ceph/\ntotal 12\n-rw-r--r-- 1 root root 185 Dec 21 23:45 ceph.client.qianyios-user.keyring\n-rw-r--r-- 1 root root 283 Dec 21 23:45 ceph.conf\n-rw-r--r-- 1 root root  92 Dec 12 08:01 rbdmap\n[root@test ~]#\n\n```\n\n##### 开始挂载\n\n```\nlsblk\n```\n\n![image-20231221234732781](../img/Ceph集群分布式存储集群/7b9e98b0b89aaee9ebe74e3b00e327c9697559838.png)\n\n```bash\n#挂载块存储\nrbd map qianyios-rbd/qy-rbd-img --keyring /etc/ceph/ceph.client.qianyios-user.keyring --id qianyios-user\n-----\n/dev/rbd0\n-----\nlsblk\n```\n\n![image-20231221235206886](../img/Ceph集群分布式存储集群/beeceb41666f2a645bae6ef99ea31e79697559838.png)\n\n此时的/dev/rbd0并不能使用，我们需要格式化，并且挂载到本机\n\n```\n#格式化\nmkfs.xfs /dev/rbd0\n```\n\n![image-20231221235300388](../img/Ceph集群分布式存储集群/2895454912e2a32aef8bd9a44bc84524697559838.png)\n\n```\n#创建挂载点\nmkdir /opt/qianyios-rbd\nmount /dev/rbd0 /opt/qianyios-rbd\necho \"qianyios-rbd\" > /opt/qianyios-rbd.txt\ncat /opt/qianyios-rbd.txt\n```\n\n![image-20231221235710235](../img/Ceph集群分布式存储集群/e5aeda5d2c58e59c16208e2424cacc38697559838.png)\n\n##### 取消挂载\n\n```\numount /opt/qianyios-rbd\nrbd unmap qianyios-rbd/qy-rbd-img\nlsblk\n```\n\n![image-20231221235845353](../img/Ceph集群分布式存储集群/6c15b24a872dc2c10e18c919d93f4be6697559838.png)\n\n### 文件存储(CephFS)\n\n#### 创建cephfs\n\n部署元数据服务器，创建一个CephFS(文件系统), 名字为qianyios-fs\n\n```\nceph fs volume create qianyios-fs --placement=\"3 ceph1 ceph2 ceph3\"\n# 查看状态\nceph fs volume ls\nceph orch ps --daemon-type mds\nceph fs status qianyios-fs\nceph mds stat\n```\n\n![image-20231222130830482](../img/Ceph集群分布式存储集群/f7d4c00cc9aa778e7644ec48f9295b50697559838.png)\n\n#### 设置nfs高可用\n\n先生成nfs和nfs_ingress配置文件。其中nfs_ingress是为了nfs高可用配置的。\n\n```yaml\ncat <<EOF > nfs.yaml\nservice_type: nfs\nservice_id: nkonfs\nplacement:\n  hosts:\n    - ceph1\n    - ceph2\n    - ceph3\nspec:\n  port: 2048\nEOF\n\ncat <<EOF >nfs_ingress.yaml\nservice_type: ingress\nservice_id: nfs.nkonfs\nplacement:\n  count: 3\nspec:\n  backend_service: nfs.nkonfs\n  frontend_port: 2049\n  monitor_port: 9001\n  virtual_ip: 192.168.48.200/24#高可用vip\nEOF\n```\n\n```\nceph orch apply -i nfs.yaml\nceph orch apply -i nfs_ingress.yaml\n\nceph orch ls --service_name=nfs.nkonfs\nceph orch ls --service_name=ingress.nfs.nkonfs\nceph nfs cluster ls\nceph nfs cluster info nkonfs\n```\n\n![image-20231222131458220](../img/Ceph集群分布式存储集群/0c06c480d86468cb6fbd5af2477d7993697559838.png)\n\n#### 导出nfs\n\n```\nceph nfs export create cephfs --cluster-id nkonfs --pseudo-path /qy-fs --fsname qianyios-fs\n# 查看详情\nceph nfs export info nkonfs /qy-fs\n```\n\n![image-20231222131516871](../img/Ceph集群分布式存储集群/714155b3d6f26119cc937353e4d58155697559838.png)\n\n#### 客户端挂载NFS\n\n注意：只支持 NFS v4.0+ 的协议。\n由于showmount 不支持 NFS v4，纯 NFSv4又不提供其他获取导出列表的方法，只能期望挂载的时候命令不要输错了。\n在客户端执行以下命令：\n\n```\ndnf install -y nfs-utils\nmkdir /qy-fs-data\nmount -t nfs -o nfsvers=4.1,proto=tcp 192.168.48.200:/qy-fs /qy-fs-data\n```\n\n![image-20231222131709705](../img/Ceph集群分布式存储集群/128567c29eeefce480d478ec756a75b2697559838.png)\n\n#### 测试文件写入\n\n```\ntar zcf etc.tar.gz /etc\n \n#测试文件写入\ncp etc.tar.gz /qy-fs-data/\nll /qy-fs-data/\n \n#生成500M大文件写入\ndd if=/dev/zero of=/qy-fs-data/testfile bs=1M count=500\n\n#查看分区使用\ndf -h /fsdata\n```\n\n![image-20231222132148957](../img/Ceph集群分布式存储集群/c892100f0204746bde00a42e9659133c697559838.png)\n\n### 对象存储(RGW)\n\n`RGW（RADOS Gateway）`是Ceph存储系统的一部分，它提供了一个`对象存储服务`\n\n`RGW`可以作为一个`独立的服务运行`，`也可以与Ceph集群的其他组件（如OSD和MON）一起部署`。\n\n`区域（zone）`: 一个ceph集群可以包含多个区域，一个区域只属于一个集群，一个区域可以有多个RGW\n\n`区域组（zonegroup）`：由一个或多个区域组成，包含一个主区域（master zone），其他区域称为Secondary Zone，区域组内的所有区域之间同步数据\n\n`域（realm）`: 同一个或多个区域组组成，包含一个主区域组，其他都次区域组。域中的所有rados网关都从位于主区域组和主区域中的rados网关拉取配置\n\n#### 设置radosgw区域和用户\n\n![image-20231220233812600](../img/Ceph集群分布式存储集群/4c29c4111ef003546990e4512d6019df697559838.png)\n\n在<font color='red'>所有节点</font>部署qianyios领域和qianyios-shenzhen 区域的rgw守护程序：\n\n<font color='red'>操作节点[所有节点]</font>\n\n```bash\n1.# 如果尚未创建 realm（领域），请首先创建一个名字为qianyios的 realm（领域） ：\nradosgw-admin realm create --rgw-realm=qianyios\nradosgw-admin realm list\n\n2.# 接下来创建一个新的 zonegroup（区域组）：\nradosgw-admin zonegroup create --rgw-zonegroup=qianyios-shenzhen  --master\nradosgw-admin zonegroup list\n\n3.#接下来创建一个 zone：\nradosgw-admin zone create --rgw-zonegroup=qianyios-shenzhen --rgw-zone=qianyios-shenzhen-zone1 --master\n#这个命令用于创建一个名为 qianyios-shenzhen-zone1 的 RadosGW 区域（Zone），并将它归属于 qianyios-shenzhen 的区域组（Zone Group）。\nradosgw-admin zone list\n\n4.#这个命令用于更新指定的 RadosGW 域（Realm）的周期（Period）。--rgw-realm=qianyios 参数指定要更新的 RadosGW 域的名称为 qianyios\nradosgw-admin period update --rgw-realm=qianyios --commit\n\n\n5.#在 Ceph 集群中部署一个名为 qianyios-rgw 的 RadosGW 实例，并将其关联到指定的域（Realm）、区域组（Zone Group）和区域（Zone），并指定了存储位置。\nceph orch apply rgw qianyios-rgw --realm=qianyios --zonegroup=qianyios-shenzhen --zone=qianyios-shenzhen-zone1 --placement=\"3 ceph1 ceph2 ceph3\" --port=8080\n\n#删除实例用这个\nceph orch rm rgw.qianyios-rgw\n\n6.# 查看各节点 rgw 是否启动\nceph orch ps --daemon-type rgw\n\n7.# 创建创建 radosgw 用户名为admin，显示名称为admin user\nradosgw-admin user create --uid=\"admin\" --display-name=\"admin user\"\n\n8.# 创建完成之后需要把access_key和secret_key保存下来，也可以使用下面的命令来查看\nradosgw-admin user info --uid=admin\n\n\"keys\": [\n        {\n            \"user\": \"admin\",\n            \"access_key\": \"LAI14X0RJVJG3QGR16FP\",\n            \"secret_key\": \"t11PVzqYtEvb22ajctD0U5tCN5d0CaDPkZENiqTb\"\n        }\n    ],\n```\n\n使用[s3 browser点击这里访问官网下载软件](https://s3browser.com/)，将以上access_key,secret_key填上，可以正常连接，但是没有桶，手动创建一个桶，并上传文件，正常。\n\n![image-20231221001128450](../img/Ceph集群分布式存储集群/76a3ec58bebf509d1f3d142a7199d1cb697559838.png)\n\n此时什么都没有，创建一个桶\n\n![image-20231221001200312](../img/Ceph集群分布式存储集群/3fd0f612edc0de586159ff4b9515acfe697559838.png)\n\n![image-20231221001228678](../img/Ceph集群分布式存储集群/8d6133baba34facea5a5023c32e0b8e5697559838.png)\n\n在桌面创建一个test文件移进去\n\n![image-20231221001351913](../img/Ceph集群分布式存储集群/99676066de089ffb0795d766a676149f697559838.png)\n\n<div class=\"tbsm\" style=\"margin-top:54px;\">\n<div class=\"tbsm-top\"><span><svg t=\"1674654360507\" class=\"icon\" viewBox=\"0 0 1024 1024\" version=\"1.1\" xmlns=\"http://www.w3.org/2000/svg\" p-id=\"987\" data-spm-anchor-id=\"a313x.7781069.0.i0\" width=\"35\" height=\"35\"><path d=\"M410.49 97.74H155.08a56.74 56.74 0 0 0-56.84 56.73V410a56.84 56.84 0 0 0 56.84 56.84h255.41A56.83 56.83 0 0 0 467.32 410V154.58a56.83 56.83 0 0 0-56.83-56.84zM410.49 558.74H155.08a56.74 56.74 0 0 0-56.84 56.73V871a56.84 56.84 0 0 0 56.84 56.84h255.41A56.83 56.83 0 0 0 467.32 871V615.58a56.83 56.83 0 0 0-56.83-56.84zM871.49 558.74H616.08a56.74 56.74 0 0 0-56.84 56.73V871a56.84 56.84 0 0 0 56.84 56.84h255.41A56.83 56.83 0 0 0 928.32 871V615.58a56.83 56.83 0 0 0-56.83-56.84z\" fill=\"#66EEFF\" p-id=\"988\"></path><path d=\"M410.49 558.74h-4.14A475 475 0 0 0 299.52 859.6a481.16 481.16 0 0 0 4.84 68.22h106.13A56.83 56.83 0 0 0 467.32 871V615.58a56.83 56.83 0 0 0-56.83-56.84zM871.49 558.74H616.08a56.74 56.74 0 0 0-56.84 56.73V871a56.84 56.84 0 0 0 56.84 56.84h255.41A56.83 56.83 0 0 0 928.32 871V615.58a56.83 56.83 0 0 0-56.83-56.84z\" fill=\"#C2F8FF\" p-id=\"989\"></path></svg></span><span style=\"font-size:30px;\"> 特别声明</span></div>\n<div class=\"tbsm-wz\">千屹博客旗下的所有文章，是通过本人课堂学习和课外自学所精心整理的知识巨著<br/>难免会有出错的地方<br/>如果细心的你发现了小失误，可以在下方评论区告诉我，或者私信我！<br />非常感谢大家的热烈支持！</div>\n</div>\n","tags":["Centos 9 stream","Ceph"],"categories":["云原生"]},{"title":"K8S高可用集群（内部etcd）","url":"/posts/7158/","content":"\n<meta name=\"referrer\" content=\"no-referrer\"/>\n\n# K8S高可用集群（内部etcd）\n\n以下会用到的资源[K8s1.28.2（内外部etcd高可用）所需资源](https://www.123pan.com/s/MYnLVv-gLp4.html)\n\n## 主机拓扑\n\n| 主机名  | ip1（NAT）     | 系统      | 磁盘 | 内存 |\n| ------- | -------------- | --------- | ---- | ---- |\n| master1 | 192.168.48.101 | Centos7.9 | 100G | 4G   |\n| master2 | 192.168.48.102 | Centos7.9 | 100G | 4G   |\n| master3 | 192.168.48.103 | Centos7.9 | 100G | 4G   |\n| node01  | 192.168.48.104 | Centos7.9 | 100G | 8G   |\n\n## 基础配置\n\ncentos通过单独安装，非克隆。安装完后进行基本环境的配置，配置一下几个方面：\n\n1. 设置主机名\n2. 关闭NetworkManager、firewalld、dnsmasq、selinux\n3. 设置ens33\n4. 优化ssh\n6. 备份并新增清华yum源、epel源、docker-ce源、k8s源\n7. 更新yum源软件包缓存\n8. 修改history格式及记录数\n9. 添加hosts解析\n10. 关闭swap分区\n11. 安装chrony服务，并同步时间\n12. 配置limits.conf\n13. 安装必备工具\n14. 升级系统并重启\n\n操作主机：[master1,master2,master3,node01]\n\n```\n#!/bin/bash\nif [ $# -eq 2 ];then\n  echo \"设置主机名为：$1\"\n  echo \"ens33设置IP地址为：192.168.48.$2\"\nelse\n  echo  \"使用方法：sh $0 主机名 主机位\"\n  exit 2\nfi\n\necho \"--------------------------------------\"\necho \"1.正在设置主机名：$1\"\nhostnamectl set-hostname $1\n\n\necho \"2.正在关闭NetworkManager、firewalld、dnsmasq、selinux\"\nsystemctl disable firewalld &> /dev/null\nsystemctl disable NetworkManager &> /dev/null\nsystemctl disable dnsmasq &> /dev/null\nsystemctl stop firewalld\nsystemctl stop NetworkManager\nsystemctl stop dnsmasq\nsed -i \"s#SELINUX=enforcing#SELINUX=disabled#g\" /etc/selinux/config\nsetenforce 0\n\n\necho \"3.正在设置ens33：192.168.48.$2\"\ncat > /etc/sysconfig/network-scripts/ifcfg-ens33 <<EOF\nTYPE=ensernet\nBOOTPROTO=static\nDEFROUTE=yes\nNAME=ens33\nDEVICE=ens33\nONBOOT=yes\nIPADDR=192.168.48.$2\nNETMASK=255.255.255.0\nGATEWAY=192.168.48.2\nDNS1=114.114.114.114\nEOF\nsystemctl restart network\n\n\necho \"4.优化ssh\"\nsed -i \"s#\\#UseDNS yes#UseDNS no#g\" /etc/ssh/sshd_config\nsed -i \"s#GSSAPIAuthentication yes#GSSAPIAuthentication no#g\" /etc/ssh/sshd_config\nsystemctl restart sshd\n\necho \"5.备份并新增清华yum源、epel源、docker-ce源、k8s源\"\nrm -rf /etc/yum.repos.d/*\ncat > /etc/yum.repos.d/Centos-Base.repo <<EOF\n[base]\nname=CentOS-$releasever - Base\nbaseurl=https://mirrors.tuna.tsinghua.edu.cn/centos/\\$releasever/os/\\$basearch/\ngpgcheck=1\ngpgkey=file:///etc/pki/rpm-gpg/RPM-GPG-KEY-CentOS-7\n\n[updates]\nname=CentOS-$releasever - Updates\nbaseurl=https://mirrors.tuna.tsinghua.edu.cn/centos/\\$releasever/updates/\\$basearch/\ngpgcheck=1\ngpgkey=file:///etc/pki/rpm-gpg/RPM-GPG-KEY-CentOS-7\n\n[extras]\nname=CentOS-$releasever - Extras\nbaseurl=https://mirrors.tuna.tsinghua.edu.cn/centos/\\$releasever/extras/\\$basearch/\ngpgcheck=1\ngpgkey=file:///etc/pki/rpm-gpg/RPM-GPG-KEY-CentOS-7\n\n[centosplus]\nname=CentOS-$releasever - Plus\nbaseurl=https://mirrors.tuna.tsinghua.edu.cn/centos/\\$releasever/centosplus/\\$basearch/\ngpgcheck=1\nenabled=0\ngpgkey=file:///etc/pki/rpm-gpg/RPM-GPG-KEY-CentOS-7\nEOF\n\ncat > /etc/yum.repos.d/epel.repo <<EOF\n[epel]\nname=Extra Packages for Enterprise Linux 7 - \\$basearch\nbaseurl=https://mirrors.tuna.tsinghua.edu.cn/epel/7/\\$basearch\nfailovermensod=priority\nenabled=1\ngpgcheck=1\ngpgkey=file:///etc/pki/rpm-gpg/RPM-GPG-KEY-EPEL-7\n\n[epel-debuginfo]\nname=Extra Packages for Enterprise Linux 7 - \\$basearch - Debug\nbaseurl=https://mirrors.tuna.tsinghua.edu.cn/epel/7/\\$basearch/debug\nfailovermensod=priority\nenabled=0\ngpgkey=file:///etc/pki/rpm-gpg/RPM-GPG-KEY-EPEL-7\ngpgcheck=1\n\n[epel-source]\nname=Extra Packages for Enterprise Linux 7 - \\$basearch - Source\nbaseurl=https://mirrors.tuna.tsinghua.edu.cn/epel/7/SRPMS\nfailovermensod=priority\nenabled=0\ngpgkey=file:///etc/pki/rpm-gpg/RPM-GPG-KEY-EPEL-7\ngpgcheck=1\nEOF\n\ncat > /etc/yum.repos.d/kubernetes.repo <<EOF\n[kubernetes]\nname=Kubernetes\nbaseurl=https://mirrors.aliyun.com/kubernetes/yum/repos/kubernetes-el7-x86_64/\nenabled=1\ngpgcheck=0\nrepo_gpgcheck=0\ngpgkey=https://mirrors.aliyun.com/kubernetes/yum/doc/yum-key.gpg https://mirrors.aliyun.com/kubernetes/yum/doc/rpm-package-key.gpg\nEOF\n\ncurl -o /etc/yum.repos.d/docker-ce.repo https://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo\n\necho \"6.更新yum源软件包缓存\"\n yum clean all && yum makecache\n\n\necho \"7.修改history格式及记录数\"\nsed -i \"s#HISTSIZE=1000##g\" /etc/profile\ncat >> /etc/profile <<EOF\nshopt -s histappend\nUSER_IP=`who -u am i 2>/dev/null| awk '{print $NF}'|sed -e 's/[()]//g'`\nexport HISTFILE=~/.commandline_warrior\nexport HISTTIMEFORMAT=\"%Y-%m-%d %H:%M:%S  `whoami`@${USER_IP}: \"\nexport HISTSIZE=200000\nexport HISTFILESIZE=1000000\nexport PROMPT_COMMAND=\"history -a\"\nEOF\nsource /etc/profile\n\n\necho \"8.添加hosts解析\"\ncat >> /etc/hosts <<EOF\n192.168.48.101 master1\n192.168.48.102 master2\n192.168.48.103 master3\n192.168.48.104 node01\nEOF\n\n\necho \"9.关闭swap分区\"\nswapoff -a && sysctl -w vm.swappiness=0 &> /dev/null\nsed -ri '/^[^#]*swap/s@^@#@' /etc/fstab\n\n\necho \"10.安装ntpdate服务，并同步时间\"\nyum install chrony -y\nsystemctl start chronyd\nsystemctl enable chronyd\nchronyc sources\nchronyc sources\n\necho \"11.配置limits.conf\"\nulimit -SHn 65535\ncat >> /etc/security/limits.conf <<EOF\n* soft nofile 65536\n* hard nofile 131072\n* soft nproc 65535\n* hard nproc 655350\n* soft memlock unlimited\n* hard memlock unlimited\nEOF\n\n\necho \"12.必备工具安装\"\nyum install wget psmisc vim net-tools telnet yum-utils device-mapper-persistent-data lvm2 git -y\n\n\necho \"13.升级系统并重启\"\nyum update -y --exclude=kernel* && reboot\n\n```\n\n```\nsh k8s_system_init.sh 主机名 主机位\n[master1] sh k8s_system_init.sh master1 101\n\n[master2] sh k8s_system_init.sh master2 102\n\n[master3] sh k8s_system_init.sh master3 103\n\n[node01] sh k8s_system_init.sh node01 104\n\n```\n\n### 配置ssh免密\n\n操作节点[master1]\n\n```\nyum install -y sshpass \ncat > sshmianmi.sh << \"EOF\"\n#!/bin/bash\n# 目标主机列表\nhosts=(\"master1\" \"master2\" \"master3\" \"node01\")\n# 密码\npassword=\"123456\"\n# 生成 SSH 密钥对\nssh-keygen -t rsa -N \"\" -f ~/.ssh/id_rsa\n\n# 循环遍历目标主机\nfor host in \"${hosts[@]}\"\ndo\n    # 复制公钥到目标主机\n    sshpass -p \"$password\" ssh-copy-id -o StrictHostKeyChecking=no \"$host\"\n    \n    # 验证免密登录\n    sshpass -p \"$password\" ssh -o StrictHostKeyChecking=no \"$host\" \"echo '免密登录成功'\"\ndone\nEOF\n\nsh sshmianmi.sh\n```\n\n## 内核及ipvs模块配置\n\n此步骤是升级内核、配置ipvs模块，开启一些k8s集群中必须的内核参数。配置一下几个方面：\n\n1. 下载安装包到/server/soft\n2. 安装kernel\n3. 更改内核启动顺序\n4. 安装ipvsadm\n5. 配置ipvs模块\n6. 开启k8s集群必须的内核参数\n7. 配置完内核，重启服务器\n\n操作主机：[master1,master2,master3,node01]\n\n```\nvi kernel_update.sh\n\n#!/bin/bash\necho \"1.下载安装包到/server/soft\"\nmkdir -p /server/soft ; cd /server/soft\nwget https://mirrors.aliyun.com/elrepo/kernel/el7/x86_64/RPMS/kernel-ml-6.6.3-1.el7.elrepo.x86_64.rpm\nwget https://mirrors.aliyun.com/elrepo/kernel/el7/x86_64/RPMS/kernel-ml-devel-6.6.3-1.el7.elrepo.x86_64.rpm\n\n\necho \"2.正在安装kernel\"\nyum localinstall -y kernel-ml*\n\n\necho \"3.更改内核启动顺序\"\ngrub2-set-default  0 && grub2-mkconfig -o /etc/grub2.cfg\ngrubby --args=\"user_namespace.enable=1\" --update-kernel=\"$(grubby --default-kernel)\"\n\n\necho \"4.输出现在内核版本信息\"\ngrubby --default-kernel\n\n\necho \"5.安装ipvsadm\"\nyum install ipvsadm ipset sysstat conntrack libseccomp -y &> /dev/null\n\n\necho \"6.配置ipvs模块\"\nmodprobe -- ip_vs\nmodprobe -- ip_vs_rr\nmodprobe -- ip_vs_wrr\nmodprobe -- ip_vs_sh\nmodprobe -- nf_conntrack\n\ncat >> /etc/modules-load.d/ipvs.conf <<EOF\nip_vs\nip_vs_lc\nip_vs_wlc\nip_vs_rr\nip_vs_wrr\nip_vs_lblc\nip_vs_lblcr\nip_vs_dh\nip_vs_sh\nip_vs_fo\nip_vs_nq\nip_vs_sed\nip_vs_ftp\nip_vs_sh\nnf_conntrack\nip_tables\nip_set\nxt_set\nipt_set\nipt_rpfilter\nipt_REJECT\nipip\nEOF\nsystemctl enable --now systemd-modules-load.service &> /dev/null\n\n\necho \"7.开启k8s集群必须的内核参数\"\ncat <<EOF > /etc/sysctl.d/k8s.conf\nnet.ipv4.ip_forward = 1\nnet.bridge.bridge-nf-call-iptables = 1\nnet.bridge.bridge-nf-call-ip6tables = 1\nfs.may_detach_mounts = 1\nnet.ipv4.conf.all.route_localnet = 1\nvm.overcommit_memory=1\nvm.panic_on_oom=0\nfs.inotify.max_user_watches=89100\nfs.file-max=52706963\nfs.nr_open=52706963\nnet.netfilter.nf_conntrack_max=2310720\n\nnet.ipv4.tcp_keepalive_time = 600\nnet.ipv4.tcp_keepalive_probes = 3\nnet.ipv4.tcp_keepalive_intvl =15\nnet.ipv4.tcp_max_tw_buckets = 36000\nnet.ipv4.tcp_tw_reuse = 1\nnet.ipv4.tcp_max_orphans = 327680\nnet.ipv4.tcp_orphan_retries = 3\nnet.ipv4.tcp_syncookies = 1\nnet.ipv4.tcp_max_syn_backlog = 16384\nnet.ipv4.ip_conntrack_max = 65536\nnet.ipv4.tcp_max_syn_backlog = 16384\nnet.ipv4.tcp_timestamps = 0\nnet.core.somaxconn = 16384\nEOF\nsysctl --system\n\n\necho \"8.配置完内核，重启服务器！\"\nreboot\n\n```\n\n```\nsh kernel_update.sh\n```\n\n## 检查ipvs加载、内核版本验证\n\n```\nlsmod | grep --color=auto -e ip_vs -e nf_conntrack\nuname -a\n```\n\n![image-20231201233238841](../img/K8S%E9%AB%98%E5%8F%AF%E7%94%A8%E9%9B%86%E7%BE%A4%EF%BC%88%E5%86%85%E9%83%A8etcd%EF%BC%89/7b6a9d8f90a78eced6f8ae1d42bbdec5697559838.png)\n\n##  高可用组件安装\n\n### haproxy配置\n\n操作节点：[master1，master2,master3]\n\n```\nyum install keepalived haproxy -y\n```\n\n所有Master节点配置HAProxy，所有Master节点的HAProxy配置相同。\n\n```yaml\n操作节点：[master1，master2]\ncat > /etc/haproxy/haproxy.cfg <<\"EOF\"\n\nglobal\n  maxconn  2000\n  ulimit-n  16384\n  log  127.0.0.1 local0 err\n  stats timeout 30s\n\ndefaults\n  log global\n  mode  http\n  option  httplog\n  timeout connect 5000\n  timeout client  50000\n  timeout server  50000\n  timeout http-request 15s\n  timeout http-keep-alive 15s\n\nfrontend monitor-in\n  bind *:33305\n  mode http\n  option httplog\n  monitor-uri /monitor\n\nfrontend k8s-master\n  bind 0.0.0.0:16443\n  bind 127.0.0.1:16443\n  mode tcp\n  option tcplog\n  tcp-request inspect-delay 5s\n  default_backend k8s-master\n\nbackend k8s-master\n  mode tcp\n  option tcplog\n  option tcp-check\n  balance roundrobin\n  default-server inter 10s downinter 5s rise 2 fall 2 slowstart 60s maxconn 250 maxqueue 256 weight 100\n  server master1   192.168.48.101:6443  check\n  server master2   192.168.48.102:6443  check\n  server master3   192.168.48.103:6443  check\nEOF\n```\n\n### Keepalived配置\n\n操作节点：[master1，master2,master3]\n\n所有Master节点配置Keepalived，以下三个Master节点配置注意ip和网卡。\n\n```\n操作节点：[master1]\n\ncat >/etc/keepalived/keepalived.conf  <<\"EOF\"\n\n! Configuration File for keepalived\nglobal_defs {\n    router_id LVS_DEVEL\nscript_user root\n    enable_script_security\n}\nvrrp_script chk_apiserver {\n    script \"/etc/keepalived/check_apiserver.sh\"\n    interval 5\n    weight -5\n    fall 2  \nrise 1\n}\nvrrp_instance VI_1 {\n    state MASTER\n    interface ens33\n    mcast_src_ip 192.168.48.101\n    virtual_router_id 51\n    priority 101\n    advert_int 2\n    authentication {\n        auth_type PASS\n        auth_pass K8SHA_KA_AUTH\n    }\n    virtual_ipaddress {\n        192.168.48.200\n    }\n    track_script {\n       chk_apiserver\n    }\n}\nEOF\n```\n\n```\n操作节点：[master2]\ncat >/etc/keepalived/keepalived.conf  <<\"EOF\"\n\n! Configuration File for keepalived\nglobal_defs {\n    router_id LVS_DEVEL\nscript_user root\n    enable_script_security\n}\nvrrp_script chk_apiserver {\n    script \"/etc/keepalived/check_apiserver.sh\"\n    interval 5\n    weight -5\n    fall 2  \nrise 1\n}\nvrrp_instance VI_1 {\n    state BACKUP\n    interface ens33\n    mcast_src_ip 192.168.48.102\n    virtual_router_id 51\n    priority 100\n    advert_int 2\n    authentication {\n        auth_type PASS\n        auth_pass K8SHA_KA_AUTH\n    }\n    virtual_ipaddress {\n        192.168.48.200\n    }\n    track_script {\n       chk_apiserver\n    }\n}\nEOF\n```\n\n```\n操作节点：[master3]\ncat >/etc/keepalived/keepalived.conf  <<\"EOF\"\n\n! Configuration File for keepalived\nglobal_defs {\n    router_id LVS_DEVEL\nscript_user root\n    enable_script_security\n}\nvrrp_script chk_apiserver {\n    script \"/etc/keepalived/check_apiserver.sh\"\n    interval 5\n    weight -5\n    fall 2  \nrise 1\n}\nvrrp_instance VI_1 {\n    state BACKUP\n    interface ens33\n    mcast_src_ip 192.168.48.103\n    virtual_router_id 51\n    priority 99\n    advert_int 2\n    authentication {\n        auth_type PASS\n        auth_pass K8SHA_KA_AUTH\n    }\n    virtual_ipaddress {\n        192.168.48.200\n    }\n    track_script {\n       chk_apiserver\n    }\n}\nEOF\n```\n\n\n\n### 配置Keepalived健康检查文件\n\n操作节点：[master1，master2,master3]\n\n```\ncat > /etc/keepalived/check_apiserver.sh <<\"EOF\"\n #!/bin/bash\n err=0\n for k in $(seq 1 3)\n do\n    check_code=$(pgrep haproxy)\n    if [[ $check_code == \"\" ]]; then\n        err=$(expr $err + 1)\n        sleep 1\n        continue\n    else\n        err=0\n        break\n    fi\n done\n \n if [[ $err != \"0\" ]]; then\n    echo \"systemctl stop keepalived\"\n    /usr/bin/systemctl stop keepalived\n    exit 1\n else\n    exit 0\n fi\nEOF\n\nchmod +x /etc/keepalived/check_apiserver.sh\n```\n\n### 启动haproxy和keepalived\n\n```\n操作节点：[master，master2,master3]\nsystemctl daemon-reload\nsystemctl enable --now haproxy\nsystemctl enable --now keepalived\n```\n\n### 测试集群负载均衡高可用\n\n查看master1的vip\n\n```\nip a\n```\n\n![image-20231109232708584](../img/K8S%E9%AB%98%E5%8F%AF%E7%94%A8%E9%9B%86%E7%BE%A4%EF%BC%88%E5%86%85%E9%83%A8etcd%EF%BC%89/0176020d9bcd8b4c85ea2e4f8d6b4afa697559838.png)\n\n模拟master1的宕机测试，看看vip会不会漂移到master2去\n\n```\n[master1] poweroff\n```\n\n![image-20231109232803276](../img/K8S%E9%AB%98%E5%8F%AF%E7%94%A8%E9%9B%86%E7%BE%A4%EF%BC%88%E5%86%85%E9%83%A8etcd%EF%BC%89/126a03a1112b6ab1ae01e0603ac0023b697559838.png)\n\n这时候查看master2的ip列表\n\n```\n[master2] ip a\n```\n\n![image-20231109232825999](../img/K8S%E9%AB%98%E5%8F%AF%E7%94%A8%E9%9B%86%E7%BE%A4%EF%BC%88%E5%86%85%E9%83%A8etcd%EF%BC%89/2a02b2b0a2310908a960dff95daf55d8697559838.png)\n\n结论：这时可以知道，负载均衡集群成功，当master1出现宕机情况，vip会从master1漂移到master2\n\n## docker安装\n\n### 安装docker\n\n操作节点[master1，master2，master3,node01]\n\n```bash\nwget https://download.docker.com/linux/static/stable/x86_64/docker-24.0.7.tgz\ntar xf docker-*.tgz\ncp -rf docker/* /usr/bin/\n#创建containerd的service文件,并且启动\ncat >/etc/systemd/system/containerd.service <<EOF\n[Unit]\nDescription=containerd container runtime\nDocumentation=https://containerd.io\nAfter=network.target local-fs.target\n[Service]\nExecStartPre=-/sbin/modprobe overlay\nExecStart=/usr/bin/containerd\nType=notify\nDelegate=yes\nKillMode=process\nRestart=always\nRestartSec=5\nLimitNPROC=infinity\nLimitCORE=infinity\nLimitNOFILE=1048576\nTasksMax=infinity\nOOMScoreAdjust=-999\n[Install]\nWantedBy=multi-user.target\nEOF\nsystemctl enable --now containerd.service\n\n#准备docker的service文件\n\ncat > /etc/systemd/system/docker.service <<EOF\n[Unit]\nDescription=Docker Application Container Engine\nDocumentation=https://docs.docker.com\nAfter=network-online.target firewalld.service containerd.service\nWants=network-online.target\nRequires=docker.socket containerd.service\n[Service]\nType=notify\nExecStart=/usr/bin/dockerd --config-file=/etc/docker/daemon.json -H fd://\ncontainerd=/run/containerd/containerd.sock\nExecReload=/bin/kill -s HUP $MAINPID\nTimeoutSec=0\nRestartSec=2\nRestart=always\nStartLimitBurst=3\nStartLimitInterval=60s\nLimitNOFILE=infinity\nLimitNPROC=infinity\nLimitCORE=infinity\nTasksMax=infinity\nDelegate=yes\nKillMode=process\nOOMScoreAdjust=-500\n[Install]\nWantedBy=multi-user.target\nEOF\n\n\n#准备docker的socket文件\n\ncat > /etc/systemd/system/docker.socket <<EOF\n[Unit]\nDescription=Docker Socket for the API\n[Socket]\nListenStream=/var/run/docker.sock\nSocketMode=0660\nSocketUser=root\nSocketGroup=docker\n[Install]\nWantedBy=sockets.target\nEOF\ngroupadd docker\n\nsystemctl enable --now docker.socket  && systemctl enable --now docker.service\n\n\n#验证\nmkdir /etc/docker\nsudo tee /etc/docker/daemon.json > /dev/null <<'EOF'\n{\n  \"registry-mirrors\": [\n    \"https://docker.xuanyuan.me\",\n    \"https://docker.m.daocloud.io\",\n    \"https://docker.1ms.run\",\n    \"https://docker.1panel.live\",\n    \"https://registry.cn-hangzhou.aliyuncs.com\",\n\t\t\"https://docker.qianyios.top\"\n  ],\n  \"max-concurrent-downloads\": 10,\n  \"log-driver\": \"json-file\",\n  \"log-level\": \"warn\",\n  \"log-opts\": {\n    \"max-size\": \"10m\",\n    \"max-file\": \"3\"\n  },\n  \"data-root\": \"/var/lib/docker\"\n}\nEOF\nsystemctl daemon-reload\nsystemctl restart docker\n```\n\n### 安装cri-docker\n\n操作节点[master1，master2，master3,node01]\n\n```\nwget https://github.com/Mirantis/cri-dockerd/releases/download/v0.3.7/cri-dockerd-0.3.7.amd64.tgz\n\ntar -zxvf cri-dockerd-0.3.7.amd64.tgz\ncp cri-dockerd/cri-dockerd  /usr/bin/\nchmod +x /usr/bin/cri-dockerd\n\n\n#写入启动配置文件\ncat >  /usr/lib/systemd/system/cri-docker.service <<EOF\n[Unit]\nDescription=CRI Interface for Docker Application Container Engine\nDocumentation=https://docs.mirantis.com\nAfter=network-online.target firewalld.service docker.service\nWants=network-online.target\nRequires=cri-docker.socket\n \n[Service]\nType=notify\nExecStart=/usr/bin/cri-dockerd --network-plugin=cni --pod-infra-container-image=registry.aliyuncs.com/google_containers/pause:3.9\nExecReload=/bin/kill -s HUP $MAINPID\nTimeoutSec=0\nRestartSec=2\nRestart=always\n \nStartLimitBurst=3\n \nStartLimitInterval=60s\n \nLimitNOFILE=infinity\nLimitNPROC=infinity\nLimitCORE=infinity\n \nTasksMax=infinity\nDelegate=yes\nKillMode=process\n \n[Install]\nWantedBy=multi-user.target\nEOF\n\n\n#写入socket配置文件\ncat > /usr/lib/systemd/system/cri-docker.socket <<EOF\n[Unit]\nDescription=CRI Docker Socket for the API\nPartOf=cri-docker.service\n \n[Socket]\nListenStream=%t/cri-dockerd.sock\nSocketMode=0660\nSocketUser=root\nSocketGroup=docker\n \n[Install]\nWantedBy=sockets.target\nEOF\n\nsystemctl daemon-reload && systemctl enable cri-docker --now\n```\n\n## K8S集群安装\n\n### 安装k8s所需的工具\n\n```\n操作节点[master1，master2，master3,node01]\n\nyum -y install  kubeadm kubelet kubectl\n\n#为了实现docker使用的cgroupdriver与kubelet使用的cgroup的一致性，配置如下：\nsed -i 's/^KUBELET_EXTRA_ARGS=/KUBELET_EXTRA_ARGS=\"--cgroup-driver=systemd\"/g' /etc/sysconfig/kubelet\n\n#设置kubelet为开机自启动即可，由于没有生成配置文件，集群初始化后自动启动\nsystemctl enable kubelet\nsystemctl enable kubelet.service\n```\n\n### 集群初始化\n\n```\n操作节点[master1]\n\ncat > kubeadm-config.yaml << EOF\napiVersion: kubeadm.k8s.io/v1beta3\nbootstrapTokens:\n- groups:\n  - system:bootstrappers:kubeadm:default-node-token\n  token: abcdef.0123456789abcdef\n  ttl: 24h0m0s\n  usages:\n  - signing\n  - authentication\nkind: InitConfiguration\nlocalAPIEndpoint:\n  advertiseAddress: 192.168.48.101\n  bindPort: 6443\nnodeRegistration:\n  criSocket: unix:///var/run/cri-dockerd.sock\n  imagePullPolicy: IfNotPresent\n  taints: null\n---\napiServer:\n  timeoutForControlPlane: 4m0s\napiVersion: kubeadm.k8s.io/v1beta3\ncertificatesDir: /etc/kubernetes/pki\nclusterName: kubernetes\ncontrollerManager: {}\ndns: {}\netcd:\n  local:\n    dataDir: /var/lib/etcd\nimageRepository: registry.aliyuncs.com/google_containers\nkind: ClusterConfiguration\nkubernetesVersion: 1.28.2\nnetworking:\n  dnsDomain: cluster.local\n  podSubnet: 10.244.0.0/16\n  serviceSubnet: 10.96.0.0/12\nscheduler: {}\ncontrolPlaneEndpoint: \"192.168.48.200:16443\"\n---\napiVersion: kubeproxy.config.k8s.io/v1alpha1\nbindAddress: 0.0.0.0\nbindAddressHardFail: false\nclientConnection:\n  acceptContentTypes: \"\"\n  burst: 0\n  contentType: \"\"\n  kubeconfig: /var/lib/kube-proxy/kubeconfig.conf\n  qps: 0\nclusterCIDR: \"\"\nconfigSyncPeriod: 0s\nconntrack:\n  maxPerCore: null\n  min: null\n  tcpCloseWaitTimeout: null\n  tcpEstablishedTimeout: null\ndetectLocal:\n  bridgeInterface: \"\"\n  interfaceNamePrefix: \"\"\ndetectLocalMode: \"\"\nenableProfiling: false\nhealthzBindAddress: \"\"\nhostnameOverride: \"\"\niptables:\n  localhostNodePorts: null\n  masqueradeAll: false\n  masqueradeBit: null\n  minSyncPeriod: 0s\n  syncPeriod: 0s\nipvs:\n  excludeCIDRs: null\n  minSyncPeriod: 0s\n  scheduler: \"\"\n  strictARP: false\n  syncPeriod: 0s\n  tcpFinTimeout: 0s\n  tcpTimeout: 0s\n  udpTimeout: 0s\nkind: KubeProxyConfiguration\nlogging:\n  flushFrequency: 0\n  options:\n    json:\n      infoBufferSize: \"0\"\n  verbosity: 0\nmetricsBindAddress: \"\"\nmode: \"\"\nnodePortAddresses: null\noomScoreAdj: null\nportRange: \"\"\nshowHiddenMetricsForVersion: \"\"\nwinkernel:\n  enableDSR: false\n  forwardHealthCheckVip: false\n  networkName: \"\"\n  rootHnsEndpointName: \"\"\n  sourceVip: \"\"\n---\napiVersion: kubelet.config.k8s.io/v1beta1\nauthentication:\n  anonymous:\n    enabled: false\n  webhook:\n    cacheTTL: 0s\n    enabled: true\n  x509:\n    clientCAFile: /etc/kubernetes/pki/ca.crt\nauthorization:\n  mode: Webhook\n  webhook:\n    cacheAuthorizedTTL: 0s\n    cacheUnauthorizedTTL: 0s\ncgroupDriver: systemd\nclusterDNS:\n- 10.96.0.10\nclusterDomain: cluster.local\ncontainerRuntimeEndpoint: \"\"\ncpuManagerReconcilePeriod: 0s\nevictionPressureTransitionPeriod: 0s\nfileCheckFrequency: 0s\nhealthzBindAddress: 127.0.0.1\nhealthzPort: 10248\nhttpCheckFrequency: 0s\nimageMinimumGCAge: 0s\nkind: KubeletConfiguration\nlogging:\n  flushFrequency: 0\n  options:\n    json:\n      infoBufferSize: \"0\"\n  verbosity: 0\nmemorySwap: {}\nnodeStatusReportFrequency: 0s\nnodeStatusUpdateFrequency: 0s\nrotateCertificates: true\nruntimeRequestTimeout: 0s\nshutdownGracePeriod: 0s\nshutdownGracePeriodCriticalPods: 0s\nstaticPodPath: /etc/kubernetes/manifests\nstreamingConnectionIdleTimeout: 0s\nsyncFrequency: 0s\nvolumeStatsAggPeriod: 0s\n\nEOF\n\nkubeadm config migrate --old-config kubeadm-config.yaml --new-config new.yaml\n\n```\n\n### 准备k8s所需的镜像\n\n```\n操作节点[master1,master2,master3]\n\nkubeadm config images pull --config /root/new.yaml \n```\n\n![image-20231110100341121](../img/K8S%E9%AB%98%E5%8F%AF%E7%94%A8%E9%9B%86%E7%BE%A4%EF%BC%88%E5%86%85%E9%83%A8etcd%EF%BC%89/39a6655a68e7fb689d3d256f91e8074c697559838.png)\n\n### master1节点初始化\n\n操作节点[master1]\n\n```\nkubeadm init --config /root/new.yaml  --upload-certs\n```\n\n会生成信息\n\n![image-20231110175843902](../img/K8S%E9%AB%98%E5%8F%AF%E7%94%A8%E9%9B%86%E7%BE%A4%EF%BC%88%E5%86%85%E9%83%A8etcd%EF%BC%89/71204e272d141fb2f7ef41d1d6a37658697559838.png)\n\n记录信息后面会用到\n\n初始化成功以后，会产生Token值，用于其他节点加入时使用，因此要记录下初始化成功生成的token值（令牌值），**有效期24小时，后续需要操作可以重新生成Token**\n\n操作节点[master1]\n\n```\nkubeadm join 192.168.48.200:16443 --token abcdef.0123456789abcdef \\\n        --discovery-token-ca-cert-hash sha256:cc5427e0e133d95250ab0aa90976fea2c383278b6345fd7e8c28702ac8dfc61f \\\n        --control-plane --certificate-key 45eeadfc9135a368d08582a90c779c0934d24c54f56134c65d67516f5e6f981d\n\n\nkubeadm join 192.168.48.200:16443 --token abcdef.0123456789abcdef \\\n        --discovery-token-ca-cert-hash sha256:cc5427e0e133d95250ab0aa90976fea2c383278b6345fd7e8c28702ac8dfc61f\n\n```\n\n`操作kubect报错：`\n\n![image-20231110180035297](../img/K8S%E9%AB%98%E5%8F%AF%E7%94%A8%E9%9B%86%E7%BE%A4%EF%BC%88%E5%86%85%E9%83%A8etcd%EF%BC%89/0ea7d75c613d48f13e34f481c6cf08b0697559838.png)\n\n此时通过kubectl操作，会出现失败，因为还没有将集群的\"钥匙\"交给root用户。`/etc/kubernetes/admin.conf` 文件是 Kubernetes（K8s）集群中的管理员配置文件，它包含了用于管理集群的身份验证和访问信息。所以下面进行配置环境变量，用于访问Kubernetes集群：\n\n`添加环境变量`\n\n操作节点[master1]\n\n```\nmkdir -p $HOME/.kube\nsudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config\nsudo chown $(id -u):$(id -g) $HOME/.kube/config\n```\n\n### 添加其他master节点至集群中\n\n操作节点[master2,master3]\n\n```\n操作节点[master2,master3]\nkubeadm join 192.168.48.200:16443 --token abcdef.0123456789abcdef \\\n        --discovery-token-ca-cert-hash sha256:cc5427e0e133d95250ab0aa90976fea2c383278b6345fd7e8c28702ac8dfc61f \\\n        --control-plane --certificate-key 45eeadfc9135a368d08582a90c779c0934d24c54f56134c65d67516f5e6f981d \\\n        --cri-socket unix:///var/run/cri-dockerd.sock \n```\n\n注意：这里末尾添加了`--cri-socket unix:///var/run/cri-dockerd.sock `\n\n接着给`master2`添加环境变量\n\n```\n操作节点[master2,master3]\nmkdir -p $HOME/.kube\nsudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config\nsudo chown $(id -u):$(id -g) $HOME/.kube/config\n```\n\n![image-20231110180919008](../img/K8S%E9%AB%98%E5%8F%AF%E7%94%A8%E9%9B%86%E7%BE%A4%EF%BC%88%E5%86%85%E9%83%A8etcd%EF%BC%89/3f20e99d3edff4874993811b81d45783697559838.png)\n\n这里没有展示master3的图片，但是步骤一样的\n\n### 模拟Token过期重新生成并加入Node节点\n\n假设加入集群的token过期了。node01无法加入了，这里就模拟一下这种情况\n\n1. Token过期后生成新的token：\n\n```bash\nkubeadm token create --print-join-command\n```\n\n```\n[root@master1 ~]# kubeadm token create --print-join-command\nkubeadm join 192.168.48.200:16443 --token tn5q1b.7w1jj77ewup7k2in --discovery-token-ca-cert-hash sha256:cc5427e0e133d95250ab0aa90976fea2c383278b6345fd7e8c28702ac8dfc61f\n\n```\n\n其中，`192.168.48.200:16443` 是你的 Kubernetes API 服务器的地址和端口，`tn5q1b.7w1jj77ewup7k2in` 是新的令牌，`sha256:cc5427e0e133d95250ab0aa90976fea2c383278b6345fd7e8c28702ac8dfc61f` 是令牌的 CA 证书哈希值。\n\n2. Master需要生成--certificate-key：\n\n```bash\nkubeadm init phase upload-certs --upload-certs\n```\n\n```\n[root@master1 ~]# kubeadm init phase upload-certs --upload-certs\nW1110 18:12:03.426245   10185 version.go:104] could not fetch a Kubernetes version from the internet: unable to get URL \"https://dl.k8s.io/release/stable-1.txt\": Get \"https://dl.k8s.io/release/stable-1.txt\": context deadline exceeded (Client.Timeout exceeded while awaiting headers)\nW1110 18:12:03.426320   10185 version.go:105] falling back to the local client version: v1.28.2\n[upload-certs] Storing the certificates in Secret \"kubeadm-certs\" in the \"kube-system\" Namespace\n[upload-certs] Using certificate key:\n5d3706028d5e569324a4c456c81ae0f5551ece88b3132f03917668c6b0605128\n```\n\n其中，`5d3706028d5e569324a4c456c81ae0f5551ece88b3132f03917668c6b0605128` 是证书密钥。\n\n3. 生成新的Token用于集群添加新Node节点\n\n操作节点[node01]\n\n```\nkubeadm join 192.168.48.200:16443 --token tn5q1b.7w1jj77ewup7k2in --discovery-token-ca-cert-hash sha256:cc5427e0e133d95250ab0aa90976fea2c383278b6345fd7e8c28702ac8dfc61f  \\\n        --cri-socket unix:///var/run/cri-dockerd.sock \n```\n\n注意：这里末尾添加了`--cri-socket unix:///var/run/cri-dockerd.sock `\n\n![image-20231110181623386](../img/K8S%E9%AB%98%E5%8F%AF%E7%94%A8%E9%9B%86%E7%BE%A4%EF%BC%88%E5%86%85%E9%83%A8etcd%EF%BC%89/3e809e4e0ccbd1d84b7563de484600dc697559838.png)\n\n这时在master查看node状态（显示为notready不影响）\n\n![image-20231111145807000](../img/K8S%E9%AB%98%E5%8F%AF%E7%94%A8%E9%9B%86%E7%BE%A4%EF%BC%88%E5%86%85%E9%83%A8etcd%EF%BC%89/35ee9666e8251b54f20eec2a53ff9058697559838.png)\n\n### 模拟新加master节点的加入K8S集群中\n\n假设我们新加master节点的话，就拼接token，`从刚刚生成的token拼接`\n\n```\n[root@master1 ~]# kubeadm token create --print-join-command\nkubeadm join 192.168.48.200:16443 --token tn5q1b.7w1jj77ewup7k2in --discovery-token-ca-cert-hash sha256:cc5427e0e133d95250ab0aa90976fea2c383278b6345fd7e8c28702ac8dfc61f\n```\n\n这里提取信息1\n\n```\nkubeadm join 192.168.48.200:16443 --token tn5q1b.7w1jj77ewup7k2in --discovery-token-ca-cert-hash sha256:cc5427e0e133d95250ab0aa90976fea2c383278b6345fd7e8c28702ac8dfc61f\n```\n\n接着\n\n```\n[root@master1 ~]# kubeadm init phase upload-certs --upload-certs\nW1110 18:12:03.426245   10185 version.go:104] could not fetch a Kubernetes version from the internet: unable to get URL \"https://dl.k8s.io/release/stable-1.txt\": Get \"https://dl.k8s.io/release/stable-1.txt\": context deadline exceeded (Client.Timeout exceeded while awaiting headers)\nW1110 18:12:03.426320   10185 version.go:105] falling back to the local client version: v1.28.2\n[upload-certs] Storing the certificates in Secret \"kubeadm-certs\" in the \"kube-system\" Namespace\n[upload-certs] Using certificate key:\n5d3706028d5e569324a4c456c81ae0f5551ece88b3132f03917668c6b0605128\n```\n\n这里提取信息2：这里前面要加上`--control-plane --certificate-key`\n\n```\n--control-plane --certificate-key 5d3706028d5e569324a4c456c81ae0f5551ece88b3132f03917668c6b0605128\n```\n\n合成\n\n```\nkubeadm join 192.168.48.200:16443 --token tn5q1b.7w1jj77ewup7k2in \\\n        --discovery-token-ca-cert-hash sha256:cc5427e0e133d95250ab0aa90976fea2c383278b6345fd7e8c28702ac8dfc61f  \\\n        --control-plane --certificate-key 5d3706028d5e569324a4c456c81ae0f5551ece88b3132f03917668c6b0605128 \\\n        --cri-socket unix:///var/run/cri-dockerd.sock\n        \n        \nkubeadm join 192.168.48.200:16443 --token lnkno8.u4v1l8n9pahzf0kj \\\n        --discovery-token-ca-cert-hash sha256:cc5427e0e133d95250ab0aa90976fea2c383278b6345fd7e8c28702ac8dfc61f \\\n        --control-plane --certificate-key 41e441fe56cb4bdfcc2fc0291958e6b1da54d01f4649b6651471c07583f85cdf \\\n        --cri-socket unix:///var/run/cri-dockerd.sock\n\n\n```\n\n注意：这里末尾添加了`--cri-socket unix:///var/run/cri-dockerd.sock `\n\n图示\n\n![image-20231110182741430](../img/K8S%E9%AB%98%E5%8F%AF%E7%94%A8%E9%9B%86%E7%BE%A4%EF%BC%88%E5%86%85%E9%83%A8etcd%EF%BC%89/7dcec71d06d286a5b7b1fcebbef15a7b697559838.png)\n\n## 安装calico网络插件\n\n操作节点[master1]\n\n添加解析记录，否则无法访问\n\n```\necho '185.199.108.133 raw.githubusercontent.com' >> /etc/hosts\n```\n\n### 应用operator资源清单文件\n\n网络组件有很多种，只需要部署其中一个即可，推荐Calico。 \nCalico是一个纯三层的数据中心网络方案，Calico支持广泛的平台，包括Kubernetes、OpenStack等。 \nCalico 在每一个计算节点利用 Linux Kernel 实现了一个高效的虚拟路由器（ vRouter） 来负责数据转发，而每个 vRouter 通过 BGP 协议负责把自己上运行的 workload 的路由信息向整个 Calico 网络内传播。 \n此外，Calico 项目还实现了 Kubernetes 网络策略，提供ACL功能。\n\n```\ncurl https://raw.githubusercontent.com/projectcalico/calico/v3.25.1/manifests/calico.yaml -O\n```\n\n```yaml\n[root@master1 ~]# vim calico.yaml\n#添加两行\n- name: IP_AUTODETECTION_METHOD\n  value: interface=ens33\n\n#ens33是你的网卡\n```\n\n![image-20231110183944854](../img/K8S%E9%AB%98%E5%8F%AF%E7%94%A8%E9%9B%86%E7%BE%A4%EF%BC%88%E5%86%85%E9%83%A8etcd%EF%BC%89/12da23b4f8d928a8ac610de1419f8f01697559838.png)\n\n```\nsed -i 's| docker.io/calico/| registry.cn-hangzhou.aliyuncs.com/qianyios/|' calico.yaml\nkubectl apply -f calico.yaml\n```\n\n![image-20231110184031455](../img/K8S%E9%AB%98%E5%8F%AF%E7%94%A8%E9%9B%86%E7%BE%A4%EF%BC%88%E5%86%85%E9%83%A8etcd%EF%BC%89/515614f130cb327d7e301ddff0ea1b75697559838.png)\n\n### 监视kube-system命名空间中pod运行情况\n\n等待估计20分钟左右吧(确保全部running)\n\n```\nkubectl get pods -n kube-system\n```\n\n![image-20231110193921266](../img/K8S%E9%AB%98%E5%8F%AF%E7%94%A8%E9%9B%86%E7%BE%A4%EF%BC%88%E5%86%85%E9%83%A8etcd%EF%BC%89/65e576c8a0ad30192f63c585bda21254697559838.png)\n\n### 拿掉master节点的污点\n\n节点 master1 和 master2 都有一个名为 `node-role.kubernetes.io/control-plane:NoSchedule` 的污点。这个污点的作用是阻止普通的 Pod 被调度到这些节点上，只允许特定的控制平面组件（如 kube-apiserver、kube-controller-manager 和 kube-scheduler）在这些节点上运行。\n\n这种设置有助于确保控制平面节点专门用于运行 Kubernetes 的核心组件，而不会被普通的工作负载占用。通过将污点添加到节点上，可以确保只有被授权的控制平面组件才能在这些节点上运行。\n\n```\nkubectl describe node master1 | grep -i taint\nkubectl describe node master2 | grep -i taint\nkubectl describe node master3 | grep -i taint\n```\n\n![image-20231111152324023](../img/K8S%E9%AB%98%E5%8F%AF%E7%94%A8%E9%9B%86%E7%BE%A4%EF%BC%88%E5%86%85%E9%83%A8etcd%EF%BC%89/7e79bf5ee514955fa2bc88a482aeace0697559838.png)\n\n去除污点\n\n```\nkubectl taint node master1 node-role.kubernetes.io/control-plane:NoSchedule-\nkubectl taint node master2 node-role.kubernetes.io/control-plane:NoSchedule-\nkubectl taint node master3 node-role.kubernetes.io/control-plane:NoSchedule-\n```\n\n![image-20231111152342956](../img/K8S%E9%AB%98%E5%8F%AF%E7%94%A8%E9%9B%86%E7%BE%A4%EF%BC%88%E5%86%85%E9%83%A8etcd%EF%BC%89/787ed2d5c1bfbafd6bf56ca9127c4d59697559838.png)\n\n## 安装dashboard\n\n操作节点[master1]\n\n下载文件\n\nhttps://github.com/kubernetes/dashboard/releases/tag/v2.7.0\n\n目前最新版本v2.7.0 \n\n```\nwget https://raw.githubusercontent.com/kubernetes/dashboard/v2.7.0/aio/deploy/recommended.yaml\nsed -i 's/kubernetesui\\/dashboard:v2.7.0/registry.cn-hangzhou.aliyuncs.com\\/qianyios\\/dashboard:v2.7.0/g' recommended.yaml\nsed -i 's/kubernetesui\\/metrics-scraper:v1.0.8/registry.cn-hangzhou.aliyuncs.com\\/qianyios\\/metrics-scraper:v1.0.8/g' recommended.yaml\n```\n\n![image-20231014174400992](../img/K8S%E9%AB%98%E5%8F%AF%E7%94%A8%E9%9B%86%E7%BE%A4%EF%BC%88%E5%86%85%E9%83%A8etcd%EF%BC%89/765d82d207c2fefcc00048060c4d1146697559838.png)\n\n修改配置文件\n\n```yaml\nvim recommended.yaml\n---\nkind: Service\napiVersion: v1\nmetadata:\n  labels:\n    app: kubernetes-dashboard\n  name: kubernetes-dashboard\n  namespace: kubernetes-dashboard\nspec:\n  ports:\n    - port: 443\n      targetPort: 8443\n      nodePort: 30001\n  type: NodePort\n  selector:\n    app: kubernetes-dashboard\n\n---\n```\n\n![image-20231014174511047](../img/K8S%E9%AB%98%E5%8F%AF%E7%94%A8%E9%9B%86%E7%BE%A4%EF%BC%88%E5%86%85%E9%83%A8etcd%EF%BC%89/33ac61c500136a4ce86567aafd1c1382697559838.png)\n\n运行dashboard\n\n```\nkubectl apply -f recommended.yaml\n```\n\n![image-20231014174622344](../img/K8S%E9%AB%98%E5%8F%AF%E7%94%A8%E9%9B%86%E7%BE%A4%EF%BC%88%E5%86%85%E9%83%A8etcd%EF%BC%89/2332124844a312fa6b5261eb90fb2c26697559838.png)\n\n检查运行状态\n\n```\nkubectl get pods -n kubernetes-dashboard\nkubectl get pod,svc -o wide -n kubernetes-dashboard\n```\n\n![image-20231111025752605](../img/K8S%E9%AB%98%E5%8F%AF%E7%94%A8%E9%9B%86%E7%BE%A4%EF%BC%88%E5%86%85%E9%83%A8etcd%EF%BC%89/39d745dff08f596e4d810445df33dbdc697559838.png)\n\n### 创建cluster-admin用户\n\n```\n创建service account并绑定默认cluster-admin管理员群角色\n#创建用户\nkubectl create serviceaccount dashboard-admin -n kubernetes-dashboard\n#用户授权\nkubectl create clusterrolebinding dashboard-admin --clusterrole=cluster-admin --serviceaccount=kubernetes-dashboard:dashboard-admin\n#获取用户Token\nkubectl create token dashboard-admin -n kubernetes-dashboard\n```\n\n![image-20231111025817854](../img/K8S%E9%AB%98%E5%8F%AF%E7%94%A8%E9%9B%86%E7%BE%A4%EF%BC%88%E5%86%85%E9%83%A8etcd%EF%BC%89/5e1825e420253c9b7aaba3307e80d3ef697559838.png)\n\n记录token\n\n```\neyJhbGciOiJSUzI1NiIsImtpZCI6IjJxb21sRTZSckhEZ09FMnlvWU5IY3dfTTRIWDEzRUpsQ000MThhSWxYNDgifQ.eyJhdWQiOlsiaHR0cHM6Ly9rdWJlcm5ldGVzLmRlZmF1bHQuc3ZjLmNsdXN0ZXIubG9jYWwiXSwiZXhwIjoxNjk5NjQ2Mjg3LCJpYXQiOjE2OTk2NDI2ODcsImlzcyI6Imh0dHBzOi8va3ViZXJuZXRlcy5kZWZhdWx0LnN2Yy5jbHVzdGVyLmxvY2FsIiwia3ViZXJuZXRlcy5pbyI6eyJuYW1lc3BhY2UiOiJrdWJlcm5ldGVzLWRhc2hib2FyZCIsInNlcnZpY2VhY2NvdW50Ijp7Im5hbWUiOiJkYXNoYm9hcmQtYWRtaW4iLCJ1aWQiOiIyNTBhNTQ2MS03MGJlLTRhZTItOWY2Yi1hMDQwOWE1NWJhMTMifX0sIm5iZiI6MTY5OTY0MjY4Nywic3ViIjoic3lzdGVtOnNlcnZpY2VhY2NvdW50Omt1YmVybmV0ZXMtZGFzaGJvYXJkOmRhc2hib2FyZC1hZG1pbiJ9.U-lH9_sRU4TVrpAznqS60INNSev9NxHu61igGUTzTBoaWo7WjPG7vzTnpZYhvsoglTzMEKhfranJkkkn95pe-prkvSasaAL6kXHw0jQjlSMzcYiF7DoLdkOtDJSukuALEubidf9eIwZXFZ-sezZdZHm4hnk5nWme5YtdOmYOJPh5sv1dzRvM1XuOHknJPTA1BbdZuVAtSGHSjkhwx-wl-41uuQoROW5GjJs0bz4zLBFn1w_pWaSMCn7pjGJNcbr6IuDV41km_etpwwxacWyfAcxNykzCtIiE1abJj7m-e944GvAn_eqxz3wCZD6Bgt41FWRzyMHjrppJfDjk7FaHNw\n\n```\n\n### 登录浏览器访问\n\n```\nhttps://192.168.48.200:30001\n\n输入token：\n----\neyJhbGciOiJSUzI1NiIsImtpZCI6IjJxb21sRTZSckhEZ09FMnlvWU5IY3dfTTRIWDEzRUpsQ000MThhSWxYNDgifQ.eyJhdWQiOlsiaHR0cHM6Ly9rdWJlcm5ldGVzLmRlZmF1bHQuc3ZjLmNsdXN0ZXIubG9jYWwiXSwiZXhwIjoxNjk5NjQ2Mjg3LCJpYXQiOjE2OTk2NDI2ODcsImlzcyI6Imh0dHBzOi8va3ViZXJuZXRlcy5kZWZhdWx0LnN2Yy5jbHVzdGVyLmxvY2FsIiwia3ViZXJuZXRlcy5pbyI6eyJuYW1lc3BhY2UiOiJrdWJlcm5ldGVzLWRhc2hib2FyZCIsInNlcnZpY2VhY2NvdW50Ijp7Im5hbWUiOiJkYXNoYm9hcmQtYWRtaW4iLCJ1aWQiOiIyNTBhNTQ2MS03MGJlLTRhZTItOWY2Yi1hMDQwOWE1NWJhMTMifX0sIm5iZiI6MTY5OTY0MjY4Nywic3ViIjoic3lzdGVtOnNlcnZpY2VhY2NvdW50Omt1YmVybmV0ZXMtZGFzaGJvYXJkOmRhc2hib2FyZC1hZG1pbiJ9.U-lH9_sRU4TVrpAznqS60INNSev9NxHu61igGUTzTBoaWo7WjPG7vzTnpZYhvsoglTzMEKhfranJkkkn95pe-prkvSasaAL6kXHw0jQjlSMzcYiF7DoLdkOtDJSukuALEubidf9eIwZXFZ-sezZdZHm4hnk5nWme5YtdOmYOJPh5sv1dzRvM1XuOHknJPTA1BbdZuVAtSGHSjkhwx-wl-41uuQoROW5GjJs0bz4zLBFn1w_pWaSMCn7pjGJNcbr6IuDV41km_etpwwxacWyfAcxNykzCtIiE1abJj7m-e944GvAn_eqxz3wCZD6Bgt41FWRzyMHjrppJfDjk7FaHNw\n\n----\n\n```\n\n![image-20231111025910110](../img/K8S%E9%AB%98%E5%8F%AF%E7%94%A8%E9%9B%86%E7%BE%A4%EF%BC%88%E5%86%85%E9%83%A8etcd%EF%BC%89/d9e668b5905d26157c9377c9462266e5697559838.png)\n\n### 部署一个nginx测试\n\n操作节点[master1]\n\n```yaml\nvim web.yaml\n\nkind: Deployment\n#apiVersion: extensions/v1beta1\napiVersion: apps/v1\nmetadata:\n  labels:\n    app: web-deployment-label\n  name: web-deployment\n  namespace: default\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: web-selector\n  template:\n    metadata:\n      labels:\n        app: web-selector\n    spec:\n      containers:\n      - name: web-container\n        image: nginx:latest\n        imagePullPolicy: Always\n        ports:\n        - containerPort: 80\n          protocol: TCP\n          name: http\n        - containerPort: 443\n          protocol: TCP\n          name: https\n\n---\nkind: Service\napiVersion: v1\nmetadata:\n  labels:\n    app: web-service-label\n  name: web-service\n  namespace: default\nspec:\n  type: NodePort\n  ports:\n  - name: http\n    port: 80\n    protocol: TCP\n    targetPort: 80\n    nodePort: 30080\n  - name: https\n    port: 443\n    protocol: TCP\n    targetPort: 443\n    nodePort: 30443\n  selector:\n    app: web-selector\n    \nkubectl apply -f web.yaml \n```\n\n![image-20231014180923818](../img/K8S%E9%AB%98%E5%8F%AF%E7%94%A8%E9%9B%86%E7%BE%A4%EF%BC%88%E5%86%85%E9%83%A8etcd%EF%BC%89/a43ccc12f086a6b24663f4030e058d51697559838.png)\n\n```\n### 查看nginx的pod 的详细信息\nkubectl get deploy,svc,pod -o wide\n```\n\n![image-20231016203536987](../img/K8S%E9%AB%98%E5%8F%AF%E7%94%A8%E9%9B%86%E7%BE%A4%EF%BC%88%E5%86%85%E9%83%A8etcd%EF%BC%89/6061b13260d568766dd53ec7fc3036ce697559838.png)\n\n访问nginx网站\n\n```\nhttp://192.168.48.200:30080\n```\n\n![image-20231111030413487](../img/K8S%E9%AB%98%E5%8F%AF%E7%94%A8%E9%9B%86%E7%BE%A4%EF%BC%88%E5%86%85%E9%83%A8etcd%EF%BC%89/e162ff6ccabaf5e49f416b7a1974777c697559838.png)\n\n<div class=\"tbsm\" style=\"margin-top:54px;\">\n<div class=\"tbsm-top\"><span><svg t=\"1674654360507\" class=\"icon\" viewBox=\"0 0 1024 1024\" version=\"1.1\" xmlns=\"http://www.w3.org/2000/svg\" p-id=\"987\" data-spm-anchor-id=\"a313x.7781069.0.i0\" width=\"35\" height=\"35\"><path d=\"M410.49 97.74H155.08a56.74 56.74 0 0 0-56.84 56.73V410a56.84 56.84 0 0 0 56.84 56.84h255.41A56.83 56.83 0 0 0 467.32 410V154.58a56.83 56.83 0 0 0-56.83-56.84zM410.49 558.74H155.08a56.74 56.74 0 0 0-56.84 56.73V871a56.84 56.84 0 0 0 56.84 56.84h255.41A56.83 56.83 0 0 0 467.32 871V615.58a56.83 56.83 0 0 0-56.83-56.84zM871.49 558.74H616.08a56.74 56.74 0 0 0-56.84 56.73V871a56.84 56.84 0 0 0 56.84 56.84h255.41A56.83 56.83 0 0 0 928.32 871V615.58a56.83 56.83 0 0 0-56.83-56.84z\" fill=\"#66EEFF\" p-id=\"988\"></path><path d=\"M410.49 558.74h-4.14A475 475 0 0 0 299.52 859.6a481.16 481.16 0 0 0 4.84 68.22h106.13A56.83 56.83 0 0 0 467.32 871V615.58a56.83 56.83 0 0 0-56.83-56.84zM871.49 558.74H616.08a56.74 56.74 0 0 0-56.84 56.73V871a56.84 56.84 0 0 0 56.84 56.84h255.41A56.83 56.83 0 0 0 928.32 871V615.58a56.83 56.83 0 0 0-56.83-56.84z\" fill=\"#C2F8FF\" p-id=\"989\"></path></svg></span><span style=\"font-size:30px;\"> 特别声明</span></div>\n<div class=\"tbsm-wz\">千屹博客旗下的所有文章，是通过本人课堂学习和课外自学所精心整理的知识巨著<br/>难免会有出错的地方<br/>如果细心的你发现了小失误，可以在下方评论区告诉我，或者私信我！<br />非常感谢大家的热烈支持！</div>\n</div>","tags":["Centos 7","K8s"],"categories":["云原生"]},{"title":"K8S高可用集群（外部etcd）","url":"/posts/59349/","content":"\n<meta name=\"referrer\" content=\"no-referrer\"/>\n\n# K8S高可用集群（外部etcd）\n\n以下会用到的资源[K8s1.28.2（内外部etcd高可用）所需资源](https://www.123pan.com/s/MYnLVv-gLp4.html)\n\n## 主机拓扑\n\n| 主机名  | ip1（NAT）     | 系统      | 磁盘 | 内存 |\n| ------- | -------------- | --------- | ---- | ---- |\n| master1 | 192.168.48.101 | Centos7.9 | 100G | 4G   |\n| master2 | 192.168.48.102 | Centos7.9 | 100G | 4G   |\n| master3 | 192.168.48.103 | Centos7.9 | 100G | 4G   |\n| node01  | 192.168.48.104 | Centos7.9 | 100G | 8G   |\n\n## 基础配置\n\ncentos通过单独安装，非克隆。安装完后进行基本环境的配置，配置一下几个方面：\n\n1. 设置主机名\n2. 关闭NetworkManager、firewalld、dnsmasq、selinux\n3. 设置ens33\n4. 优化ssh\n5. 备份并新增清华yum源、epel源、docker-ce源、k8s源\n6. 更新yum源软件包缓存\n7. 修改history格式及记录数\n8. 添加hosts解析\n9. 关闭swap分区\n10. 安装chrony服务，并同步时间\n11. 配置limits.conf\n12. 安装必备工具\n13. 升级系统并重启\n\n操作主机：[master1,master2,master3,node01]\n\n```\nvim k8s_system_init.sh\n```\n\n```\n#!/bin/bash\nif [ $# -eq 2 ];then\n  echo \"设置主机名为：$1\"\n  echo \"ens33设置IP地址为：192.168.48.$2\"\nelse\n  echo  \"使用方法：sh $0 主机名 主机位\"\n  exit 2\nfi\n\necho \"--------------------------------------\"\necho \"1.正在设置主机名：$1\"\nhostnamectl set-hostname $1\n\n\necho \"2.正在关闭NetworkManager、firewalld、dnsmasq、selinux\"\nsystemctl disable firewalld &> /dev/null\nsystemctl disable NetworkManager &> /dev/null\nsystemctl disable dnsmasq &> /dev/null\nsystemctl stop firewalld\nsystemctl stop NetworkManager\nsystemctl stop dnsmasq\nsed -i \"s#SELINUX=enforcing#SELINUX=disabled#g\" /etc/selinux/config\nsetenforce 0\n\n\necho \"3.正在设置ens33：192.168.48.$2\"\ncat > /etc/sysconfig/network-scripts/ifcfg-ens33 <<EOF\nTYPE=ensernet\nBOOTPROTO=static\nDEFROUTE=yes\nNAME=ens33\nDEVICE=ens33\nONBOOT=yes\nIPADDR=192.168.48.$2\nNETMASK=255.255.255.0\nGATEWAY=192.168.48.2\nDNS1=114.114.114.114\nEOF\nsystemctl restart network\n\n\necho \"4.优化ssh\"\nsed -i \"s#\\#UseDNS yes#UseDNS no#g\" /etc/ssh/sshd_config\nsed -i \"s#GSSAPIAuthentication yes#GSSAPIAuthentication no#g\" /etc/ssh/sshd_config\nsystemctl restart sshd\n\necho \"5.备份并新增清华yum源、epel源、docker-ce源、k8s源\"\nrm -rf /etc/yum.repos.d/*\ncat > /etc/yum.repos.d/Centos-Base.repo <<EOF\n[base]\nname=CentOS-$releasever - Base\nbaseurl=https://mirrors.tuna.tsinghua.edu.cn/centos/\\$releasever/os/\\$basearch/\ngpgcheck=1\ngpgkey=file:///etc/pki/rpm-gpg/RPM-GPG-KEY-CentOS-7\n\n[updates]\nname=CentOS-$releasever - Updates\nbaseurl=https://mirrors.tuna.tsinghua.edu.cn/centos/\\$releasever/updates/\\$basearch/\ngpgcheck=1\ngpgkey=file:///etc/pki/rpm-gpg/RPM-GPG-KEY-CentOS-7\n\n[extras]\nname=CentOS-$releasever - Extras\nbaseurl=https://mirrors.tuna.tsinghua.edu.cn/centos/\\$releasever/extras/\\$basearch/\ngpgcheck=1\ngpgkey=file:///etc/pki/rpm-gpg/RPM-GPG-KEY-CentOS-7\n\n[centosplus]\nname=CentOS-$releasever - Plus\nbaseurl=https://mirrors.tuna.tsinghua.edu.cn/centos/\\$releasever/centosplus/\\$basearch/\ngpgcheck=1\nenabled=0\ngpgkey=file:///etc/pki/rpm-gpg/RPM-GPG-KEY-CentOS-7\nEOF\n\ncat > /etc/yum.repos.d/epel.repo <<EOF\n[epel]\nname=Extra Packages for Enterprise Linux 7 - \\$basearch\nbaseurl=https://mirrors.tuna.tsinghua.edu.cn/epel/7/\\$basearch\nfailovermensod=priority\nenabled=1\ngpgcheck=1\ngpgkey=file:///etc/pki/rpm-gpg/RPM-GPG-KEY-EPEL-7\n\n[epel-debuginfo]\nname=Extra Packages for Enterprise Linux 7 - \\$basearch - Debug\nbaseurl=https://mirrors.tuna.tsinghua.edu.cn/epel/7/\\$basearch/debug\nfailovermensod=priority\nenabled=0\ngpgkey=file:///etc/pki/rpm-gpg/RPM-GPG-KEY-EPEL-7\ngpgcheck=1\n\n[epel-source]\nname=Extra Packages for Enterprise Linux 7 - \\$basearch - Source\nbaseurl=https://mirrors.tuna.tsinghua.edu.cn/epel/7/SRPMS\nfailovermensod=priority\nenabled=0\ngpgkey=file:///etc/pki/rpm-gpg/RPM-GPG-KEY-EPEL-7\ngpgcheck=1\nEOF\n\ncat > /etc/yum.repos.d/kubernetes.repo <<EOF\n[kubernetes]\nname=Kubernetes\nbaseurl=https://mirrors.aliyun.com/kubernetes/yum/repos/kubernetes-el7-x86_64/\nenabled=1\ngpgcheck=0\nrepo_gpgcheck=0\ngpgkey=https://mirrors.aliyun.com/kubernetes/yum/doc/yum-key.gpg https://mirrors.aliyun.com/kubernetes/yum/doc/rpm-package-key.gpg\nEOF\n\ncurl -o /etc/yum.repos.d/docker-ce.repo https://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo\n\necho \"6.更新yum源软件包缓存\"\n yum clean all && yum makecache\n\n\necho \"7.修改history格式及记录数\"\nsed -i \"s#HISTSIZE=1000##g\" /etc/profile\ncat >> /etc/profile <<EOF\nshopt -s histappend\nUSER_IP=`who -u am i 2>/dev/null| awk '{print $NF}'|sed -e 's/[()]//g'`\nexport HISTFILE=~/.commandline_warrior\nexport HISTTIMEFORMAT=\"%Y-%m-%d %H:%M:%S  `whoami`@${USER_IP}: \"\nexport HISTSIZE=200000\nexport HISTFILESIZE=1000000\nexport PROMPT_COMMAND=\"history -a\"\nEOF\nsource /etc/profile\n\n\necho \"8.添加hosts解析\"\ncat >> /etc/hosts <<EOF\n192.168.48.101 master1\n192.168.48.102 master2\n192.168.48.103 master3\n192.168.48.104 node01\nEOF\n\n\necho \"9.关闭swap分区\"\nswapoff -a && sysctl -w vm.swappiness=0 &> /dev/null\nsed -ri '/^[^#]*swap/s@^@#@' /etc/fstab\n\n\necho \"10.安装ntpdate服务，并同步时间\"\nyum install chrony -y\nsystemctl start chronyd\nsystemctl enable chronyd\nchronyc sources\nchronyc sources\n\necho \"11.配置limits.conf\"\nulimit -SHn 65535\ncat >> /etc/security/limits.conf <<EOF\n* soft nofile 65536\n* hard nofile 131072\n* soft nproc 65535\n* hard nproc 655350\n* soft memlock unlimited\n* hard memlock unlimited\nEOF\n\n\necho \"12.必备工具安装\"\nyum install wget psmisc vim net-tools telnet yum-utils device-mapper-persistent-data lvm2 git -y\n\n\necho \"13.升级系统并重启\"\nyum update -y --exclude=kernel* && reboot\n\n```\n\n```\nsh k8s_system_init.sh 主机名 主机位\n[master1] sh k8s_system_init.sh master1 101\n\n[master2] sh k8s_system_init.sh master2 102\n\n[master3] sh k8s_system_init.sh master3 103\n\n[node01] sh k8s_system_init.sh node01 104\n\n```\n\n### 配置ssh免密\n\n操作节点[master1]\n\n```\nyum install -y sshpass \ncat > sshmianmi.sh << \"EOF\"\n#!/bin/bash\n# 目标主机列表\nhosts=(\"master1\" \"master2\" \"master3\" \"node01\")\n# 密码\npassword=\"123456\"\n# 生成 SSH 密钥对\nssh-keygen -t rsa -N \"\" -f ~/.ssh/id_rsa\n\n# 循环遍历目标主机\nfor host in \"${hosts[@]}\"\ndo\n    # 复制公钥到目标主机\n    sshpass -p \"$password\" ssh-copy-id -o StrictHostKeyChecking=no \"$host\"\n    \n    # 验证免密登录\n    sshpass -p \"$password\" ssh -o StrictHostKeyChecking=no \"$host\" \"echo '免密登录成功'\"\ndone\nEOF\n\nsh sshmianmi.sh\n```\n\n\n\n## 内核及ipvs模块配置\n\n此步骤是升级内核、配置ipvs模块，开启一些k8s集群中必须的内核参数。配置一下几个方面：\n\n1. 下载安装包到/server/soft\n2. 安装kernel\n3. 更改内核启动顺序\n4. 安装ipvsadm\n5. 配置ipvs模块\n6. 开启k8s集群必须的内核参数\n7. 配置完内核，重启服务器\n\n操作主机：[master1,master2,master3,node01]\n\n```\nvi kernel_update.sh\n\n#!/bin/bash\necho \"1.下载安装包到/server/soft\"\nmkdir -p /server/soft ; cd /server/soft\nwget https://mirrors.aliyun.com/elrepo/kernel/el7/x86_64/RPMS/kernel-ml-6.6.3-1.el7.elrepo.x86_64.rpm\nwget https://mirrors.aliyun.com/elrepo/kernel/el7/x86_64/RPMS/kernel-ml-devel-6.6.3-1.el7.elrepo.x86_64.rpm\n\n\necho \"2.正在安装kernel\"\nyum localinstall -y kernel-ml*\n\n\necho \"3.更改内核启动顺序\"\ngrub2-set-default  0 && grub2-mkconfig -o /etc/grub2.cfg\ngrubby --args=\"user_namespace.enable=1\" --update-kernel=\"$(grubby --default-kernel)\"\n\n\necho \"4.输出现在内核版本信息\"\ngrubby --default-kernel\n\n\necho \"5.安装ipvsadm\"\nyum install ipvsadm ipset sysstat conntrack libseccomp -y &> /dev/null\n\n\necho \"6.配置ipvs模块\"\nmodprobe -- ip_vs\nmodprobe -- ip_vs_rr\nmodprobe -- ip_vs_wrr\nmodprobe -- ip_vs_sh\nmodprobe -- nf_conntrack\n\ncat >> /etc/modules-load.d/ipvs.conf <<EOF\nip_vs\nip_vs_lc\nip_vs_wlc\nip_vs_rr\nip_vs_wrr\nip_vs_lblc\nip_vs_lblcr\nip_vs_dh\nip_vs_sh\nip_vs_fo\nip_vs_nq\nip_vs_sed\nip_vs_ftp\nip_vs_sh\nnf_conntrack\nip_tables\nip_set\nxt_set\nipt_set\nipt_rpfilter\nipt_REJECT\nipip\nEOF\nsystemctl enable --now systemd-modules-load.service &> /dev/null\n\n\necho \"7.开启k8s集群必须的内核参数\"\ncat <<EOF > /etc/sysctl.d/k8s.conf\nnet.ipv4.ip_forward = 1\nnet.bridge.bridge-nf-call-iptables = 1\nnet.bridge.bridge-nf-call-ip6tables = 1\nfs.may_detach_mounts = 1\nnet.ipv4.conf.all.route_localnet = 1\nvm.overcommit_memory=1\nvm.panic_on_oom=0\nfs.inotify.max_user_watches=89100\nfs.file-max=52706963\nfs.nr_open=52706963\nnet.netfilter.nf_conntrack_max=2310720\n\nnet.ipv4.tcp_keepalive_time = 600\nnet.ipv4.tcp_keepalive_probes = 3\nnet.ipv4.tcp_keepalive_intvl =15\nnet.ipv4.tcp_max_tw_buckets = 36000\nnet.ipv4.tcp_tw_reuse = 1\nnet.ipv4.tcp_max_orphans = 327680\nnet.ipv4.tcp_orphan_retries = 3\nnet.ipv4.tcp_syncookies = 1\nnet.ipv4.tcp_max_syn_backlog = 16384\nnet.ipv4.ip_conntrack_max = 65536\nnet.ipv4.tcp_max_syn_backlog = 16384\nnet.ipv4.tcp_timestamps = 0\nnet.core.somaxconn = 16384\nEOF\nsysctl --system\n\n\necho \"8.配置完内核，重启服务器！\"\nreboot\n\n```\n\n```\nsh kernel_update.sh\n```\n\n## 检查ipvs加载、内核版本验证\n\n```\nlsmod | grep --color=auto -e ip_vs -e nf_conntrack\nuname -a\n```\n\n![image-20231201233238841](../img/K8S%E9%AB%98%E5%8F%AF%E7%94%A8%E9%9B%86%E7%BE%A4%EF%BC%88%E5%A4%96%E9%83%A8etcd%EF%BC%89/7b6a9d8f90a78eced6f8ae1d42bbdec5697559838.png)\n\n## 部署ETCD集群\n\n本次在master1、master2、master3上进行etcd集群部署\n\n### 安装etcd\n\n#### 下载安装包\n\n```\nwget https://github.com/etcd-io/etcd/releases/download/v3.5.10/etcd-v3.5.10-linux-amd64.tar.gz --no-check-certificate\n```\n\n![image-20231201233751721](../img/K8S%E9%AB%98%E5%8F%AF%E7%94%A8%E9%9B%86%E7%BE%A4%EF%BC%88%E5%A4%96%E9%83%A8etcd%EF%BC%89/e651e3d7cbd00991c8afa5ad082945cc697559838.png)\n\n#### 解压\n\n```\ntar xf etcd-v3.5.10-linux-amd64.tar.gz\nmv etcd-v3.5.10-linux-amd64 /tmp/etcd\ncp /tmp/etcd/etcd* /usr/local/bin/\n```\n\n![image-20231201234030329](../img/K8S%E9%AB%98%E5%8F%AF%E7%94%A8%E9%9B%86%E7%BE%A4%EF%BC%88%E5%A4%96%E9%83%A8etcd%EF%BC%89/67d93a3046dffd6ee8c251428424acac697559838.png)\n\n![image-20231015012712425](../img/K8S%E9%AB%98%E5%8F%AF%E7%94%A8%E9%9B%86%E7%BE%A4%EF%BC%88%E5%A4%96%E9%83%A8etcd%EF%BC%89/8771daaf594a82a3d312ac6e55254ecc697559838.png)\n\n#### 添加环境变量\n\n将文件夹中**etcd**和**etcdctl**两个文件添加到环境变量中\n\n```\nmkdir -p /var/lib/etcd/\nmkdir -p /etc/etcd/\nchmod 700 /var/lib/etcd\n```\n\n![image-20231015012808701](../img/K8S%E9%AB%98%E5%8F%AF%E7%94%A8%E9%9B%86%E7%BE%A4%EF%BC%88%E5%A4%96%E9%83%A8etcd%EF%BC%89/ca7ff97219be392c73ce9e36ebe09b40697559838.png)\n\n#### 创建默认配置文件\n\n```\ncat <<EOF | sudo tee /etc/etcd/etcd.conf\n#节点名称\nETCD_NAME=$(hostname -s)\n#数据存放位置\nETCD_DATA_DIR=/var/lib/etcd\nEOF\n```\n\n![image-20231015012819394](../img/K8S%E9%AB%98%E5%8F%AF%E7%94%A8%E9%9B%86%E7%BE%A4%EF%BC%88%E5%A4%96%E9%83%A8etcd%EF%BC%89/ab7af0c23088dfbd6083947b7b59c127697559838.png)\n\n#### 创建etcd服务\n\n```\ncat <<EOF | sudo tee /etc/systemd/system/etcd.service\n \n[Unit]\nDescription=Etcd Server\nDocumentation=https://github.com/coreos/etcd\nAfter=network.target\n \n[Service]\nUser=root\nType=notify\nEnvironmentFile=-/etc/etcd/etcd.conf\nExecStart=/usr/local/bin/etcd\nRestart=on-failure\nRestartSec=10s\nLimitNOFILE=40000\n \n[Install]\nWantedBy=multi-user.target\nEOF\n```\n\n![image-20231015012847141](../img/K8S%E9%AB%98%E5%8F%AF%E7%94%A8%E9%9B%86%E7%BE%A4%EF%BC%88%E5%A4%96%E9%83%A8etcd%EF%BC%89/de5dec2c81df4b27cbb395f0da812217697559838.png)\n\n#### 开启服务\n\n```\nsystemctl daemon-reload && systemctl enable etcd && systemctl start etcd\n```\n\n![image-20231015012901227](../img/K8S%E9%AB%98%E5%8F%AF%E7%94%A8%E9%9B%86%E7%BE%A4%EF%BC%88%E5%A4%96%E9%83%A8etcd%EF%BC%89/e6dd7c1044841ed87f880586044f817f697559838.png)\n\n#### **查看版本信息**\n\n```\netcd -version\n```\n\n![image-20231201234123720](../img/K8S%E9%AB%98%E5%8F%AF%E7%94%A8%E9%9B%86%E7%BE%A4%EF%BC%88%E5%A4%96%E9%83%A8etcd%EF%BC%89/a2a7efe249c90e8a65947102b5aec717697559838.png)\n\n### 在<font color='red'>master1</font>节点上生成etcd配置文件\n\n```\nvim etcd_install.sh\n\netcd1=192.168.48.101\netcd2=192.168.48.102\netcd3=192.168.48.103\n\nTOKEN=smartgo\nETCDHOSTS=($etcd1 $etcd2 $etcd3)\nNAMES=(\"master1\" \"master2\" \"master3\")\nfor i in \"${!ETCDHOSTS[@]}\"; do\nHOST=${ETCDHOSTS[$i]}\nNAME=${NAMES[$i]}\ncat << EOF > /tmp/$NAME.conf\n# [member]\nETCD_NAME=$NAME\nETCD_DATA_DIR=\"/var/lib/etcd/default.etcd\"\nETCD_LISTEN_PEER_URLS=\"http://$HOST:2380\"\nETCD_LISTEN_CLIENT_URLS=\"http://$HOST:2379,http://127.0.0.1:2379\"\n#[cluster]\nETCD_INITIAL_ADVERTISE_PEER_URLS=\"http://$HOST:2380\"\nETCD_INITIAL_CLUSTER=\"${NAMES[0]}=http://${ETCDHOSTS[0]}:2380,${NAMES[1]}=http://${ETCDHOSTS[1]}:2380,${NAMES[2]}=http://${ETCDHOSTS[2]}:2380\"\nETCD_INITIAL_CLUSTER_STATE=\"new\"\nETCD_INITIAL_CLUSTER_TOKEN=\"$TOKEN\"\nETCD_ADVERTISE_CLIENT_URLS=\"http://$HOST:2379\"\nEOF\ndone\nls /tmp/master*\nscp /tmp/master2.conf $etcd2:/etc/etcd/etcd.conf\nscp /tmp/master3.conf $etcd3:/etc/etcd/etcd.conf\ncp /tmp/master1.conf /etc/etcd/etcd.conf\nrm -f /tmp/master*.conf\n```\n\n![image-20231014195615912](../img/K8S%E9%AB%98%E5%8F%AF%E7%94%A8%E9%9B%86%E7%BE%A4%EF%BC%88%E5%A4%96%E9%83%A8etcd%EF%BC%89/01b659900a16525724d55fa35984fbf1697559838.png)\n\n```\nsh etcd_install.sh\n```\n\n![image-20231014195602840](../img/K8S%E9%AB%98%E5%8F%AF%E7%94%A8%E9%9B%86%E7%BE%A4%EF%BC%88%E5%A4%96%E9%83%A8etcd%EF%BC%89/0b062e64c96a5015d933f85645d66577697559838.png)\n\n### 在k8s集群master节点上启动etcd\n\n```\nsystemctl restart etcd\nsystemctl enable --now etcd\n```\n\n![image-20231014195712942](../img/K8S%E9%AB%98%E5%8F%AF%E7%94%A8%E9%9B%86%E7%BE%A4%EF%BC%88%E5%A4%96%E9%83%A8etcd%EF%BC%89/9fa6cc52778a5f76435e622e12b340d5697559838.png)\n\n### 检查etcd集群是否正常\n\n```\netcdctl member list\netcdctl endpoint health\n```\n\n![image-20231015013040955](../img/K8S%E9%AB%98%E5%8F%AF%E7%94%A8%E9%9B%86%E7%BE%A4%EF%BC%88%E5%A4%96%E9%83%A8etcd%EF%BC%89/e5f0c10de8411ddb2b53def5a838e744697559838.png)\n\n![image-20231015013053386](../img/K8S%E9%AB%98%E5%8F%AF%E7%94%A8%E9%9B%86%E7%BE%A4%EF%BC%88%E5%A4%96%E9%83%A8etcd%EF%BC%89/a92e88f10383a90ed89a0c0f843d29bd697559838.png)\n\n![image-20231015013100578](../img/K8S%E9%AB%98%E5%8F%AF%E7%94%A8%E9%9B%86%E7%BE%A4%EF%BC%88%E5%A4%96%E9%83%A8etcd%EF%BC%89/5dd106819d20f456f21da551140a8039697559838.png)\n\n##  高可用组件安装\n\n### haproxy配置\n\n操作节点：[master1，master2,master3]\n\n```\nyum install keepalived haproxy -y\n```\n\n所有Master节点配置HAProxy，所有Master节点的HAProxy配置相同。\n\n```yaml\n操作节点：[master1，master2]\ncat > /etc/haproxy/haproxy.cfg <<\"EOF\"\n\nglobal\n  maxconn  2000\n  ulimit-n  16384\n  log  127.0.0.1 local0 err\n  stats timeout 30s\n\ndefaults\n  log global\n  mode  http\n  option  httplog\n  timeout connect 5000\n  timeout client  50000\n  timeout server  50000\n  timeout http-request 15s\n  timeout http-keep-alive 15s\n\nfrontend monitor-in\n  bind *:33305\n  mode http\n  option httplog\n  monitor-uri /monitor\n\nfrontend k8s-master\n  bind 0.0.0.0:16443\n  bind 127.0.0.1:16443\n  mode tcp\n  option tcplog\n  tcp-request inspect-delay 5s\n  default_backend k8s-master\n\nbackend k8s-master\n  mode tcp\n  option tcplog\n  option tcp-check\n  balance roundrobin\n  default-server inter 10s downinter 5s rise 2 fall 2 slowstart 60s maxconn 250 maxqueue 256 weight 100\n  server master1   192.168.48.101:6443  check\n  server master2   192.168.48.102:6443  check\n  server master3   192.168.48.103:6443  check\nEOF\n```\n\n### Keepalived配置\n\n操作节点：[master1，master2,master3]\n\n所有Master节点配置Keepalived，以下三个Master节点配置注意ip和网卡。\n\n```\n操作节点：[master1]\n\ncat >/etc/keepalived/keepalived.conf  <<\"EOF\"\n\n! Configuration File for keepalived\nglobal_defs {\n    router_id LVS_DEVEL\nscript_user root\n    enable_script_security\n}\nvrrp_script chk_apiserver {\n    script \"/etc/keepalived/check_apiserver.sh\"\n    interval 5\n    weight -5\n    fall 2  \nrise 1\n}\nvrrp_instance VI_1 {\n    state MASTER\n    interface ens33\n    mcast_src_ip 192.168.48.101\n    virtual_router_id 51\n    priority 101\n    advert_int 2\n    authentication {\n        auth_type PASS\n        auth_pass K8SHA_KA_AUTH\n    }\n    virtual_ipaddress {\n        192.168.48.200\n    }\n    track_script {\n       chk_apiserver\n    }\n}\nEOF\n```\n\n```\n操作节点：[master2]\ncat >/etc/keepalived/keepalived.conf  <<\"EOF\"\n\n! Configuration File for keepalived\nglobal_defs {\n    router_id LVS_DEVEL\nscript_user root\n    enable_script_security\n}\nvrrp_script chk_apiserver {\n    script \"/etc/keepalived/check_apiserver.sh\"\n    interval 5\n    weight -5\n    fall 2  \nrise 1\n}\nvrrp_instance VI_1 {\n    state BACKUP\n    interface ens33\n    mcast_src_ip 192.168.48.102\n    virtual_router_id 51\n    priority 100\n    advert_int 2\n    authentication {\n        auth_type PASS\n        auth_pass K8SHA_KA_AUTH\n    }\n    virtual_ipaddress {\n        192.168.48.200\n    }\n    track_script {\n       chk_apiserver\n    }\n}\nEOF\n```\n\n```\n操作节点：[master3]\ncat >/etc/keepalived/keepalived.conf  <<\"EOF\"\n\n! Configuration File for keepalived\nglobal_defs {\n    router_id LVS_DEVEL\nscript_user root\n    enable_script_security\n}\nvrrp_script chk_apiserver {\n    script \"/etc/keepalived/check_apiserver.sh\"\n    interval 5\n    weight -5\n    fall 2  \nrise 1\n}\nvrrp_instance VI_1 {\n    state BACKUP\n    interface ens33\n    mcast_src_ip 192.168.48.103\n    virtual_router_id 51\n    priority 99\n    advert_int 2\n    authentication {\n        auth_type PASS\n        auth_pass K8SHA_KA_AUTH\n    }\n    virtual_ipaddress {\n        192.168.48.200\n    }\n    track_script {\n       chk_apiserver\n    }\n}\nEOF\n```\n\n### 配置Keepalived健康检查文件\n\n操作节点：[master1，master2,master3]\n\n```\ncat > /etc/keepalived/check_apiserver.sh <<\"EOF\"\n #!/bin/bash\n err=0\n for k in $(seq 1 3)\n do\n    check_code=$(pgrep haproxy)\n    if [[ $check_code == \"\" ]]; then\n        err=$(expr $err + 1)\n        sleep 1\n        continue\n    else\n        err=0\n        break\n    fi\n done\n \n if [[ $err != \"0\" ]]; then\n    echo \"systemctl stop keepalived\"\n    /usr/bin/systemctl stop keepalived\n    exit 1\n else\n    exit 0\n fi\nEOF\n\nchmod +x /etc/keepalived/check_apiserver.sh\n```\n\n### 启动haproxy和keepalived\n\n```\n操作节点：[master，master2,master3]\nsystemctl daemon-reload\nsystemctl enable --now haproxy\nsystemctl enable --now keepalived\n```\n\n### 测试集群负载均衡高可用\n\n查看master1的vip\n\n```\nip a\n```\n\n![image-20231109232708584](../img/K8S%E9%AB%98%E5%8F%AF%E7%94%A8%E9%9B%86%E7%BE%A4%EF%BC%88%E5%A4%96%E9%83%A8etcd%EF%BC%89/0176020d9bcd8b4c85ea2e4f8d6b4afa697559838.png)\n\n模拟master1的宕机测试，看看vip会不会漂移到master2去\n\n```\n[master1] poweroff\n```\n\n![image-20231109232803276](../img/K8S%E9%AB%98%E5%8F%AF%E7%94%A8%E9%9B%86%E7%BE%A4%EF%BC%88%E5%A4%96%E9%83%A8etcd%EF%BC%89/126a03a1112b6ab1ae01e0603ac0023b697559838.png)\n\n这时候查看master2的ip列表\n\n```\n[master2] ip a\n```\n\n![image-20231109232825999](../img/K8S%E9%AB%98%E5%8F%AF%E7%94%A8%E9%9B%86%E7%BE%A4%EF%BC%88%E5%A4%96%E9%83%A8etcd%EF%BC%89/2a02b2b0a2310908a960dff95daf55d8697559838.png)\n\n结论：这时可以知道，负载均衡集群成功，当master1出现宕机情况，vip会从master1漂移到master2\n\n## docker安装\n\n### 安装docker\n\n操作节点[master1，master2，master3,node01]\n\n```\nwget https://download.docker.com/linux/static/stable/x86_64/docker-24.0.7.tgz\ntar xf docker-*.tgz\ncp -rf docker/* /usr/bin/\n#创建containerd的service文件,并且启动\ncat >/etc/systemd/system/containerd.service <<EOF\n[Unit]\nDescription=containerd container runtime\nDocumentation=https://containerd.io\nAfter=network.target local-fs.target\n[Service]\nExecStartPre=-/sbin/modprobe overlay\nExecStart=/usr/bin/containerd\nType=notify\nDelegate=yes\nKillMode=process\nRestart=always\nRestartSec=5\nLimitNPROC=infinity\nLimitCORE=infinity\nLimitNOFILE=1048576\nTasksMax=infinity\nOOMScoreAdjust=-999\n[Install]\nWantedBy=multi-user.target\nEOF\nsystemctl enable --now containerd.service\n\n#准备docker的service文件\n\ncat > /etc/systemd/system/docker.service <<EOF\n[Unit]\nDescription=Docker Application Container Engine\nDocumentation=https://docs.docker.com\nAfter=network-online.target firewalld.service containerd.service\nWants=network-online.target\nRequires=docker.socket containerd.service\n[Service]\nType=notify\nExecStart=/usr/bin/dockerd --config-file=/etc/docker/daemon.json -H fd://\ncontainerd=/run/containerd/containerd.sock\nExecReload=/bin/kill -s HUP $MAINPID\nTimeoutSec=0\nRestartSec=2\nRestart=always\nStartLimitBurst=3\nStartLimitInterval=60s\nLimitNOFILE=infinity\nLimitNPROC=infinity\nLimitCORE=infinity\nTasksMax=infinity\nDelegate=yes\nKillMode=process\nOOMScoreAdjust=-500\n[Install]\nWantedBy=multi-user.target\nEOF\n\n\n#准备docker的socket文件\n\ncat > /etc/systemd/system/docker.socket <<EOF\n[Unit]\nDescription=Docker Socket for the API\n[Socket]\nListenStream=/var/run/docker.sock\nSocketMode=0660\nSocketUser=root\nSocketGroup=docker\n[Install]\nWantedBy=sockets.target\nEOF\ngroupadd docker\n\nsystemctl enable --now docker.socket  && systemctl enable --now docker.service\n\n\n#验证\nmkdir /etc/docker\nsudo tee /etc/docker/daemon.json > /dev/null <<'EOF'\n{\n  \"registry-mirrors\": [\n    \"https://docker.xuanyuan.me\",\n    \"https://docker.m.daocloud.io\",\n    \"https://docker.1ms.run\",\n    \"https://docker.1panel.live\",\n    \"https://registry.cn-hangzhou.aliyuncs.com\",\n\t\t\"https://docker.qianyios.top\"\n  ],\n  \"max-concurrent-downloads\": 10,\n  \"log-driver\": \"json-file\",\n  \"log-level\": \"warn\",\n  \"log-opts\": {\n    \"max-size\": \"10m\",\n    \"max-file\": \"3\"\n  },\n  \"data-root\": \"/var/lib/docker\"\n}\nEOF\nsystemctl daemon-reload\nsystemctl restart docker\n```\n\n### 安装cri-docker\n\n操作节点[master1，master2，master3,node01]\n\n```\nwget https://github.com/Mirantis/cri-dockerd/releases/download/v0.3.7/cri-dockerd-0.3.7.amd64.tgz\n\ntar -zxvf cri-dockerd-0.3.7.amd64.tgz\ncp cri-dockerd/cri-dockerd  /usr/bin/\nchmod +x /usr/bin/cri-dockerd\n\n\n#写入启动配置文件\ncat >  /usr/lib/systemd/system/cri-docker.service <<EOF\n[Unit]\nDescription=CRI Interface for Docker Application Container Engine\nDocumentation=https://docs.mirantis.com\nAfter=network-online.target firewalld.service docker.service\nWants=network-online.target\nRequires=cri-docker.socket\n \n[Service]\nType=notify\nExecStart=/usr/bin/cri-dockerd --network-plugin=cni --pod-infra-container-image=registry.aliyuncs.com/google_containers/pause:3.9\nExecReload=/bin/kill -s HUP $MAINPID\nTimeoutSec=0\nRestartSec=2\nRestart=always\n \nStartLimitBurst=3\n \nStartLimitInterval=60s\n \nLimitNOFILE=infinity\nLimitNPROC=infinity\nLimitCORE=infinity\n \nTasksMax=infinity\nDelegate=yes\nKillMode=process\n \n[Install]\nWantedBy=multi-user.target\nEOF\n\n\n#写入socket配置文件\ncat > /usr/lib/systemd/system/cri-docker.socket <<EOF\n[Unit]\nDescription=CRI Docker Socket for the API\nPartOf=cri-docker.service\n \n[Socket]\nListenStream=%t/cri-dockerd.sock\nSocketMode=0660\nSocketUser=root\nSocketGroup=docker\n \n[Install]\nWantedBy=sockets.target\nEOF\n\nsystemctl daemon-reload && systemctl enable cri-docker --now\n```\n\n## K8S集群安装\n\n### 安装k8s所需的工具\n\n```\n操作节点[master1，master2，master3,node01]\n\nyum -y install  kubeadm kubelet kubectl\n\n#为了实现docker使用的cgroupdriver与kubelet使用的cgroup的一致性，配置如下：\nsed -i 's/^KUBELET_EXTRA_ARGS=/KUBELET_EXTRA_ARGS=\"--cgroup-driver=systemd\"/g' /etc/sysconfig/kubelet\n\n#设置kubelet为开机自启动即可，由于没有生成配置文件，集群初始化后自动启动\nsystemctl enable kubelet\nsystemctl enable kubelet.service\n```\n\n### 初始化集群\n\n```\ncat > kubeadm-config.yaml << EOF\n---\napiVersion: kubeadm.k8s.io/v1beta3\nbootstrapTokens:\n- groups:\n  - system:bootstrappers:kubeadm:default-node-token\n  token: abcdef.0123456789abcdef\n  ttl: 24h0m0s\n  usages:\n  - signing\n  - authentication\nkind: InitConfiguration\nlocalAPIEndpoint:\n  advertiseAddress: 192.168.48.101\n  bindPort: 6443\nnodeRegistration:\n  criSocket: unix:///var/run/cri-dockerd.sock\n---\napiVersion: kubeadm.k8s.io/v1beta3\nkind: ClusterConfiguration\nkubernetesVersion: 1.28.2\nimageRepository: registry.aliyuncs.com/google_containers\nnetworking:\n  dnsDomain: cluster.local\n  podSubnet: 10.244.0.0/16\n  serviceSubnet: 10.96.0.0/12\nscheduler: {}\napiServerCertSANs:\n- 192.168.48.200\ncontrolPlaneEndpoint: \"192.168.48.200:16443\"\netcd:\n  external:\n    endpoints:\n      - http://192.168.48.101:2379\n      - http://192.168.48.102:2379\n      - http://192.168.48.103:2379\n---\napiVersion: kubeproxy.config.k8s.io/v1alpha1\nkind: KubeProxyConfiguration\nfeatureGates:\n  # SupportIPVSProxyMode: false\nmode: ipvs\n---\napiVersion: kubelet.config.k8s.io/v1beta1\nauthentication:\n  anonymous:\n    enabled: false\n  webhook:\n    cacheTTL: 0s\n    enabled: true\n  x509:\n    clientCAFile: /etc/kubernetes/pki/ca.crt\nauthorization:\n  mode: Webhook\n  webhook:\n    cacheAuthorizedTTL: 0s\n    cacheUnauthorizedTTL: 0s\ncgroupDriver: systemd\nclusterDNS:\n- 10.96.0.10\nclusterDomain: cluster.local\ncpuManagerReconcilePeriod: 0s\nevictionPressureTransitionPeriod: 0s\nfileCheckFrequency: 0s\nhealthzBindAddress: 127.0.0.1\nhealthzPort: 10248\nhttpCheckFrequency: 0s\nimageMinimumGCAge: 0s\nkind: KubeletConfiguration\nlogging:\n  flushFrequency: 0\n  options:\n    json:\n      infoBufferSize: \"0\"\n  verbosity: 0\nmemorySwap: {}\nnodeStatusReportFrequency: 0s\nnodeStatusUpdateFrequency: 0s\nrotateCertificates: true\nruntimeRequestTimeout: 0s\nshutdownGracePeriod: 0s\nshutdownGracePeriodCriticalPods: 0s\nstaticPodPath: /etc/kubernetes/manifests\nstreamingConnectionIdleTimeout: 0s\nsyncFrequency: 0s\nvolumeStatsAggPeriod: 0s\nEOF\n\n```\n\n### 准备k8s所需的镜像\n\n```\n操作节点[master1]\n\nkubeadm config images pull --config kubeadm-config.yaml\n```\n\n![image-20231202000515399](../img/K8S%E9%AB%98%E5%8F%AF%E7%94%A8%E9%9B%86%E7%BE%A4%EF%BC%88%E5%A4%96%E9%83%A8etcd%EF%BC%89/ce115b5b28cc5ab3ebcd567294737a43697559838.png)\n\n### master1节点初始化\n\n操作节点[master1]\n\n```\nkubeadm init --config kubeadm-config.yaml --upload-certs --v=9\n```\n\n会生成信息\n\n![image-20231202000611013](../img/K8S%E9%AB%98%E5%8F%AF%E7%94%A8%E9%9B%86%E7%BE%A4%EF%BC%88%E5%A4%96%E9%83%A8etcd%EF%BC%89/7f60e65f8637a54135d92dd6a756595f697559838.png)\n\n记录信息后面会用到\n\n初始化成功以后，会产生Token值，用于其他节点加入时使用，因此要记录下初始化成功生成的token值（令牌值），**有效期24小时，后续需要操作可以重新生成Token**\n\n操作节点[master1]\n\n```\nkubeadm join 192.168.48.200:16443 --token abcdef.0123456789abcdef \\\n        --discovery-token-ca-cert-hash sha256:bc27d821932d27bb4b49c187ddd412569ead01b14009e03b6d03aa3ea54e4612 \\\n        --control-plane --certificate-key 37b1370abd3584c354517603bf97e10c795e3367e05e5ff3f2f6ca14288d8054\n\n\nkubeadm join 192.168.48.200:16443 --token abcdef.0123456789abcdef \\\n        --discovery-token-ca-cert-hash sha256:bc27d821932d27bb4b49c187ddd412569ead01b14009e03b6d03aa3ea54e4612\n```\n\n`操作kubect报错：`\n\n![image-20231110180035297](../img/K8S%E9%AB%98%E5%8F%AF%E7%94%A8%E9%9B%86%E7%BE%A4%EF%BC%88%E5%A4%96%E9%83%A8etcd%EF%BC%89/0ea7d75c613d48f13e34f481c6cf08b0697559838.png)\n\n此时通过kubectl操作，会出现失败，因为还没有将集群的\"钥匙\"交给root用户。`/etc/kubernetes/admin.conf` 文件是 Kubernetes（K8s）集群中的管理员配置文件，它包含了用于管理集群的身份验证和访问信息。所以下面进行配置环境变量，用于访问Kubernetes集群：\n\n`添加环境变量`\n\n操作节点[master1]\n\n```\nmkdir -p $HOME/.kube\nsudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config\nsudo chown $(id -u):$(id -g) $HOME/.kube/config\n```\n\n### 添加其他master节点至集群中\n\n操作节点[master2,master3]\n\n```\n操作节点[master2,master3]\nkubeadm join 192.168.48.200:16443 --token abcdef.0123456789abcdef \\\n        --discovery-token-ca-cert-hash sha256:bc27d821932d27bb4b49c187ddd412569ead01b14009e03b6d03aa3ea54e4612 \\\n        --control-plane --certificate-key 37b1370abd3584c354517603bf97e10c795e3367e05e5ff3f2f6ca14288d8054 \\\n        --cri-socket unix:///var/run/cri-dockerd.sock \n```\n\n注意：这里末尾添加了`--cri-socket unix:///var/run/cri-dockerd.sock `\n\n接着给`master2`添加环境变量\n\n```\n操作节点[master2,master3]\nmkdir -p $HOME/.kube\nsudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config\nsudo chown $(id -u):$(id -g) $HOME/.kube/config\n```\n\n![image-20231110180919008](../img/K8S%E9%AB%98%E5%8F%AF%E7%94%A8%E9%9B%86%E7%BE%A4%EF%BC%88%E5%A4%96%E9%83%A8etcd%EF%BC%89/3f20e99d3edff4874993811b81d45783697559838.png)\n\n这里没有展示master3的图片，但是步骤一样的\n\n### 模拟Token过期重新生成并加入Node节点\n\n假设加入集群的token过期了。node01无法加入了，这里就模拟一下这种情况\n\n1. Token过期后生成新的token：\n\n```bash\nkubeadm token create --print-join-command\n```\n\n```\n[root@master1 ~]# kubeadm token create --print-join-command\nkubeadm join 192.168.48.200:16443 --token ke773y.6hv9utk33to4vwfy --discovery-token-ca-cert-hash sha256:bc27d821932d27bb4b49c187ddd412569ead01b14009e03b6d03aa3ea54e4612\n[root@master1 ~]#\n\n```\n\n其中，`192.168.48.200:16443` 是你的 Kubernetes API 服务器的地址和端口，`ke773y.6hv9utk33to4vwfy` 是新的令牌，`sha256:bc27d821932d27bb4b49c187ddd412569ead01b14009e03b6d03aa3ea54e4612` 是令牌的 CA 证书哈希值。\n\n2. Master需要生成--certificate-key：\n\n```bash\nkubeadm init phase upload-certs --upload-certs\n```\n\n```\n[root@master1 ~]# kubeadm init phase upload-certs --upload-certs\nW1110 18:12:03.426245   10185 version.go:104] could not fetch a Kubernetes version from the internet: unable to get URL \"https://dl.k8s.io/release/stable-1.txt\": Get \"https://dl.k8s.io/release/stable-1.txt\": context deadline exceeded (Client.Timeout exceeded while awaiting headers)\nW1110 18:12:03.426320   10185 version.go:105] falling back to the local client version: v1.28.2\n[upload-certs] Storing the certificates in Secret \"kubeadm-certs\" in the \"kube-system\" Namespace\n[upload-certs] Using certificate key:\n5d3706028d5e569324a4c456c81ae0f5551ece88b3132f03917668c6b0605128\n```\n\n其中，`5d3706028d5e569324a4c456c81ae0f5551ece88b3132f03917668c6b0605128` 是证书密钥。\n\n3. 生成新的Token用于集群添加新Node节点\n\n操作节点[node01]\n\n```\nkubeadm join 192.168.48.200:16443 \\\n        --token ke773y.6hv9utk33to4vwfy \\\n        --discovery-token-ca-cert-hash sha256:bc27d821932d27bb4b49c187ddd412569ead01b14009e03b6d03aa3ea54e4612  \\\n        --cri-socket unix:///var/run/cri-dockerd.sock \n```\n\n注意：这里末尾添加了`--cri-socket unix:///var/run/cri-dockerd.sock `\n\n![image-20231110181623386](../img/K8S%E9%AB%98%E5%8F%AF%E7%94%A8%E9%9B%86%E7%BE%A4%EF%BC%88%E5%A4%96%E9%83%A8etcd%EF%BC%89/3e809e4e0ccbd1d84b7563de484600dc697559838.png)\n\n这时在master查看node状态（显示为notready不影响）\n\n![image-20231111145807000](../img/K8S%E9%AB%98%E5%8F%AF%E7%94%A8%E9%9B%86%E7%BE%A4%EF%BC%88%E5%A4%96%E9%83%A8etcd%EF%BC%89/35ee9666e8251b54f20eec2a53ff9058697559838.png)\n\n### 模拟新加master节点的加入K8S集群中\n\n假设我们新加master节点的话，就拼接token，`从刚刚生成的token拼接`\n\n```\n[root@master1 ~]# kubeadm token create --print-join-command\nkubeadm join 192.168.48.200:16443 --token tn5q1b.7w1jj77ewup7k2in --discovery-token-ca-cert-hash sha256:cc5427e0e133d95250ab0aa90976fea2c383278b6345fd7e8c28702ac8dfc61f\n```\n\n这里提取信息1\n\n```\nkubeadm join 192.168.48.200:16443 --token tn5q1b.7w1jj77ewup7k2in --discovery-token-ca-cert-hash sha256:cc5427e0e133d95250ab0aa90976fea2c383278b6345fd7e8c28702ac8dfc61f\n```\n\n接着\n\n```\n[root@master1 ~]# kubeadm init phase upload-certs --upload-certs\nW1110 18:12:03.426245   10185 version.go:104] could not fetch a Kubernetes version from the internet: unable to get URL \"https://dl.k8s.io/release/stable-1.txt\": Get \"https://dl.k8s.io/release/stable-1.txt\": context deadline exceeded (Client.Timeout exceeded while awaiting headers)\nW1110 18:12:03.426320   10185 version.go:105] falling back to the local client version: v1.28.2\n[upload-certs] Storing the certificates in Secret \"kubeadm-certs\" in the \"kube-system\" Namespace\n[upload-certs] Using certificate key:\n5d3706028d5e569324a4c456c81ae0f5551ece88b3132f03917668c6b0605128\n```\n\n这里提取信息2：这里前面要加上`--control-plane --certificate-key`\n\n```\n--control-plane --certificate-key 5d3706028d5e569324a4c456c81ae0f5551ece88b3132f03917668c6b0605128\n```\n\n合成\n\n```\nkubeadm join 192.168.48.200:16443 --token tn5q1b.7w1jj77ewup7k2in \\\n        --discovery-token-ca-cert-hash sha256:cc5427e0e133d95250ab0aa90976fea2c383278b6345fd7e8c28702ac8dfc61f  \\\n        --control-plane --certificate-key 5d3706028d5e569324a4c456c81ae0f5551ece88b3132f03917668c6b0605128 \\\n        --cri-socket unix:///var/run/cri-dockerd.sock\n        \n        \nkubeadm join 192.168.48.200:16443 --token lnkno8.u4v1l8n9pahzf0kj \\\n        --discovery-token-ca-cert-hash sha256:cc5427e0e133d95250ab0aa90976fea2c383278b6345fd7e8c28702ac8dfc61f \\\n        --control-plane --certificate-key 41e441fe56cb4bdfcc2fc0291958e6b1da54d01f4649b6651471c07583f85cdf \\\n        --cri-socket unix:///var/run/cri-dockerd.sock\n\n\n```\n\n注意：这里末尾添加了`--cri-socket unix:///var/run/cri-dockerd.sock `\n\n图示\n\n![image-20231110182741430](../img/K8S%E9%AB%98%E5%8F%AF%E7%94%A8%E9%9B%86%E7%BE%A4%EF%BC%88%E5%A4%96%E9%83%A8etcd%EF%BC%89/7dcec71d06d286a5b7b1fcebbef15a7b697559838.png)\n\n## 安装calico网络插件\n\n操作节点[master1]\n\n添加解析记录，否则无法访问\n\n```\necho '185.199.108.133 raw.githubusercontent.com' >> /etc/hosts\n```\n\n### 应用operator资源清单文件\n\n网络组件有很多种，只需要部署其中一个即可，推荐Calico。 \nCalico是一个纯三层的数据中心网络方案，Calico支持广泛的平台，包括Kubernetes、OpenStack等。 \nCalico 在每一个计算节点利用 Linux Kernel 实现了一个高效的虚拟路由器（ vRouter） 来负责数据转发，而每个 vRouter 通过 BGP 协议负责把自己上运行的 workload 的路由信息向整个 Calico 网络内传播。 \n此外，Calico 项目还实现了 Kubernetes 网络策略，提供ACL功能。\n\n```\ncurl https://raw.githubusercontent.com/projectcalico/calico/v3.25.1/manifests/calico.yaml -O\n```\n\n```yaml\n[root@master1 ~]# vim calico.yaml\n#添加两行\n- name: WAIT_FOR_DATASTORE\n  value: \"true\"\n- name: IP_AUTODETECTION_METHOD\n  value: interface=ens33\n#ens33是你的网卡\n```\n\n![image-20231110183944854](../img/K8S%E9%AB%98%E5%8F%AF%E7%94%A8%E9%9B%86%E7%BE%A4%EF%BC%88%E5%A4%96%E9%83%A8etcd%EF%BC%89/12da23b4f8d928a8ac610de1419f8f01697559838.png)\n\n```\nsed -i 's| docker.io/calico/| registry.cn-hangzhou.aliyuncs.com/qianyios/|' calico.yaml\nkubectl apply -f calico.yaml\n```\n\n![image-20231110184031455](../img/K8S%E9%AB%98%E5%8F%AF%E7%94%A8%E9%9B%86%E7%BE%A4%EF%BC%88%E5%A4%96%E9%83%A8etcd%EF%BC%89/515614f130cb327d7e301ddff0ea1b75697559838.png)\n\n### 监视kube-system命名空间中pod运行情况\n\n等待估计20分钟左右吧(确保全部running)\n\n```\nkubectl get pods -n kube-system\n```\n\n![image-20231110193921266](../img/K8S%E9%AB%98%E5%8F%AF%E7%94%A8%E9%9B%86%E7%BE%A4%EF%BC%88%E5%A4%96%E9%83%A8etcd%EF%BC%89/65e576c8a0ad30192f63c585bda21254697559838.png)\n\n### 拿掉master节点的污点\n\n节点 master1 和 master2 都有一个名为 `node-role.kubernetes.io/control-plane:NoSchedule` 的污点。这个污点的作用是阻止普通的 Pod 被调度到这些节点上，只允许特定的控制平面组件（如 kube-apiserver、kube-controller-manager 和 kube-scheduler）在这些节点上运行。\n\n这种设置有助于确保控制平面节点专门用于运行 Kubernetes 的核心组件，而不会被普通的工作负载占用。通过将污点添加到节点上，可以确保只有被授权的控制平面组件才能在这些节点上运行。\n\n```\nkubectl describe node master1 | grep -i taint\nkubectl describe node master2 | grep -i taint\nkubectl describe node master3 | grep -i taint\n```\n\n![image-20231111152324023](../img/K8S%E9%AB%98%E5%8F%AF%E7%94%A8%E9%9B%86%E7%BE%A4%EF%BC%88%E5%A4%96%E9%83%A8etcd%EF%BC%89/7e79bf5ee514955fa2bc88a482aeace0697559838.png)\n\n去除污点\n\n```\nkubectl taint node master1 node-role.kubernetes.io/control-plane:NoSchedule-\nkubectl taint node master2 node-role.kubernetes.io/control-plane:NoSchedule-\nkubectl taint node master3 node-role.kubernetes.io/control-plane:NoSchedule-\n```\n\n![image-20231111152342956](../img/K8S%E9%AB%98%E5%8F%AF%E7%94%A8%E9%9B%86%E7%BE%A4%EF%BC%88%E5%A4%96%E9%83%A8etcd%EF%BC%89/787ed2d5c1bfbafd6bf56ca9127c4d59697559838.png)\n\n## 安装dashboard\n\n操作节点[master1]\n\n下载文件\n\nhttps://github.com/kubernetes/dashboard/releases/tag/v2.7.0\n\n目前最新版本v2.7.0 \n\n```\nwget https://raw.githubusercontent.com/kubernetes/dashboard/v2.7.0/aio/deploy/recommended.yaml\nsed -i 's/kubernetesui\\/dashboard:v2.7.0/registry.cn-hangzhou.aliyuncs.com\\/qianyios\\/dashboard:v2.7.0/g' recommended.yaml\nsed -i 's/kubernetesui\\/metrics-scraper:v1.0.8/registry.cn-hangzhou.aliyuncs.com\\/qianyios\\/metrics-scraper:v1.0.8/g' recommended.yaml\n```\n\n![image-20231014174400992](../img/K8S%E9%AB%98%E5%8F%AF%E7%94%A8%E9%9B%86%E7%BE%A4%EF%BC%88%E5%A4%96%E9%83%A8etcd%EF%BC%89/765d82d207c2fefcc00048060c4d1146697559838.png)\n\n修改配置文件\n\n```yaml\nvim recommended.yaml\n---\nkind: Service\napiVersion: v1\nmetadata:\n  labels:\n    app: kubernetes-dashboard\n  name: kubernetes-dashboard\n  namespace: kubernetes-dashboard\nspec:\n  ports:\n    - port: 443\n      targetPort: 8443\n      nodePort: 30001\n  type: NodePort\n  selector:\n    app: kubernetes-dashboard\n\n---\n```\n\n![image-20231014174511047](../img/K8S%E9%AB%98%E5%8F%AF%E7%94%A8%E9%9B%86%E7%BE%A4%EF%BC%88%E5%A4%96%E9%83%A8etcd%EF%BC%89/33ac61c500136a4ce86567aafd1c1382697559838.png)\n\n运行dashboard\n\n```\nkubectl apply -f recommended.yaml\n```\n\n![image-20231014174622344](../img/K8S%E9%AB%98%E5%8F%AF%E7%94%A8%E9%9B%86%E7%BE%A4%EF%BC%88%E5%A4%96%E9%83%A8etcd%EF%BC%89/2332124844a312fa6b5261eb90fb2c26697559838.png)\n\n检查运行状态\n\n```\nkubectl get pods -n kubernetes-dashboard\nkubectl get pod,svc -o wide -n kubernetes-dashboard\n```\n\n![image-20231111025752605](../img/K8S%E9%AB%98%E5%8F%AF%E7%94%A8%E9%9B%86%E7%BE%A4%EF%BC%88%E5%A4%96%E9%83%A8etcd%EF%BC%89/39d745dff08f596e4d810445df33dbdc697559838.png)\n\n### 创建cluster-admin用户\n\n```\n创建service account并绑定默认cluster-admin管理员群角色\n#创建用户\nkubectl create serviceaccount dashboard-admin -n kubernetes-dashboard\n#用户授权\nkubectl create clusterrolebinding dashboard-admin --clusterrole=cluster-admin --serviceaccount=kubernetes-dashboard:dashboard-admin\n#获取用户Token\nkubectl create token dashboard-admin -n kubernetes-dashboard\n```\n\n![image-20231111025817854](../img/K8S%E9%AB%98%E5%8F%AF%E7%94%A8%E9%9B%86%E7%BE%A4%EF%BC%88%E5%A4%96%E9%83%A8etcd%EF%BC%89/5e1825e420253c9b7aaba3307e80d3ef697559838.png)\n\n记录token\n\n```\neyJhbGciOiJSUzI1NiIsImtpZCI6IjJxb21sRTZSckhEZ09FMnlvWU5IY3dfTTRIWDEzRUpsQ000MThhSWxYNDgifQ.eyJhdWQiOlsiaHR0cHM6Ly9rdWJlcm5ldGVzLmRlZmF1bHQuc3ZjLmNsdXN0ZXIubG9jYWwiXSwiZXhwIjoxNjk5NjQ2Mjg3LCJpYXQiOjE2OTk2NDI2ODcsImlzcyI6Imh0dHBzOi8va3ViZXJuZXRlcy5kZWZhdWx0LnN2Yy5jbHVzdGVyLmxvY2FsIiwia3ViZXJuZXRlcy5pbyI6eyJuYW1lc3BhY2UiOiJrdWJlcm5ldGVzLWRhc2hib2FyZCIsInNlcnZpY2VhY2NvdW50Ijp7Im5hbWUiOiJkYXNoYm9hcmQtYWRtaW4iLCJ1aWQiOiIyNTBhNTQ2MS03MGJlLTRhZTItOWY2Yi1hMDQwOWE1NWJhMTMifX0sIm5iZiI6MTY5OTY0MjY4Nywic3ViIjoic3lzdGVtOnNlcnZpY2VhY2NvdW50Omt1YmVybmV0ZXMtZGFzaGJvYXJkOmRhc2hib2FyZC1hZG1pbiJ9.U-lH9_sRU4TVrpAznqS60INNSev9NxHu61igGUTzTBoaWo7WjPG7vzTnpZYhvsoglTzMEKhfranJkkkn95pe-prkvSasaAL6kXHw0jQjlSMzcYiF7DoLdkOtDJSukuALEubidf9eIwZXFZ-sezZdZHm4hnk5nWme5YtdOmYOJPh5sv1dzRvM1XuOHknJPTA1BbdZuVAtSGHSjkhwx-wl-41uuQoROW5GjJs0bz4zLBFn1w_pWaSMCn7pjGJNcbr6IuDV41km_etpwwxacWyfAcxNykzCtIiE1abJj7m-e944GvAn_eqxz3wCZD6Bgt41FWRzyMHjrppJfDjk7FaHNw\n\n```\n\n### 登录浏览器访问\n\n```\nhttps://192.168.48.200:30001\n\n输入token：\n----\neyJhbGciOiJSUzI1NiIsImtpZCI6IjJxb21sRTZSckhEZ09FMnlvWU5IY3dfTTRIWDEzRUpsQ000MThhSWxYNDgifQ.eyJhdWQiOlsiaHR0cHM6Ly9rdWJlcm5ldGVzLmRlZmF1bHQuc3ZjLmNsdXN0ZXIubG9jYWwiXSwiZXhwIjoxNjk5NjQ2Mjg3LCJpYXQiOjE2OTk2NDI2ODcsImlzcyI6Imh0dHBzOi8va3ViZXJuZXRlcy5kZWZhdWx0LnN2Yy5jbHVzdGVyLmxvY2FsIiwia3ViZXJuZXRlcy5pbyI6eyJuYW1lc3BhY2UiOiJrdWJlcm5ldGVzLWRhc2hib2FyZCIsInNlcnZpY2VhY2NvdW50Ijp7Im5hbWUiOiJkYXNoYm9hcmQtYWRtaW4iLCJ1aWQiOiIyNTBhNTQ2MS03MGJlLTRhZTItOWY2Yi1hMDQwOWE1NWJhMTMifX0sIm5iZiI6MTY5OTY0MjY4Nywic3ViIjoic3lzdGVtOnNlcnZpY2VhY2NvdW50Omt1YmVybmV0ZXMtZGFzaGJvYXJkOmRhc2hib2FyZC1hZG1pbiJ9.U-lH9_sRU4TVrpAznqS60INNSev9NxHu61igGUTzTBoaWo7WjPG7vzTnpZYhvsoglTzMEKhfranJkkkn95pe-prkvSasaAL6kXHw0jQjlSMzcYiF7DoLdkOtDJSukuALEubidf9eIwZXFZ-sezZdZHm4hnk5nWme5YtdOmYOJPh5sv1dzRvM1XuOHknJPTA1BbdZuVAtSGHSjkhwx-wl-41uuQoROW5GjJs0bz4zLBFn1w_pWaSMCn7pjGJNcbr6IuDV41km_etpwwxacWyfAcxNykzCtIiE1abJj7m-e944GvAn_eqxz3wCZD6Bgt41FWRzyMHjrppJfDjk7FaHNw\n\n----\n\n```\n\n![image-20231111025910110](../img/K8S%E9%AB%98%E5%8F%AF%E7%94%A8%E9%9B%86%E7%BE%A4%EF%BC%88%E5%A4%96%E9%83%A8etcd%EF%BC%89/d9e668b5905d26157c9377c9462266e5697559838.png)\n\n### 部署一个nginx测试\n\n操作节点[master1]\n\n```yaml\nvim web.yaml\n\nkind: Deployment\n#apiVersion: extensions/v1beta1\napiVersion: apps/v1\nmetadata:\n  labels:\n    app: web-deployment-label\n  name: web-deployment\n  namespace: default\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: web-selector\n  template:\n    metadata:\n      labels:\n        app: web-selector\n    spec:\n      containers:\n      - name: web-container\n        image: nginx:latest\n        imagePullPolicy: Always\n        ports:\n        - containerPort: 80\n          protocol: TCP\n          name: http\n        - containerPort: 443\n          protocol: TCP\n          name: https\n\n---\nkind: Service\napiVersion: v1\nmetadata:\n  labels:\n    app: web-service-label\n  name: web-service\n  namespace: default\nspec:\n  type: NodePort\n  ports:\n  - name: http\n    port: 80\n    protocol: TCP\n    targetPort: 80\n    nodePort: 30080\n  - name: https\n    port: 443\n    protocol: TCP\n    targetPort: 443\n    nodePort: 30443\n  selector:\n    app: web-selector\n    \nkubectl apply -f web.yaml \n```\n\n![image-20231014180923818](../img/K8S%E9%AB%98%E5%8F%AF%E7%94%A8%E9%9B%86%E7%BE%A4%EF%BC%88%E5%A4%96%E9%83%A8etcd%EF%BC%89/a43ccc12f086a6b24663f4030e058d51697559838.png)\n\n```\n### 查看nginx的pod 的详细信息\nkubectl get deploy,svc,pod -o wide\n```\n\n![image-20231016203536987](../img/K8S%E9%AB%98%E5%8F%AF%E7%94%A8%E9%9B%86%E7%BE%A4%EF%BC%88%E5%A4%96%E9%83%A8etcd%EF%BC%89/6061b13260d568766dd53ec7fc3036ce697559838.png)\n\n访问nginx网站\n\n```\nhttp://192.168.48.200:30080\n```\n\n![image-20231111030413487](../img/K8S%E9%AB%98%E5%8F%AF%E7%94%A8%E9%9B%86%E7%BE%A4%EF%BC%88%E5%A4%96%E9%83%A8etcd%EF%BC%89/e162ff6ccabaf5e49f416b7a1974777c697559838.png)\n\n<div class=\"tbsm\" style=\"margin-top:54px;\">\n<div class=\"tbsm-top\"><span><svg t=\"1674654360507\" class=\"icon\" viewBox=\"0 0 1024 1024\" version=\"1.1\" xmlns=\"http://www.w3.org/2000/svg\" p-id=\"987\" data-spm-anchor-id=\"a313x.7781069.0.i0\" width=\"35\" height=\"35\"><path d=\"M410.49 97.74H155.08a56.74 56.74 0 0 0-56.84 56.73V410a56.84 56.84 0 0 0 56.84 56.84h255.41A56.83 56.83 0 0 0 467.32 410V154.58a56.83 56.83 0 0 0-56.83-56.84zM410.49 558.74H155.08a56.74 56.74 0 0 0-56.84 56.73V871a56.84 56.84 0 0 0 56.84 56.84h255.41A56.83 56.83 0 0 0 467.32 871V615.58a56.83 56.83 0 0 0-56.83-56.84zM871.49 558.74H616.08a56.74 56.74 0 0 0-56.84 56.73V871a56.84 56.84 0 0 0 56.84 56.84h255.41A56.83 56.83 0 0 0 928.32 871V615.58a56.83 56.83 0 0 0-56.83-56.84z\" fill=\"#66EEFF\" p-id=\"988\"></path><path d=\"M410.49 558.74h-4.14A475 475 0 0 0 299.52 859.6a481.16 481.16 0 0 0 4.84 68.22h106.13A56.83 56.83 0 0 0 467.32 871V615.58a56.83 56.83 0 0 0-56.83-56.84zM871.49 558.74H616.08a56.74 56.74 0 0 0-56.84 56.73V871a56.84 56.84 0 0 0 56.84 56.84h255.41A56.83 56.83 0 0 0 928.32 871V615.58a56.83 56.83 0 0 0-56.83-56.84z\" fill=\"#C2F8FF\" p-id=\"989\"></path></svg></span><span style=\"font-size:30px;\"> 特别声明</span></div>\n<div class=\"tbsm-wz\">千屹博客旗下的所有文章，是通过本人课堂学习和课外自学所精心整理的知识巨著<br/>难免会有出错的地方<br/>如果细心的你发现了小失误，可以在下方评论区告诉我，或者私信我！<br />非常感谢大家的热烈支持！</div>\n</div>\n","tags":["Centos 7","K8s"],"categories":["云原生"]},{"title":"基于阿里云容器服务构建私人docker镜像","url":"/posts/54563/","content":"\n<meta name=\"referrer\" content=\"no-referrer\"/>\n\n# 基于阿里云容器服务构建私人docker镜像\n\n## 前情提要\n\n你是否被<font color='red'>国外镜像</font>拉取速度<font color='red'>慢</font>的情况所折磨，甚至一个小时都未必能下载好或者下载不到。\n\n接下来我们通过阿里云容器服务构建这些<font color='red'>海外镜像</font>为<font color='red'>私人镜像</font>\n\n![image-20231130213622452](../img/基于阿里云容器私人docker镜像/962688b00e6628fafeca069533d9ff87697559838.png)\n\n<font color='red'>使用之前，要有自己的阿里云账户，且要有一定的dockerfile知识</font>\n\n[Docker笔记 - 严千屹博客 (qianyios.top)](https://blog.qianyios.top/posts/27092/)\n\n原理图：\n\n![image-20231130220200466](../img/基于阿里云容器私人docker镜像/1b2e659b30bdb217780825f7cb56c865697559838.png)\n\n## 创建海外镜像Dockerfile\n\n[Codeup · 企业级代码管理平台 (aliyun.com)](https://codeup.aliyun.com/)\n\n注册账号过程不解释，自行探索\n\n![image-20231130212602525](../img/基于阿里云容器私人docker镜像/9f50e6ef0965a3bf02c2ac801a958b48697559838.png)\n\n添加文件\n\n![image-20231130212529981](../img/基于阿里云容器私人docker镜像/a2d705e5c71361d13f0ff1d99bd6e7df697559838.png)\n\n创建dockerfile\n\n假设这里是你遇到的海外镜像，拉取很慢的镜像\n\n![image-20231130213751443](../img/基于阿里云容器私人docker镜像/024b2f811e483b26d56cb03fc5e79c70697559838.png)\n\n提交之后我们就可以看见文件了\n\n![image-20231130213811247](../img/基于阿里云容器私人docker镜像/0db126c45476ef2593b6cbd9c9b6afab697559838.png)\n\n去个人中心设置里设置你的克隆密码\n\n![image-20231130214355804](../img/基于阿里云容器私人docker镜像/d2a8b4fcc14ae81839a9e5f8f6ebbb17697559838.png)\n\n![image-20231130214422020](../img/基于阿里云容器私人docker镜像/cd3acb1ed8dc41133a49c25a986f3b34697559838.png)\n\n创建个人访问令牌\n\n![image-20231130214730356](../img/基于阿里云容器私人docker镜像/8e8a098fe3436944d6534fe735726ee0697559838.png)\n\n![image-20231130214749060](../img/基于阿里云容器私人docker镜像/37b23cc0c76e4be9636bb7aa7afaab92697559838.png)\n\n下面构建镜像要用到这个个人访问令牌（<font color='red'>这个只会出现一次，要记下来</font>）\n\n## 阿里容器服务构建镜像\n\n[容器镜像服务 (aliyun.com)](https://cr.console.aliyun.com/cn-hangzhou/instances)\n\n同样，注册账号过程不做解释\n\n创建个人实例，并点击\n\n![image-20231130213006943](../img/基于阿里云容器私人docker镜像/338968eb03407a98fd073e2f50b6f259697559838.png)\n\n创建命名空间\n\n![image-20231130213103002](../img/基于阿里云容器私人docker镜像/4e02ec7838fb97dfecb3d328b94cc9be697559838.png)\n\n创建镜像仓库（仓库名称=docker镜像名称），并点击进去\n\n![image-20231130213902477](../img/基于阿里云容器私人docker镜像/73d9479c86d63a7b49d22e41eba6c7a8697559838.png)\n\n绑定代码源（一定要勾选海外构建镜像）\n\n![image-20231130214016359](../img/基于阿里云容器私人docker镜像/8f6823af84aa3eb0c19b072d54dcf775697559838.png)\n\n用codeup获取的克隆账号\n\n![image-20231130214912189](../img/基于阿里云容器私人docker镜像/bd980a3805f988ee058f9c305360be5e697559838.png)\n\n![image-20231130215146722](../img/基于阿里云容器私人docker镜像/e25c874218fec925ba4f9ffdc74a62b6697559838.png)\n\n填写信息\n\n![image-20231130215527348](../img/基于阿里云容器私人docker镜像/0f64618ec6dd79a76180fd1e77dc4d1f697559838.png)\n\n构建镜像，过一会他会自己构建好\n\n![image-20231130215727359](../img/基于阿里云容器私人docker镜像/ed9dc9e6f70bb80d4dfcab01517216ed697559838.png)\n\n获取镜像地址\n\n![image-20231130215810561](../img/基于阿里云容器私人docker镜像/e8bcea4dc207821759287b73db662bd1697559838.png)\n\n```\nregistry.cn-hangzhou.aliyuncs.com/qianyios/pause:3.1\n```\n\n## 验证\n\n```\ndocker pull registry.cn-hangzhou.aliyuncs.com/qianyios/pause:3.1\n```\n\n![image-20231130215905914](../img/基于阿里云容器私人docker镜像/7ce31274e625643173f8de8e36b51a16697559838.png)\n\n<font color='red'>你会发现已经下载好了！还很快！</font>\n\n以下是一个k8s部署实例文件，有时候会因为镜像拉取慢，我们就可以替换为我们自己构建的镜像\n\n![image-20231130220355498](../img/基于阿里云容器私人docker镜像/fb9aa1ccf6eeba72514434d916fd35ee697559838.png)\n\n<div class=\"tbsm\" style=\"margin-top:54px;\">\n<div class=\"tbsm-top\"><span><svg t=\"1674654360507\" class=\"icon\" viewBox=\"0 0 1024 1024\" version=\"1.1\" xmlns=\"http://www.w3.org/2000/svg\" p-id=\"987\" data-spm-anchor-id=\"a313x.7781069.0.i0\" width=\"35\" height=\"35\"><path d=\"M410.49 97.74H155.08a56.74 56.74 0 0 0-56.84 56.73V410a56.84 56.84 0 0 0 56.84 56.84h255.41A56.83 56.83 0 0 0 467.32 410V154.58a56.83 56.83 0 0 0-56.83-56.84zM410.49 558.74H155.08a56.74 56.74 0 0 0-56.84 56.73V871a56.84 56.84 0 0 0 56.84 56.84h255.41A56.83 56.83 0 0 0 467.32 871V615.58a56.83 56.83 0 0 0-56.83-56.84zM871.49 558.74H616.08a56.74 56.74 0 0 0-56.84 56.73V871a56.84 56.84 0 0 0 56.84 56.84h255.41A56.83 56.83 0 0 0 928.32 871V615.58a56.83 56.83 0 0 0-56.83-56.84z\" fill=\"#66EEFF\" p-id=\"988\"></path><path d=\"M410.49 558.74h-4.14A475 475 0 0 0 299.52 859.6a481.16 481.16 0 0 0 4.84 68.22h106.13A56.83 56.83 0 0 0 467.32 871V615.58a56.83 56.83 0 0 0-56.83-56.84zM871.49 558.74H616.08a56.74 56.74 0 0 0-56.84 56.73V871a56.84 56.84 0 0 0 56.84 56.84h255.41A56.83 56.83 0 0 0 928.32 871V615.58a56.83 56.83 0 0 0-56.83-56.84z\" fill=\"#C2F8FF\" p-id=\"989\"></path></svg></span><span style=\"font-size:30px;\"> 特别声明</span></div>\n<div class=\"tbsm-wz\">千屹博客旗下的所有文章，是通过本人课堂学习和课外自学所精心整理的知识巨著<br/>难免会有出错的地方<br/>如果细心的你发现了小失误，可以在下方评论区告诉我，或者私信我！<br />非常感谢大家的热烈支持！</div>\n</div>","tags":["Docker"],"categories":["Docker"]},{"title":"Lsky Pro图床","url":"/posts/6726/","content":"\n<meta name=\"referrer\" content=\"no-referrer\"/>\n\n# Lsky Pro图床\n\n系统：centos 8 stream  ip：192.168.48.11\n\n## 介绍\n\n-  支持`本地`等多种第三方云储存 `AWS S3`、`阿里云 OSS`、`腾讯云 COS`、`七牛云`、`又拍云`、`SFTP`、`FTP`、`WebDav`、`Minio`\n-  多种数据库驱动支持，`MySQL 5.7+`、`PostgreSQL 9.6+`、`SQLite 3.8.8+`、`SQL Server 2017+`\n-  支持配置使用多种缓存驱动，`Memcached`、`Redis`、`DynamoDB`、等其他关系型数据库，默认以文件的方式缓存\n-  多图上传、拖拽上传、粘贴上传、动态设置策略上传、复制、一键复制链接\n-  强大的图片管理功能，瀑布流展示，支持鼠标右键、单选多选、重命名等操作\n-  自由度极高的角色组配置，可以为每个组配置多个储存策略，同时储存策略可以配置多个角色组\n-  可针对角色组设置上传文件、文件夹路径命名规则、上传频率限制、图片审核等功能\n-  支持图片水印、文字水印、水印平铺、设置水印位置、X/y 轴偏移量设置、旋转角度等\n-  支持通过接口上传、管理图片、管理相册\n-  支持在线增量更新、跨版本更新\n-  图片广场\n\n## 要求\n\n- PHP >= 8.0.2\n- BCMath PHP 扩展\n- Ctype PHP 扩展\n- DOM PHP 拓展\n- Fileinfo PHP 扩展\n- JSON PHP 扩展\n- Mbstring PHP 扩展\n- OpenSSL PHP 扩展\n- PDO PHP 扩展\n- Tokenizer PHP 扩展\n- XML PHP 扩展\n- Imagick 拓展\n- exec、shell_exec 函数\n- readlink、symlink 函数\n- putenv、getenv 函数\n- chmod、chown、fileperms 函数\n\n## 安装Lsky Pro\n\n### 下载Lsky Pro项目文件\n\n项目地址:[Releases · lsky-org/lsky-pro (github.com)](https://github.com/lsky-org/lsky-pro/releases)\n\n```\nwget https://github.com/lsky-org/lsky-pro/releases/download/2.1/lsky-pro-2.1.zip\nunzip lsky-pro-2.1.zip -d /var/www/html/lsky\nchmod 755 -R /var/www/html/lsky\nchown -R nginx:nginx /var/www/html/lsky\n```\n\n### 安装nginx\n\n```\nsudo dnf upgrade --refresh -y\nsudo dnf install \\\n   https://dl.fedoraproject.org/pub/epel/8/Everything/x86_64/Packages/e/epel-release-8-19.el8.noarch.rpm \\\n   https://dl.fedoraproject.org/pub/epel/8/Everything/x86_64/Packages/e/epel-next-release-8-19.el8.noarch.rpm \\\n   http://rpms.remirepo.net/enterprise/remi-release-8.8.rpm \\\n   dnf-utils -y\ndnf module list | grep php\n\n# 删除 PHP\nsudo dnf -y remove php php-fpm\n   \n# 删除相关扩展包\nsudo dnf -y remove php*\n   \n# 重置 PHP 模块列表\nsudo dnf -y module reset php\n\n启用（安装）PHP 8.0\nsudo dnf -y module enable php:remi-8.0\n\nsudo dnf -y install php php-fpm\n\nsudo dnf install php-cli php-fpm php-curl php-mysqlnd php-gd php-opcache php-zip php-intl php-common php-bcmath php-imagick php-xmlrpc php-json php-readline php-memcached php-redis php-mbstring php-apcu php-xml php-dom php-redis php-memcached php-memcache php-devel php-ctype php-fileinfo  php-openssl php-pdo php-tokenizer -y\n\nsed -i 's/user = apache/user = nginx/; s/group = apache/group = nginx/' /etc/php-fpm.d/www.conf\n\ndnf install -y http://nginx.org/packages/rhel/8/x86_64/RPMS/nginx-1.24.0-1.el8.ngx.x86_64.rpm\nsystemctl\tenable --now nginx\nsudo systemctl restart php-fpm.service\n\n```\n\n### 安装mysql\n\n```\nsudo dnf install mysql-server mysql -y\nsystemctl enable --now mysqld\n#mysql初始化\nsudo mysql_secure_installation\n根据自身需要设置\nmysql -uroot -p\n```\n\n### 设置兰空页面\n\n```\n[root@localhost ~]# cat /etc/nginx/conf.d/default.conf\nserver {\n    listen       80;\n    server_name  localhost;\n    root          /var/www/html/lsky/public/;\n    index        index.php;\n    location / {\n      try_files $uri $uri/ /index.php?$query_string;\n    }\n    location ~ \\.php$ {\n      root           /var/www/html/lsky/public/;\n      fastcgi_pass   unix:/run/php-fpm/www.sock;\n      fastcgi_index  index.php;\n      fastcgi_param  SCRIPT_FILENAME $document_root$fastcgi_script_name;\n      include        fastcgi_params;\n    }\n}\n\n#重启nginx\nnginx -s reload\n\n\n```\n\n访问页面192.168.48.11\n\n![image-20231130195414702](../img/Lsky-por/image-20231130195414702.png)\n\n![image-20231130195439402](../img/Lsky-por/image-20231130195439402.png)\n\n## 利用postman获取token\n\n官网：[Postman API Platform](https://www.postman.com/)\n\n自己注册一个账号，并且下载桌面版的postman（如果你的项目部署在服务器，可以不用下载，直接从第二步开始）\n\n软件下载：[Download Postman | Get Started for Free](https://www.postman.com/downloads/)\n\n### 下载软件并双击运行\n\n![image-20231130201640225](../img/Lsky-por/image-20231130201640225.png)\n\n![image-20231130201704089](../img/Lsky-por/image-20231130201704089.png)\n\n### 打开页面\n\n![image-20231130201727276](../img/Lsky-por/image-20231130201727276.png)\n\n![image-20231130202249851](../img/Lsky-por/image-20231130202249851.png)\n\n```\n6|0kKPF29VXPv2Kv6lEqu1chyxHjTpjiiEdwwkRE0T\n```\n\n## 实现typro自动上传\n\n[Releases · ygxbnet/lsky-upload (github.com)](https://github.com/ygxbnet/lsky-upload/releases)\n\n### 下载自动上传项目\n\nhttps://github.com/ygxbnet/lsky-upload/releases/download/0.3.0/lsky-upload_0.3.0_windows_amd64.zip\n\n![image-20231130194623114](../img/Lsky-por/image-20231130194623114.png)\n\n打开配置文件可以看见一下信息，更换为前面的获取的token\n\n![image-20231130203425977](../img/Lsky-por/6568818d78139.png)\n\n### 验证能否自动上传\n\n打开typroa\n\n![image-20231130203326580](../img/Lsky-por/656881521a4d8.png)\n\n![image-20231130203516988](../img/Lsky-por/656881c07f24c.png)\n\n再去看看后台图库\n\n![image-20231130203549871](../img/Lsky-por/656881e175d77.png)\n\n至此项目成功\n\n<div class=\"tbsm\" style=\"margin-top:54px;\">\n<div class=\"tbsm-top\"><span><svg t=\"1674654360507\" class=\"icon\" viewBox=\"0 0 1024 1024\" version=\"1.1\" xmlns=\"http://www.w3.org/2000/svg\" p-id=\"987\" data-spm-anchor-id=\"a313x.7781069.0.i0\" width=\"35\" height=\"35\"><path d=\"M410.49 97.74H155.08a56.74 56.74 0 0 0-56.84 56.73V410a56.84 56.84 0 0 0 56.84 56.84h255.41A56.83 56.83 0 0 0 467.32 410V154.58a56.83 56.83 0 0 0-56.83-56.84zM410.49 558.74H155.08a56.74 56.74 0 0 0-56.84 56.73V871a56.84 56.84 0 0 0 56.84 56.84h255.41A56.83 56.83 0 0 0 467.32 871V615.58a56.83 56.83 0 0 0-56.83-56.84zM871.49 558.74H616.08a56.74 56.74 0 0 0-56.84 56.73V871a56.84 56.84 0 0 0 56.84 56.84h255.41A56.83 56.83 0 0 0 928.32 871V615.58a56.83 56.83 0 0 0-56.83-56.84z\" fill=\"#66EEFF\" p-id=\"988\"></path><path d=\"M410.49 558.74h-4.14A475 475 0 0 0 299.52 859.6a481.16 481.16 0 0 0 4.84 68.22h106.13A56.83 56.83 0 0 0 467.32 871V615.58a56.83 56.83 0 0 0-56.83-56.84zM871.49 558.74H616.08a56.74 56.74 0 0 0-56.84 56.73V871a56.84 56.84 0 0 0 56.84 56.84h255.41A56.83 56.83 0 0 0 928.32 871V615.58a56.83 56.83 0 0 0-56.83-56.84z\" fill=\"#C2F8FF\" p-id=\"989\"></path></svg></span><span style=\"font-size:30px;\"> 特别声明</span></div>\n<div class=\"tbsm-wz\">千屹博客旗下的所有文章，是通过本人课堂学习和课外自学所精心整理的知识巨著<br/>难免会有出错的地方<br/>如果细心的你发现了小失误，可以在下方评论区告诉我，或者私信我！<br />非常感谢大家的热烈支持！</div>\n</div>\n","tags":["Centos 8 stream","Lsky Pro"],"categories":["杂项"]},{"title":"基于K8S1.28.2实验rook部署ceph","url":"/posts/58032/","content":"\n<meta name=\"referrer\" content=\"no-referrer\"/>\n\n# 基于K8S1.28.2实验rook部署ceph\n\nRook 支持 Kubernetes **v1.22** 或更高版本。\n\nrook版本1.12.8\n\nK8S版本1.28.2\n\n部署出来ceph版本是quincy版本\n\n| 主机名  | ip1（NAT）     | 系统      | 新硬盘 | 磁盘 | 内存 |\n| ------- | -------------- | --------- | ------ | ---- | ---- |\n| master1 | 192.168.48.101 | Centos7.9 | 100G   | 100G | 4G   |\n| master2 | 192.168.48.102 | Centos7.9 |        | 100G | 4G   |\n| master3 | 192.168.48.103 | Centos7.9 |        | 100G | 4G   |\n| node01  | 192.168.48.104 | Centos7.9 | 100G   | 100G | 6G   |\n| node02  | 192.168.48.105 | Centos7.9 | 100G   | 100G | 6G   |\n\n我这里是五台机，本应该ceph（三节点）是需要部署在三台node上的，这里为了测试方便，<font color='red'>仅部署在master1，node01，node02上所以需要给这三台加一个物理硬盘</font>\n\n注意！使用之前，请确定是否去掉master节点的污点\n\n[【去污点方法】](https://blog.qianyios.top/posts/7158/#拿掉master节点的污点)\n\n<font color='red'>以下所有操作都在master进行</font>\n\n## 前期准备\n\n### 克隆仓库\n\n```\ngit clone --single-branch --branch v1.12.8 https://github.com/rook/rook.git\ncd rook/deploy/examples\n```\n\n### 查看所需镜像\n\n```\n[root@master1 examples]# cat operator.yaml | grep IMAGE:\n  # ROOK_CSI_CEPH_IMAGE: \"quay.io/cephcsi/cephcsi:v3.9.0\"\n  # ROOK_CSI_REGISTRAR_IMAGE: \"registry.k8s.io/sig-storage/csi-node-driver-registrar:v2.8.0\"\n  # ROOK_CSI_RESIZER_IMAGE: \"registry.k8s.io/sig-storage/csi-resizer:v1.8.0\"\n  # ROOK_CSI_PROVISIONER_IMAGE: \"registry.k8s.io/sig-storage/csi-provisioner:v3.5.0\"\n  # ROOK_CSI_SNAPSHOTTER_IMAGE: \"registry.k8s.io/sig-storage/csi-snapshotter:v6.2.2\"\n  # ROOK_CSI_ATTACHER_IMAGE: \"registry.k8s.io/sig-storage/csi-attacher:v4.3.0\"\n  # ROOK_CSIADDONS_IMAGE: \"quay.io/csiaddons/k8s-sidecar:v0.7.0\"\n  \n[root@master1 examples]# cat operator.yaml | grep image:\n          image: rook/ceph:v1.12.8\n```\n\n![image-20231119001814854](../img/rook部署ceph/e8d02f5e7e6cffb17ea83b39794b45b6697559838.png)\n\n![image-20231122001213717](../img/rook部署ceph/99bdb183c537ef879eb2ac4a6bc59914697559838.png)\n\n基本都是国外的镜像，在这里通过阿里云+github方式构建镜像仓库解决（以下是添加为自己私人构建的镜像）\n\n```yaml\nsed -i 's/# ROOK_CSI_CEPH_IMAGE: \"quay.io\\/cephcsi\\/cephcsi:v3.9.0\"/ROOK_CSI_CEPH_IMAGE: \"registry.cn-hangzhou.aliyuncs.com\\/qianyios\\/cephcsi:v3.9.0\"/g' operator.yaml\n\nsed -i 's/# ROOK_CSI_REGISTRAR_IMAGE: \"registry.k8s.io\\/sig-storage\\/csi-node-driver-registrar:v2.8.0\"/ROOK_CSI_REGISTRAR_IMAGE: \"registry.cn-hangzhou.aliyuncs.com\\/qianyios\\/csi-node-driver-registrar:v2.8.0\"/g' operator.yaml\n\nsed -i 's/# ROOK_CSI_RESIZER_IMAGE: \"registry.k8s.io\\/sig-storage\\/csi-resizer:v1.8.0\"/ROOK_CSI_RESIZER_IMAGE: \"registry.cn-hangzhou.aliyuncs.com\\/qianyios\\/csi-resizer:v1.8.0\"/g' operator.yaml\n\nsed -i 's/# ROOK_CSI_PROVISIONER_IMAGE: \"registry.k8s.io\\/sig-storage\\/csi-provisioner:v3.5.0\"/ROOK_CSI_PROVISIONER_IMAGE: \"registry.cn-hangzhou.aliyuncs.com\\/qianyios\\/csi-provisioner:v3.5.0\"/g' operator.yaml\n\nsed -i 's/# ROOK_CSI_SNAPSHOTTER_IMAGE: \"registry.k8s.io\\/sig-storage\\/csi-snapshotter:v6.2.2\"/ROOK_CSI_SNAPSHOTTER_IMAGE: \"registry.cn-hangzhou.aliyuncs.com\\/qianyios\\/csi-snapshotter:v6.2.2\"/g' operator.yaml\n\nsed -i 's/# ROOK_CSI_ATTACHER_IMAGE: \"registry.k8s.io\\/sig-storage\\/csi-attacher:v4.3.0\"/ROOK_CSI_ATTACHER_IMAGE: \"registry.cn-hangzhou.aliyuncs.com\\/qianyios\\/csi-attacher:v4.3.0\"/g' operator.yaml\n\nsed -i 's/# ROOK_CSIADDONS_IMAGE: \"quay.io\\/csiaddons\\/k8s-sidecar:v0.7.0\"/ROOK_CSIADDONS_IMAGE: \"registry.cn-hangzhou.aliyuncs.com\\/qianyios\\/k8s-sidecar:v0.7.0\"/g' operator.yaml\n\nsed -i 's/image: rook\\/ceph:v1.12.8/image: registry.cn-hangzhou.aliyuncs.com\\/qianyios\\/ceph:v1.12.8/g' operator.yaml\n\n```\n\n开启自动发现磁盘（用于后期扩展）\n\n```\nsed -i 's/ROOK_ENABLE_DISCOVERY_DAEMON: \"false\"/ROOK_ENABLE_DISCOVERY_DAEMON: \"true\"/' /root/rook/deploy/examples/operator.yaml\n```\n\n建议提前下载镜像\n\n```\ndocker pull registry.cn-hangzhou.aliyuncs.com/qianyios/cephcsi:v3.9.0\ndocker pull registry.cn-hangzhou.aliyuncs.com/qianyios/csi-node-driver-registrar:v2.8.0\ndocker pull registry.cn-hangzhou.aliyuncs.com/qianyios/csi-resizer:v1.8.0\ndocker pull registry.cn-hangzhou.aliyuncs.com/qianyios/csi-provisioner:v3.5.0\ndocker pull registry.cn-hangzhou.aliyuncs.com/qianyios/csi-snapshotter:v6.2.2\ndocker pull registry.cn-hangzhou.aliyuncs.com/qianyios/csi-attacher:v4.3.0\ndocker pull registry.cn-hangzhou.aliyuncs.com/qianyios/k8s-sidecar:v0.7.0\ndocker pull registry.cn-hangzhou.aliyuncs.com/qianyios/ceph:v1.12.8\n```\n\n## 安装rook+ceph集群\n\n### 开始部署\n\n1. 创建crd&common&operator\n\n```\nkubectl create -f crds.yaml -f common.yaml -f operator.yaml\n```\n\n![image-20231119182815198](../img/rook部署ceph/4482ea21f7f87a432695f6fcd5e48880697559838.png)\n\n2. 创建cluster（ceph）\n\n<font color='red'>修改配置：</font>等待operator容器和discover容器<font color='red'>启动</font>，配置osd节点\n\n先注意一下自己的磁盘（lsblk）根据自身情况修改下面的配置文件\n\n![image-20231119011441790](../img/rook部署ceph/c9ffdcc25e86bb74b11a58deed32eccf697559838.png)\n\n```\n#更改为国内镜像\nsed -i 's#image: quay.io/ceph/ceph:v17.2.6#image: registry.cn-hangzhou.aliyuncs.com/qianyios/ceph:v17.2.6#' cluster.yaml\n```\n\n```yaml\nvim cluster.yaml\n-------------------------------------\n \n- 修改镜像\n    image: registry.cn-hangzhou.aliyuncs.com/qianyios/ceph:v17.2.6\n \n- 改为false，并非使用所有节点所有磁盘作为osd\n- 启用deviceFilter\n- 按需配置config\n- 会自动跳过非裸盘\n  storage: # cluster level storage configuration and selection\n    useAllNodes: false\n    useAllDevices: false\n    deviceFilter:\n    config:\n    nodes:\n      - name: \"master1\"\n        deviceFilter: \"sda\"\n      - name: \"node01\"\n        deviceFilter: \"sda\"\n      - name: \"node02\"\n        deviceFilter: \"^sd.\"  #自动匹配sd开头的裸盘\n```\n\n这里的三个节点，是我们开头讲到的三台机，自行根据修改调整，注意这里的名字是k8s集群的名字可以在<font color='red'>kubectl get nodes</font>查看\n\n![image-20231119011622231](../img/rook部署ceph/8defa12ca29d58735dd919b3cd62897f697559838.png)\n\n![image-20231119011844526](../img/rook部署ceph/1f4a6c053724354ce60c86d5c5233631697559838.png)\n\n部署cluster\n\n```\nkubectl create -f cluster.yaml\n```\n\n### 查看状态\n\n```\n- 实时查看pod创建进度\nkubectl get pod -n rook-ceph -w\n \n- 实时查看集群创建进度\nkubectl get cephcluster -n rook-ceph rook-ceph -w\n \n- 详细描述\nkubectl describe cephcluster -n rook-ceph rook-ceph\n```\n\n![image-20231119184740824](../img/rook部署ceph/a8a6ca303cfdcd6afe66ac9cbf0157fd697559838.png)\n\n安装ceph客户端工具\n\n```\n- 进入工作目录\ncd rook/deploy/examples/\n\n- 查看所需镜像\n[root@master1 examples]# cat toolbox.yaml | grep image:\n          image: quay.io/ceph/ceph:v17.2.6\n- 更改为国内镜像\n\nsed -i 's#image: quay.io/ceph/ceph:v17.2.6#image: registry.cn-hangzhou.aliyuncs.com/qianyios/ceph:v17.2.6#' toolbox.yaml\n\n- 创建toolbox\nkubectl  create -f toolbox.yaml -n rook-ceph\n \n- 查看pod\nkubectl  get pod -n rook-ceph -l app=rook-ceph-tools\n \n- 进入pod\nkubectl -n rook-ceph exec -it deploy/rook-ceph-tools -- bash\n \n- 查看集群状态\nceph status\n \n- 查看osd状态\nceph osd status\n \n- 集群空间用量\nceph df\n```\n\n![image-20231119185510701](../img/rook部署ceph/db949d4f6d00b47903b66498f1e892a4697559838.png)\n\n![image-20231119185604869](../img/rook部署ceph/2c7745862a1dd2c9ef38fd73af0e9e9d697559838.png)\n\n### 暴露dashboard\n\n```\ncat > rook-dashboard.yaml << EOF\n\n---\napiVersion: v1\nkind: Service\nmetadata:\n  labels:\n    app: rook-ceph-mgr\n    ceph_daemon_id: a\n    rook_cluster: rook-ceph\n  name: rook-ceph-mgr-dashboard-np\n  namespace: rook-ceph\nspec:\n  ports:\n  - name: http-dashboard\n    port: 8443\n    protocol: TCP\n    targetPort: 8443\n    nodePort: 30700\n  selector:\n    app: rook-ceph-mgr\n    ceph_daemon_id: a\n  sessionAffinity: None\n  type: NodePort\nEOF\n\nkubectl apply -f rook-dashboard.yaml\n```\n\n查看dashboard密码\n\n```\nkubectl -n rook-ceph get secret rook-ceph-dashboard-password -o jsonpath=\"{['data']['password']}\" | base64 --decode && echo\n\nQmu/!$ZvfQTAd-aCuHF+\n```\n\n访问dashboard\n\n```\nhttps://192.168.48.200:30700\n```\n\n![image-20231119194020314](../img/rook部署ceph/970359409249d0b62859dc76b67e5a05697559838.png)\n\n如果出现以下报错（可以按下面解决，反之跳过）\n\n消除HEALTH_WARN警告\n\n- 查看警告详情\n  - AUTH_INSECURE_GLOBAL_ID_RECLAIM_ALLOWED: mons are allowing insecure global_id reclaim\n  - MON_DISK_LOW: mons a,b,c are low on available space\n\n![image-20210621191403196](../img/rook%E9%83%A8%E7%BD%B2ceph/f363d6115f47d3be9b65b691e8676c62.png)\n\n> 官方解决方案：https://docs.ceph.com/en/latest/rados/operations/health-checks/\n\n- AUTH_INSECURE_GLOBAL_ID_RECLAIM_ALLOWED\n\n```yaml\n方法一：\n- 进入toolbox\n\nkubectl -n rook-ceph exec -it deploy/rook-ceph-tools -- bash\n\nceph config set mon auth_allow_insecure_global_id_reclaim false\n\n方法二：\nkubectl get configmap rook-config-override -n rook-ceph -o yaml\nkubectl edit configmap rook-config-override -n rook-ceph -o yaml\n\n\nconfig: |\n    [global]\n    mon clock drift allowed = 1\n    \n#删除pod\nkubectl -n rook-ceph delete pod $(kubectl -n rook-ceph get pods -o custom-columns=NAME:.metadata.name --no-headers| grep mon)\n#显示一下信息\npod \"rook-ceph-mon-a-557d88c-6ksmg\" deleted\npod \"rook-ceph-mon-b-748dcc9b89-j8l24\" deleted\npod \"rook-ceph-mon-c-5d47c664-p855m\" deleted\n#最后查看健康值\nceph -s\n```\n\n![image-20231203203949171](../img/rook%E9%83%A8%E7%BD%B2ceph/a1e3b048a1ff9259316edb8f3b7a7df9697559838.png)\n\n- MON_DISK_LOW：根分区使用率过高，清理即可。\n\n![image-20210621195325516](../img/rook%E9%83%A8%E7%BD%B2ceph/261190930bee367b1a07ee81a311b3e2.png)\n\n## Ceph存储使用\n\n### 三种存储类型\n\n| 存储类型           | 特征                                                         | 应用场景          | 典型设备  |\n| :----------------- | :----------------------------------------------------------- | :---------------- | :-------- |\n| 块存储（RBD）      | 存储速度较快 不支持共享存储 [**ReadWriteOnce**]              | 虚拟机硬盘        | 硬盘 Raid |\n| 文件存储（CephFS） | 存储速度慢（需经操作系统处理再转为块存储） 支持共享存储 [**ReadWriteMany**] | 文件共享          | FTP NFS   |\n| 对象存储（Object） | 具备块存储的读写性能和文件存储的共享特性 操作系统不能直接访问，只能通过应用程序级别的API访问 | 图片存储 视频存储 | OSS       |\n\n### 块存储\n\n#### 创建CephBlockPool和StorageClass\n\n- 文件路径：`/root/rook/deploy/examples/csi/rbd/storageclass.yaml`\n- CephBlockPool和StorageClass都位于storageclass.yaml 文件\n- 配置文件简要解读：\n\n```\ncd /root/rook/deploy/examples/csi/rbd\n[root@master1 rbd]# grep -vE '^\\s*(#|$)' storageclass.yaml\napiVersion: ceph.rook.io/v1\nkind: CephBlockPool\nmetadata:\n  name: replicapool\n  namespace: rook-ceph # namespace:cluster\nspec:\n  failureDomain: host              # host级容灾\n  replicated:\n    size: 3                              # 默认三个副本\n    requireSafeReplicaSize: true\n---\napiVersion: storage.k8s.io/v1\nkind: StorageClass                 # sc无需指定命名空间\nmetadata:\n  name: rook-ceph-block\nprovisioner: rook-ceph.rbd.csi.ceph.com    # 存储驱动\nparameters:\n  clusterID: rook-ceph # namespace:cluster\n  pool: replicapool                  # 关联到CephBlockPool\n  imageFormat: \"2\"\n  imageFeatures: layering\n  csi.storage.k8s.io/provisioner-secret-name: rook-csi-rbd-provisioner\n  csi.storage.k8s.io/provisioner-secret-namespace: rook-ceph # namespace:cluster\n  csi.storage.k8s.io/controller-expand-secret-name: rook-csi-rbd-provisioner\n  csi.storage.k8s.io/controller-expand-secret-namespace: rook-ceph # namespace:cluster\n  csi.storage.k8s.io/node-stage-secret-name: rook-csi-rbd-node\n  csi.storage.k8s.io/node-stage-secret-namespace: rook-ceph # namespace:cluster\n  csi.storage.k8s.io/fstype: ext4\nallowVolumeExpansion: true                          # 是否允许扩容\nreclaimPolicy: Delete                                    # PV回收策略\n[root@master1 rbd]#\n\n```\n\n创建CephBlockPool和StorageClass\n\n```\nkubectl create -f storageclass.yaml\n```\n\n查看\n\n```\n- 查看sc\nkubectl get sc\n \n- 查看CephBlockPool（也可在dashboard中查看）\nkubectl get cephblockpools -n rook-ceph\n```\n\n![image-20231119195332077](../img/rook部署ceph/8eb33944dd86046d203aefd8da82cf26697559838.png)\n\n![image-20231119195400264](../img/rook部署ceph/cd95d62d7f3131ac890383048257ed3c697559838.png)\n\n#### 块存储使用示例\n\n- **Deployment**单副本+**PersistentVolumeClaim**\n\n```yaml\ncat > nginx-deploy-rbd.yaml << \"EOF\"\n\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    app: nginx-deploy-rbd\n  name: nginx-deploy-rbd\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: nginx-deploy-rbd\n  template:\n    metadata:\n      labels:\n        app: nginx-deploy-rbd\n    spec:\n      containers:\n      - image: registry.cn-hangzhou.aliyuncs.com/qianyios/nginx:latest\n        name: nginx\n        volumeMounts:\n        - name: data\n          mountPath: /usr/share/nginx/html\n      volumes:\n      - name: data\n        persistentVolumeClaim:\n          claimName: nginx-rbd-pvc\n\n---\napiVersion: v1\nkind: PersistentVolumeClaim\nmetadata:\n  name: nginx-rbd-pvc\nspec:\n  storageClassName: \"rook-ceph-block\"   #就是这里指定了前面的创建的sc\n  accessModes:\n    - ReadWriteOnce\n  resources:\n    requests:\n      storage: 5Gi\n\nEOF\n```\n\n```\nkubectl create -f nginx-deploy-rbd.yaml\nkubectl exec -it nginx-deploy-rbd-7886bf6666-qhw74 bash\necho \"hello,nginx-deploy-rbd\" > /usr/share/nginx/html/index.html\nexit\n\nkubectl get pod -o wide | grep nginx\n\n#测试完就删除\nkubectl delete -f nginx-deploy-rbd.yaml\n```\n\n![image-20231119203414038](../img/rook部署ceph/78427bca0ed2e464f619a1d20b9bca9d697559838.png)\n\n![image-20231119203735080](../img/rook部署ceph/47d21207397036100c7d1e4969615e7b697559838.png)\n\n![image-20231119203755919](../img/rook部署ceph/cf68495385eb2de397cda2f6c851f1d4697559838.png)\n\n- **StatefulSet**多副本+**volumeClaimTemplates**\n\n```yaml\ncat > nginx-ss-rbd.yaml << \"EOF\"\n \napiVersion: apps/v1\nkind: StatefulSet\nmetadata:\n  name: nginx-ss-rbd\nspec:\n  selector:\n    matchLabels:\n      app: nginx-ss-rbd \n  serviceName: \"nginx\"\n  replicas: 3 \n  template:\n    metadata:\n      labels:\n        app: nginx-ss-rbd \n    spec:\n      containers:\n      - name: nginx\n        image: registry.cn-hangzhou.aliyuncs.com/qianyios/nginx:latest\n        ports:\n        - containerPort: 80\n          name: web\n        volumeMounts:\n        - name: www\n          mountPath: /usr/share/nginx/html\n  volumeClaimTemplates:\n  - metadata:\n      name: www\n    spec:\n      accessModes: [ \"ReadWriteOnce\" ]\n      storageClassName: \"rook-ceph-block\"  #就是这里指定了前面的创建的sc\n      resources:\n        requests:\n          storage: 2Gi\nEOF\n```\n\n部署\n\n```\nkubectl create -f nginx-ss-rbd.yaml\n\nkubectl get pod -o wide | grep nginx-ss\n\nkubectl exec -it nginx-ss-rbd-0 bash\necho \"hello,nginx-ss-rbd-0\" > /usr/share/nginx/html/index.html && exit\n\nkubectl exec -it nginx-ss-rbd-1 bash\necho \"hello,nginx-ss-rbd-1\" > /usr/share/nginx/html/index.html && exit\n\nkubectl exec -it nginx-ss-rbd-2 bash\necho \"hello,nginx-ss-rbd-2\" > /usr/share/nginx/html/index.html && exit\n\n#测试完就删除\nkubectl delete -f nginx-ss-rbd.yaml\n\n这里可能需要手动删除一下pvc\n[root@master1 ~]# kubectl get pvc\nNAME                 STATUS   VOLUME                                     CAPACITY   ACCESS MODES   STORAGECLASS      AGE\nwww-nginx-ss-rbd-0   Bound    pvc-4a75f201-eec0-47fa-990c-353c52fe14f4   2Gi        RWO            rook-ceph-block   6m27s\nwww-nginx-ss-rbd-1   Bound    pvc-d5f7e29f-79e4-4d1e-bcbb-65ece15a8172   2Gi        RWO            rook-ceph-block   6m21s\nwww-nginx-ss-rbd-2   Bound    pvc-8cce06e9-dfe4-429d-ae44-878f8e4665e0   2Gi        RWO            rook-ceph-block   5m53s\n[root@master1 ~]# kubectl delete  pvc www-nginx-ss-rbd-0\npersistentvolumeclaim \"www-nginx-ss-rbd-0\" deleted\n[root@master1 ~]# kubectl delete  pvc www-nginx-ss-rbd-1\npersistentvolumeclaim \"www-nginx-ss-rbd-1\" deleted\n[root@master1 ~]# kubectl delete  pvc www-nginx-ss-rbd-2\npersistentvolumeclaim \"www-nginx-ss-rbd-2\" deleted\n\n```\n\n![image-20231119204319948](../img/rook部署ceph/491fde79a9bd682388bda9159e9f7053697559838.png)\n\n![image-20231119204602188](../img/rook部署ceph/4fcb24bea5788cb9245410d95ec051ce697559838.png)\n\n### 共享文件存储\n\n#### 部署MDS服务\n\n创建Cephfs文件系统需要先部署MDS服务，该服务负责处理文件系统中的元数据。\n\n- 文件路径：`/root/rook/deploy/examples/filesystem.yaml`\n\n配置文件解读\n\n```\ncd /root/rook/deploy/examples\n[root@master1 examples]# grep -vE '^\\s*(#|$)' filesystem.yaml\napiVersion: ceph.rook.io/v1\nkind: CephFilesystem\nmetadata:\n  name: myfs\n  namespace: rook-ceph # namespace:cluster\nspec:\n  metadataPool:\n    replicated:\n      size: 3            # 元数据副本数\n      requireSafeReplicaSize: true\n    parameters:\n      compression_mode:\n        none\n  dataPools:\n    - name: replicated\n      failureDomain: host\n      replicated:\n        size: 3             # 存储数据的副本数\n        requireSafeReplicaSize: true\n      parameters:\n        compression_mode:\n          none\n  preserveFilesystemOnDelete: true\n  metadataServer:\n    activeCount: 1        # MDS实例的副本数，默认1，生产环境建议设置为3\n    activeStandby: true\n  ......省略\n\nkubectl create -f filesystem.yaml\nkubectl get pod -n rook-ceph | grep mds\n```\n\n![image-20231119210143026](../img/rook部署ceph/380a84c6e412e69d84beba5b6b7e47f3697559838.png)\n\n```\n- 进入pod\nkubectl -n rook-ceph exec -it deploy/rook-ceph-tools -- bash\n \n- 查看集群状态\nceph status\n```\n\n![image-20231119210339096](../img/rook部署ceph/5b4dd656122e2b64787fb30b8a20a97c697559838.png)\n\n#### 配置存储(StorageClass)\n\n配置文件：`/root/rook/deploy/examples/csi/cephfs/storageclass.yaml`\n\n```\ncd /root/rook/deploy/examples/csi/cephfs\nkubectl apply -f storageclass.yaml\n```\n\n![image-20231119210625832](../img/rook部署ceph/19ede1d5988df074b7b8bd884ce5feb1697559838.png)\n\n#### 共享文件存储使用示例\n\n```\ncat > nginx-deploy-cephfs.yaml << \"EOF\"\n \napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    app: nginx-deploy-cephfs\n  name: nginx-deploy-cephfs\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: nginx-deploy-cephfs\n  template:\n    metadata:\n      labels:\n        app: nginx-deploy-cephfs\n    spec:\n      containers:\n      - image: registry.cn-hangzhou.aliyuncs.com/qianyios/nginx:latest\n        name: nginx\n        volumeMounts:\n        - name: data\n          mountPath: /usr/share/nginx/html\n      volumes:\n      - name: data\n        persistentVolumeClaim:\n          claimName: nginx-cephfs-pvc\n---\napiVersion: v1\nkind: PersistentVolumeClaim\nmetadata:\n  name: nginx-cephfs-pvc\nspec:\n  storageClassName: \"rook-cephfs\"\n  accessModes:\n    - ReadWriteMany\n  resources:\n    requests:\n      storage: 1Gi\nEOF\nkubectl apply -f nginx-deploy-cephfs.yaml\nkubectl get pod -o wide | grep cephfs\nkubectl exec -it nginx-deploy-cephfs-6dc8797866-4s564 bash\necho \"hello cephfs\" > /usr/share/nginx/html/index.html && exit\n\n#测试完删除 \nkubectl delete -f nginx-deploy-cephfs.yaml\n```\n\n![image-20231119215220294](../img/rook部署ceph/a6ab12847a41e35c1564805a5246d9af697559838.png)\n\n## 在K8S中直接调用出ceph命令\n\n```\n#安装epel源\nyum install epel-release -y\n\n#安装ceph仓库\nyum install https://mirrors.aliyun.com/ceph/rpm-octopus/el7/noarch/ceph-release-1-1.el7.noarch.rpm -y\nyum list ceph-common  --showduplicates |sort -r\n\n#安装ceph客户端\nyum install ceph-common -y\n```\n\n同步ceph中的认证文件\n\n```\nkubectl -n rook-ceph exec -it deploy/rook-ceph-tools -- bash\n\n[root@master1 ~]# kubectl -n rook-ceph exec -it deploy/rook-ceph-tools -- bash\n\nbash-4.4$  cat /etc/ceph/ceph.conf\n[global]\nmon_host = 10.97.121.57:6789,10.104.235.210:6789,10.96.136.90:6789\n\n[client.admin]\nkeyring = /etc/ceph/keyring\n\nbash-4.4$ cat /etc/ceph/keyring\n[client.admin]\nkey = AQC241lltDbVKBAANrzwgqZd1A2eY+8h1A+BOg==\nbash-4.4$\n\n\n注意这两个文件，复制内容之后exit退出\n\n```\n\n![image-20231119221441175](../img/rook部署ceph/226133fd1f73556b78ec0135527d2750697559838.png)\n\n```\n\n直接在master1创建这两个文件（这里的master1是指我要在master1可以调用ceph的客户端）\n\ncat > /etc/ceph/ceph.conf << \"EOF\"\n[global]\nmon_host = 10.97.121.57:6789,10.104.235.210:6789,10.96.136.90:6789\n\n[client.admin]\nkeyring = /etc/ceph/keyring\nEOF\n\ncat > /etc/ceph/keyring << \"EOF\"\n[client.admin]\nkey = AQC241lltDbVKBAANrzwgqZd1A2eY+8h1A+BOg==\nEOF\n```\n\n当你添加完之后直接调用ceph的命令\n\n![image-20231119221546943](../img/rook部署ceph/697b4f16bd1e1a5d7ec359d02c91ff73697559838.png)\n\n## 删除pvc，sc及对应的存储资源\n\n```\n- 按需删除pvc、pv\nkubectl get pvc -n [namespace] | awk '{print $1};' | xargs kubectl delete pvc -n [namespace]\nkubectl get pv | grep Released | awk '{print $1};' | xargs kubectl delete pv\n \n- 删除块存储及SC\nkubectl delete -n rook-ceph cephblockpool replicapool\nkubectl delete storageclass rook-ceph-block\n\n```\n\n<div class=\"tbsm\" style=\"margin-top:54px;\">\n<div class=\"tbsm-top\"><span><svg t=\"1674654360507\" class=\"icon\" viewBox=\"0 0 1024 1024\" version=\"1.1\" xmlns=\"http://www.w3.org/2000/svg\" p-id=\"987\" data-spm-anchor-id=\"a313x.7781069.0.i0\" width=\"35\" height=\"35\"><path d=\"M410.49 97.74H155.08a56.74 56.74 0 0 0-56.84 56.73V410a56.84 56.84 0 0 0 56.84 56.84h255.41A56.83 56.83 0 0 0 467.32 410V154.58a56.83 56.83 0 0 0-56.83-56.84zM410.49 558.74H155.08a56.74 56.74 0 0 0-56.84 56.73V871a56.84 56.84 0 0 0 56.84 56.84h255.41A56.83 56.83 0 0 0 467.32 871V615.58a56.83 56.83 0 0 0-56.83-56.84zM871.49 558.74H616.08a56.74 56.74 0 0 0-56.84 56.73V871a56.84 56.84 0 0 0 56.84 56.84h255.41A56.83 56.83 0 0 0 928.32 871V615.58a56.83 56.83 0 0 0-56.83-56.84z\" fill=\"#66EEFF\" p-id=\"988\"></path><path d=\"M410.49 558.74h-4.14A475 475 0 0 0 299.52 859.6a481.16 481.16 0 0 0 4.84 68.22h106.13A56.83 56.83 0 0 0 467.32 871V615.58a56.83 56.83 0 0 0-56.83-56.84zM871.49 558.74H616.08a56.74 56.74 0 0 0-56.84 56.73V871a56.84 56.84 0 0 0 56.84 56.84h255.41A56.83 56.83 0 0 0 928.32 871V615.58a56.83 56.83 0 0 0-56.83-56.84z\" fill=\"#C2F8FF\" p-id=\"989\"></path></svg></span><span style=\"font-size:30px;\"> 特别声明</span></div>\n<div class=\"tbsm-wz\">千屹博客旗下的所有文章，是通过本人课堂学习和课外自学所精心整理的知识巨著<br/>难免会有出错的地方<br/>如果细心的你发现了小失误，可以在下方评论区告诉我，或者私信我！<br />非常感谢大家的热烈支持！</div>\n</div>\n","tags":["Ceph","K8s"],"categories":["云原生"]},{"title":"Python-总手册","url":"/posts/28626/","content":"\n<meta name=\"referrer\" content=\"no-referrer\"/>\n\n# Python-总手册\n\n1. [Python环境准备](#Python环境准备)\n2. [Python程序手册](#Python程序手册)\n\n# Python环境准备\n\n## Thonny（首推，自用！！）\n\nThonny 由爱沙尼亚的 Tartu 大学开发，它采用了不同的方法，因为它的调试器是专为学习和教学编程而设计的。\n\n该软件基于python内置图形库tkinter开发，体积小巧，界面直观，支持语法着色、代码自动补全、debug等强劲功能，并具备了一个友好的IDE，为您提供了几个有用的学习工具，所有这些都打包成一个直观的GUI，能够让你更快的熟悉Python编程语言。同时，thonny内置了Python3.7，因此只需要一个简单的安装程序，您就可以学习编程了，可谓称的上是最好的自助服务教学工具。\n\n官网地址：[Thonny，Python IDE初学者](https://thonny.org/)\n\n### 进入官网下载\n\n![image-20230911213459655](../img/Python-%E6%80%BB%E6%89%8B%E5%86%8C.assets/c8099719e962a1986f0b3477afea6fcfbfe04452-1726156094788-20.png)\n\n\n\n![image-20230911213655489](../img/Python-%E6%80%BB%E6%89%8B%E5%86%8C.assets/6759a1f4d67e3298d0c193e35a60fd204188bfd8-1726156094788-21.png)\n\n\n\n### 双击运行\n\n![image-20230911213731514](../img/Python-%E6%80%BB%E6%89%8B%E5%86%8C.assets/3693e61e00196c4b1793c6da94c58e8e8bfc6455-1726156094788-22.png)\n\n![image-20230911213742866](../img/Python-%E6%80%BB%E6%89%8B%E5%86%8C.assets/e80b8f094dcc85c7166f4501bbf7b800a7000005-1726156094788-23.png)\n\n### 接受安装协议，安装\n\n<font color='red'>请选择一个不带中文的路径存放他</font>\n\n这里的c盘仅做测试\n\n![image-20230911213952417](../img/Python-%E6%80%BB%E6%89%8B%E5%86%8C.assets/7c8b64d86fb9a2e895589168f52b199b46313408-1726156094788-24.png)\n\n### 创建桌面图标\n\n![image-20230911213946121](../img/Python-%E6%80%BB%E6%89%8B%E5%86%8C.assets/a5c15b9f02c7fefbe07ffc0d9209be056fd79212-1726156094788-25.png)\n\n### 选择中文\n\n![image-20230911214016041](../img/Python-%E6%80%BB%E6%89%8B%E5%86%8C.assets/ec46eaeb9444c467ebd7bd2c720a25927d4d8ea4-1726156094788-26.png)\n\n### 安装成功\n\n![image-20230911214038572](../img/Python-%E6%80%BB%E6%89%8B%E5%86%8C.assets/ccf69f4daeb9b05d21cd0bd9af7648651c37daf3-1726156094788-27.png)\n\n\n\n## Centos7部署Python\n\n在 CentOS 7.9 上安装 Python，你可以使用 yum 包管理器和 EPEL 存储库来完成。以下是安装的步骤：\n\n1. 首先，确保你的系统已经安装了 EPEL 存储库。EPEL 是一个额外的软件源，提供了许多额外的软件包。如果你的系统尚未安装 EPEL 存储库，可以使用以下命令安装它：\n\n```\nsudo yum update -y\nsudo yum install epel-release\n```\n\n<font color='red'>自选版本</font>\n\n2. 安装 Python 3：CentOS 7 默认使用 Python 2.7，但是你可以安装 Python 3。使用以下命令安装 Python 3：\n\n```\nsudo yum install python3\n```\n\n3. 安装 Python 2：如果你还需要安装 Python 2，可以使用以下命令安装：\n\n```\nsudo yum install python2\n```\n\n4. 验证安装：安装完成后，你可以使用以下命令验证 Python 的安装：\n\n```\npython3 --version\npython2 --version\n```\n\n这些命令将显示安装的 Python 版本号，确认安装成功。\n\n### 使用python\n\n```\npython\n```\n\n## Pycham\n\n安装教程：[PyCharm2024.1安装教程 - 严千屹博客 (qianyios.top)](https://blog.qianyios.top/posts/cf6ce79f/)\n\n官网地址[PyCharm：JetBrains为专业开发者提供的Python IDE](https://www.jetbrains.com/zh-cn/pycharm/)\n\n\n\n# Python程序手册\n\n## Python程序基础\n\n### 初识Python程序\n\n新建一个hello.py\n\n![image-20230911221032751](../img/Python-%E6%80%BB%E6%89%8B%E5%86%8C.assets/be107876f089bb105714edeb908e55abfcda36e7-1726156094788-28.png)→![image-20230911221044375](../img/Python-%E6%80%BB%E6%89%8B%E5%86%8C.assets/23da562133d5d5abda87fe9795d3c3ea1df500d9-1726156094789-29.png) \n\n打开输入代码→运行\n\n![image-20230911220949326](../img/Python-%E6%80%BB%E6%89%8B%E5%86%8C.assets/f0141934281be1baa7c85c7518c754bd7c169225-1726156094789-30.png)\n\n```\n#格式\nprint(输出项1,输出项2,······)\n```\n\n每个输出项可以是数值，字符串等\n\n### Python程序风格\n\n一个程序往往有输入输出语句，还带有逻辑判断，现在介绍一个程序\n\n例2.1 输入一个数，计算平方根\n\n```\nimport math\ns=input(\"请输入一个数：\")\ns=float(s)\nif s>=0:\n    s=math.sqrt(s)\n    print(\"平方根是：\",s)\nelse:\n    print(\"负数不是平方根\")\nprint(\"The End\")\n```\n\n在这可以很清晰看到python程序的风格，不会像c语言，需要先声明变量类型，才可以使用\n\n如：\n\nc语言：(可以看见没行语句，需要一个<font color='red'>分号</font>)\n\n```\nint s\nprintf(\"请输入一个数:\");\nscanf(\"%d\",&s);\n```\n\n> <font color='red'>在这显得python更加简单快捷</font>\n\n![image-20230911222208194](../img/Python-%E6%80%BB%E6%89%8B%E5%86%8C.assets/3517eb301ba0893c47a45d706a69832457a8fb91-1726156094789-31.png)\n\n#### 开始分解\n\n1. 输入语句\n\n```\ns=input(\"请输入一个数：\")\n```\n\n此时输入4之后，会存入到s，<font color='red'>但是此时的s是个字符串，还不是数值，不能进行计算，需要转换类型</font>\n\n2. 转化类型\n\n```\ns=float(s)\n```\n\n在这，需要将s（字符串）转化为实数，才可以计算\n\n3. 缩进\n\n要注意缩进量，否则代码会串行\n\n![image-20230911223018053](../img/Python-%E6%80%BB%E6%89%8B%E5%86%8C.assets/19d939fc05daa6e3edbc5d6daacfe2655649fb3a-1726156094789-32.png)\n\n<font color='red'>如：</font>\n\n<font color='red'>错误代码：</font>\n\n![image-20230911223124209](../img/Python-%E6%80%BB%E6%89%8B%E5%86%8C.assets/774e6e9ba7c39b3e91bbf630cd75ecd8ff4b53ac-1726156094789-33.png)\n\n正确显示结果：\n\n![image-20230911223204576](../img/Python-%E6%80%BB%E6%89%8B%E5%86%8C.assets/c7d90cc45856724a926dec270e52bfb0b71df666-1726156094789-34.png)\n\n通过之前修改代码变成else的语句之后，就没显示了，\n\n![image-20230911223230379](../img/Python-%E6%80%BB%E6%89%8B%E5%86%8C.assets/a2ba8b96b8ba4a661030846962909c1f29633d26-1726156094789-35.png)\n\n必须输入负数之后才显示出来\n\n![image-20230911223314908](../img/Python-%E6%80%BB%E6%89%8B%E5%86%8C.assets/647fd0495ae122968576879b645ed79277f45d22-1726156094789-36.png)\n\n所以要注意缩进量\n\n### Python注释\n\n在 Python 中，注释用于在代码中添加解释、说明或提供文档。Python 支持两种类型的注释：单行注释和多行注释。\n\n1. 单行注释：以 `#` 开头，用于在一行中添加注释。\n\n```python\n# 这是一个单行注释\n```\n\n2. 多行注释：用三个单引号 `'''` 或三个双引号 `\"\"\"` 包围的多行文本，用于添加多行注释。\n\n```python\n'''\n这是一个多行注释。\n可以在这里添加多行的说明。\n'''\n```\n\n或者\n\n```python\n\"\"\"\n这是一个多行注释。\n可以在这里添加多行的说明。\n\"\"\"\n```\n\n注释是非常有用的工具，可以提高代码的可读性和可维护性。它们可以用于解释代码的目的、算法、参数、返回值等信息，使其他人更容易理解和使用你的代码。\n\n请注意，注释不会被 Python 解释器执行，它们只是用于代码的解释和文档目的。在运行程序时，注释部分会被忽略。\n\n### Python数据类型\n\n#### 数据类型\n\n##### 常量：\n\nPython 中有许多内置的数据类型，用于存储和操作不同类型的数据。下面是 Python 的一些常见数据类型：\n\n1. 整数（int）：用于表示整数值，例如 `42`、`-10`、`0` 等。\n2. 浮点数（float）：用于表示带有小数部分的数值，例如 `3.14`、`-0.5` 等。\n3. 字符串（str）：用于表示文本数据，由一系列字符组成，例如 `\"Hello, World!\"`、`'Python'` 等。\n4. 列表（list）：用于存储多个有序的元素，可以包含不同类型的数据，例如 `[1, 2, 3]`、`['apple', 'banana', 'cherry']` 等。\n\n##### 变量：\n\n1. 变量命名规则：\n\n- 变量名由字母、数字和下划线组成。\n- 变量名必须以字母或下划线开头，不能以<font color='red'>数字</font>开头。\n- 变量名区分大小写，例如 `count` 和 `Count` 是不同的变量名。\n- 避免使用 Python 的关键字（如 `if`、`for`、`while` 等）作为变量名。\n- 建议使用有意义的变量名，以提高代码的可读性。\n\n2. 变量赋值：\n\n- 使用赋值运算符 `=` 将一个值赋给一个变量。\n- 变量在首次赋值时被创建，并根据赋值的值确定其数据类型。\n- 可以将不同类型的数据赋给同一个变量，变量的类型会随着赋值而改变。\n\n```python\nx = 42  # 整数\ny = 3.14  # 浮点数\nname = \"Alice\"  # 字符串\n```\n\n3. 变量使用：\n\n- 可以使用变量名来访问存储在变量中的值。\n- 可以在表达式中使用变量，并对其进行操作。\n- 变量的值可以随时改变，可以重新赋值给同一个变量。\n\n```python\nx = 10\ny = x + 5\nprint(y)  # 输出：15\n\nx = 20\nprint(x)  # 输出：20\n```\n\n变量在 Python 中是一种非常重要的概念，它们允许我们存储和操作数据。通过合理使用变量，可以使代码更灵活、可读性更好，并且可以减少重复代码。\n\n#### 数据类型的转换\n\n1.数值转换字符串\n\n```\na=1\nb=1.2\nx=str(a)\ny=str(b)\n#此时，要是输出，他们在系统中是带引号的字符串\n#  \"1\",\"1.2\"\n```\n\n2.字符串转换数值\n\n```\na=\"1\"\nb=\"1.2\"\nx=int(a)\ny=float(b)  #实数（带小数）\n#此时，要是输出，他们在系统中是数值\n#  1,1.2\n```\n\n<font color='red'>错误形态：</font>\n\n```\ns=\"1a\"\na=int(s)\n```\n\n在这种情况下，字符串 `\"1a\"` 包含了字母 `\"a\"`，因此无法将其转换为整数。如果你想要将一个合法的整数字符串转换为整数，确保字符串只包含数字字符。\n\n#### 整数格式化输出\n\n1. 使用 `format()` 方法格式化输出整数的示例：\n\n```python\nx = 10\ny = 20\nprint(\"x: {}, y: {}\".format(x, y))\n```\n\n输出结果为：\n\n```\nx: 10, y: 20\n```\n\n在这个示例中，我们使用了 `\"x: {}, y: {}\"` 这个字符串作为格式化模板。在模板中的 `{}` 部分会被 `format()` 方法中的参数依次替换。\n\n2. 使用 f-string。下面是使用 f-string 格式化输出整数的示例：\n\n```python\nx = 10\ny = 20\nprint(f\"x: {x}, y: {y}\")\n```\n\n输出结果也是：\n\n```\nx: 10, y: 20\n```\n\n在这个示例中，我们在字符串前面加上了 `f`，然后在字符串中使用花括号 `{}` 来引用变量。\n\n![image-20230911230031082](../img/Python-%E6%80%BB%E6%89%8B%E5%86%8C.assets/f624bcf9ec2c15c1f787856894b11bf23ece130d-1726156094789-37.png)\n\n3. 使用使用 `%` 符号进行格式化输出整数的示例：\n\n```python\nx = 10\ny = 20\nprint(\"x: %d, y: %d\" % (x, y))\n```\n\n输出结果为：\n\n```\nx: 10, y: 20\n```\n\n在这个示例中，我们使用了 `\"x: %d, y: %d\"` 这个字符串作为格式化模板。`%d` 是整数的占位符。然后，我们将要格式化的整数值 `(x, y)` 作为元组传递给 `%` 运算符。\n\n例：1.4.3.1输出年月日\n\n![image-20230911225550413](../img/Python-%E6%80%BB%E6%89%8B%E5%86%8C.assets/5c31f48eaab585c33f0ddd127b4e042f92ccf368-1726156094789-38.png)\n\n#### 浮点数格式化输出\n\n使用 `%` 符号配合格式化字符串来实现。下面是一个示例代码：\n\n```python\nnum = 3.14159\nprint(\"浮点数：%.2f\" % num)\n```\n\n在这个示例中，`%.2f` 是浮点数的格式化字符串。`%` 符号后的 `.2f` 表示将浮点数保留两位小数进行输出。如果要保留更多或更少的小数位数，只需相应地调整数字即可。\n\n输出结果为：\n\n```\n浮点数：3.14\n```\n\n这样就实现了将浮点数格式化输出并保留指定小数位数。\n\n### Python表达式\n\n| 类别       | 运算符 | 描述                   | 实例                                          |\n| ---------- | ------ | ---------------------- | --------------------------------------------- |\n| 算术运算符 | +      | 加法                   | 2 + 3 = 5                                     |\n|            | -      | 减法                   | 5 - 2 = 3                                     |\n|            | *      | 乘法                   | 2 * 3 = 6                                     |\n|            | /      | 除法                   | 6 / 2 = 3                                     |\n|            | %      | 取模（取余数）         | 7 % 3 = 1                                     |\n|            | **     | 幂运算                 | 2 ** 3 = 8                                    |\n|            | //     | 整除（取商的整数部分） | 7 // 3 = 2                                    |\n| 赋值运算符 | =      | 赋值                   | x = 5                                         |\n|            | +=     | 加法赋值               | x += 3 （等价于 x = x + 3）                   |\n|            | -=     | 减法赋值               | x -= 2 （等价于 x = x - 2）                   |\n|            | *=     | 乘法赋值               | x *= 2 （等价于 x = x * 2）                   |\n|            | /=     | 除法赋值               | x /= 4 （等价于 x = x / 4）                   |\n|            | %=     | 取模赋值               | x %= 3 （等价于 x = x % 3）                   |\n| 比较运算符 | ==     | 等于                   | 3 == 3 （返回 True）                          |\n|            | !=     | 不等于                 | 2 != 3 （返回 True）                          |\n|            | >      | 大于                   | 5 > 2 （返回 True）                           |\n|            | <      | 小于                   | 2 < 5 （返回 True）                           |\n|            | >=     | 大于等于               | 5 >= 5 （返回 True）                          |\n|            | <=     | 小于等于               | 2 <= 5 （返回 True）                          |\n| 逻辑运算符 | and    | 与                     | True and False （返回 False）两者为真才为真   |\n|            | or     | 或                     | True or False （返回 True）一个为真就为真     |\n|            | not    | 非                     | not True （返回 False）                       |\n| 成员运算符 | in     | 存在于                 | 2 in [1, 2, 3] （返回 True）                  |\n|            | not in | 不存在于               | 4 not in [1, 2, 3] （返回 True）              |\n| 身份运算符 | is     | 是                     | x is None （返回 True，如果 x 为 None）       |\n|            | is not | 不是                   | x is not None （返回 True，如果 x 不为 None） |\n\n\n\n<div class=\"tbsm\" style=\"margin-top:54px;\">\n<div class=\"tbsm-top\"><span><svg t=\"1674654360507\" class=\"icon\" viewBox=\"0 0 1024 1024\" version=\"1.1\" xmlns=\"http://www.w3.org/2000/svg\" p-id=\"987\" data-spm-anchor-id=\"a313x.7781069.0.i0\" width=\"35\" height=\"35\"><path d=\"M410.49 97.74H155.08a56.74 56.74 0 0 0-56.84 56.73V410a56.84 56.84 0 0 0 56.84 56.84h255.41A56.83 56.83 0 0 0 467.32 410V154.58a56.83 56.83 0 0 0-56.83-56.84zM410.49 558.74H155.08a56.74 56.74 0 0 0-56.84 56.73V871a56.84 56.84 0 0 0 56.84 56.84h255.41A56.83 56.83 0 0 0 467.32 871V615.58a56.83 56.83 0 0 0-56.83-56.84zM871.49 558.74H616.08a56.74 56.74 0 0 0-56.84 56.73V871a56.84 56.84 0 0 0 56.84 56.84h255.41A56.83 56.83 0 0 0 928.32 871V615.58a56.83 56.83 0 0 0-56.83-56.84z\" fill=\"#66EEFF\" p-id=\"988\"></path><path d=\"M410.49 558.74h-4.14A475 475 0 0 0 299.52 859.6a481.16 481.16 0 0 0 4.84 68.22h106.13A56.83 56.83 0 0 0 467.32 871V615.58a56.83 56.83 0 0 0-56.83-56.84zM871.49 558.74H616.08a56.74 56.74 0 0 0-56.84 56.73V871a56.84 56.84 0 0 0 56.84 56.84h255.41A56.83 56.83 0 0 0 928.32 871V615.58a56.83 56.83 0 0 0-56.83-56.84z\" fill=\"#C2F8FF\" p-id=\"989\"></path></svg></span><span style=\"font-size:30px;\"> 特别声明</span></div>\n<div class=\"tbsm-wz\">千屹博客旗下的所有文章，是通过本人课堂学习和课外自学所精心整理的知识巨著<br/>难免会有出错的地方<br/>如果细心的你发现了小失误，可以在下方评论区告诉我，或者私信我！<br />非常感谢大家的热烈支持！</div>\n</div>\n","tags":["Python"],"categories":["编程"]},{"title":"Ansible-总手册","url":"/posts/27532/","content":"\n<meta name=\"referrer\" content=\"no-referrer\"/>\n\n# Ansible-总手册\n\n1. [Ansible三机部署](#Ansible三机部署)\n2. [Ansible配置及相关指令](#Ansible配置及相关指令)\n3. [用户级ansible环境构建（小练习）](#用户级ansible环境构建)\n4. [Ansible-常用模块](#Ansible-常用模块)\n5. [Ansible-playblock](#Ansible-Playbook)\n6. [Ansible-templates](#Ansible-templates)\n7. [Ansible-Roles](#Roles)\n8. [实验任务：安装httpd服务](#实验任务：安装httpd服务)\n\n# Ansible三机部署\n\n## 关于\n\n　ansible是新出现的自动化运维工具，基于Python开发，集合了众多运维工具（puppet、chef、func、fabric）的优点，实现了批量系统配置、批量程序部署、批量运行命令等功能。\n　　ansible是基于 paramiko 开发的,并且基于模块化工作，本身没有批量部署的能力。真正具有批量部署的是ansible所运行的模块，ansible只是提供一种框架。ansible不需要在远程主机上安装client/agents，因为它们是基于ssh来和远\n程主机通讯的。ansible目前已经已经被红帽官方收购，是自动化运维工具中大家认可度最高的，并且上手容易，学习简单。是每位运维工程师必须掌握的技能之一。\n\n## 主机分布\n\n| 主机名     | ip             | 系统      | 内存 | 硬盘 |\n| ---------- | -------------- | --------- | ---- | ---- |\n| controller | 192.168.48.100 | Centos7.9 | 4G   | 100G |\n| node01     | 192.168.48.101 | Centos7.9 | 4G   | 100G |\n| node02     | 192.168.48.102 | Centos7.9 | 4G   | 100G |\n\n## 修改主机名\n\n`controlle`\n\n```\nhostnamectl set-hostname controller && bash\n```\n\n`node01`\n\n```\nhostnamectl set-hostname node01 && bash\n```\n\n`node02`\n\n```\nhostnamectl set-hostname node02 && bash\n```\n\n`三台机加入hosts`\n\n```\ncat >> /etc/hosts << EOF\n192.168.48.100 controller\n192.168.48.101 node01\n192.168.48.102 node02\nEOF\n```\n\n## 设置阿里yum\n\n```\nmkdir repo.bak\nmv /etc/yum.repos.d/* repo.bak/\nwget -O /etc/yum.repos.d/CentOSBase.repo https://mirrors.aliyun.com/repo/Centos-7.repo\nyum clean all && yum makecache\nsystemctl disable firewalld --now\nsed -i 's/SELINUX=enforcing/SELINUX=disabled/g' /etc/sysconfig/selinux\nsed -i 's/SELINUX=enforcing/SELINUX=disabled/g' /etc/selinux/config\nyum update -y\n```\n\n## 安装python\n\n`已安装可以忽略。`\n\n`确保python版本>=2.6`\n\n```\nsudo yum install epel-release\nsudo yum install https://centos7.iuscommunity.org/ius-release.rpm\nsudo yum install python27\n```\n\n```\n[root@controller ~]# python --version\nPython 2.7.5\n#有显示说明python安装成功\n```\n\n## 安装Ansible\n\n```\nsudo yum install epel-release ansible openssh\n\n[root@controller ~]# ansible --version\nansible 2.9.27\n  config file = /etc/ansible/ansible.cfg\n  configured module search path = [u'/root/.ansible/plugins/modules', u'/usr/share/ansible/plugins/modules']\n  ansible python module location = /usr/lib/python2.7/site-packages/ansible\n  executable location = /usr/bin/ansible\n  python version = 2.7.5 (default, Oct 14 2020, 14:45:30) [GCC 4.8.5 20150623 (Red Hat 4.8.5-44)]\n\n```\n\n## 测试\n\n### 测试主机是否存活\n\n```\nvim /etc/ansible/hosts\n\n#在末尾添加ip\n192.168.48.101\n192.168.48.102\n-----------------------\n```\n\n```\nansible 192.168.48.101 -m ping -k\nansible 192.168.48.102 -m ping -k\n```\n\n如果controller没有首次进行ssh至node01-02节点，则ansible会出错，如下图：\n\n![image-20230909230311692](../img/Ansible-%E6%80%BB%E6%89%8B%E5%86%8C.assets/d532cd4e257c3d44938697760ad2984a697559838-1726155218419-20.png)\n\n![image-20230909230328295](../img/Ansible-%E6%80%BB%E6%89%8B%E5%86%8C.assets/17b123269de38e723b5fadf4bb900190697559838-1726155218419-21.png)\n\n所以我们必须先ssh至各节点，让其生成缓存信息\n\n```\n[root@controller ~]# ssh 192.168.48.101\n##输入密码\n\n[root@node01 ~]# exit\n\n\n[root@controller ~]# ssh 192.168.48.102\n##输入密码\n\n[root@node02 ~]# exit\n```\n\n这时我们在进行测试\n\n![image-20230909230535153](../img/Ansible-%E6%80%BB%E6%89%8B%E5%86%8C.assets/8f2e0efd9625bb551134c558141fb934697559838-1726155218420-22.png)\n\n\n\n## SSH免密配置\n\n```\nssh-keygen   （一路回车，三次）\n[root@controller ~]# ls -al ~/.ssh\ntotal 12\ndrwx------  2 root root   57 Sep  6 00:43 .\ndr-xr-x---. 8 root root  236 Sep  9 23:05 ..\n-rw-------  1 root root 1675 Sep  6 00:42 id_rsa\n-rw-r--r--  1 root root  397 Sep  6 00:42 id_rsa.pub\n-rw-r--r--  1 root root  352 Sep  6 00:35 known_hosts\n#有密钥文件了\n\n#将密钥文件复制到node01-02节点，实现ssh免密登入\n(先yes 然后输入密码即可)\nssh-copy-id root@192.168.48.101\n\nssh-copy-id root@192.168.48.102\n```\n\n最后我们在进行测试\n\n![image-20230909231047461](../img/Ansible-%E6%80%BB%E6%89%8B%E5%86%8C.assets/83de0f2327321a1b510793c35eb218cb697559838-1726155218420-23.png)\n\n![image-20230909231103976](../img/Ansible-%E6%80%BB%E6%89%8B%E5%86%8C.assets/f7125008aaa709e1106fa073483995bc697559838-1726155218420-24.png)\n\n# Ansible配置及相关指令\n\n## ansible 程序结构\n\n安装目录如下(yum安装)：\n　　配置文件目录：/etc/ansible/\n　　执行文件目录：/usr/bin/\n　　Lib库依赖目录：/usr/lib/pythonX.X/site-packages/ansible/\n　　Help文档目录：/usr/share/doc/ansible-X.X.X/\n　　Man文档目录：/usr/share/man/man1/\n\n## ansible配置文件查找顺序\n\nansible与我们其他的服务在这一点上有很大不同，这里的配置文件查找是从多个地方找的，顺序如下：\n\n1. 检查环境变量`ANSIBLE_CONFIG`指向的路径文件\n   (export ANSIBLE_CONFIG=/etc/ansible.cfg)；\n\n2. `~/.ansible.cfg`，检查当前目录下的ansible.cfg配置文件；\n\n3. `/etc/ansible.cfg`检查etc目录的配置文件。\n\n## ansible配置文件\n\n　ansible 的配置文件为`/etc/ansible/ansible.cfg`，ansible 有许多参数，下面我们列出一些常见的参数：\n\n```\n[defaults]\n \n#inventory      = /etc/ansible/hosts   //定义Inventory\n#library        = /usr/share/my_modules/  //自定义lib库存放目录 \n#remote_tmp     = ~/.ansible/tmp       //零时文件远程主机存放目录\n#local_tmp      = ~/.ansible/tmp       //零时文件本地存放目录\n#forks          = 5                    //默认开启的并发数\n#poll_interval  = 15                   //默认轮询时间间隔\n#sudo_user      = root                 //默认sudo用户\n#ask_sudo_pass = True                  //是否需要sudo密码\n#ask_pass      = True                  //是否需要密码\n#host_key_checking = False             //首次连接是否检查key认证\n#roles_path    = /etc/ansible/roles    //默认下载的Roles存放的目录\n#log_path = /var/log/ansible.log       //执行日志存放目录\n#module_name = command                 //默认执行的模块\n#action_plugins     = /usr/share/ansible/plugins/action //action插件存放目录\n#callback_plugins   = /usr/share/ansible/plugins/callback //callback插件存放目录\n#connection_plugins = /usr/share/ansible/plugins/connection  //connection插件存放目录\n#lookup_plugins     = /usr/share/ansible/plugins/lookup //lookup插件存放目录\n#vars_plugins       = /usr/share/ansible/plugins/vars //vars插件存放目录\n#filter_plugins     = /usr/share/ansible/plugins/filter //filter插件存放目录\n#test_plugins       = /usr/share/ansible/plugins/test //test插件存放目录\n#strategy_plugins   = /usr/share/ansible/plugins/strategy //strategy插件存放目录\n#fact_caching = memory                 //getfact缓存的主机信息存放方式\n#retry_files_enabled = False              \n#retry_files_save_path = ~/.ansible-retry  //错误重启文件存放目录\n```\n\n### 配置文件的分类与优先级\n\nAnsible只有一个配置文件ansible.cfg，但配置文件可以存在不同的位置，并且只有一个可用 (数字代表优先级，数字越小代表优先级越高) :\n\n![image-20230912232830688](../img/Ansible-%E6%80%BB%E6%89%8B%E5%86%8C.assets/bf211db73aea2394ac38fa2bb217ca34697559838.png)\n\n### 配置文件选项\n\n![image-20230912232950364](../img/Ansible-%E6%80%BB%E6%89%8B%E5%86%8C.assets/3ddb17ad5a833513f53be5cf483f51a5697559838.png)\n\n![image-20230912233003740](../img/Ansible-%E6%80%BB%E6%89%8B%E5%86%8C.assets/c4e994cdce2311a90a1f20272421ff40697559838.png)\n\n![image-20230912233019308](../img/Ansible-%E6%80%BB%E6%89%8B%E5%86%8C.assets/6ce1bdfe949bd22740329bf08f66d443697559838.png)\n\n官网配置参考网址\n\n[Ansible Configuration Settings — Ansible Documentation](https://docs.ansible.com/ansible/2.9/reference_appendices/config.html)\n\n![image-20230912233124916](../img/Ansible-%E6%80%BB%E6%89%8B%E5%86%8C.assets/aadcbffa6a3f0cd1d2da9f4ee3a9d950697559838.png)\n\n## ansuble主机清单\n\n```\n1、 定义单独主机：\n\t## green.example.com#\n\t# blue.example.com#\n\t# 192.168.100.1\n\t# 192.168.100.10\n2、 定义一个主机组[组名]把地址或主机名加进去\n\t[mysql_test]\n\t192.168.253.159\n\t192.168.253.160\n\t192.168.253.153\n```\n\n需要注意的是，这里的`组成员可以使用通配符来匹配`，这样对于一些标准化的管理来说就很轻松方便了。\n　　我们可以根据实际情况来配置我们的主机列表，具体操作如下：\n\n```\n[root@server ~]# vim /etc/ansible/hosts\n\t[web]\n\t192.168.37.122\n\t192.168.37.133\n```\n\n```\n3、 定义嵌套组\n    [web-mysql]\n       mysql_test\n       web\n4、 定义范围化ip\n    172.16.[0:4].[2:254]  \n```\n\n\n\n## ansible 常用命令\n\n> `/usr/bin/ansible`　　Ansibe AD-Hoc 临时命令执行工具，常用于临时命令的执行\n> `/usr/bin/ansible-doc` 　Ansible 模块功能查看工具\n> `/usr/bin/ansible-galaxy`　　下载/上传优秀代码或Roles模块 的官网平台，基于网络的\n> `/usr/bin/ansible-playbook`　　Ansible 定制自动化的任务集编排工具\n> `/usr/bin/ansible-pull`　　Ansible远程执行命令的工具，拉取配置而非推送配置（使用较少，海量机器时使用，对运维的架构能力要求较高）\n> `/usr/bin/ansible-vault`　　Ansible 文件加密工具\n> `/usr/bin/ansible-console`　　Ansible基于Linux Consoble界面可与用户交互的命令执行工具\n\n　　其中，我们比较常用的是`/usr/bin/ansible`和`/usr/bin/ansible-playbook`。\n\n### ansible 命令详解\n\n命令的具体格式如下：\n\n```css\nansible <host-pattern> [-f forks] [-m module_name] [-a args]\n```\n\n　　也可以通过`ansible -h`来查看帮助，下面我们列出一些比较常用的选项，并解释其含义：\n\n> `-a MODULE_ARGS`　　　#模块的参数，如果执行默认COMMAND的模块，即是命令参数，如： “date”，“pwd”等等\n> `-k`，`--ask-pass` #ask for SSH password。登录密码，提示输入SSH密码而不是假设基于密钥的验证\n> `--ask-su-pass` #ask for su password。su切换密码\n> `-K`，`--ask-sudo-pass` #ask for sudo password。提示密码使用sudo，sudo表示提权操作\n> `--ask-vault-pass` #ask for vault password。假设我们设定了加密的密码，则用该选项进行访问\n> `-B SECONDS` #后台运行超时时间\n> `-C` #模拟运行环境并进行预运行，可以进行查错测试\n> `-c CONNECTION` #连接类型使用\n> `-f FORKS` #并行任务数，默认为5\n> `-i INVENTORY` #指定主机清单的路径，默认为`/etc/ansible/hosts`\n> `--list-hosts` #查看有哪些主机组\n> `-m MODULE_NAME` #执行模块的名字，默认使用 command 模块，所以如果是只执行单一命令可以不用 -m参数\n> `-o` #压缩输出，尝试将所有结果在一行输出，一般针对收集工具使用\n> `-S` #用 su 命令\n> `-R SU_USER` #指定 su 的用户，默认为 root 用户\n> `-s` #用 sudo 命令\n> `-U SUDO_USER` #指定 sudo 到哪个用户，默认为 root 用户\n> `-T TIMEOUT` #指定 ssh 默认超时时间，默认为10s，也可在配置文件中修改\n> `-u REMOTE_USER` #远程用户，默认为 root 用户\n> `-v` #查看详细信息，同时支持`-vvv`，`-vvvv`可查看更详细信息\n\n## ansible 配置公私钥\n\n　　上面我们已经提到过 ansible 是基于 ssh 协议实现的，所以其配置公私钥的方式与 ssh 协议的方式相同，具体操作步骤如下：\n\n```csharp\n#1.生成私钥\n[root@server ~]# ssh-keygen \n#2.向主机分发私钥\n[root@server ~]# ssh-copy-id root@192.168.48.101\n[root@server ~]# ssh-copy-id root@192.168.48.102\n```\n\n`192.168.48.101为node01的ip地址`\n\n这样的话，就可以实现无密码登录，我们的实验过程也会顺畅很多。\n　　注意，如果出现了一下报错：\n\n```dockerfile\n-bash: ssh-copy-id: command not found\n```\n\n　　那么就证明我们需要安装一个包：\n\n```markdown\nyum -y install openssh\n```\n\n　　把包安装上即可。\n\n注意：先ssh 192.168.48.101和ssh 192.168.48.102各节点，生成缓存信息，才能进行`主机连通性测试`\n\n## ansible ping模块\n\n### 主机连通性测试\n\n　　我们使用`ansible web -m ping`命令来进行主机连通性测试，效果如下：\n\n```ruby\n[root@server ~]# ansible web -m ping\n192.168.48.101 | SUCCESS => {\n    \"changed\": false, \n    \"ping\": \"pong\"\n}\n192.168.48.102 | SUCCESS => {\n    \"changed\": false, \n    \"ping\": \"pong\"\n}\n```\n\n　　这样就说明我们的主机是连通状态的。接下来的操作才可以正常进行。\n\n# 用户级ansible环境构建\n\n## 主机分布\n\n| 主机名     | ip             | 系统      | 内存 | 硬盘 |\n| ---------- | -------------- | --------- | ---- | ---- |\n| controller | 192.168.48.100 | Centos7.9 | 4G   | 100G |\n| node01     | 192.168.48.101 | Centos7.9 | 4G   | 100G |\n| node02     | 192.168.48.102 | Centos7.9 | 4G   | 100G |\n\n## 创建student用户\n\n<font color='red'>三台机创建student用户</font>\n\n```\n#创建student用户\nuseradd student\npasswd student\n123456\n```\n\n## controller创建student用户工作目录\n\n```\n#切换student用户，创建工作目录，新建ansible.cfg配置文件，验证配置文件生效。\nsu student\ncd \n#创建资产清单 \nmkdir ansible\ncat >> /home/student/ansible/inventory <<EOF\n[servers]\n192.168.48.101\n192.168.48.102\nEOF\n```\n\n## controller编辑配置文件ansible.cfg\n\n```\ncd ansible\ncat >> /home/student/ansible/ansible.cfg <<EOF\n[defaults]\ninventory=/home/student/ansible/inventory\nremote_port=22\nremote_user=root\n#指定远程用户为root\nask_pass=True\nEOF\n```\n\n## 验证清单主机存活（指定root）\n\n验证清单主机存活 ,执行命令进行测试，可以看到在每次执行ansible时都会询问连接用户的密码（相 当于-K参数）\n\n```\nansible all --list\n\n[student@controller ansible]$ ansible all --list\nSSH password:\n  hosts (2):\n    192.168.48.101\n    192.168.48.102\n[student@controller ansible]$\n#成功\n```\n\n如果不想输入密码，那需要修改配置文件：\n\n```\nvi /home/student/ansible/ansible.cfg\n······\nask_pass=False\n```\n\n![image-20230912224807001](../img/Ansible-%E6%80%BB%E6%89%8B%E5%86%8C.assets/e1d902512d1ed9c395ad0dc927a3211e04e28fba-1726155218420-25.png)\n\n```\n[student@controller ansible]$ ansible all --list\n  hosts (2):\n    192.168.48.101\n    192.168.48.102\n[student@controller ansible]$\n#无输入密码选项\n```\n\n## 实例（指定student）\n\n<font color='red'>远程用户指定为普通用户（student）</font>\n\n```\n[student@controller ansible]$ vim ansible.cfg\n[defaults]\ninventory=/home/student/ansible/inventory\nremote_port=22\nremote_user=student\n#指定远程用户为student\nask_pass=False\n```\n\n这时候执行ping会报错\n\n```\nansible all -m ping\n```\n\n![image-20230912225310702](../img/Ansible-%E6%80%BB%E6%89%8B%E5%86%8C.assets/36030bdebb9cbe2cb9cf85a57f527991fc70eba3-1726155218420-26.png)\n\n![image-20230912225331509](../img/Ansible-%E6%80%BB%E6%89%8B%E5%86%8C.assets/093cb2bedadf9dacdf83186c216de62efbbea1bb-1726155218420-27.png)\n\n这时候我们要配置免密登入（这里的密钥是student用户的，和root不一样，不会覆盖root用户的，这是在student用户下执行的命令）\n\n```\n[student@controller ansible]$ ssh-keygen\n#回车三次\n[student@controller ansible]$ ssh-copy-id student@192.168.48.101\n#输入yes和node1的root密码\n\n[student@controller ansible]$ ssh-copy-id student@192.168.48.102\n#输入yes和node2的root密码\n```\n\n这是执行ping命令\n\n```\n ansible all -m ping\n```\n\n![image-20230912230245638](../img/Ansible-%E6%80%BB%E6%89%8B%E5%86%8C.assets/fbfb0421bf54c003e1a9cc2e28ffd60fea8755cf-1726155218420-28.png)\n\n## 测试提取文件\n\n这个普通用户（student）并不能执行所有的操作，比如ansible以student身份登录，执行（ls /root）发普通用户没有权限，\n\n```\nansible all -m shell -a \"ls /root\"\n```\n\n![image-20230912230504092](../img/Ansible-%E6%80%BB%E6%89%8B%E5%86%8C.assets/dcc6b723a386323cf562bade58b2cf2a8957be6f-1726155218420-29.png)\n\n解决这个问题就需要提权：sudo 提权\n\n在受控主机(<font color='red'>node01、node02</font>)上执行visudo（配置 /etc/sudoers）\n\n<font color='red'>node01机子</font>\n\n```\n[root@node01 ~]# visudo\n```\n\n![image-20230912230747742](../img/Ansible-%E6%80%BB%E6%89%8B%E5%86%8C.assets/91e2a38e7ef071a3cb51f5b89dc133df750e339c-1726155218420-30.png)\n\n<font color='red'>node02机子</font>\n\n```\n[root@node02 ~]# visudo\n```\n\n![image-20230912230906568](../img/Ansible-%E6%80%BB%E6%89%8B%E5%86%8C.assets/645d2da0ea2f30c86fe3f4719053de461825fd10-1726155218420-31.png)\n\n或者(<font color='red'>node01和node02执行以下指令</font>)\n\n```\ncat >>/etc/sudoers.d/student << EOF \nstudent          ALL=(ALL)        NOPASSWD: ALL\nEOF\n```\n\n在<font color='red'>控制主机（controller）</font>上(<font color='red'>student用户</font>)修改ansible.cfg配置文件提权\n\n```\n[student@controller ansible]$ vim ansible.cfg\n[defaults]\ninventory=/home/student/ansible/inventory\nremote_port=22\nremote_user=student\nask_pass=False\n[privilege_escalation]\nbecome=True\nbecome_method=sudo\nbecome_user=root\nbecome_ask_pass=False\n```\n\n![image-20230912231556770](../img/Ansible-%E6%80%BB%E6%89%8B%E5%86%8C.assets/0575ae46b3b79b6f7beffd757fd79427cee52b0e-1726155218420-32.png)\n\n验证\n\n```\nansible all -m shell -a \"ls /root\"\n```\n\n![image-20230912231635877](../img/Ansible-%E6%80%BB%E6%89%8B%E5%86%8C.assets/5e66812c14fd8690a9025e8436b5d6d3edd08ccf-1726155218420-33.png)\n\n<font color='red'>#在控制节点的student经过sudo提权之后可以读取/root目录了</font>\n\n# Ansible-常用模块\n\n## command模块\n\nlinux命令，不支持管道、重定向等，不建议使用\n\n```\nansible all -m command -a \"pwd\"\nansible all -m command -a \"ls\"\nansible all -m command -a \"cat /etc/passwd |grep student\" #这个不能正常使用 ansible all -m command -a \"echo bb >>/tmp/testansible\"\nansible all -m command -a \"cat /tmp/testansible\"\n```\n\n#重定向也无法正常使用\n\n课堂练习：\n\n使用command命令查询各主机磁盘状态、查询内存状态\n\n```\nansible all -m command -a \"df -h\"\nansible all -m command -a \"free -m\"\n```\n\n## shell模块\n\n支持管道、重定向等，常用模块\n\n```\nansible all -m shell -a \"cat /etc/passwd | grep student\" #支持管道\nansible all -m shell -a \"echo bb >>/tmp/testansible\"\nansible all -m shell -a \"cat /tmp/testansible\"\n```\n\n\\#支持重定向\n\n课堂练习：\n\n使用shell模块查看selinux状态\n\n```\nansible all -m shell -a \"getenforce\"\n```\n\n通过shell模块批量关闭selinux\n\n```\n临时关闭：\n\nansible all -m shell -a \"setenforce 0\"\n\n永久关闭：\n\nansible all -m shell -a \"sed -ri 's/SELINUX=enforcing/SELINUX=disabled/g' /etc/selinux/config\"\n\nansible all -m shell -a \"reboot\"\n\n```\n\n## 文件模块\n\n###  copy模块\n\n从主控端复制文件到远程主机\n\n```\nansible-doc copy\n```\n\n<font color='red'>常用参数</font>\n\n<font color='red'>src</font>：source源路径文件/目录。即要复制到远程主机的文件在本地的地址，可以是绝对路径，也可以是 相对路径。如果路径是一个目录，它将递归复制。在这种情况下，<font color='red'>如果路径使用\"/\"来结尾，则只复制目录里的内容，如果没有使用\"/\"来结尾，则包含目录在内的整个内容全部复制。</font>\n\n<font color='red'>dest</font>：destnation受管主机上的一个目标路径，即要将源文件复制到的远程主机的绝对路径，<font color='red'>如果源文件是一个目录，那么该路径也必须是个目录（必须）</font>\n\n<font color='red'>content</font>：代替src，将本机指定内容传至远程主机并生成目标文件，相当于 echo 重定向内容到文件\n\n<font color='red'>mode</font>：文件权限（chmod）\n\nlinux权限回顾\n\n![image-20230919103608153](../img/Ansible-%E6%80%BB%E6%89%8B%E5%86%8C.assets/52827ecf0f65ab744206c34f261d3a9a697559838.png)\n\nowner：文件属主（chown）\ngroup：文件属组（chgrp）\nbackup：在覆盖之前将原文件备份，备份文件包含时间信息。\ndirectory_mode： 递归地设定目录的权限，默认为系统默认权限\nforce： 若目标主机包含该文件，但内容不同，如果设置为yes，则强制覆盖，如果为no，则只有当目标 主机的存放位置不存在该文件时，才复制。默认为yes\n\n#### 使用案例\n\n-----------------------------------------------\n\n1. 复制dir1目录及其文件到受控主机/tmp/下（无斜杠-操作整个目录）\n\n注：关于src目录加不加/的演示\n\n```\n#复制dir1目录及其文件到受控主机/tmp/下\nsu student\ncd ~\nll\nmkdir ansible\ncd ansible/\nmkdir dir1\necho \"123\" >dir1/file1\nansible 192.168.48.101 -m copy -a \"src='dir1' dest=/tmp/\" \n```\n\n![image-20230919104532341](../img/Ansible-%E6%80%BB%E6%89%8B%E5%86%8C.assets/26297293d1c6d55d60a07ba276b8f34d697559838.png)\n\n查看受控主机是否复制成功\n\n![image-20230919104230231](../img/Ansible-%E6%80%BB%E6%89%8B%E5%86%8C.assets/8ac7e84618a6a21b32f22fd0ddd6293c697559838.png)\n\n成功\n\n------------------------------------------------------\n\n2.仅复制dir1目录下的文件（有斜杠-操作目录下的文件，不复制目录）\n\n```\nansible 192.168.48.101 -m copy -a\"src='dir1/' dest=/tmp/\"\n```\n\n![image-20230919104627377](../img/Ansible-%E6%80%BB%E6%89%8B%E5%86%8C.assets/aeb91a6fcfd4c46cab9b2f1753021736697559838.png)\n\n--------------------------\n\n#### 练习\n\n1. 将控制主机的copyfile<font color='red'>文件</font>复制到受管主机的 /tmp 目录\n\n```\necho '123' > copyfile\nansible 192.168.48.101 -m copy -a 'src=copyfile dest=/tmp'\n```\n\n![image-20230919104938353](../img/Ansible-%E6%80%BB%E6%89%8B%E5%86%8C.assets/5f44b73d5f3a76ac330e4c548dd2a4a4697559838.png)\n\n2. 直接在受管主机上生成一个指定内容的文件文件\n\n```\nansible 192.168.48.101 -m copy -a \"content='test copy\\n' dest=/tmp/f1\"\n```\n\n![image-20230919105205728](../img/Ansible-%E6%80%BB%E6%89%8B%E5%86%8C.assets/a3c76e0b0aec925240c70f4cb5eee82a697559838.png)\n\n3. 在受管主机上生成指定属性和内容的文件\n\n```\nansible 192.168.48.101 -m copy -a \"content='test copy 2\\n' dest=/tmp/f2 mode=0644 owner=student group=student\"\n```\n\n![image-20230919105358641](../img/Ansible-%E6%80%BB%E6%89%8B%E5%86%8C.assets/fb9ee5353f0251d1948b1c0c4c231262697559838.png)\n\n4. 在文件覆盖前生成备份文件\n\n```\nansible 192.168.48.101 -m copy -a \"content='test copy 1\\n' dest=/tmp/f1 backup=yes\"\n\nansible 192.168.48.101 -m shell -a \"ls -l /tmp/f1*\"\n```\n\n![image-20230919105648041](../img/Ansible-%E6%80%BB%E6%89%8B%E5%86%8C.assets/b5e4b14ac0ca160bde8ddf210cb96ab7697559838.png)\n\n![image-20230919105803096](../img/Ansible-%E6%80%BB%E6%89%8B%E5%86%8C.assets/70416fb0306aabae0a84614e1dd8616c697559838.png)\n\n### script模块\n\n在远程主机上运行ansible服务器上的脚本，优点是不需手动传送脚本至每个服务器。\n\n其实是ansible自动传到远程主机、执行然后再删除脚本：copy+shell+delete\n\n```\ncat >> tesh.sh << EOF\n#！/bin/bash \necho hello\nEOF\nansible all -m script -a tesh.sh\n```\n\n![image-20230919110133298](../img/Ansible-%E6%80%BB%E6%89%8B%E5%86%8C.assets/982643f18a7e268bacd57c50e218c612697559838.png)\n\n执行结果显示了每台主机的执行情况。\n\n`CHANGED` 表示执行过程中发生了变化，即脚本被成功执行。\n\n`rc` 字段显示返回码为 0，表示执行成功。\n\n`stderr` 字段显示了标准错误输出，其中包含了连接关闭的信息。\n\n`stdout` 字段显示了标准输出，其中包含了脚本执行的结果，即 \"hello\"。\n\n```\ncat >>  ansible_ntp.sh << EOF\n#!/bin/bash\nsystemctl status ntpd >/dev/null 2>&1\nif [ \\$? == 0 ]; then\n\techo \"ntp service has been installed\"\n\texit\nfi\nyum install -y ntp >/dev/null 2>&1\nif [ \\$? == 0 ]; then\n\tsystemctl start ntpd\n\tsystemctl enabled ntpd >/dev/null 2>&1\n\tsleep 5\n\tntpq -p\nelse\n\techo \"ntp service install failed,check network or yum\"\nfi\nEOF\n\n这条命令的意思就是在后台执行这个程序,并将错误输出2重定向到标准输出1,然后将标准输出1全部放 到/dev/null文件,也就是清空.\n所以可以看出\" >/dev/null 2>&1 \"常用来避免shell命令或者程序等运行中有内容输出。\n\nchmod 777 ansible_ntp.sh\n\nansible all -m script -a \"ansible_ntp.sh\"\n```\n\n![image-20230919112000710](../img/Ansible-%E6%80%BB%E6%89%8B%E5%86%8C.assets/9fbb36b86b4fd085fa37a09953f27fd7697559838.png)\n\n### fetch模块\n\n从受管主机上，拉取文件到控制节点（目前不支持目录,可以先打包,再提取文件）\n\n常见参数\n\n<font color='red'>dest</font>：控制节点的保存路径\n\n<font color='red'>src</font>：受管节点要拉取文件的路径（必须是文件，不能是目录）\n\n<font color='red'>flat</font>：直接保存到目标指定位置，而不是在受管主机名下的文件路径中。\n\n<font color='cornflowerblue'>使用案例</font>\n\n1. 从受管主机拉取指定文件\n\n```\nansible 192.168.48.101 -m fetch -a \"src=/etc/hosts dest=/home/student/ansible\"\n```\n\n索取到本地目录下的文件会<font color='red'>自动生成与目标主机的域名或IP地址的目录</font>存放索取的文件\n\n![image-20230919122430880](../img/Ansible-%E6%80%BB%E6%89%8B%E5%86%8C.assets/4fdb0ca42f7652416648856e326af850697559838.png)\n\n\n\n2. 直接拉取受管主机文件到控制节点指定位置\n\n<font color='red'>flat</font>：直接保存到目标指定位置，而不是在受管主机名下的文件路径中。\n\n```\nansible 192.168.48.101 -m fetch -a \"src=/etc/hosts dest=/home/student/ansible/file1 flat=yes\"\n```\n\n![image-20230919124219445](../img/Ansible-%E6%80%BB%E6%89%8B%E5%86%8C.assets/945aaa435a8d0362f4d908f5f76ffea0697559838.png)\n\n\n\n3. 打包目录并所有内容到控制节点指定位置\n\n```\nansible 192.168.48.101 -m shell -a 'pwd'\n\nansible 192.168.48.101 -m shell -a 'tar cf test.tar.gz /var/log'\nansible 192.168.48.101 -m shell -a 'ls -l /home/student/'\nansible 192.168.48.101 -m fetch -a \"src=/home/student/test.tar.gz dest=/home/student/ansible/ flat=yes\"\n```\n\n![image-20230919124935075](../img/Ansible-%E6%80%BB%E6%89%8B%E5%86%8C.assets/32d69277b0e420ee14c86f38bbf177f7697559838.png)\n\n![image-20230919125130417](../img/Ansible-%E6%80%BB%E6%89%8B%E5%86%8C.assets/896d2a405049a0e8f4dcf8bcd147ef62697559838.png)\n\n### file模块\n\nfile 模块可以帮助我们完成一些对文件的基本操作。比如，创建文件或目录、删除文件或目录、修改文 件权限等。\n\n<font color='red'>常用参数</font>\n\n<font color='red'>mode</font>： 定义文件/目录的权限,比如，如果想要将文件权限设置为\"rw-r-x---\"，则可以使用mode=650进行 设置，或者使用mode=0650，效果也是相同的。\n<font color='red'>owner</font>： 定义文件/目录的所有者,属主对应的用户必须在远程主机中存在,否则会报错。\n<font color='red'>group</font>： 定义文件/目录的属组,属组对应的组必须在远程主机中存在，否则会报错。\n<font color='red'>path</font>： 必选项，定义受管主机的文件/目录的路径\n<font color='red'>recurse</font>： 递归地设置文件的属性，只对目录有效\n<font color='red'>src</font>： 要被链接的源文件的路径，只应用于state=hard/link的情况 \n<font color='red'>dest</font>： 被链接到的路径，只应用于state=hard/link的情况。\n<font color='red'>state</font>： 操作方法\n\t<font color='red'>directory</font>：如果目录不存在，创建目录 \n   <font color='red'>file</font>：即使文件不存在，也不会被创建（只能指定已存在的文件） \n   <font color='red'>touch</font>：如果文件不存在，则会创建一个新的文件，如果文件或目录已存在，则更新其最后修改时间 \n\t<font color='red'>link</font>：创建软链接\n\t<font color='red'>hard</font>：创建硬链接 \n\t<font color='red'>absent</font>：删除目录、文件或者取消链接文件，相当于rm -rf\n<font color='red'>force</font>： 只应用于state=hard/link的情况，若需要在两种情况下<font color='red'>强制创建软链接</font>，一种是源文件不存在但 之后会建立的情况下；另一种是目标软链接已存在，需要先取消之前的软链，然后创建新的软链，有两个选 项：yes|no\n\n<font color='cornflowerblue'>使用案例</font>\n\n1. 创建指定文件属性的空目录\n\n```\nansible 192.168.48.101 -m file -a \"path=/tmp/dir2 state=directory owner=student group=student mode=0755\"\n\nansible 192.168.48.101 -m shell -a \"ls -l /tmp/\"\n```\n\n![image-20230919130328712](../img/Ansible-%E6%80%BB%E6%89%8B%E5%86%8C.assets/d119b1a6c075c04724ea0b5d18b24ff6697559838.png)\n\n\n\n2. 创建指定文件属性的空文件\n\n```\nansible 192.168.48.101 -m file -a \"path=/tmp/file2 state=touch owner=student group=student mode=0755\"\nansible 192.168.48.101 -m shell -a \"ls -l /tmp/\"\n```\n\n![image-20230919130652157](../img/Ansible-%E6%80%BB%E6%89%8B%E5%86%8C.assets/f919f4d5b5a8b68e20e4f95ccb967700697559838.png)\n\n<font color='red'>注意：为何不能用state=file</font>\n\n<font color='red'>file</font>：即使文件不存在，也不会被创建（只能指定已存在的文件） \n\nfile3不存在\n\n```\nansible 192.168.48.101 -m file -a \"path=/tmp/file3 state=file owner=student group=student mode=0755\"\n```\n\n![image-20230919131409780](../img/Ansible-%E6%80%BB%E6%89%8B%E5%86%8C.assets/1619642d3c6cc025192515591e26ace8697559838.png)\n\n如果指定file1（已存在）呢（将root用户属组改成student）\n\n```\nansible 192.168.48.101 -m file -a \"path=/tmp/file1 state=file owner=student group=student mode=0755\"\n```\n\n![image-20230919131653294](../img/Ansible-%E6%80%BB%E6%89%8B%E5%86%8C.assets/e5f778ea43b30d28fd675e0a6a864038697559838.png)\n\n\n\n3. 删除目录、删除文件\n\n```\nansible 192.168.48.101 -m file -a \"path=/tmp/dir1 state=absent\"\nansible 192.168.48.101 -m file -a \"path=/tmp/file1 state=absent\"\nansible 192.168.48.101 -m shell -a \"ls -l /tmp/\"\n```\n\n![image-20230919131825229](../img/Ansible-%E6%80%BB%E6%89%8B%E5%86%8C.assets/c3c6450ce672a745e0d7d65a0a3bd3ac697559838.png)\n\n\n\n4. 创建链接文件\n\n软链接：快捷方式\nfile2→file1（link）\n\n生成file1（<font color='red'>如果已存在就忽略这步</font>）\n\n```\nansible 192.168.48.101 -m copy -a \"content='123 \\n' dest=/tmp/file1\"\n```\n\n![image-20230919132425256](../img/Ansible-%E6%80%BB%E6%89%8B%E5%86%8C.assets/35c2e36d03caece46fbd21381a3800a7697559838.png)\n\n生成软链接\n\n```\nansible 192.168.48.101 -m file -a \"src=/tmp/file1 path=/tmp/file2 state=link force=true\"\n```\n\n![image-20230919132542883](../img/Ansible-%E6%80%BB%E6%89%8B%E5%86%8C.assets/ac380dd1f6da597ec6270ef6ca593bf9697559838.png)\n\n取消软连接\n\n```\nansible 192.168.48.101 -m file -a \"path=/tmp/file2 state=absent\"\n```\n\n![image-20230919132733624](../img/Ansible-%E6%80%BB%E6%89%8B%E5%86%8C.assets/98bf109db0eb83ac92dc76a4cddb0777697559838.png)\n\n硬链接：指向同一个inode\n\nfile3→file1（hard）\n\nfile3不存在\n\n```\nansible 192.168.48.101 -m file -a \"src=/tmp/file1 path=/tmp/file3 state=hard\"\n```\n\n![image-20230919132952435](../img/Ansible-%E6%80%BB%E6%89%8B%E5%86%8C.assets/3e287d7e0e2660964cd890ef1adc3c72697559838.png)\n\n#### 课堂练习\n\n1、在/tmp/下创建目录ansiblefile,并在该文件夹下创建test.txt文件，指定属主student,赋予权限0700\n\n```\nansible all -m shell -a \"useradd student\"\t#创建一个用户与组\nansible 192.168.48.101 -m file -a 'path=/tmp/ansiblefile state=directory'\nansible 192.168.48.101 -m file -a 'path=/tmp/ansiblefile/test.txt state=touch owner=student mode=0700'\n```\n\n![image-20230919133407177](../img/Ansible-%E6%80%BB%E6%89%8B%E5%86%8C.assets/cdef89811e66ad695a1c99667c0c89b2697559838.png)\n\n2、删除远程机器上的指定文件或目录(删除远程主机上的文件：/tmp/ansiblefile/test.txt\n\n```\nansible 192.168.48.101 -m file -a 'path=/tmp/ansiblefile/test.txt state=absent'\n```\n\n![image-20230919133445932](../img/Ansible-%E6%80%BB%E6%89%8B%E5%86%8C.assets/e93984ad9e575561dbec75452154899b697559838.png)\n\n\n\n### lineinfile模块\n\n增加或修改文件内容（以行为单位做流式处理），该模块在自动化运维中非常重要,他可以通过正则表达 式替换指定文本;例如开启一些配置选项等可以新加一行文本,或者是删除指定的行,本命令一定认真掌握 下来.\n\n***\\*常见参数\\****\n\n<font color='red'>path</font>：必须参数，远端文件路径 \n\n<font color='red'>line</font>：必须参数，修改后的内容（按行写入），追加 \n\n<font color='red'>regexp</font>：（定位）匹配正则语句,与要过滤的关键字 \n\n<font color='red'>state</font>：文件修改状态（present 添加生效 / absent 删除） \n\n<font color='red'>replace</font>：替换文件内容 \n\n<font color='red'>create</font>：当文件不存在时，是否创建对应文件 \n\n<font color='red'>backup</font>：若文件更新时创建备份副本 \n\n<font color='red'>insertafter</font>：在指定位置的下一行插入（定位） \n\n<font color='red'>insertbefore</font>：在指定位置的上一行插入（定位）\n\n\n\n<font color='orange'>使用案例</font>\n\n\n\n假设前提：将控制节点的/etc/selinux/config文件复制到受管主机192.168.48.101，另存为/tmp/selinux文件\n\n```\nansible 192.168.48.101 -m copy -a \"src=/etc/selinux/config dest=/tmp/selinux\"\nansible 192.168.48.101 -m shell -a \"cat /tmp/selinux\"\n```\n\n![image-20230919134240077](../img/Ansible-%E6%80%BB%E6%89%8B%E5%86%8C.assets/756073d3a371c5ad80ed9d2b96cc0735697559838.png)\n\n![image-20230919134251941](../img/Ansible-%E6%80%BB%E6%89%8B%E5%86%8C.assets/3fbdf2b0b76d46ef1cbd8df403861593697559838.png)\n\n1. 修改文件内容：考虑两个问题，修改哪个部分，修改成什么内容\n\n修改SELINUX开头的行，更新内容为：SELINUX=disabled\n\n```\nansible 192.168.48.101 -m lineinfile -a \"path=/tmp/selinux regexp='^SELINUX=' line='SELINUX=disabled' \"\nansible 192.168.48.101 -m shell -a \"cat /tmp/selinux\"\n```\n\n![image-20230919134315158](../img/Ansible-%E6%80%BB%E6%89%8B%E5%86%8C.assets/ff41c79a4849ffafdc9c6cc72a4b5209697559838.png)\n\n2.增加文件内容：考虑两个问题，增加什么内容，增加在哪个位置（上一行或下一行）\n\n在SELINUX开头的行，在下一行加个注释，并且应用生效\n\n```\nansible 192.168.48.101 -m lineinfile -a \"path=/tmp/selinux insertafter='^SELINUX=' line='##Disabled SELINUX' \"\n```\n\n![image-20230919134429117](../img/Ansible-%E6%80%BB%E6%89%8B%E5%86%8C.assets/001e419cf858d7c28354f565a2791a01697559838.png)\n\n通过正则匹配查找/tmp/selinux文本,并在文本末尾插入一行##end\n\n```\nansible 192.168.48.101 -m lineinfile -a 'path=/tmp/selinux regexp=\"EOF\" line=\"#end\"'\n```\n\n![image-20230919134600319](../img/Ansible-%E6%80%BB%E6%89%8B%E5%86%8C.assets/a47131b7c20e123dfee16dcde867fb21697559838.png)\n\n\n\n3.删除文件内容:把刚才添加的“<font color='orange'>##disabled selinux</font>”注释去掉（删除所在行）\n\n```\nansible 192.168.48.101 -m lineinfile -a \"path=/tmp/selinux regexp='^##Disa' state=absent\"\nansible 192.168.48.101 -m shell -a \"cat /tmp/selinux\"\n```\n\n![image-20230919134741516](../img/Ansible-%E6%80%BB%E6%89%8B%E5%86%8C.assets/8388d27ba2f82a7ac5c10deb1cd88c1d697559838.png)\n\n![image-20230919134748069](../img/Ansible-%E6%80%BB%E6%89%8B%E5%86%8C.assets/1538eecbf87fa1ebe7ae12f47572f272697559838.png)\n\n\n\n4. 备份文件:在SELINUX开头的行，前一行加个注释，并且生效，生成备份文件\n\n```\nansible 192.168.48.101 -m lineinfile -a \"path=/tmp/selinux insertbefore='^SELINUX=' line='##Disabled SELINUX' backup=yes state=present\"\nansible 192.168.48.101 -m shell -a \"ls -l /tmp/selinux*\"\n```\n\n![image-20230919134951862](../img/Ansible-%E6%80%BB%E6%89%8B%E5%86%8C.assets/d0ae22dee29f7c9fedf16e8d93de70bb697559838.png)\n\n![image-20230919135043656](../img/Ansible-%E6%80%BB%E6%89%8B%E5%86%8C.assets/3ac6894ea15fb06f10ad21e6a0e48994697559838.png)\n\n\n\n课堂练习：\n\n修改192.168.48.101主机的/etc/hosts文件，\n\n1、增加内容192.168.48.102 node03,验证增加成功\n\n```\nansible 192.168.48.101 -m lineinfile -a \"path=/etc/hosts line='192.168.48.102 node03' \"\nansible 192.168.48.101 -m shell -a \"cat /etc/hosts\"\n```\n\n![image-20230919143706370](../img/Ansible-%E6%80%BB%E6%89%8B%E5%86%8C.assets/3480653ecbfb7b45c39bfe37641abe94697559838.png)\n\n2、匹配以192开头的行，修改192.168.48.102 对应的 域名为node02，验证增加成功\n\n```\nansible 192.168.48.101 -m lineinfile -a \"path=/etc/hosts regexp='^192' line='192.168.48.102 node02' \"\n```\n\n![image-20230919143745061](../img/Ansible-%E6%80%BB%E6%89%8B%E5%86%8C.assets/82f79ccd0582587791246c164466ddfe697559838.png)\n\n3、匹配以192开头的行之前增加 192.168.48.101 node01 ，验证增加成功\n\n```\nansible 192.168.48.101 -m lineinfile -a \"path=/etc/hosts insertbefore='^192' line='192.168.48.101 node01' \"\n```\n\n![image-20230919143806128](../img/Ansible-%E6%80%BB%E6%89%8B%E5%86%8C.assets/fbf2e090c6d8759eb5147754e3ef2e95697559838.png)\n\n4、在文档结尾增加 192.168.48.100 controller\n\n```\nansible 192.168.48.101 -m lineinfile -a 'path=/etc/hosts regexp=\"EOF\" line=\"192.168.48.100 controller\"'\n```\n\n![image-20230919143820201](../img/Ansible-%E6%80%BB%E6%89%8B%E5%86%8C.assets/fc1024bf695130888d3ec14f3358268e697559838.png)\n\n5、删除步骤1-3加入的内容\n\n```\nansible 192.168.48.101 -m lineinfile -a \"path=/etc/hosts regexp='^192.' state=absent\"\nansible 192.168.48.101 -m shell -a \"cat /etc/hosts\"\n```\n\n![image-20230919143831042](../img/Ansible-%E6%80%BB%E6%89%8B%E5%86%8C.assets/85dcd9c0186a3eb51446a05cb9dc497c697559838.png)\n\n## 软件包模块\n\n### yum模块\n\n***\\*常用参数\\****\n\nname：软件包名称（必填） \n\nstate：\n\nlatest（更新到最新） \n\npresent（安装） \n\nversion（版本） \n\nabsent（卸载）\n\n查看是否安装了某个服务 rpm -qa|grep httpd\n\n***\\*使用案例\\****\n\n给node01安装httpd服务\n\n```\nansible 192.168.48.101 -m yum -a 'name=httpd state=present'\n```\n\n![image-20230919144212748](../img/Ansible-%E6%80%BB%E6%89%8B%E5%86%8C.assets/077acbe660f8d5467cead949a6261b86697559838.png)\n\n验证安装\n\n```\nansible 192.168.48.101 -m shell -a 'rpm -qa|grep httpd'\n```\n\n卸载 state=absent\n\n```\nansible 192.168.48.101 -m yum -a 'name=httpd state=absent'\n```\n\n更新软件state=latest\n\n```\nansible 192.168.48.101 -m yum -a 'name='httpd' state=latest'\n```\n\n## 系统模块\n\n### user模块\n\n<font color='red'>常用参数</font>\n\n```\ncomment：注释信息\ngroup：主要组\ngroups：附加组\nstate：present/absent\ngenerate_ssh_key：生成SSH验证密钥\nname：用户名\nshell：Shell类型\nuid：UID\n```\n\n<font color='red'>使用案例</font>\n\n1、在node1上创建用户 test_user UID=1010\n\n```\nansible 192.168.48.101 -m user -a \"name=test_user  uid=1010 comment='ansible_test_user' shell=/bin/bash generate_ssh_key=yes  state=present\"\n```\n\n```\nansible 192.168.48.101 -m shell -a 'id test_user'\n```\n\n![image-20230920001519202](../img/Ansible-%E6%80%BB%E6%89%8B%E5%86%8C.assets/9fcc14b7641e8a2a1cbbc2c8f89b9ce4697559838.png)\n\n2、删除用户test_user（userdel test_user）\n\n```\nansible 192.168.48.101 -m user -a \"name=test_user  state=absent force=yes\"\nansible 192.168.48.101 -m shell -a 'getent passwd |grep test_user'\n```\n\n![image-20230920001533536](../img/Ansible-%E6%80%BB%E6%89%8B%E5%86%8C.assets/ecb24faf569f346c43de8b49d857ad39697559838.png)\n\n### group组模块\n\n1、创建组test_group (groupadd -g 1010 test_group）\n\n```\nansible 192.168.48.101 -m group -a \"name=test_group  gid=1010  state=present\"\nansible 192.168.48.101 -m shell -a 'getent group|grep test_group'\n```\n\n![image-20230920001545680](../img/Ansible-%E6%80%BB%E6%89%8B%E5%86%8C.assets/f14a0dfa0cd30c96aa4d1d88602dbf29697559838.png)\n\n2、删除组test_group （groupdel test_group）\n\n```\nansible 192.168.48.101 -m group -a \"name=test_group   state=absent\"\nansible 192.168.48.101 -m shell -a 'getent group|grep test_group'\n```\n\n![image-20230920001557200](../img/Ansible-%E6%80%BB%E6%89%8B%E5%86%8C.assets/984c33ed39dd849a2495d5bfce57835b697559838.png)\n\n### service模块\n\n启用/启动/停止指定的服务\n\n<font color='red'>常用参数</font>\n\n```\nname：服务名（确定服务存在）（必选项）\nstate：服务目标状态\n\t（state=started/stopped/restarted/...）（必选项）\nenabled：是否开机启动(yes/no)\n```\n\n1、在node01上安装和启用httpd服务（相当于systemctl enable --now httpd）\n\n安装\n\n```\nansible 192.168.48.101 -m yum -a 'name=httpd state=present'\n```\n\n启用\n\n```\nansible 192.168.48.101 -m service -a \"name=httpd state=started  enabled=yes\"\n```\n\n```\nansible 192.168.48.101 -m shell -a 'systemctl status httpd'\n```\n\n![image-20230920001809879](../img/Ansible-%E6%80%BB%E6%89%8B%E5%86%8C.assets/ebf18d1d264fdb90968c717a86e6888d697559838.png)\n\n![image-20230920001826386](../img/Ansible-%E6%80%BB%E6%89%8B%E5%86%8C.assets/b42ddf38524dddc14e86d4c710d97922697559838.png)\n\n2、停止服务\n\n```\nansible 192.168.48.101 -m service -a 'name=httpd state=stopped'\n```\n\n![image-20230920001941649](../img/Ansible-%E6%80%BB%E6%89%8B%E5%86%8C.assets/7ddf22463363605d6f0e87cf6ff1e725697559838.png)\n\n3、重启服务\n\n```\nansible 192.168.48.101 -m service -a 'name=httpd state=restarted'\n```\n\n![image-20230920002005593](../img/Ansible-%E6%80%BB%E6%89%8B%E5%86%8C.assets/d80886bd03e975c2b785a9498f3376a3697559838.png)\n\n### firewalld模块\n\n<font color='red'>常见参数</font>\n\n```\nsource：数据源（相当于--add-source）\ninterface：端口（相当于--add-port）\nservice：服务（相当于--add-service）\nzone：关联区域（相当于--zone）\npermanent：永久生效（相当于--permanent）\nimmediate：立即生效（相当于执行了firewall-cmd --reload）\nstate：防火墙规则状态（enabled | disabled）（必填项）\nrich_rule：富规则（相当于--add-rich-rule=''）\n```\n\n<font color='red'>使用案例</font>\n\n1、添加基本规则\n\n在node1中将http服务进行放行，并关联到public区域中，立即生效且永久生效\n\n```\nansible 192.168.48.101 -m firewalld -a 'zone=public service=http permanent=yes immediate=yes state=enabled'\n```\n\n## 综合练习\n\n（1）在node01上创建一个用户devops：\n\n```shell\nansible node01 -m user -a \"name=devops state=present\"\n```\n\n![image-20230919211657605](../img/Ansible-%E6%80%BB%E6%89%8B%E5%86%8C.assets/43311590cf4293eebf8e6c6e4525fe7f697559838.png)\n\n（2）在node01上创建一个目录 /devops，设置所属组、权限：\n\n```shell\nansible node01 -m file -a \"path=/devops state=directory owner=devops group=devops mode=0755\"\n ansible node01 -m shell -a \"ls -l /\"  \n```\n\n![image-20230919211756676](../img/Ansible-%E6%80%BB%E6%89%8B%E5%86%8C.assets/c070db8ae1c1081b3afa5ce73bfd475c697559838.png)\n\n（3）安装httpd服务，设定开机自启动，验证服务状态为启动：\n\n```shell\nansible node01 -m yum -a \"name=httpd state=present\"\nansible node01 -m service -a \"name=httpd state=started enabled=yes\"\n```\n\n![image-20230912173234830](../img/Ansible-%E6%80%BB%E6%89%8B%E5%86%8C.assets/e161fc889e76fee81d98bb5f76ab6b4f697559838.png)\n\n![image-20230912173228899](../img/Ansible-%E6%80%BB%E6%89%8B%E5%86%8C.assets/2945a200e016c4bdc2785f2b5616d9e5697559838.png)\n\n（4）创建一个文件 /devops/index.html 包含一行内容：DevOps：\n\n```shell\nansible node01 -m copy -a \"content='DevOps\\n' dest=/devops/index.html\"\n```\n\n![image-20230919211916628](../img/Ansible-%E6%80%BB%E6%89%8B%E5%86%8C.assets/e5ca64b7e2b60729b8f77919d2cbe9fd697559838.png)\n\n（5）创建软链接：/var/www/html/index.html 到 /devops/index.html：\n\n```shell\nansible node01 -m file -a \"src=/devops/index.html dest=/var/www/html/index.html state=link force=true\"\n```\n\n![image-20230919211928515](../img/Ansible-%E6%80%BB%E6%89%8B%E5%86%8C.assets/1459bab864fc683648b370727a50ab0e697559838.png)\n\n（6）验证软链接：\n\n```shell\nansible node01 -m shell -a \"ls -l  /var/www/html/index.html\"\n```\n\n![image-20230919211941716](../img/Ansible-%E6%80%BB%E6%89%8B%E5%86%8C.assets/6a902872ae6c3a772f771257ad5ebdca697559838.png)\n\n（7）取消软链接，新建/var/www/html/index.html 文档，访问网页：\n\n```shell\nansible node01 -m file -a \"path=/var/www/html/index.html state=absent\"\nansible node01 -m copy -a \"content='Hello World' dest=/var/www/html/index.html\"\n```\n\n![image-20230919212000893](../img/Ansible-%E6%80%BB%E6%89%8B%E5%86%8C.assets/942dcfaf88048644ec1383c6aaf454c5697559838.png)\n\n![image-20230919212022836](../img/Ansible-%E6%80%BB%E6%89%8B%E5%86%8C.assets/25c4d54e6951d50a51ae34425952395e697559838.png)\n\n使用浏览器访问http://192.168.48.101验证主页信息\n\n# Ansible-Playbook\n\n## 介绍\n\n> playbook是由一个或多个\"play\"组成的列表\n> play的主要功能在于将预定义的一组主机，装扮成事先通过ansible中的task定义好的角色。\n> Task实际是调用ansible的一个module，将多个play组织在一个playbook中，\n> 即可以让它们联合起来，按事先编排的机制执行预定义的动作\n> Playbook采用YAML语言编写\n\n```\n用户通过ansible命令直接调用yml语言写好的playbook,playbook由多条play组成\n每条play都有一个任务(task)相对应的操作,然后调用模块modules，应用在主机清单上,通过ssh远程连接\n从而控制远程主机或者网络设备\n```\n\n## YAML语法\n\n```\n> 在单一档案中，可用连续三个连字号（---）区分多个档案。\n  另外，还有选择性的连续三个点号( ... )用来表示档案结尾\n> 次行开始正常写Playbook的内容，一般建议写明该Playbook的功能\n> 使用#号注释代码\n> 缩进必须是统一的，不能空格和tab混用，一般缩进2个空格\n> 缩进的级别也必须是一致的，同样的缩进代表同样的级别，程序判别配置的级别是通过缩进结合换行来实现的\n> YAML文件内容是区别大小写的，key/value的值均需大小写敏感\n> 多个key/value可同行写也可换行写，同行使用:分隔，同一行使用 , 逗号分隔\n> value可以是个字符串，也可是另一个列表[]\n> 一个完整的代码块功能需最少元素需包括 name 和 task\n> 一个name只能包括一个task\n> YAML中不允许在双引号中出现转义符号，所以都是以单引号来避免转义符错误\n> 使用 | 和 > 来分隔多行，实际上这只是一行。 \n> YAML文件扩展名通常为yml或yaml\n```\n\n三种常见的数据交换格式\n\n![7](../img/Ansible-%E6%80%BB%E6%89%8B%E5%86%8C.assets/0b09dccd30360520c75ca7cf06f2027a697559838.png)\n\n```\nYAML的语法和其他高阶语言类似，并且可以简单表达清单、散列表、标量等数据结构。\n序列（Sequence）里的项用\"-\"来代表，Map里的键值对（字典）用\":\"分隔\n示例\n    name: John Smith\n    age: 41\n    gender: Male\n    spouse:\n      name: Jane Smith\n      age: 37\n      gender: Female\n    children:\n      - name: Jimmy Smith\n        age: 17\n        gender: Male\n      - name: Jenny Smith\n        age 13\n        gender: Female\n```\n\n## 修改vim\n\n```\nvim ~/.vimrc\nset nu       \nset paste    \nset cursorline \nset cursorcolumn \nautocmd FileType yaml setlocal ai et ts=2 sw=2 \n\n\nset nu       #显示行号\nset paste    #黏贴内容保留格式\nset cursorline #行定位\nset cursorcolumn #列定位\nautocmd FileType yaml setlocal ai et ts=2 sw=2 \n#FileType 代表文件类型,后边跟参数yaml，就是这个作用于yaml文件，编写其他文件时不起作用\n#ts=2是tabstop=2的缩写，表示使用2个空格自动代替tab键\n#et=expandtab 表示tab键的缩写\n#sw=2 是shiftwidth=2的缩写，表示开启自动缩进对齐，缩进宽度为2个空格\n#ai=auto indent   自动退格对齐\\\n\n```\n\n将这段代码添加到 `~/.vimrc` 文件中，以使 Vim 在启动时自动应用这些设置\n\n## playbook基础组件\n\n一个简单的剧本模型（YAML语言） \n\n1> 缩进：用两个空格缩进 \n\n2> 列表：用 - \n\n3> 字典：key: value \n\n```\n--- \n- hosts: YYY          #待操作主机集，可以不写，执行时通过 -i 调用host文件\n  remote_user： root  #在远端使用哪个用户执行\n  tasks:              #任务集（必须）\n  - name: task1       #只是一个文本提示，执行时会输出其中内容（例如输出Install httpd）\n    module1:          #真正干活的部分，其实就是前面讲过的ansible各种模块\n      argument1 : value1 \n      argument2 : value2 \n  - name: task2 \n    module2:\n      argument1 : value1 \n      argument2 : value2 \n... \n```\n\n解释：\n\n```\nHosts：\n    > playbook中的每一个play的目的都是为了让特定主机以某个指定的用户身份执行任务。\n      hosts用于指定要执行指定任务的主机，须事先定义在主机清单中\n\n```\n\n```\nremote_user: \n    可用于Host和task中。\n    也可以通过指定其通过sudo的方式在远程主机上执行任务，其可用于play全局或某任务；\n    此外，甚至可以在sudo时使用sudo_user指定sudo时切换的用户\n    - hosts: all\n      remote_user: root   (可省略,默认为root)  以root身份连接\n      tasks:    指定任务\n      - name: test connection\n        ping:\n          remote_user: magedu\n          sudo: yes           默认sudo为root\n          sudo_user:wang      sudo为wang\n```\n\n```\ntask列表和action\n    任务列表task:由多个动作,多个任务组合起来的,每个任务都调用的模块,一个模块一个模块执行\n    1> play的主体部分是task list，task list中的各任务按次序逐个在hosts中指定的所有主机上执行，\n       即在所有主机上完成第一个任务后，再开始第二个任务\n\n    2> task的目的是使用指定的参数执行模块，而在模块参数中可以使用变量。\n   模块执行是幂等的，这意味着多次执行是安全的，因为其结果均一致\n\n    3> 每个task都应该有其name，用于playbook的执行结果输出，建议其内容能清晰地描述任务执行步骤。\n   如果未提供name，则action的结果将用于输出\n```\n\n## playbook书写风格\n\n简单案例：\n\n编写echo.yaml文件，内容如下\n\n```\nvim echo.yaml\n---\n- hosts: 192.168.48.102\n  tasks:\n  - name: 输出1\n    shell: echo \"1\"\n  - name: 输出2\n    shell: echo \"2\"\n...\n#执行该剧本文件：\nansible-playbook echo.yaml  \n```\n\n命令执行返回的结果:\n\n第一行PLAY表示执行的主机或者主机组。\n第二行TASK[Gathering Facts]，在 Playbook 中并没有定义，这是Ansible自带的task 收集主机的信息，此功能非常实用，后面的任务中会详细讲解。这里仅需知晓task为Ansible自带的功能，可以通过Playbook中添加 gather_facts: no 进行关闭。\n下面两个task是自行编辑的task，可以发现没有返回结果，但是当出现黄色的changed时代表执行或者修改成功。changed代表前后状态发生改变,例如使用copy模块，拷贝同一个东西，第一次执行成功的时候是changed状态，第二次再执行的时候就是ok状态。ok状态代表:Ansible检查了需要更改的内容发现前后没有变化，所以直接返回ok状态，实际上 Ansible并没有去执行该操作。最后代表状态,即 Playbook的执行结果。ok表示检查了但不需要操作的任务量。failed表示执行失败的数量，changRed代表状unreachable表示不可达的主机数态更改的数量，ok+changed 才代表执行完成的任务数量。\n\n## 编写playbook\n\n```yaml\nvim httpd.yaml\n--- ##列出第一个play \n- name: Install httpd package and start httpd service ##标明 该play的用途 \n  hosts: 192.168.142.101 ##指定对其运行play中任务的主机（必填项，指定多台主机可以使用分组，或者 , 分隔） \n  tasks: ##play的任务列表 \n  - name: Install httpd package ##任务1的描述 \n    yum: ##任务1调用yum模块，模块内容往下写 \n      name: httpd ##参数1：yum模块需要使用的软件包 \n      state: present ##参数2：安装软件包#以上任务等同于 ansible 192.168.142.101 -m yum -a \"name=httpd state=present\" \n\n  - name: Start httpd service ##任务2的描述 \n    service: ##任务2调用服务模块 \n      name: httpd ##参数1：service调用的服务名称 \n      state: started ##参数2：service调用服务要达到的目标状态 \n      enabled: yes ##参数3：调用的服务开机启动 \n#以上任务等同于 ansible 192.168.142.101 -m service -a \"name=httpd state=started enabled=yes\" \n```\n\n![image-20221114191416282](../img/Ansible-%E6%80%BB%E6%89%8B%E5%86%8C.assets/d3e9b9147d35e3d3f3456b1054e3fafa697559838.png)\n\n## 运行playbook\n\n```\n运行playbook的方式\n    ansible-playbook <filename.yaml> ... [options]\n\n常见选项\n    --check -C       只检测可能会发生的改变，但不真正执行操作 \n                     (只检查语法,如果执行过程中出现问题,-C无法检测出来)\n                     (执行playbook生成的文件不存在,后面的程序如果依赖这些文件,也会导致检测失败)\n    --list-hosts     列出运行任务的主机\n    --list-tags      列出tag  (列出标签)\n    --list-tasks     列出task (列出任务)\n    --limit 主机列表 只针对主机列表中的主机执行\n    -v -vv -vvv      显示过程\n\n示例\n    ansible-playbook hello.yaml --check 只检测\n    ansible-playbook hello.yaml --list-hosts  显示运行任务的主机\n    ansible-playbook hello.yaml --limit 192.168.142.101  限制主机\n    ansible-playbook hello.yaml --list-tasks  显示运行任务的主机\n\n```\n\n**1、在ansible工作目录运行** 完整剧本：httpd.yaml\n\n```\n执行剧本\nansible-playbook playbooks/httpd.yaml\n验证服务\nansible 192.168.142.101 -m shell -a 'rpm -qa |grep httpd'\nansible 192.168.142.101 -m shell -a 'netstat -ntulp |grep 80'\n```\n\n![image-20221025160724333](../img/Ansible-%E6%80%BB%E6%89%8B%E5%86%8C.assets/7f7fc00f8a894e4ae4cd203a40586c6f697559838.png)\n\n**2.提高输出的详细程度**\n\n![image-20221025160900182](../img/Ansible-%E6%80%BB%E6%89%8B%E5%86%8C.assets/fd3bad2b52a5e7a286d566f404cd32c3697559838.png)\n\n注：通常使用 ansible-playbook -v 即可。\n\n![image-20221025160914676](../img/Ansible-%E6%80%BB%E6%89%8B%E5%86%8C.assets/ebc8eb622e0c51ce411c8fc6e565b080697559838.png)\n\n**3.执行空运行（冒烟运行）**\n\n![image-20221025160948414](../img/Ansible-%E6%80%BB%E6%89%8B%E5%86%8C.assets/fa4468962ea4914e6af8862b73fc400c697559838.png)\n\n![image-20221025160959873](../img/Ansible-%E6%80%BB%E6%89%8B%E5%86%8C.assets/8dc2f2b09e7590c3e41c6707c5e3cbcd697559838.png)\n\n## handlers+notify\n\nHandlers 实际上就是一个<font color='red'>触发</font>器，是task列表，这些task与前述的task并没有本质上的不同,用于当关注的资源发生变化时，才会采取一定的操作。任务都有状态changed或者ok，只有在任务执行状态为change时，才执行该任务调用的handler。\n\nNotify此action可用于在每个play的最后被触发，这样可避免多次有改变发生时每次都执行指定的操作，仅在所有的变化发生完成后一次性地执行指定操作。在notify中列出的操作称为handler，也<font color='red'>即notify中调用handler中定义的操作</font>\n\n\n\n<font color='red'>示例1：</font>\n\n1. 使用playbook安装httpd，并验证服务启动，查看httpd使用的端口\n\n```shell\nvim httpd3.yaml\n---\n- hosts: all\n  remote_user: root\n\n  tasks:\n  - name: Install httpd\n    yum:\n      name: httpd\n      state: present\n  - name: ensure apache is running\n    service:\n      name: httpd\n      state: started\n      enabled: yes\n\nansible-playbook httpd3.yaml\nansible all -m shell -a 'systemctl status httpd'\nansible all -m shell -a 'netstat -tunlp|grep httpd'\n```\n\n2. 在被控端（<font color='red'>两台机</font>）修改httpd的conf文件，监听端口改成8080\n\n```yaml\nmkdir -p /root/ansible/files\ncp /etc/httpd/conf/httpd.conf  /root/ansible/files\n#如果前面httpd3运行成功，说明成功安装httpd，则httpd.conf会存在\nvim /root/ansible/files/httpd.conf\n#将Listen 80 修改为Listen 8080\n```\n\n3. 修改剧本文件，增加拷贝配置文件的task，并重新执行剧本。\n\n```yaml\nvim httpd4.yaml\n---\n- hosts: all\n  remote_user: root\n  tasks:   \n  - name: Install httpd\n    yum:\n      name: httpd\n      state: present\n  - name: backup httpd.conf\n    shell: cp /etc/httpd/conf/httpd.conf{,.bak}\n  #备份原文件\n  - name: copy configure file\n    copy: \n      src: /root/ansible/files/httpd.conf \n      dest: /etc/httpd/conf/\n      backup: yes\n  #第二步修改了8080端口，将文件移回原处覆盖源文件\n  - name: ensure apache is running\n    service:\n      name: httpd\n      state: started\n      enabled: yes\n\nansible-playbook httpd4.yaml\nansible all -m shell -a 'cat /etc/httpd/conf/httpd.conf|grep 8080'\nansible all -m shell -a 'systemctl status httpd'\nansible all -m shell -a 'netstat -tunlp|grep httpd'\n#发现修改配置，但没有生效，因为没有重启httpd应用\n```\n\n3. 增加handlers和notify\n\n```yaml\nvim httpd4.yaml\n---\n- hosts: all\n  remote_user: root\n  tasks:   \n  - name: Install httpd\n    yum:\n      name: httpd\n      state: present\n  - name: copy configure file\n    copy: \n      src: /root/ansible/files/httpd.conf \n      dest: /etc/httpd/conf/\n      backup: yes\n    #调用触发列表里的 restart httpd任务，调用之后重启httpd，配置文件即刻生效\n    notify: restart httpd\n  - name: ensure apache is running\n    service:\n      name: httpd\n      state: started\n      enabled: yes\n#触发器列表\n  handlers:\n  - name: restart httpd\n    service: \n      name: httpd \n      state: restarted\n        \n        \nansible-playbook httpd4.yaml\nansible all -m shell -a 'netstat -tunlp|grep httpd'\n发现端口是8080（即成功）\n```\n\n修改/root/ansible/files/httpd.conf ，将端口修改为8081，重新执行httpd4.yaml，并验证服务端口已经改变。\n\n```\nansible-playbook httpd4.yaml\nansible all -m shell -a 'netstat -tunlp|grep httpd'\n```\n\n发现端口变成8081，说明只有在任务执行状态为change时，才执行该任务调用的handler。\n\n## TAGS\n\n<font color='red'>tage: 添加标签 </font>\n<font color='orange'>可以指定某一个任务添加一个标签,添加标签以后,想执行某个动作可以做出挑选来执行,多个动作可以使用同一个标签</font>\n\n停止httpd服务\n\n```\nansible all -m service -a 'name=httpd  state=stopped'\nansible all -m shell -a 'ss -tln |grep :8081'\n```\n\n```yaml\n[root@controller ~]# vi httpd5.yaml\n---\n- hosts: all\n  remote_user: root\n  tasks:\n  - name: install httpd\n    yum:\n      name: httpd\n      state: present\n    tags: install #install标签\n  - name: set listen8080\n    shell: sed -i \"s/Listen 80/Listen 8080/g\" /etc/httpd/conf/httpd.conf\n    tags: set8080 #设置8080标签\n  - name: backup cofing\n    copy:\n      src: /etc/httpd/conf/httpd.conf\n      dest: /etc/httpd/conf/httpd.conf\n      backup: yes\n    notify: restart httpd\n    tags: backup #备份标签\n  - name: 配置 httpd 服务\n    service:\n      name: httpd\n      state: started\n      enabled: yes\n    tags: started #开启httpd服务标签\n  handlers:\n  - name: restart httpd\n    service:\n      name: httpd\n      state: restarted\n    tags: restart  #重启服务标签\n...\n\n```\n\n```yaml\nansible-playbook -tstarted httpd5.yaml   \n#指定执行started 这个标签\nansible all -m shell -a 'ss -tln |grep :8080'\nansible-playbook -t install,conf httpd.yaml   \n#指定执行install,backup 两个标签\n```\n\n## 管理变量\n\n![image-20221025165509586](../img/Ansible-%E6%80%BB%E6%89%8B%E5%86%8C.assets/ae1d61c9756b2d4c0b078b277db79758697559838.png)\n\n变量定义：key=value\n    示例：http_port=80\n\n变量调用方式：\n    1> 通过{{ variable_name }} 调用变量，<font color='red'>且变量名前后必须有空格</font>，有时用\"{{ variable_name }}\"才生效 (<font color='red'>引号</font>）\n\n### 在playbook中定义\n\nvars语句定义全局变量（该变量作用于整个Play） \n\n```yaml\nvim test_vars.yaml\n\n---\n- name: test_var\n  hosts: all\n  vars:\n    username: test_user1\n  tasks:\n  - name:  create user via a variable file\n    user:\n      name: \"{{ username }}\"    \n      #冒号后面不能以{开头，不然会报语法错误，需要加上引号。\n      state: present\n#创建一个test_user1的用户\n \n ansible-playbook -v test_vars.yaml \n \n ansible all -m shell -a 'getent passwd test_user1'\n```\n\n![image-20221025165757353](../img/Ansible-%E6%80%BB%E6%89%8B%E5%86%8C.assets/474483b4ac7c6bae8c1f67e44e1488a2697559838.png)\n\n执行结果： \n\n![image-20221025165815465](../img/Ansible-%E6%80%BB%E6%89%8B%E5%86%8C.assets/6a81099b1493d280df6d9bc47ddc7034697559838.png)\n\n#### 课堂练习\n\n通过playbook中定义用户名和组名，实现变量引用，创建用户和组。\n\n```yaml\nvim var.yaml\n---\n- hosts: all\n  remote_user: root\n  vars:\n  - username: user1\n  - groupname: group1\n  tasks:\n  - name: create group\n    group: \n      name: \"{{ groupname }}\" \n      state: present\n  - name: create user\n    user: \n      name: \"{{ username }}\" \n      state: present\n\nansible-playbook -v var.yaml\nansible all -m shell -a 'getent passwd user1'\nansible all -m shell -a 'getent group group1'\n```\n\n2.\n\n```yaml\n开启防火墙\nansible all -m shell -a 'systemctl start firewalld'\n\nvim firewall.yaml\n---\n- hosts: all\n  remote_user: root\n  vars:\n  - http_port: 80\n  tasks:\n  - name: insert firewalld rule for httpd\n    firewalld: \n      port: \"{{ http_port }}/tcp\" \n      permanent: true \n      state: enabled \n      immediate: yes\n    \nansible-playbook -v firewall.yaml\n\nansible all -m shell -a 'systemctl stop firewalld'\nansible all -m shell -a 'firewall-cmd --query-port=80/tcp'  \n```\n\n### 在独立的变量YAML文件中定义\n\n当变量较多的时候，或者变量需要多个playbook重用的时候，可以把变量放到独立的文件中，通过关键字\"var_files\"把文件中定义的变量引用到playbook中。\n\nvars_files 引用变量文件（只能所用于Play全局，不能在某个task中单独被引用）\n\n```yaml\nvim var_file.yaml\nusername: test_user3\n\nvim test_var_file.yaml\n---\n- name: test_var_file\n  hosts: all\n  vars_files:\n  - /root/var_file.yaml\n  tasks:\n  - name:  create user via a variable file\n    user:\n      name: \"{{ username }}\"\n      state: present\n...\n \n ansible-playbook -v test_var_file.yaml\n \n ansible all -m shell -a 'getent passwd test_user3'\n\n```\n\n练习：将防火墙端口写入\n\n```yaml\n将变量写进单独的配置文件中引用\ntest_var_file.yaml\n---\n- hosts: all\n  remote_user: root\n  vars_files:\n  - /root/var_file.yaml\n  tasks:\n  - name: insert firewalld rule for httpd\n    firewalld: \n      port: \"{{ http_port }}/tcp\" \n      permanent: true \n      state: enabled \n      immediate: yes\n...\nvim var_file.yaml\nhttp_port: 78\n\nansible-playbook -v test_var_file.yaml\nansible all -m shell -a 'firewall-cmd --query-port=78/tcp'  \n```\n\n### 远程主机上的系统变量（Facts事实）\n\nansible会通过setup模块来搜集主机的系统信息，这些搜集到的系统信息叫做Facts。\n\n![image-20221026102238684](../img/Ansible-%E6%80%BB%E6%89%8B%E5%86%8C.assets/24c7b2090b6a9419a3aefc79545adba5697559838.png)\n\n每个playbook在执行前都会默认执行setup模块，所以这些facts信息是可以以变量的形式被使用。\n\n#### 查看Facts变量\n\n```yaml\nansible all -m setup 能查看到node节点的所有信息\nansible 192.168.48.101 -m setup |grep ansible_hostname\n或者可以使用filter过滤信息\nansible all -m setup -a 'filter=\"ansible_hostname\"'  查询主机名\nansible all -m setup -a 'filter=\"ansible_default_ipv4\"'  查询ipv4地址\nansible all -m setup -a \"filter=ansible_memory_mb\"查询内存\n\n\n其他常用信息列出如下：\nansible_all_ipv4_addresses：仅显示ipv4的信息。\nansible_devices：仅显示磁盘设备信息。\nansible_distribution：显示是什么系统，例：centos,suse等。\nansible_distribution_major_version：显示是系统主版本。\nansible_distribution_version：仅显示系统版本。\nansible_machine：显示系统类型，例：32位，还是64位。\nansible_eth0：仅显示eth0的信息。\nansible_hostname：仅显示主机名。\nansible_kernel：仅显示内核版本。\nansible_lvm：显示lvm相关信息。\nansible_memtotal_mb：显示系统总内存。\nansible_memfree_mb：显示可用系统内存。\nansible_memory_mb：详细显示内存情况。\nansible_swaptotal_mb：显示总的swap内存。\nansible_swapfree_mb：显示swap内存的可用内存。\nansible_mounts：显示系统磁盘挂载情况。\nansible_processor：显示cpu个数(具体显示每个cpu的型号)。\nansible_processor_vcpus：显示cpu个数(只显示总的个数)。\n```\n\n#### 使用Facts变量\n\n```yaml\nvim var2.yaml\n---\n- hosts: all\n  remote_user: root\n  tasks:\n  - name: create log file\n    file: \n      name: /root/{{ ansible_hostname }} \n      state: touch\n\nansible-playbook var2.yaml\n\nansible all -m shell -a 'ls /root|grep node*'\n```\n\n#### 复杂Facts变量的使用\n\n![image-20231002194745624](../img/Ansible-%E6%80%BB%E6%89%8B%E5%86%8C.assets/cd3caf0b2d86c1b4b3865e00a3b021b6697559838.png)\n\n方式1：使用中括号\n\n```\n{{ ansible_date_time[\"date\"] }}\n```\n\n方式2：使用点号（<font color='red'>推荐</font>）\n\n```\n{{ ansible_date_time.date }}\n```\n\n```yaml\nvim var2.yaml\n---\n- hosts: all\n  remote_user: root\n  tasks:\n  - name: 22\n    copy:\n      content: \"{{ ansible_date_time.date }}\"\n      dest: /tmp/f1\n\nansible-playbook var2.yaml\n\nansible all -m shell -a 'cat /tmp/f1'\n```\n\n#### 关闭Facts\n\n搜集facts会消耗额外时间，可以在剧本中设置是否开启和关闭facts搜集。\n\n开启gather_facts:yes，关闭gather_facts:no\n\n![image-20221026112345723](../img/Ansible-%E6%80%BB%E6%89%8B%E5%86%8C.assets/56eb52bea0d5b4c256492463c0e30800697559838.png)\n\n### 在/etc/ansible/hosts(主机清单)中定义变量\n\n<font color='red'>普通变量</font>：主机组中主机单独定义，优先级高于公共变量(单个主机 )\n<font color='red'>公共(组)变量</font>：针对主机组中所有主机定义统一变量(一组主机的同一类别)\n\n可以是主机级别或者是主机组级别的 \n\n**定义主机级别变量**\n\n```\nvim  /etc/ansible/hosts\n[all]\n192.168.48.101 username=test_user3   #主机级别变量\n192.168.48.102 username=test_user4  \n\n```\n\n编辑剧本文件\n\n```\nvim test_vars2.yaml\n---\n- name: test inventory vars\n  hosts: all\n  tasks:\n  - name:  create user via a variable file\n    user:\n      name: \"{{ username }}\"\n      state: present\n\nansible-playbook -v test_vars2.yaml \n \nansible all -m shell -a 'getent passwd test_user3'\nansible all -m shell -a 'getent passwd test_user4'\n```\n\n**主机组级别定义变量（相对于主机级别定义的变量，优先级较低）**\n\n```\nvim  /etc/ansible/hosts\n[all]\n192.168.142.101 username=test_user3   #主机级别变量\n192.168.142.102   \n\n[all:vars]\nusername=test_user5\n\nansible-playbook -v test_vars2.yaml \n发现第一台主机不变，第二台主机创建新的用户test_user5,证明主机组变量比主机变量优先级低\n```\n\n### 通过命令行指定变量\n\n```\nansible-playbook -e 变量 剧本（优先级最高）\n\nansible-playbook -v -e username=test_user10 test_vars2.yaml \n```\n\n![image-20231002210715495](../img/Ansible-%E6%80%BB%E6%89%8B%E5%86%8C.assets/263bfcf810cb6203d0f09bfc2cab051a697559838.png)\n\n\n\n安装httpd服务\n\n```\n示例：test_vars3.yaml \n---\n- hosts: all\n  remote_user: root\n  tasks:\n  - name: install package\n    yum:\n      name: \"{{ pkname }}\"\n      state: present\n  - name: start service\n    service:\n      name: \"{{ pkname }}\"\n      state: started\n      enabled: yes\n\n\nansible-playbook –e pkname=httpd test_vars3.yaml \n```\n\n\n\n```\n示例：test_vars3.yaml \n---\n- hosts: all\n  remote_user: root\n  tasks:\n  - name: install package\n    yum: \n      name: \"{{ pkname1 }}\" \n      state: present\n  - name: install package\n    yum: \n      name: \"{{ pkname2 }}\" \n      state: present\n  \nansible-playbook -e 'pkname1=httpd pkname2=tree' -v test_vars3.yaml \n```\n\n### 复杂变量的使用\n\n#### **数组**\n\n如果我们定义变量，而这些值都属于同一类型的元素，那么我们必定要用数组。\n\n例如：\n\n```\nvim test_com_var.yaml\n\n---\n- hosts: all\n  vars:\n    user_name:\n    - test_user11\n    - test_user12\n    - test_user13\n    - test_user14\n  tasks:\n  - name: create users\n    user:\n      name: \"{{ user_name[1] }}\"\n      state: present\n```\n\n![image-20221115081508398](../img/Ansible-%E6%80%BB%E6%89%8B%E5%86%8C.assets/6f57de99c88237b43b4ccbc3a67c02d4697559838.png)\n\n验证：ansible-playbook -v test_com_var.yaml\n\n![image-20221026101059249](../img/Ansible-%E6%80%BB%E6%89%8B%E5%86%8C.assets/b254ba1554853d1d124698f5bdd079cd697559838.png)\n\n注意：在用user模块建用户的时候，只能调用数组中的某一个值，不能全部调用，否则报错“用户名不合法”\n\n![image-20221026101118216](../img/Ansible-%E6%80%BB%E6%89%8B%E5%86%8C.assets/2bc27ba298e15057aac6e29976c63050697559838.png)\n\n![image-20221115081951322](../img/Ansible-%E6%80%BB%E6%89%8B%E5%86%8C.assets/ed1ae8495f0953b23e7e6a5944652254697559838.png)\n\n#### 字典（dictionary）\n\n如果我们的变量信息中具备多种不同的元素时，采用字典。\n\n例如：\n\n```\nvim test_com_var.yaml\n\n---\n- name: test_dict\n  hosts: all\n  vars:\n    user_info:\n      test_user20:\n        name: test_user20\n        shell: /bin/bash\n        comment: test_user20\n      test_user21:\n        name: test_user21\n        shell: /bin/bash\n        comment: test_user21\n  tasks:\n  - name: create users via dict\n    user:\n      name: \"{{ user_info['test_user20']['name'] }}\"\n      shell: \"{{ user_info['test_user20']['shell'] }}\"\n      state: present\n\n```\n\n![image-20221026101138894](../img/Ansible-%E6%80%BB%E6%89%8B%E5%86%8C.assets/2c0f83a584a0de9b2f45259771a498c7697559838.png)\n\n![image-20221115083012804](../img/Ansible-%E6%80%BB%E6%89%8B%E5%86%8C.assets/28bbd22e9a70bfe446654d04e842304e697559838.png)\n\n变量引用的另一种写法：引用对象写法（python语法）\n\n![image-20221026101222577](../img/Ansible-%E6%80%BB%E6%89%8B%E5%86%8C.assets/0cb84cd54a577813a2f32a666c2f2721697559838.png)\n\n注意：以点作为分隔（引用对象）这种方式，可能会和python本身的语义引起冲突，所以不建议使用这种方式\n\n### 注册变量\n\n注册变量是指将一个任务（task）的输出结果定义到一个变量中，这个变量就可以在随后的任务中像普通变量一样使用。\n很多情况下，注册变量用来收集shell的执行结果，结果中包含标准输入和标准输出。接下来使用shell模块执行命令将命令结果传入名为var_echo 的变量并使用debug进行检测。\nregister 的使用形如 register: varname，即 register模块后直接加变量名即可，而register这一行仅仅需要写在需要收集输出的那一行下即可。\n\n案例：\n\n```\nvim test_com_var.yaml\n\n---\n- name: test_dict\n  hosts: all\n  vars:\n    user_info:\n      test_user20:\n        name: test_user20\n        shell: /bin/bash\n        comment: test_user20\n      test_user21:\n        name: test_user21\n        shell: /bin/bash\n        comment: test_user21\n  tasks:\n  - name: create users via dict\n    user:\n      name: \"{{ user_info.test_user21.name }}\"\n      shell: \"{{ user_info.test_user21.shell }}\"\n      state: present\n\nansible-playbook test_com_var.yaml\n\n```\n\n执行结果如下：\n\n![image-20221115083847092](../img/Ansible-%E6%80%BB%E6%89%8B%E5%86%8C.assets/6211a906fd3492c7c9a38e99578b03ba697559838.png)\n\n修改剧本文件，加入debug模块\n\n```\nvim test_com_var.yaml\n\n- name: test_dict\n  hosts: all\n  vars:\n    user_info:\n      test_user20:\n        name: test_user20\n        shell: /sbin/nologin\n        comment: test_user20\n      test_user21:\n        name: test_user21\n        shell: /sbin/nologin\n        comment: test_user21\n  tasks:\n  - name: create users via dict\n    user:\n      name: \"{{ user_info.test_user21.name }}\"\n      shell: \"{{ user_info.test_user21.shell }}\"\n      state: present\n    register: user_result\n\n  - name: debug result of user creation\n    debug:\n      msg: \"{{ user_result }}\"\n\n      \nansible-playbook test_com_var.yaml\n\n```\n\n运行结果：\n\n![image-20221115084502083](../img/Ansible-%E6%80%BB%E6%89%8B%E5%86%8C.assets/2a24783539db1e28f3235517339f1677697559838.png)\n\n可以引用结果中的部分元素（user_result['uid'] / user_result.uid）\n\n```\nvim test_com_var.yaml\n\n- name: test_dict\n  hosts: all\n  vars:\n    user_info:\n      test_user20:\n        name: test_user20\n        shell: /sbin/nologin\n        comment: test_user20\n      test_user21:\n        name: test_user21\n        shell: /sbin/nologin\n        comment: test_user21\n  tasks:\n  - name: create users via dict\n    user:\n      name: \"{{ user_info.test_user21.name }}\"\n      shell: \"{{ user_info.test_user21.shell }}\"\n      state: present\n    register: user_result\n\n  - name: debug result of user creation\n    debug:\n      msg: \"{{ user_result.uid }}\"\n      \n  ansible-playbook test_com_var.yaml    \n```\n\n运行结果：\n\n![image-20221115084642928](../img/Ansible-%E6%80%BB%E6%89%8B%E5%86%8C.assets/03f435628b2b8c8482455bb564e6bcb1697559838.png)\n\n可以对输出结果进行迭代引用（用register存在多个变量中）\n\n```\nvim test_com_var.yaml\n---\n- name: test_dict\n  hosts: all\n  vars:\n    user_info:\n      test_user20:\n        name: test_user20\n        shell: /sbin/nologin\n        comment: test_user20\n      test_user21:\n        name: test_user21\n        shell: /sbin/nologin\n        comment: test_user21\n  tasks:\n  - name: create users via dict\n    user:\n      name: \"{{ user_info.test_user21.name }}\"\n      shell: \"{{ user_info.test_user21.shell }}\"\n      state: present\n    register: user_result\n\n  - name: debug result of user creation\n    debug:\n      msg: \"{{ user_result.uid }}\"\n    register: shell_result\n  \n  - name: debug result of shell\n    debug:\n      msg: \"{{ shell_result }}\"\n      \n  ansible-playbook test_com_var.yaml    \n```\n\n\n\n![image-20221026101500419](../img/Ansible-%E6%80%BB%E6%89%8B%E5%86%8C.assets/afce8fc500c006fdc6c8a45e60ddfedf697559838.png)\n\n## Ansible Vault（Ansible 保管箱）\n\n作用：加密敏感的数据、密码等信息，通常情况下都是定义在变量内的敏感信息。\n\n应用的情景：\n\n1> 加密变量文件（敏感数据、密码信息等）\n\n2> 加密证书\n\n命令：ansible-vault\n\n命令用法：\n\n### 创建一个加密文件：\n\n**ansible-vault create sec.yaml**\n\n![image-20221026101756674](../img/Ansible-%E6%80%BB%E6%89%8B%E5%86%8C.assets/7e575bfdbbc81080494e244fa61c97b1697559838.png)\n\n使用vim sec.ym或者cat sec.yaml只能看到加密后的内容\n\n![image-20221115085325103](../img/Ansible-%E6%80%BB%E6%89%8B%E5%86%8C.assets/9dfe8e950735a40ce3ba0c269e2308c4697559838.png)\n\n### 如何查看加密过的文件内容：\n\n![image-20221026101816806](../img/Ansible-%E6%80%BB%E6%89%8B%E5%86%8C.assets/8aae3bf08d3fcaa251077bcc3a4f3511697559838.png)\n\n### 如何在剧本中调用加密文件\n\n```\nvim test_vault.yaml\n\n---\n- name: Create users via vault\n  hosts: all\n  vars_files:\n  - /root/sec.yaml\n  tasks:\n  - name: Create users\n    user:\n      name: \"{{ username }}\"\n      state: present\n\n```\n\n执行剧本时报错\n\n![image-20221115090123132](../img/Ansible-%E6%80%BB%E6%89%8B%E5%86%8C.assets/025f933f2f98e83475e47b50a770d61d697559838.png)\n\n解决方法：\n\n方法一：ansible-playbook 命令时候添加--ask-vault-pass参数\n\nansible-playbook --ask-vault-pass test_vault.yaml\n\n![image-20221115090305979](../img/Ansible-%E6%80%BB%E6%89%8B%E5%86%8C.assets/82a563fff0f7f621f16ca3d89d291984697559838.png)\n\n方法二：ansible-playbook --vault-id @prompt test_vault.yaml（2.3之后使用，建议）\n\n![image-20221115090343892](../img/Ansible-%E6%80%BB%E6%89%8B%E5%86%8C.assets/80a2a5817cb83a38d6b390b6527dce2b697559838.png)\n\n方法三：ansible-playbook --vault-password-file=pass.yaml  test_vault.yaml\n\n（纯文本形式的密码存放在文件中，只能单行写一个密码，需要对该密码文件加强安全措施）\n\n```\necho 123456 > pass.yaml\n```\n\n![image-20221115090537834](../img/Ansible-%E6%80%BB%E6%89%8B%E5%86%8C.assets/a4679558621742cc1686f226db97fa95697559838.png)\n\n### 解密\n\n![image-20221115090755579](../img/Ansible-%E6%80%BB%E6%89%8B%E5%86%8C.assets/5d1b2c41b8ab4d90c396d5152562751b697559838.png)\n\n### 加密一个已存在的文件\n\n![image-20221115090808908](../img/Ansible-%E6%80%BB%E6%89%8B%E5%86%8C.assets/4013570bd030a34a9106c8076dc20fb9697559838.png)\n\n### 重置加密文件的密码\n\n![image-20221115090908211](../img/Ansible-%E6%80%BB%E6%89%8B%E5%86%8C.assets/caf0c57add1d5190b8257e56dce85667697559838.png)\n\n### 编辑已存在的加密文件\n\n![image-20221115090956109](../img/Ansible-%E6%80%BB%E6%89%8B%E5%86%8C.assets/89af0166415695c89a5711c014ca410f697559838.png)\n\nTips：如果我们使用加密文件保存变量、密码等敏感数据，最好采用隐藏文件来存放，增强安全性。\n\n![image-20221115091217928](../img/Ansible-%E6%80%BB%E6%89%8B%E5%86%8C.assets/c691ac4b1c29f213060409edcc3de254697559838.png)\n\n![image-20221115091252760](../img/Ansible-%E6%80%BB%E6%89%8B%E5%86%8C.assets/498cf7e4e15fe6dfe844f225b30b41ba697559838.png)\n\n```\nansible-playbook --vault-password-file=.pass.yaml  test_vault.yaml\n```\n\n![image-20221115091403345](../img/Ansible-%E6%80%BB%E6%89%8B%E5%86%8C.assets/4f45d34d83e8abd8fb954cd8389cc991697559838.png)\n\n## 综合实践\n\n编辑剧本文件实现以下功能：\n\n0、设置主机组 all\n\n1、设置变量 定义nginx服务端口为8081\n\n2、关闭facts\n\n3、调用service模块，卸载受控端的httpd\n\n4、调用SELinux模块，关闭selinux\n\n5、调用yum模块安装epel源\n\n6、调用yum模块安装nginx\n\n7、调用lineinfile模块修改nginx配置文件中的监听端口，使用自定义的服务端口变量，并将结果注册到 port_result\n\n8、调用service模块启动nginx，并设置为开机自启动\n\n9、调用debug模块，msg信息为port_result\n\n10、验证受控端服务及端口\n\n```\n---\n- hosts: all\n  gather_facts: no\n  vars: \n    nginx_port: \"8081\"\n  tasks:   \n  - name: uninstall httpd\n    yum:\n      name: httpd\n      state: absent\n  - name: stop selinux\n    selinux:\n      state: disabled\n  - name: install epel\n    yum:\n      name: epel-release\n      state: present\n  - name: \n    yum:\n      name: nginx\n      state: present\n  - name: set nginx_port\n    lineinfile:\n      path: /etc/nginx/nginx.conf\n      regexp: \"        listen       80;\"\n      line: \"        listen       {{ nginx_port }};\"\n    register: port_result   \n  - name: start nginx\n    service:\n      name: nginx\n      state: started\n      enabled: yes\n  - name: debug msg\n    debug:\n      msg: \"{{ port_result }}\"\n\n\nansible-playbook  install_nginx.yaml -C\n\nansible-playbook install_nginx.yaml  \n\nansible all -m shell -a  \"ps aux |grep nginx \"  \n\nansible all -m shell -a  \"netstat -lntp |grep nginx \" \n\n```\n\n![image-20230926165830835](../img/Ansible-%E6%80%BB%E6%89%8B%E5%86%8C.assets/aa4e8fcbb552d3e8d48e4e3e14619f90697559838.png)\n\n![image-20230926165852495](../img/Ansible-%E6%80%BB%E6%89%8B%E5%86%8C.assets/0c68702617a92029f20139bba48637ad697559838.png)\n\n# Ansible-templates\n\n## JINJA2语法简要介绍\n\nJinja2语言，支持的数据类型：\n\n```\n    字符串：使用单引号或双引号\n    数字：整数，浮点数\n    列表：[item1, item2, ...]\n    元组：(item1, item2, ...)\n    字典：{key1:value1, key2:value2, ...}\n    布尔型：true/false\n```\n\n支持的运算及操作：\n\n```\n算术运算：+, -, *, /, //, %, **\n比较操作：==, !=, >, >=, <, <=\n逻辑运算：and，or，not\n流表达式：For，If，When\n```\n\n## Playbook的进阶应用\n\n### 使用when实现条件判断\n\n条件测试:如果需要根据变量、facts或此前任务的执行结果来做为某task执行与否的前提时要用到条件测试。**剧本中不能使用if判断，需要使用when判断。**\n\nwhen语句：在task后添加when子句即可使用条件测试，可以使用facts或playbook中定义的变量，支持Jinja2表达式语法\n\n示例：\n\n```\ntasks:\n  - name: \"shutdown RedHat flavored systems\"\n    command: /sbin/shutdown -h now\n    when: ansible_os_family == \"RedHat\"  当系统属于红帽系列,执行command模块，注意：'所有变量'都可以直接在条件语句中使用，而无需使用双大括号\n```\n\n也可以使用多个when进行多条件判断，等效于and。\n\n```\nvim test_when.yml\n---\n- hosts: all\n  tasks:\n  - name: copy file\n    copy:\n      src: /etc/hosts\n      dest: /root/hosts_when\n    when: ansible_hostname is match \"node1\"\t\t#when支持通配符\n\nansible all --list\nansible-playbook  test_when.yml\nansible all -m shell -a \"ls -l /root/hosts_when\"\n```\n\n\n\n### 使用with_items实现迭代\n\n迭代：当有需要重复性执行的任务时，可以使用迭代机制\n    > 对迭代项的引用，固定变量名为\"item\"\n\n> 要在task中使用with_items给定要迭代的元素列表，\n>     > 列表格式：\n>          字符串\n>          字典\n\n### **示例：打印1、2、3**\n\n```\nvim test_items.yml\n\n---\n- name: add serveral users\n  gather_facts: no\n  hosts: all\n  tasks:\n  - name: test loop\n    debug: \n      msg: \"name --- {{ item }}\" #{{ item }} 系统自定义变量\n    with_items:   ##with_items定义{{ item }} 的值和个数,      一般放到模块的末尾，与模块同一缩进级别    \n    - one\n    - two\n    - three\n```\n\n### 示例：创建用户\n\n```\nvim test_items.yml\n\n---\n- name: add serveral users\n  hosts: all\n  tasks:\n  - user:\n      name: \"{{ item  }}\"  #{{ item }} 系统自定义变量\n      state: present\n    with_items:           ##with_items定义{{ item }} 的值和个数,一般放到模块的末尾，与模块同一缩进级别    \n    - testuser1\n    - testuser2\n\nansible all --list\nansible-playbook  test_items.yml\nansible all -m shell -a \"getent passwd testuser1\"\n\n上面语句的功能等同于下面的语句：\n- name: add user testuser1\n  user: name=testuser1 state=present \n- name: add user testuser2\n  user: name=testuser2 state=present \n```\n\n### 示例：拷贝多个文件\n\n```\ntouch /root/1.txt /root/2.txt\n\nvim test_items2.yml\n---\n- name: copy serveral files\n  hosts: all\n  tasks:\n  - copy:\n      src: /root/{{ item  }}\n      dest: /etc/{{ item }}\n    with_items:          \n    - 1.txt\n    - 2.txt\n\nansible-playbook  test_items2.yml\nansible all -m shell -a \"ls -l /etc/*.txt\"\n```\n\n### 示例：迭代字典\n\n```\nwith_items中可以使用元素还可为hashes\n示例：\nvim test_items3.yml\n---\n- name: add several users\n  gather_facts: no\n  hosts: all\n  tasks:\n  - user:\n      name: \"{{ item.name }}\"\n      state: present\n      groups: \" {{ item.groups }}\"\n    with_items:\n    - { name: 'testuser3', groups: 'wheel' }\n    - { name: 'testuser4', groups: 'root' }\n\n\nansible-playbook  test_items3.yml\nansible all -m shell -a \"getent passwd testuser3\"\nansible all -m shell -a \"id testuser3\"\nansible all -m shell -a \"getent passwd testuser4\"\nansible all -m shell -a \"id testuser4\"\n\n```\n\n### 课堂作业：使用with—items拷贝多个文件\n\n要求：item列表条目为字典类型，包含src、dest、mode3个键值对，使用with_items实现多个文件的拷贝，并赋予设定的权限。\n\n```\ntouch /root/3.txt /root/4.txt\nvim test_items4.yml\n---\n- name: copy several files\n  hosts: all\n  tasks:\n  - copy:\n      src: \"{{ item.src }}\"\n      dest: \"{{ item.dest }}\"\n      mode: \"{{ item.mode }}\"\n    with_items:          \n    - { src: \"/root/3.txt\", dest: \"/root/\", mode: \"0644\" }\n    - { src: \"/root/4.txt\", dest: \"/root/\", mode: \"0644\" }\n\nansible-playbook  test_items4.yml\nansible all -m shell -a \"ls -l /root/*.txt\"\n\n```\n\n#### when和with items组合使用\n\n 当when和with_items一起使用的时候，每个项都会单独被when语句处理\n\n```\nvim test_when_items.yml\n---\n- hosts: all\n  tasks:\n  - command: echo {{ item }}\n    with_items: [ 1,2,3,4,5,6,8,10]\n    when: item > 5\n         \n ansible-playbook test_when_items.yml\n```\n\n\n\n## templates 模板\n\ntemplates功能：根据模板文件动态生成对应的配置文件，命名必须以.j2结尾，支持jinja2语法。\n\n在呈现 JINJA2模板时，文件中引用的变量和表达式被替换为对应的值。模板中使用的变量可以在 Playbook 的 vars 部分中指定。可以将受管主机的事实用作模板中的变量。\n\n分隔符使用规范：\n\n```\n{% EXPR %}：用于表达式或逻辑（如循环、判断等）\n\n{{ EXPR }}：用于向最终用户输出表达式或变量的结果。在呈现时将被替换为一个或多个值，对最终用户可见。\n\n{# COMMENT #}，用于注释，不会出现在最终文件中。\n```\n\n### templates的使用场景\n\n在实际的工作中由于每台服务器的环境配置都可能不同，但是往往很多服务的配置文件都需要根据服务器环境进行不同的配置，比如Nginx最大进程数、Redis最大内存等。\n\n为了解决这个问题可以使用Ansible的template模块，该模块和copy模块作用基本一样，都是把管理端的文件复制到客户端主机上，但是区别在于template模块可以通过变量来获取配置值，支持多种判断、循环、逻辑运算等，而copy只能原封不动的把文件内容复制过去。\n\n#### 示例：httpd.conf的templates模板\n\n创建并编辑httpd.conf.j2文件\n\n```\nyum -y install httpd\nrpm -qa httpd\n \ncp /etc/httpd/conf/httpd.conf /root/httpd.conf.j2\n \nvim /root/httpd.conf.j2\n \n---------42行----------\nListen {{port}}\n \n----------95行---------\nServerName {{domain}}\n \nvim /etc/ansible/hosts\n \n[websrvs]\n192.168.142.101 port=80 domain=www.node1.com\n192.168.142.102 port=81 domain=www.node2.com\n```\n\n卸载受控机上的httpd服务\n\n```\nansible websrvs -m shell -a 'yum remove -y httpd'\nansible websrvs -m shell -a 'yum remove -y nginx'\n```\n\n新建yaml文件\n\n```\ncd /root\nvim a.yaml\n---\n- hosts: websrvs\n  remote_user: root\n  vars:\n  - package: httpd\n  - service: httpd\n  tasks:\n  - name: install service\n    yum:\n      name: \"{{ package }}\"\n      state: latest\n\n  - name: httpd.conf\n    template:\n      src: /root/httpd.conf.j2\n      dest: /etc/httpd/conf/httpd.conf\n    notify: restart service\n\n  - name: start service\n    service:\n      name: \"{{ service }}\"\n      state: started\n      enabled: true\n \n handlers:\n  - name: restart service\n    service:\n      name: \"{{ service }}\"\n      state: restarted\n\n```\n\n执行yaml文件并验证\n\n```\nansible-playbook a.yaml --syntax-check\nansible-playbook a.yaml\nansible websrvs -a 'systemctl status httpd'\nansible websrvs -m shell -a 'ss -ntl'\nansible websrvs -m shell -a 'netstat -ntlp |grep httpd'\nansible websrvs -m shell -a 'lsof -i:80'\nansible websrvs -m shell -a 'lsof -i:81'\n```\n\n#### tamplates-for(循环)\n\n语法：\n\n```\n{% for 变量 in 列表 %}\n{{ 文本内容调用变量 }}\n{% endfor %}\n```\n\n示例：使用for循环遍历调用users列表变量的元素\n\n```\n{%  for user in users %}\n{{  user }}\n{% endfor %}\n```\n\n### 示例：yaml文件中变量的调用\n\n编写yaml文件 jinja2_for.yml\n\n```\nvim jinja2_for.yml\n---\n- name: jinja2_for example\n  hosts: all\n  remote_user: root\n  vars:\n    users:\n    - user1\n    - user2\n  tasks:\n  - name: Copy template\n    template: \n      src: /root/users.j2\n      dest: /root/users \n```\n\n编写/root/users.j2文件\n\n```\nvim /root/users.j2\n{% for user in users %}\nusername: {{ user }}\n{% endfor %}\n```\n\n执行并验证\n\n```\nansible-playbook jinjia2_for.yml --syntax-check\nansible-playbook jinjia2_for.yml\nansible all -m shell -a \"cat /root/users\"\n```\n\n**扩展示例：**\n\n以下示例模板使用for语句逐一运行users变量中的所有值，将user替换为各个值，但值为root时除外。\n\n```\nvim users.j2\n\n{# for statement #}\n{% for user in users if not user ==\"root\" %}\nUser number {{ loop.index }}- {{ user }}\n{% endfor %}\n```\n\nloop.index变量扩展至循环当前所处的索引号。它在循环第一次执行时值为1，每一次迭代递增1.\n\n```\nansible-playbook jinjia2_for.yml --syntax-check\nansible-playbook jinjia2_for.yml\n\nansible all -m shell -a \"cat /root/users\"\n```\n\n\n\n### 示例：事实变量的调用\n\n编写yaml文件  jinja2_for2.yml\n\n```\nvim jinja2_for2.yml\n---\n- name: jinja2_for example2\n  hosts: all\n  remote_user: root\n  vars:\n    users:\n    - user1\n    - user2\n  tasks:\n  - name: Copy template\n    template: \n      src: /root/host.j2\n      dest: /root/hosts \n```\n\n编写/root/host.j2文件\n\n```\nvim /root/host.j2\n{% for host in groups['websrvs'] %}\n{{ ansible_facts.default_ipv4.address }}{{ ansible_facts.fqdn }}\n{% endfor %}\n```\n\n执行并验证\n\n```\nansible-playbook jinjia2_for2.yml --syntax-check\nansible-playbook jinjia2_for2.yml\n\nansible websrvs -m shell -a \"cat /root/hosts\"\n```\n\n\n\n#### tamplates-if（判断）\n\nJinja2使用 if 语句来提供条件控制。如果满足条件，允许在文件中添加一行内容。\n\n语法：\n\n```\n{% if 条件 %}\n{{ 语句 }}\n{% endif %}\n```\n\n### 示例：\n\n编写yaml文件 jinja2_if.yml\n\n```\nvim jinja2_if.yml\n---\n- name: jinja2_if example\n  hosts: websrvs\n  remote_user: root\n\n  tasks:\n  - name: Copy template\n    template: \n      src: /root/host2.j2\n      dest: /root/hosts2 \n```\n\n编辑host2.j2文件\n\n```\nvim /root/host2.j2\n\n{% if ansible_facts.default_ipv4.address =='192.168.142.101' %}\n{{ ansible_facts.default_ipv4.address }}{{ ansible_facts.fqdn }}\n{% endif %}\n```\n\n执行并验证\n\n```\nansible-playbook jinja2_if.yml --syntax-check\nansible-playbook jinja2_if.yml\nansible all -m shell -a \"cat /root/hosts2\"\n```\n\n\n\n## 综合案例：nginx templates\n\n0、编辑主机清单，组websrvs，包含2台受控主机\n\n1、主控端安装ngxin、拷贝nginx配置文件为nginx.conf.j2模板文件。创建nginx首页模版，命名为html.j2,引用实事变量：主机名，文件内容格式如： Welcome to {{  需要引用的实事变量 }}\n\n2、编写test_template.yaml文件，要求tasks\n\n​      1）安装epel源 2）安装nginx 3）拷贝nginx.conf.j2模板文件为受控主机的nginx配置文件4）拷贝html.j2模板文件为受控主机的nginx首页文件4）开启服务\n\n3、校验playbook语法并执行，验证受控主机的nginx进程数\\服务端口\\首页\n\n4、修改nginx.conf.j2模板文件，配置 worker_processes数量为实事变量：受控主机处理器vcpu个数的两倍，保存\n\n5、修改test_template.yaml文件，添加notify和handlers，在配置文件变化时，重启nginx\n\n6、校验playbook语法并执行，验证受控主机的nginx进程数\n\n7、修改hosts文件为每台主机定义服务端口变量 第一台 8082，第二台8083\n\n8、修改test_template.yaml文件，修改监听端口行，增加主机端口变量的引用\n\n9、校验playbook语法并执行，验证受控主机的nginx服务端口\n\n10、修改test_template.yaml，增加端口变量定义，端口88\n\n11、校验playbook语法并执行，验证受控主机的nginx服务端口\n\n\n\n1、主控端安装ngxin、拷贝nginx配置文件为nginx.conf.j2模板文件\n\n```\nyum install -y nginx\ncp /etc/nginx/nginx.conf /root/nginx.conf.j2\necho \"welcome to {{ ansible_hostname  }}\" > html.j2\n\nansible all -m setup |grep hostname\nansible all -m setup |grep vcpu\n```\n\n2、创建nginx首页模版，命名为html.j2,引用实事变量：主机名\n\n内容格式如： Welcome to {{  需要引用的实事变量 }}\n\n2、编写test_template.yaml文件\n\n```\nvim test_template.yaml\n---\n- hosts: websrvs\n  remote_user: root\n  tasks:\n  - name: install epel\n    yum:\n      name: epel-release\n  - name: install package\n    yum:\n      name: nginx\n  - name: copy template\n    template:\n      src: /root/nginx.conf.j2\n      dest: /etc/nginx/nginx.conf\n  - name: copy template\n    template:\n      src: /root/html.j2\n      dest: /usr/share/nginx/html\n  - name: copy html\n    template:\n      src: /root/html.j2\n      dest: /usr/share/nginx/html/index.html    \n  - name: start service\n    service:\n      name: nginx\n      state: started\n      enabled: yes\n```\n\n执行并验证\n\n```\nansible-playbook test_template.yaml  --syntax-check\nansible-playbook test_template.yaml  \nansible all -m shell -a 'systemctl status nginx'\nansible all -m shell -a 'ss -ntpl|grep nginx'\n#可以查看到进程，每个cpu一个\nansible all -m shell -a 'ps aux|grep nginx'\n```\n\n\n\n3、修改template文件，修改进程数为cpu内核的2倍\n\n```i\nansible websrvs -m setup|grep \"cpu\"\n\nvim nginx.conf.j2\n修改第6行\nworker_processes {{ ansible_processor_vcpus*2  }}    #worker_processes auto\n```\n\n修改test_template.yaml文件，添加notify和handlers，在配置文件变化时，重启nginx\n\n```\nvim test_template.yaml\n---\n- hosts: websrvs\n  remote_user: root\n  tasks:\n  - name: install package\n    yum:\n      name: nginx\n  - name: copy template\n    template:\n      src: /root/nginx.conf.j2\n      dest: /etc/nginx/nginx.conf\n    notify:\n    - restart service\n  - name: copy html\n    template:\n      src: /root/html.j2\n      dest: /usr/share/nginx/html/index.html    \n  - name: start service\n    service:\n      name: nginx\n      state: started\n      enabled: yes\n  handlers:\n  - name: restart service\n    service:\n      name: nginx\n      state: restarted\n```\n\n执行并验证\n\n```\nansible-playbook test_template.yaml\n#可以查看到进程，\nansible all -m shell -a 'ps aux|grep nginx' #查看nginx进程数为cpu核数的2倍\n```\n\n检验nginx配置文件是否存在语法错误\n\nnginx -t \n\nnginx和httpd服务，web服务保证只有一个运行。\n\n\n\n4、使用主机变量，修改服务端口\n\n修改hosts文件增加端口变量\n\n```\n#使用主机变量\n#修改nginx对应的端口\nvim /etc/ansible/hosts\n[websrvs]\n192.168.142.101 http_port=8083\n192.168.142.102 http_port=8084\n```\n\n修改模板文件，增加端口引用\n\n```\nvim nginx.conf.j2\n修改39、40行\nserver{\n    listen   {{ http_port }} ;\n    listen   [::]:{{  http_port  }} ;\n}\n```\n\n执行并验证\n\n```\nansible-playbook test_template.yaml\nansible websrvs -m shell -a 'ss -ntpl|grep nginx'\n```\n\n\n\n5、使用playbook变量\n\n修改test_template.yaml，增加端口信息\n\n```\nvim test_template.yaml\n\n---\n- hosts: websrvs\n  remote_user: root\n  vars：\n  - http_port: 88\n  tasks:\n  - name: install package\n    yum:\n      name: nginx\n  - name: copy template\n    template:\n      src: /root/nginx.conf.j2\n      dest: /etc/nginx/nginx.conf\n    notify:\n    - restart service\n  - name: copy html\n    template:\n      src: /root/html.j2\n      dest: /usr/share/nginx/html/index.html   \n  - name: start service\n    service:\n      name: nginx\n      state: started\n      enabled: yes\n  handlers:\n  - name: restart service\n    service:\n      name: nginx\n      state: restarted\n\n```\n\n执行并验证\n\n```\nansible-playbook test_template.yaml\nansible websrvs -m shell -a 'ss -ntpl|grep nginx'\n#发现端口变成88\n```\n\n6、使用命令行变量\n\n```\nansible-playbook -e \"http_port=99\"  test_template.yaml\nansible websrvs -m shell -a 'ss -ntpl|grep nginx'\n#发现端口变成99\n```\n\n# Roles\n\n```\n·由来: ansible自动化运行，基础由AD-Hoc命令来完成，在命令变多时，产生了playbook进行管理任务，简单任务使用playcook可以轻松处理，但是有复杂任务时单个playbook不可以胜任了，这时需要把多个playbook进行组合，少量用include将剧本中任务互相关联即可完成，但是playbook还在增多的情况时就不方便管理了，这时引入roles对playbook进行有效组织就十分必要了\n· Roles:角色，是ansible自1.2版本开始引入的新特性\n·目的:用于层次性，结构化地组织playbook, roles能够根据层次型结构自动装载变量、文件、任务、模块及触发器·方法: roles通过分别将放置于变量、文件、任务、模块及触发器单独的目录中，并可以便捷地include它们的一种机制·应用:角色一般用于基于主机构建服务的场景中、但也可以是用于构建守护进程等场景中\n```\n\n## roles默认路径设置\n\n```\n/etc/ansible/ansible.cfg\nroles_path= /etc/ansible/roles\n```\n\n## Roles各目录结构及作用\n\n```\n每个角色，以特定的层级目录结构进行组织\nroles目录结构：\nplaybook.yml  调用角色\nroles/\n  project/ (角色名称)\n    tasks/\n    files/\n    vars/\n    templates/\n    handlers/\n    default/ 不常用，设定默认变量时使用此目录中的main.yml文件\n    meta/    不常用，定义当前角色的特殊设定及其依赖关系,至少应该包含一个名为main.yml的文件；其它文件需在此文件中通过include进行包含\n各目录的作用：\n/roles/project/ :项目名称,有以下子目录，project可以是mysql\\httpd\\nginx\\memcached等\n    files/ ：存放由copy或script模块等调用的文件\n    templates/：template模块查找所需要模板文件的目录\n    tasks/：定义task,role的基本元素，至少应该包含一个名为main.yml的文件, 其定义了此角色的任务列表.\n             在handler中使用include包含的其它的handler文件也应该位于此目录中；\n    handlers/：至少应该包含一个名为main.yml的文件；用于定义此角色用到的各handler；\n               其它的文件需要在此文件中通过include进行包含\n    vars/：定义变量，至少应该包含一个名为main.yml的文件,；\n           其它的文件需要在此文件中通过include进行包含\n    meta/：定义当前角色的特殊设定及其依赖关系,至少应该包含一个名为main.yml的文件，\n           其它文件需在此文件中通过include进行包含, ansible1.3及其以后的版本才支持；\n    defaults/：为当前角色设定默认变量时使用此目录；应当包含一个main.yml文件\n```\n\n### 创建role框架\n\n您可以使用标准Linux命令创建新角色所需的所有子目录和文件。\n\n```\ncd /etc/ansible/roles/\nmkdir  httpd\ncd httpd\nmkdir  tasks  handlers  vars  meta  defaults templates files \n```\n\n或者可以运行ansible-galaxy init来创建新角色的目录结构。指定角色的名称作为命令的参数，该命令在当前工作目录中为新角色创建子目录。\n\n```\ncd /etc/ansible/roles\nansible-galaxy init httpd\ntree httpd\n[root@controller roles]# tree httpd\nhttpd      #具体的⾓⾊项⽬名称，   ⽐如nginx、tomcat、php  (⾃由设置)\n├── defaults  #⽤于为当前⾓⾊设定默认变量，  此⽬录应当包含⼀个main.yml⽂件\n│   └── main.yml  #类似代码中的主函数，  进⾏统⼀管理\n├── files      #⽤来存放由copy模块或script模块等模块调⽤的⽂件\n├── handlers    #⽤于定义此⾓⾊中触发条件时执⾏的动作，  此⽬录应当包含⼀个main.yml⽂件\n│   └── main.yml\n├── meta      #⽤于定义此⾓⾊的特殊设定及其依赖关系，  此⽬录应当包含⼀个main.yml⽂件\n│   └── main.yml\n├── README.md   #说明⽂件\n├── tasks       #⽤于定义当前⾓⾊的任务列表，  此⽬录应当包含⼀个main.yml⽂件\n│   └── main.yml\n├── templates  #⽤来存放jinjia2模板，template模块会⾃动在此⽬录中寻找jinjia2模板⽂件\n├── tests   #⽤于存放测试role本⾝功能的playbook和主机定义⽂件，  在开发测试阶段⽐较常⽤ ,此⽬录应当包含⼀个main.yml⽂件和⾃⾝资源设定invetory\n│   ├── inventory\n│   └── test.yml\n└── vars    #⽤于定义此⾓⾊⽤到的变量，  此⽬录应当包含⼀个main.yml⽂件\n    └── main.yml\n\n```\n\n\n\n# 实验任务：安装httpd服务\n\n原始的playbook版本\n\n1、制作主页\n\necho hi > index.html\n\n2、拷贝本机httpd的配置文件为httpd.conf.j2模版，并修改\n\ncp /etc/httpd/conf/httpd.conf  httpd.conf.j2\n\nvim  httpd.j2   #42行 修改为\n\n```\n{% if http_port is defined %}\nListen {{ ansible_facts.default_ipv4.address }}:{{ http_port }}\n{% endif %}\n```\n\n3、编写playbook文件，\n\n创建变量http_port: 8080\n\n执行任务：\n\n1)安装httpd\n\n2)拷贝主页\n\n3)拷贝配置（做触发器）\n\n4)防火墙放通自定义的端口\n\n```\n- name: firewalld configuration\n  firewalld:  \n    port: \"{{  http_port }}/tcp\"\n    permanent: yes \n    immediate: yes \n    state: enabled\n  when: http_port is defined\n```\n\n5)开启服务\n\n```\n---                                                                                                                                                                           \n- hosts: all \n  remote_user: root\n  vars:\n    http_port: 8080\n  tasks:\n  - name: install httpd package\n    yum:\n      name: httpd\n      state: present\n  - name: create a web content\n    copy:\n      src: index.html\n      dest: /var/www/html/index.html\n  - name: config file\n    template:\n      src: httpd.conf.j2\n      dest: /etc/httpd/conf/httpd.conf\n    notify: restart_httpd\n    when: http_port is defined                                                                                                                                                \n  - name: firewalld configuration\n    firewalld:                                                                   \n      port: \"{{  http_port }}/tcp\"\n      permanent: yes \n      immediate: yes \n      state: enabled\n    when: http_port is defined\n  - name: start service\n    service: \n      name: httpd \n      state: started \n      enabled: yes\n  handlers:\n  - name: restart_httpd\n    service:\n      name: httpd\n      state: restarted\n```\n\n验证端口及主页\n\nansible all -m shell -a \"ss -tunlp|grep httpd\" \n\n## 任务分析：\n\n1.配置 httpd 的时候，可能存在配置文件，配置文件可能含有变量\n\n2.必要变量的定义\n\n3.源码文件的定义\n\n## 创建httpd角色框架\n\n```\nansible-galaxy init httpd\n```\n\n查看目录结构\n\n```\n[root@controller roles]# tree httpd\nhttpd\n├── defaults\n│  └── main.yml\n├── files\n├── handlers\n│   └── main.yml\n├── meta\n│   └── main.yml\n├── README.md\n├── tasks\n│   └── main.yml\n├── templates\n├── tests\n│   ├── inventory\n│   └── test.yml\n└── vars\n    └── main.yml\n```\n\n## 部署完善httpd角色框架\n\n```\n   cd roles/httpd/tasks/\n   touch install.yml conf_template.yml service.yml index.yml   httpd_firewalld.yml\n```\n\n## 定义分任务(tasks/中存放)\n\n```\nvim install.yml\n- name: install httpd package\n  yum: \n    name: httpd\n    state: present\n     \nvim conf_template.yml\n- name: config file\n  template: \n    src: httpd.conf.j2 \n    dest: /etc/httpd/conf/httpd.conf \n  notify: restart_httpd\n  when: http_port is defined\n         \nvim service.yml\n- name: start service\n  service: \n    name: httpd \n    state: started \n    enabled: yes\n    \nvim  index.yml\n- name: create a web content\n  copy:\n    src: index.html\n    dest: /var/www/html/index.html\n\nvim httpd_firewalld.yml\n- name: firewalld configuration\n  firewalld:\n    port: \"{{  http_port }}/tcp\"\n    permanent: yes\n    immediate: yes\n    state: enabled\n  when: http_port is defined\n```\n\n## 定义主任务(tasks/main.yml)\n\n```\n创建main.yml主控文件,调用以上单独的yml文件,main.yml定义了谁先执行谁后执行的顺序\nvim main.yml\n- include: install.yml\n- include: index.yml\n- include: conf_template.yml\n- include: httpd_firewalld.yml\n- include: service.yml\n```\n\n## 定义变量（vars/main.yml）\n\n```\nvim /etc/ansible/roles/httpd/vars/main.yml\n\n---\n#vars file for httpd\nhttp_port: 8080\n```\n\n## 定义首页文件（files/index.html）\n\n```\ncd    /etc/ansible/roles/httpd/files/\nvim index.html\n<h1> welcome to wd home <\\h1>\n```\n\n## 定义模板(templates/httpd.conf.j2 )\n\n``` fr\nyum -y install httpd\n\ncp /etc/httpd/conf/httpd.conf  /etc/ansible/roles/httpd/templates/httpd.conf.j2 \n\nvim templates/httpd.conf.j2\n将LISTEN 80 行修改为以下内容\n{% if http_port is defined %}\nListen {{ ansible_facts.default_ipv4.address }}:{{ http_port }}\n{% endif %}\n```\n\n## 定义角色处理程序（handlers/mail.yml）\n\n```\nvim /etc/ansible/roles/httpd/handlers/main.yml\n- name: restart_httpd\n  service: \n    name: httpd \n    state: restarted\n```\n\n## 调用角色，配置httpd服务（roles/role_httpd.yml）\n\n```\ncd /etc/ansidle/roles\nvim role_httpd.yml\n---\n# httpd role\n- name: httpd deployment\n  hosts: websrvs\n  remote_user: root    \n  \n  roles:       #调用角色\n  - httpd   \n```\n\n## 检查语法及冒烟运行\n\n```\n ansible-playbook role_httpd.yml -C\n```\n\n## 正式执行\n\n```\n ansible-playbook role_httpd.yml\n```\n\n## 验证服务\n\n```\nansible all -m shell -a \"ss -tunlp |grep httpd\"\ncurl 192.168.142.101:8080\n\n```\n\n<div class=\"tbsm\" style=\"margin-top:54px;\">\n<div class=\"tbsm-top\"><span><svg t=\"1674654360507\" class=\"icon\" viewBox=\"0 0 1024 1024\" version=\"1.1\" xmlns=\"http://www.w3.org/2000/svg\" p-id=\"987\" data-spm-anchor-id=\"a313x.7781069.0.i0\" width=\"35\" height=\"35\"><path d=\"M410.49 97.74H155.08a56.74 56.74 0 0 0-56.84 56.73V410a56.84 56.84 0 0 0 56.84 56.84h255.41A56.83 56.83 0 0 0 467.32 410V154.58a56.83 56.83 0 0 0-56.83-56.84zM410.49 558.74H155.08a56.74 56.74 0 0 0-56.84 56.73V871a56.84 56.84 0 0 0 56.84 56.84h255.41A56.83 56.83 0 0 0 467.32 871V615.58a56.83 56.83 0 0 0-56.83-56.84zM871.49 558.74H616.08a56.74 56.74 0 0 0-56.84 56.73V871a56.84 56.84 0 0 0 56.84 56.84h255.41A56.83 56.83 0 0 0 928.32 871V615.58a56.83 56.83 0 0 0-56.83-56.84z\" fill=\"#66EEFF\" p-id=\"988\"></path><path d=\"M410.49 558.74h-4.14A475 475 0 0 0 299.52 859.6a481.16 481.16 0 0 0 4.84 68.22h106.13A56.83 56.83 0 0 0 467.32 871V615.58a56.83 56.83 0 0 0-56.83-56.84zM871.49 558.74H616.08a56.74 56.74 0 0 0-56.84 56.73V871a56.84 56.84 0 0 0 56.84 56.84h255.41A56.83 56.83 0 0 0 928.32 871V615.58a56.83 56.83 0 0 0-56.83-56.84z\" fill=\"#C2F8FF\" p-id=\"989\"></path></svg></span><span style=\"font-size:30px;\"> 特别声明</span></div>\n<div class=\"tbsm-wz\">千屹博客旗下的所有文章，是通过本人课堂学习和课外自学所精心整理的知识巨著<br/>难免会有出错的地方<br/>如果细心的你发现了小失误，可以在下方评论区告诉我，或者私信我！<br />非常感谢大家的热烈支持！</div>\n</div>\n","tags":["Centos 7","Ansible"],"categories":["运维"]},{"title":"先电IaaS2.2部署OpenStack","url":"/posts/52877/","content":"\n<meta name=\"referrer\" content=\"no-referrer\"/>\n\n\n\n# 先电IaaS2.2私有云部署OpenStack\n\n## 前期准备\n\n### ip拓扑\n\n|    主机名     |  ip1（NAT）   | ip2（仅主机）  | 硬盘 | 内存 |\n| :-----------: | :-----------: | :------------: | :--: | :--: |\n| controller-48 | 192.168.48.10 | 192.168.148.10 | 100G |  8G  |\n|  computer-48  | 192.168.48.20 | 192.168.148.20 | 100G |  3G  |\n\n### 基础镜像\n\n[CentOS-7-x86_64-DVD-2009.iso](https://mirrors.aliyun.com/centos/7/isos/x86_64/CentOS-7-x86_64-DVD-2009.iso?spm=a2c6h.25603864.0.0.74092d1ctaON7P)\n[chinaskills_cloud_iaas.iso](https://pan.quark.cn/s/baeeb5269112)\n\n```\n[root@localhost ~]# ll\ntotal 4758568\n-rw-r--r--  1 root root  861155328 Jun 19 03:06 CentOS-7-x86_64-DVD-2009.iso\n-rw-r--r--  1 root root 3799093248 Jun 19 03:06 chinaskills_cloud_iaas.iso\n```\n\n\n\n### 虚拟机硬件配置\n\n![image-20230619160042336](../img/xiandian-openstack/2c6ee30d82a77a9207d568f1f75ebeaf539c598f.png)\n\ncontroller\n\n![](../img/xiandian-openstack/1.png)\n\ncomputer\n\n![image-20230618184522907](../img/xiandian-openstack/181f86237817db4d8a51d251d6d6138463bea45e.png)\n\n**sdb和sdc是分别作为cinder服务和swift服务的存储磁盘。**\n\n### 配置主机名和hosts，关闭防火墙和永久关闭selinux\n\ncontroller\n\n```\nhostnamectl set-hostname controller && bash\nsystemctl disable firewalld --now\nsed -i 's/SELINUX=enforcing/SELINUX=disabled/g' /etc/sysconfig/selinux\nsed -i 's/SELINUX=enforcing/SELINUX=disabled/g' /etc/selinux/config\necho \"192.168.48.10 controller\" >> /etc/hosts\necho \"192.168.48.20 computer\" >> /etc/hosts\nsetenforce 0\n```\n\ncomputer\n\n```\nhostnamectl set-hostname computer && bash\nsystemctl disable firewalld --now\nsed -i 's/SELINUX=enforcing/SELINUX=disabled/g' /etc/sysconfig/selinux\nsed -i 's/SELINUX=enforcing/SELINUX=disabled/g' /etc/selinux/config\necho \"192.168.48.10 controller\" >> /etc/hosts\necho \"192.168.48.20 computer\" >> /etc/hosts\nsetenforce 0\n```\n\n确保两者可以互通！\n\n### 格式化compute磁盘（在compute中操作）\n\n```\nmkfs.xfs /dev/sdb\nmkfs.xfs /dev/sdc\n```\n\n### 配置yum源\n\ncontroller\n\n```\nrm -rf /etc/yum.repos.d/*\ncat >> /etc/yum.repos.d/centos.repo << EOF\n[centos]\nname=centos\nbaseurl=file:///qianyios/centos\ngpgcheck=0\nenabled=1\n[iaas]\nname=iaas\nbaseurl=file:///qianyios/iaas-repo\ngpgcheck=0\nenabled=1\nEOF\n```\n\ncomputer\n\n```\nmkdir repo.bak\nmv /etc/yum.repos.d/* repo.bak/\ncat >> /etc/yum.repos.d/centos.repo << EOF\n[centos]\nname=centos\nbaseurl=ftp://192.168.48.10/centos\ngpgcheck=0\nenabled=1\n[iaas]\nname=iaas\nbaseurl=ftp://192.168.48.10/iaas-repo\ngpgcheck=0\nenabled=1\nEOF\n```\n\n### 挂载iso镜像文件\n\n```\n#控制节点\nmkdir /qianyios/centos -p\nmount -o loop CentOS-7-x86_64-DVD-2009.iso /mnt/\ncp -rvf /mnt/* /qianyios/centos/\numount /mnt/\nmount -o loop chinaskills_cloud_iaas.iso /mnt/\ncp -rvf /mnt/* /qianyios/\numount /mnt/\nyum clean all && yum makecache\n```\n\n### 搭建ftp服务器\n\n```\n控制节点\nyum install vsftpd -y\ncat>> /etc/vsftpd/vsftpd.conf <<EOF\nanon_root=/qianyios/\nEOF\nsystemctl start vsftpd && systemctl enable vsftpd\n```\n\n验证操作\n\n1.清理yum缓存\n\n```\n#各节点\nyum clean all && yum makecache\n```\n\n2.在文件资源管理器输入ftp://192.168.48.10/\n\n![image-20230618192456867](../img/xiandian-openstack/e8657f54037c60e02ba43b1b9c4410e75f05a433.png)\n\n## 编辑xiandian变量\n\n```\n#各节点\nyum install iaas-xiandian -y\n#使用sed命令批量去除第一个#注释符为空\nsed -i -e 's/^#//'g /etc/xiandian/openrc.sh\n使用sed命令批量修改密码默认000000\nsed -i -e 's/PASS=/PASS=000000/'g /etc/xiandian/openrc.sh\n```\n\n```\ngrep -v \"^#\" /etc/xiandian/openrc.sh | grep -v \"^$\"\nHOST_IP=192.168.48.10\nHOST_PASS=123456\n#ssh登入密码\nHOST_NAME=controller\nHOST_IP_NODE=192.168.48.20\nHOST_PASS_NODE=123456\n#ssh登入密码\nHOST_NAME_NODE=computer\nnetwork_segment_IP=192.168.48.0/24\nRABBIT_USER=openstack\nRABBIT_PASS=000000\nDB_PASS=000000\nDOMAIN_NAME=demo\nADMIN_PASS=000000\nDEMO_PASS=000000\nKEYSTONE_DBPASS=000000\nGLANCE_DBPASS=000000\nGLANCE_PASS=000000\nNOVA_DBPASS=000000\nNOVA_PASS=000000\nNEUTRON_DBPASS=000000\nNEUTRON_PASS=000000\nMETADATA_SECRET=000000\nINTERFACE_IP=192.168.48.10\n#复制到第二台机的时候，记得改成192.168.48.20\nINTERFACE_NAME=ens36\n#第二块网卡的名字\nPhysical_NAME=provider\nminvlan=2\nmaxvlan=300\nCINDER_DBPASS=000000\nCINDER_PASS=000000\nBLOCK_DISK=sdb\nSWIFT_PASS=000000\nOBJECT_DISK=sdc\nSTORAGE_LOCAL_NET_IP=192.168.48.20\nHEAT_DBPASS=000000\nHEAT_PASS=000000\nZUN_DBPASS=000000\nZUN_PASS=000000\nKURYR_DBPASS=000000\nKURYR_PASS=000000\nCEILOMETER_DBPASS=000000\nCEILOMETER_PASS=000000\nAODH_DBPASS=000000\nAODH_PASS=000000\nBARBICAN_DBPASS=000000\nBARBICAN_PASS=000000\n\n```\n\n```\nscp /etc/xiandian/openrc.sh computer:/etc/xiandian/openrc.sh \n#以下在计算节点\nsed -i 's/INTERFACE_IP=192.168.48.10/INTERFACE_IP=192.168.48.20/g' /etc/xiandian/openrc.sh\n```\n\n## 安装平台基本服务\n\n```\n[root@controller ~]# iaas-pre-host.sh \n[root@compute ~]# iaas-pre-host.sh \n#双节点\nreboot\n# 可同时执行，执行完毕后脚本会提示重启，不然rabbitmq服务会报错！！！此脚本会初始化虚拟机环境，如修改主机\n名、主机映射、时间同步等，自己可去尝试解读脚本，手工搭建平台！！！！，由于重启可能导致平台出现问题可用ssh\n连接自己的IP地址重新登陆，只要出现屏幕登录时间以及看到屏幕欢迎界面即可\nController节点\niaas-install-mysql.sh\niaas-install-keystone.sh\niaas-install-glance.sh\n\nController节点\niaas-install-nova-controller.sh\nCompute节点\niaas-install-nova-compute.sh\n\nController节点\nsed -i 's/yum install openstack-neutron openstack-neutron-ml2 openstack-neutron-linuxbridge ebtables -y/yum install openstack-neutron openstack-neutron-ml2 openstack-neutron-linuxbridge ebtables -y --skip-broken/g' /usr/local/bin/iaas-install-neutron-controller.sh\n\niaas-install-neutron-controller.sh\nCompute节点\niaas-install-neutron-compute.sh\n\nController节点\niaas-install-dashboard.sh\n\n从Ftp服务器上下载镜像到本地。（在controller中操作）\nsource /etc/keystone/admin-openrc.sh\nglance image-create --name CentOS7.5 --disk-format qcow2 --container-format bare --progress < /qianyios/images/CentOS_7.5_x86_64_XD.qcow2\n\n```\n\n访问页面http://192.168.48.10/dashboard/\n\n![image-20230619014112445](../img/xiandian-openstack/5080427a3e62da8a697977a9a280cce2a6c194b4.png)\n\n## 更多服务\n\n```\n#所以安装脚本都在/usr/local/bin/目录下\n#按照自己需求安装\n安装Swift对象存储服务\niaas-install-swift-controller.sh\n安装Heat编配服务\niaas-install-heat.sh\n安装Zun服务\niaas-install-zun-controller.sh\n安装Ceilometer监控服务\niaas-install-ceilometer-controller.sh\n安装Aodh监控服务\niaas-install-aodh.sh\n```\n\n\n\n<div class=\"tbsm\" style=\"margin-top:54px;\">\n<div class=\"tbsm-top\"><span><svg t=\"1674654360507\" class=\"icon\" viewBox=\"0 0 1024 1024\" version=\"1.1\" xmlns=\"http://www.w3.org/2000/svg\" p-id=\"987\" data-spm-anchor-id=\"a313x.7781069.0.i0\" width=\"35\" height=\"35\"><path d=\"M410.49 97.74H155.08a56.74 56.74 0 0 0-56.84 56.73V410a56.84 56.84 0 0 0 56.84 56.84h255.41A56.83 56.83 0 0 0 467.32 410V154.58a56.83 56.83 0 0 0-56.83-56.84zM410.49 558.74H155.08a56.74 56.74 0 0 0-56.84 56.73V871a56.84 56.84 0 0 0 56.84 56.84h255.41A56.83 56.83 0 0 0 467.32 871V615.58a56.83 56.83 0 0 0-56.83-56.84zM871.49 558.74H616.08a56.74 56.74 0 0 0-56.84 56.73V871a56.84 56.84 0 0 0 56.84 56.84h255.41A56.83 56.83 0 0 0 928.32 871V615.58a56.83 56.83 0 0 0-56.83-56.84z\" fill=\"#66EEFF\" p-id=\"988\"></path><path d=\"M410.49 558.74h-4.14A475 475 0 0 0 299.52 859.6a481.16 481.16 0 0 0 4.84 68.22h106.13A56.83 56.83 0 0 0 467.32 871V615.58a56.83 56.83 0 0 0-56.83-56.84zM871.49 558.74H616.08a56.74 56.74 0 0 0-56.84 56.73V871a56.84 56.84 0 0 0 56.84 56.84h255.41A56.83 56.83 0 0 0 928.32 871V615.58a56.83 56.83 0 0 0-56.83-56.84z\" fill=\"#C2F8FF\" p-id=\"989\"></path></svg></span><span style=\"font-size:30px;\"> 特别声明</span></div>\n<div class=\"tbsm-wz\">千屹博客旗下的所有文章，是通过本人课堂学习和课外自学所精心整理的知识巨著<br/>难免会有出错的地方<br/>如果细心的你发现了小失误，可以在下方评论区告诉我，或者私信我！<br />非常感谢大家的热烈支持！</div>\n</div>","tags":["Centos 7","OpenStack","Iaas"],"categories":["云原生"]},{"title":"公共留言区","url":"/posts/22484/","content":"\n<meta name=\"referrer\" content=\"no-referrer\"/>\n\n<link rel=\"stylesheet\" href=\"https://cdnjs.cloudflare.com/ajax/libs/animate.css/4.1.1/animate.min.css\" />\n\n<div class=\"all animate__animated  animate__infinite animate__fadeIn animate__slow\" style=\"display: flex;justify-content: center;margin-bottom:30px; \">\n        <div class=\"icon\" style=\"width:36px;height: 36px;float:left;background-size: cover\">\n            <svg t=\"1684948258846\" class=\"icon\" viewBox=\"0 0 1024 1024\" version=\"1.1\" xmlns=\"http://www.w3.org/2000/svg\" p-id=\"1080\" width=\"36\" height=\"36\"><path d=\"M334.12987 788.779221m-187.012987 0a187.012987 187.012987 0 1 0 374.025974 0 187.012987 187.012987 0 1 0-374.025974 0Z\" fill=\"#FFDEBB\" p-id=\"1081\"></path><path d=\"M114.094545 861.779117C114.094545 925.124156 164.987013 975.792208 228.608 975.792208h611.893195c63.617662 0 114.511792-50.673039 114.511792-114.013091V163.883221C955.012987 100.543169 904.118857 49.87013 840.501195 49.87013H230.925299C167.307636 49.87013 116.413506 100.543169 116.413506 163.883221v82.920727H86.336831C77.082597 246.803948 68.987013 254.866286 68.987013 264.075636v50.674702c0 9.212675 8.095584 17.276675 17.349818 17.276675H116.413506v64.493714H86.336831C77.082597 396.520727 68.987013 404.57974 68.987013 413.792416v50.674701c0 9.211013 8.095584 17.271688 17.349818 17.271688H116.413506v62.188052H86.336831C77.082597 543.926857 68.987013 551.995844 68.987013 561.205195v52.972052c0 9.216 8.095584 17.276675 17.349818 17.276675H116.413506v64.492052H86.336831C77.082597 695.945974 68.987013 704.008312 68.987013 713.219325v50.673039c0 9.212675 8.095584 17.278338 17.349818 17.278337H116.413506v54.125715l-2.313974 26.487688-0.004987-0.004987z m94.138182-164.849039H167.433974v-64.432208h40.798753c9.329039 0 17.487792-8.059013 17.487792-17.263376v-50.626494c0-9.202701-8.158753-17.25839-17.487792-17.25839H167.433974v-64.432207h40.798753c9.329039 0 17.487792-8.052364 17.487792-17.256728v-50.63148c0-9.204364-8.158753-17.25839-17.487792-17.25839H167.433974v-64.432208h40.798753c9.329039 0 17.487792-8.054026 17.487792-17.258389v-50.626494c0-9.204364-8.158753-17.261714-17.487792-17.261714H167.433974V164.200727c0-31.069091 24.481247-55.229506 55.949299-55.229506h616.610909c31.474701 0 55.950961 24.165403 55.950961 55.229506v697.260883c0 31.069091-24.47626 55.229506-55.950961 55.229507H223.384935c-31.468052 0-55.949299-24.160416-55.949299-55.229507v-80.540259h40.798754c9.329039 0 17.487792-8.052364 17.487792-17.256728v-47.17548c0-11.505039-8.158753-19.559065-17.487792-19.559065z m162.819325-272.751377h380.342857c25.357299 0 46.10161-21.274597 46.10161-47.28187V235.054545c0-26.002286-20.744312-47.28187-46.103272-47.28187H371.052052c-25.353974 0-46.10161 21.274597-46.10161 47.28187v140.660364c0 27.189195 20.744312 48.463792 46.10161 48.463792z\" fill=\"#86BC9F\" p-id=\"1082\"></path></svg>\n        </div>\n        <div class=\"wz\" style=\"padding:0 5px;line-height: 38px;height: 36px;float:left;\n        font-size: 20px;text-align: center;letter-spacing: 5px;\">\n            千屹留言区\n        </div>\n                <div class=\"icon\" style=\"width:36px;height: 36px;float:left;background-size: cover\">\n            <svg t=\"1684948258846\" class=\"icon\" viewBox=\"0 0 1024 1024\" version=\"1.1\" xmlns=\"http://www.w3.org/2000/svg\" p-id=\"1080\" width=\"36\" height=\"36\"><path d=\"M334.12987 788.779221m-187.012987 0a187.012987 187.012987 0 1 0 374.025974 0 187.012987 187.012987 0 1 0-374.025974 0Z\" fill=\"#FFDEBB\" p-id=\"1081\"></path><path d=\"M114.094545 861.779117C114.094545 925.124156 164.987013 975.792208 228.608 975.792208h611.893195c63.617662 0 114.511792-50.673039 114.511792-114.013091V163.883221C955.012987 100.543169 904.118857 49.87013 840.501195 49.87013H230.925299C167.307636 49.87013 116.413506 100.543169 116.413506 163.883221v82.920727H86.336831C77.082597 246.803948 68.987013 254.866286 68.987013 264.075636v50.674702c0 9.212675 8.095584 17.276675 17.349818 17.276675H116.413506v64.493714H86.336831C77.082597 396.520727 68.987013 404.57974 68.987013 413.792416v50.674701c0 9.211013 8.095584 17.271688 17.349818 17.271688H116.413506v62.188052H86.336831C77.082597 543.926857 68.987013 551.995844 68.987013 561.205195v52.972052c0 9.216 8.095584 17.276675 17.349818 17.276675H116.413506v64.492052H86.336831C77.082597 695.945974 68.987013 704.008312 68.987013 713.219325v50.673039c0 9.212675 8.095584 17.278338 17.349818 17.278337H116.413506v54.125715l-2.313974 26.487688-0.004987-0.004987z m94.138182-164.849039H167.433974v-64.432208h40.798753c9.329039 0 17.487792-8.059013 17.487792-17.263376v-50.626494c0-9.202701-8.158753-17.25839-17.487792-17.25839H167.433974v-64.432207h40.798753c9.329039 0 17.487792-8.052364 17.487792-17.256728v-50.63148c0-9.204364-8.158753-17.25839-17.487792-17.25839H167.433974v-64.432208h40.798753c9.329039 0 17.487792-8.054026 17.487792-17.258389v-50.626494c0-9.204364-8.158753-17.261714-17.487792-17.261714H167.433974V164.200727c0-31.069091 24.481247-55.229506 55.949299-55.229506h616.610909c31.474701 0 55.950961 24.165403 55.950961 55.229506v697.260883c0 31.069091-24.47626 55.229506-55.950961 55.229507H223.384935c-31.468052 0-55.949299-24.160416-55.949299-55.229507v-80.540259h40.798754c9.329039 0 17.487792-8.052364 17.487792-17.256728v-47.17548c0-11.505039-8.158753-19.559065-17.487792-19.559065z m162.819325-272.751377h380.342857c25.357299 0 46.10161-21.274597 46.10161-47.28187V235.054545c0-26.002286-20.744312-47.28187-46.103272-47.28187H371.052052c-25.353974 0-46.10161 21.274597-46.10161 47.28187v140.660364c0 27.189195 20.744312 48.463792 46.10161 48.463792z\" fill=\"#86BC9F\" p-id=\"1082\"></path></svg>\n        </div>\n    </div>\n\n\n<div class=\"animate__animated animate__slideInRight animate__slow animate__slower \"style=\"font-size: 20px;letter-spacing: 5px; text-align:center;\"> \n    这里是公共留言区，有什么问题和建议都可以畅所欲言，在下面留言哦！\n</div>\n\n\n\n![image-20230525011705837](../img/千屹留言区/462ade84ae8f233a3ac9ddf3cfad433a7c3f1f90.png)","tags":["Public"]},{"title":"GitBash笔记","url":"/posts/36392/","content":"\n<meta name=\"referrer\" content=\"no-referrer\"/>\n\n# GitBash笔记\n\n下载gitbash工具[Git for Windows](https://gitforwindows.org/)安装教程在**<u>文末</u>**\n\n·官网下载 https://git-scm.com/downloads\n·Windows系统直接用https://gitforwindows.org/\n\n## 基本环境\n\n### 定义用户名和邮箱\n\n```\ngit config --global user.name \"xxx\"\ngit config --global user.email \"xxx@xxx.xxx\"\n\n检查设对没有\ngit config user.name\ngit config user.email\n```\n\n![image-20230412004900608](../img/GitBash/58e73758ae7c606bc967c3e090df2e69550a8886.png)用户名，邮箱就是你绑定的邮箱\n\n### 生成远程连接密钥\n\n```\nssh-keygen -t rsa -C \"xxx@xxx.xxx\"\n查看密钥\ncat ~/.ssh/id_rsa.pub\n\n会有一串密密麻麻的文字，全部复制到这 生成就行了\n```\n\n全局使用\n\n![image-20230412005423098](../img/GitBash/40216bcf81c291877129352b3e60819b7fabe274.png)\n\n### 测试远程连接\n\n```\nssh -T git@github.com\n```\n\n## 基本命令\n\n官方给了一个较好的解释文档\n\n![image-20230412022423485](../img/GitBash/60bb244f9e296e276d574e0c708e36a75f2f761d.png)\n\n### git init \n\n```\n#初始化一个新的git仓库\ngit init\n```\n\n### README.MD文件\n\n没有它会报错，如果你没准备可以用以下命令\n\n```\necho \"# 123456\" >> README.md\n```\n\n`README.md`是一个文本文件，通常在Git项目的根目录中，用于向其他人介绍该项目的信息。其中，`.md`是Markdown（标记语言）的文件格式，在GitHub等网站中被广泛使用。\n\n具体来说，`README.md`文件通常包含以下信息：\n\n1. 项目名称和描述\n2. 如何安装和运行该项目\n3. 项目的使用方法和注意事项\n4. 贡献者的信息和代码许可\n5. 项目的版本历史和最新更新内容等等。\n\n通过编写`README.md`文件，可以提供给其他人一个简洁、清晰的项目概述，方便其他人快速了解和使用该项目。同时，也可以通过修改`README.md`文件来更新和维护项目的最新信息和文档。\n\n在GitHub等网站中，`README.md`文件会被自动渲染为网页显示，因此对项目的宣传和文档编写具有重要意义。\n\n### git add\n\n```\n将文件添加到git仓库\ngit add <file>\n例如 ：\n注意指令末尾小数点\ngit add . \n#将项目的所有文件添加到仓库中\n```\n\n### git commit\n\n```\ngit commit -m \"message\"\n提交更改，并附上提交信息\n```\n\n### git status\n\n```\n#查看Git仓库状态\ngit status\n```\n\n### git log\n\n```\ngit log\n查看提交记录\n```\n\n### git clone <url>\n\n![image-20230412012126767](../img/GitBash/98806c97ba049a4349a5c30259daf2eaf217673c.png)\n\n```\ngit clone https://github.com······\n#克隆一个Git仓库到本地\n```\n\n### git push\n\n```\n#将本地的更改推送到远程仓库\ngit push\n```\n\n### git pull\n\n```\n#从远程仓库拉取最新更改\ngit pull\n```\n\n### git branch\n\n```\n#查看和管理分支\ngit branch\n```\n\n### git merge <branch>\n\n```\ngit merge\n#将一个分支合并到当前分支中\n```\n\n### git stash：\n\n```\n#将当前的更改保存到“存储区”，以便以后再次使用\ngit stash\n```\n\n### git remote add <name> <url>：\n\n```\n#将远程仓库添加到本地Git仓库中\n关联本地仓库和远程仓库\n```\n\n## 实例操作\n\n<span style=color:red;font-size:18px>请先完成 **1.基本环境**的所有步骤</span>\n\n假设我要上传项目\n\n### GitHub建好一个新库\n\n![image-20230412021445830](../img/GitBash/534f06d9a51cf391c26370aa6132f7e8eca7fabc.png)\n\n### 在本地也创建一个本地库\n\n勾选显示隐藏的项目\n\n![image-20230412012857747](../img/GitBash/44c261e2a705959f8f0ceb87f35e2591e7c508c9.png)\n\n![image-20230412021542032](../img/GitBash/7daadf525c1c8828d00b1e0a4e471976ad1a8362.png)\n\n右键空白处\n\n![image-20230412021558652](../img/GitBash/86b28b1209dc8c90595fcf9864967f8190863acb.png)\n\n### 初始化本地仓库\n\n```\ngit init\n```\n\n![image-20230412021648634](../img/GitBash/ff6eb402955eb345213491c87d72a15ef389ed9f.png)\n\n### 将项目的所有文件添加到本地仓库中\n\n```\ngit add .\n#注意小数点\n```\n\n### 添加README.md文件\n\n要求当前文件下有这个文件，没有会报错\n\n```\ngit add README.md\n```\n\n### 提交到仓库，附上信息备注\n\n```\ngit commit -m \"上传测试文件\"\n```\n\n![image-20230412021712910](../img/GitBash/bde6c3201ca433b1fef97b64df466e8d5b404985.png)\n\n### 修改分支（名字自定）\n\n```\ngit branch -M main\n```\n\n`git branch -M main`命令用于将当前分支的名称修改为`main`，并将所有已有分支指向新的主分支`main`。\n\n### 将本地仓库关联到GitHub仓库\n\n```\ngit remote add origin https://github.com/······\n```\n\nhttps的地址，如果https不行也可以换成ssh地址\n\n![image-20230412021750914](../img/GitBash/405ae6f37791bad3e46a087d3170def4041dfd47.png)\n\n### 拉取最新更改\n\n```\ngit pull origin main\n##上传github之前pull一下,第一次创建的库没有main分支,所有第一次不用打这个，以后建议，习惯的pull以下\n```\n\n### 上传代码至GitHub远程仓库\n\n```\ngit push -u origin main\n```\n\n![image-20230412021831978](../img/GitBash/536ee70341cf5273432f947c3ab29f6c20f6f93f.png)\n\n![image-20230412021905011](../img/GitBash/9132fb58eda2e345b8fd5edca2e56d5b240338e1.png)\n\n## 克隆代码\n\n###从远程库克隆\n这是针对在本地的一个空的项目，要从远程库考代码下来，一般有**两个**步骤：\n\n**1.在本地想要克隆的文件夹下面创建GIT版本库，以及建立远程库的连接。（详细步骤可以查看前面章节内容）**\n\n####建好本地库，基础环境 初始化等步骤，最后pull一下\n\n```\ngit init\ngit remote add origin https://github.com/·······\ngit pull origin main\n```\n\n![image-20230412020003450](../img/GitBash/cd960cede63ee9bda65a9e114fb341c6375fb4b4.png)\n\n\n\n**2.用git clone克隆远程库所在项目的代码，比如要克隆上一节的代码，用下面命令即可**\n\n```\ngit clone https://github.com/·······\n```\n\n![image-20230412021953276](../img/GitBash/97a6403c89ccd5dfd51cf2bb7844ad045d34771e.png)\n\n## 更新代码\n\n在本地仓库添加一个test2.txt\n\n![image-20230412020630452](../img/GitBash/f78640adb66874cff18c24fb1c4173118503b68e.png)\n\n1. 查看当前的git仓库状态\n\n```\ngit status\n```\n\n2. 更新test2.txt文件\n\n```\ngit add test2.txt\n```\n\n3. 对test2.txt文件注入备注信息\n\n```\ngit commit -m \"上传test2.txt\"\n```\n\n4. 拉取main分支最新代码\n\n```\ngit pull origin main\n```\n\n5. push到远程main分支上\n\n```\ngit push origin main\n```\n\n你也可以更新全部\n\n```\ngit add *\ngit commit -m \"上传所有文件\"\ngit pull origin main\ngit push origin main\n```\n\n打开GitHub已经同步了\n\n![image-20230412020938339](../img/GitBash/c836702bafb01847aad25089b436afdfc3c8d995.png)\n\n## 安装教程\n\n### 建议新建一个文件夹，放git，作为安装路径\n\n![image-20230412001233082](../img/GitBash/59b310da6cac2759c4dad518aa320a35c753c388.png)\n\n![image-20230412001348748](../img/GitBash/e1ae716c98cd8f95e02e07e0d5d8f9ad75801b59.png)\n\n### 更换路径\n\n![image-20230412001424892](../img/GitBash/07c2d38ab489d892fb7764a580efa632acbd2023.png)\n\n### 按需自助选择\n\n![image-20230412001812933](../img/GitBash/aeda6d2f6bfb12f8c73fd092fc04125883f829ca.png)\n\n![image-20230412001959068](../img/GitBash/dc57717b7f1110709dfbff07630513010c05742b.png)\n\n### 选择开始文件夹\n\n方框内 Git 可改为其他名字，也可点击 “Browse…” 选择其他文件夹或者给\"Don’t create a Start Menu folder\" 打勾不要文件夹，点击 [next]\n\n![image-20230412002158820](../img/GitBash/e94d7b0df64115e771ce255f7e86cab7c63c19ec.png)\n\n### Git编辑器\n\n![image-20230412002151766](../img/GitBash/ba491439ced78aef015bd5bbafc90dccfd5a48e9.png)\n\n### 决定初始化新项目(仓库)的主干名字\n\n![image-20230412002328765](../img/GitBash/dddd718c71ad2392e6cfc4166d20a6e54f66f2c2.png)\n\n### 调整环境变量\n\n![image-20230412002502629](../img/GitBash/0ffa79254e4ef5ed0d31bf38363c4eafbe49900f.png)\n\n### 选择SSH执行文件\n\n![image-20230412002529388](../img/GitBash/a9841e6a5668e102ce9cc6c5dea649ef9b96bd61.png)\n\n### 选择HTTPS后端传输\n\n注意：如果具有企业管理证书的组织中使用Git，就需要使用安全通道。\n\n![image-20230412003005628](../img/GitBash/ef6b6ebd40cfbe21eb565a0bd6107031fb9fc6de.png)\n\n### 配置行尾符号转换\n\n![image-20230412003215788](../img/GitBash/435edd74569571f7af49772b297b2ca6a6803809.png)\n\n### 配置终端模拟器以与 Git Bash 一起使用\n\n![image-20230412003320788](../img/GitBash/092402ecec84b2b1d2c66d65d7dcac010d6e9091.png)\n\n### 选择默认的 git pull 模式\n\n`git pull` 就是获取最新的远程仓库分支到本地，并与本地分支合并。\n\n![image-20230412003411911](../img/GitBash/c9f6c5f14c09d7640f421bb6ab19141cd33aa846.png)\n\n### 选择一个凭证帮助程序\n\n![image-20230412003524413](../img/GitBash/d13036dc15fe51c408fae1c0cfc8956b68f043f4.png)\n\n### 配置额外的选项\n\n配置建议两个都选\n\n![image-20230412003604092](../img/GitBash/91b859e7561297074a5b07826757e8d4b47db990.png)\n\n### 配置实验性选择\n\n![image-20230412003707549](../img/GitBash/f1ee851e62e8b3f64add0f38616858324428f4f7.png)\n\n安装完成！！\n\n<div class=\"tbsm\" style=\"margin-top:54px;\">\n<div class=\"tbsm-top\"><span><svg t=\"1674654360507\" class=\"icon\" viewBox=\"0 0 1024 1024\" version=\"1.1\" xmlns=\"http://www.w3.org/2000/svg\" p-id=\"987\" data-spm-anchor-id=\"a313x.7781069.0.i0\" width=\"35\" height=\"35\"><path d=\"M410.49 97.74H155.08a56.74 56.74 0 0 0-56.84 56.73V410a56.84 56.84 0 0 0 56.84 56.84h255.41A56.83 56.83 0 0 0 467.32 410V154.58a56.83 56.83 0 0 0-56.83-56.84zM410.49 558.74H155.08a56.74 56.74 0 0 0-56.84 56.73V871a56.84 56.84 0 0 0 56.84 56.84h255.41A56.83 56.83 0 0 0 467.32 871V615.58a56.83 56.83 0 0 0-56.83-56.84zM871.49 558.74H616.08a56.74 56.74 0 0 0-56.84 56.73V871a56.84 56.84 0 0 0 56.84 56.84h255.41A56.83 56.83 0 0 0 928.32 871V615.58a56.83 56.83 0 0 0-56.83-56.84z\" fill=\"#66EEFF\" p-id=\"988\"></path><path d=\"M410.49 558.74h-4.14A475 475 0 0 0 299.52 859.6a481.16 481.16 0 0 0 4.84 68.22h106.13A56.83 56.83 0 0 0 467.32 871V615.58a56.83 56.83 0 0 0-56.83-56.84zM871.49 558.74H616.08a56.74 56.74 0 0 0-56.84 56.73V871a56.84 56.84 0 0 0 56.84 56.84h255.41A56.83 56.83 0 0 0 928.32 871V615.58a56.83 56.83 0 0 0-56.83-56.84z\" fill=\"#C2F8FF\" p-id=\"989\"></path></svg></span><span style=\"font-size:30px;\"> 特别声明</span></div>\n<div class=\"tbsm-wz\">千屹博客旗下的所有文章，是通过本人课堂学习和课外自学所精心整理的知识巨著<br/>难免会有出错的地方<br/>如果细心的你发现了小失误，可以在下方评论区告诉我，或者私信我！<br />非常感谢大家的热烈支持！</div>\n</div>","tags":["GitBash"],"categories":["运维"]},{"title":"Hadoop组件部署","url":"/posts/4909/","content":"\n<meta name=\"referrer\" content=\"no-referrer\"/>\n\n# Hadoop组件部署\n\n[Hadoop部署 - 严千屹 (qianyios.top)](https://blog.qianyios.top/posts/32436/)本笔记建立在Hadoop伪分布机子上，可以前往查看安装机子\n\n## Zookeeper\n\n你需要克隆出三台hadoop的基础模版机，[这里有教程和说明](https://blog.qianyios.top/posts/32436/#%E5%AE%89%E8%A3%85Hadoop)，然后再进行开始操作，这个Zookeeper是hadoop的一个组件，独立出来了的，也就是说是一个独立的Zookeeper集群，Hbase是需要基于Zookeeper运行的，如果你不需要独立的Zookeeper可以不用做这个，hbase有自带的Zookeeper\n\n| 名称 |      ip       |\n| :--: | :-----------: |\n| zk01 | 192.168.48.11 |\n| zk02 | 192.168.48.12 |\n| zk03 | 192.168.48.13 |\n\n### 设置hosts\n\n```\n[root@localhost ~]# cat /etc/hosts\n127.0.0.1   localhost localhost.localdomain localhost4 localhost4.localdomain4\n::1         localhost localhost.localdomain localhost6 localhost6.localdomain6\n192.168.48.11 zk01\n192.168.48.12 zk02\n192.168.48.13 zk03\n```\n\n### 更改主机名\n\n```\nhostnamectl set-hostname zk01 && bash\n```\n\n### 检查java版本\n\n```\n[root@zk01 ~]# java -version\njava version \"1.8.0_162\"\nJava(TM) SE Runtime Environment (build 1.8.0_162-b12)\nJava HotSpot(TM) 64-Bit Server VM (build 25.162-b12, mixed mode)\n```\n\n### 检查hadoop版本\n\n```\n[root@zk01 ~]# hadoop version\nHadoop 3.1.3\nSource code repository https://gitbox.apache.org/repos/asf/hadoop.git -r ba631c436b806728f8ec2f54ab1e289526c90579\nCompiled by ztang on 2019-09-12T02:47Z\nCompiled with protoc 2.5.0\nFrom source with checksum ec785077c385118ac91aadde5ec9799\nThis command was run using /usr/local/hadoop/share/hadoop/common/hadoop-common-3.1.3.jar\n```\n\n### 安装zookeeper\n\n```\ntar -xf apache-zookeeper-3.8.0-bin.tar.gz -C /opt\necho \"export ZOOKEEPER_HOME=/opt/apache-zookeeper-3.8.0-bin\" >> /etc/profile\necho \"export PATH=\\$ZOOKEEPER_HOME/bin:\\$PATH\" >> /etc/profile\nsource /etc/profile\ncd /opt/apache-zookeeper-3.8.0-bin/\ncp conf/zoo_sample.cfg conf/zoo.cfg\n\nvi conf/zoo.cfg\n    tickTime=2000\n    dataDir=/opt/apache-zookeeper-3.8.0-bin/data\n    clientPort=2181\n    initLimit=10\n    syncLimit=5\n    maxClientCnxns=60\n    server.1=zk01:2888:3888\n    server.2=zk02:2888:3888\n    server.3=zk03:2888:3888\n\nmkdir /opt/apache-zookeeper-3.8.0-bin/data\necho 1 > /opt/apache-zookeeper-3.8.0-bin/data/myid\ncat /opt/apache-zookeeper-3.8.0-bin/data/myid\n```\n\n### 关机克隆出两台机 zk02 zk03\n\nzk02  192.168.48.12\n\n```\nvi /opt/apache-zookeeper-3.8.0-bin/data/myid\n2\n```\n\nzk03  192.168.48.13\n\n```\nvi /opt/apache-zookeeper-3.8.0-bin/data/myid\n3\n```\n\n### 互相ping测试连通性\n\n```\nping zk01\nping zk02\nping zk03\n```\n\n能互通说明成功\n\n### 开启zookeeper服务\n\n需开启两台才能看见Mode: follower\n\n```\nzkServer.sh start\nzkServer.sh status\nzkServer.sh stop\n```\n\n## HBase安装\n\n### 安装hbase\n\n```\n[root@hadoop ~]# ll\n-rw-r--r--  1 root root 232190985 3月  17 19:37 hbase-2.2.2-bin.tar.gz\n\ntar -xf hbase-2.2.2-bin.tar.gz -C /usr/local/\nmv /usr/local/hbase-2.2.2 /usr/local/hbase\necho \"export HBASE_HOME=/usr/local/hbase\" >> /etc/profile\necho \"export PATH=\\$PATH:\\$HBASE_HOME/bin\" >> /etc/profile\nsource /etc/profile\n\n------------------------------------------------------------------------\n[root@hadoop ~]# vi /usr/local/hbase/bin/hbase\nCLASSPATH=${CLASSPATH}:$JAVA_HOME/lib/tools.jar:/usr/local/hbase/lib/*\n或\n[root@hadoop ~]# sed -i \"s/CLASSPATH=\\${CLASSPATH}:\\$JAVA_HOME\\/lib\\/tools.jar/CLASSPATH=\\${CLASSPATH}:\\$JAVA_HOME\\/lib\\/tools.jar:\\/usr\\/local\\/hbase\\/lib\\/*/g\" /usr/local/hbase/bin/hbase\n------------------------------------------------------------------------\n\n[root@hadoop ~]# hbase version                                                       SLF4J: Class path contains multiple SLF4J bindings.\nSLF4J: Found binding in [jar:file:/usr/local/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.25.jar!/org/slf4j/impl/StaticLoggerBinder.class]\nSLF4J: Found binding in [jar:file:/usr/local/hbase/lib/client-facing-thirdparty/slf4j-log4j12-1.7.25.jar!/org/slf4j/impl/StaticLoggerBinder.class]\nSLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.\nSLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]\nHBase 2.2.2\nSource code repository git://6ad68c41b902/opt/hbase-rm/output/hbase revision=e6513a76c91cceda95dad7af246ac81d46fa2589\nCompiled by hbase-rm on Sat Oct 19 10:10:12 UTC 2019\nFrom source with checksum 4d23f97701e395c5d34db1882ac5021b\n```\n\n### HBase配置\n\n`HBASE_MANAGES_ZK=true`设置为true就是说用hbase自带的Zookeeper，如果你有独立的Zookeeper集群，自行设置\n\n```bash\necho \"export JAVA_HOME=/usr/lib/jvm/jdk1.8.0_162\" >> $HBASE_HOME/conf/hbase-env.sh\necho \"export HBASE_CLASSPATH=/usr/local/hbase/conf\" >> $HBASE_HOME/conf/hbase-env.sh\necho \"export HBASE_MANAGES_ZK=true\" >> $HBASE_HOME/conf/hbase-env.sh\n\nvi $HBASE_HOME/conf/hbase-site.xml\n<configuration>\n        <property>\n                <name>hbase.rootdir</name>\n                <value>hdfs://yjx48:9000/hbase</value>\n        </property>\n        <property>\n                <name>hbase.cluster.distributed</name>\n                <value>true</value>#是否分布式运行，false即为单机\n        </property>\n        <property>\n                <name>hbase.unsafe.stream.capability.enforce</name>\n                <value>false</value>\n        </property>\n</configuration>\n```\n\n### HBase启动\n\n```\nstart-all.sh \nstart-hbase.sh\n[root@hadoop hbase]# jps\n16532 ResourceManager\n22502 HMaster-----------\n15799 NameNode\n16697 NodeManager\n23097 Jps\n15962 DataNode\n22666 HRegionServer-----------\n16223 SecondaryNameNode\n22431 HQuorumPeer\n[root@hadoop ~]# hbase shell\nhbase(main):001:0> list\nTABLE\n0 row(s)\nTook 0.3118 seconds\n=> []\nhbase(main):002:0> exit\n```\n\n### 访问网页\n\nip:16010\n\n### HBase管理\n\n| 学号（S_No） | 姓名（S_Name） | 性别（S_Sex） | 年龄（S_Age） |\n| :----------: | :------------: | :-----------: | :-----------: |\n|   2015001    |    zhangsan    |     male      |      23       |\n|   2015002    |      Mary      |    female     |      22       |\n|   2015003    |      Lisi      |     male      |      24       |\n\n#### 创建学生表\n\n```\nhbase(main):004:0> create 'student','no','name','sex','age'\nCreated table student\nTook 1.3125 seconds\n=> Hbase::Table - student\nhbase(main):005:0> list\nTABLE\nstudent\n1 row(s)\nTook 0.0074 seconds\n=> [\"student\"]\n#查看表结构\nhbase(main):001:0> describe 'student'\nTable student is ENABLED\nstudent\nCOLUMN FAMILIES DESCRIPTION\n{NAME => 'age', VERSIONS => '1', EVICT_BLOCKS_ON_CLOSE => 'false'\n.......\n```\n\n#### 添加数据\n\ns001为行键\n\n```\nhbase(main):001:0> scan 'student'\nROW                        COLUMN+CELL\n0 row(s)\nTook 0.2712 seconds\nhbase(main):002:0> put 'student','s001','no','2015001'\nTook 0.0236 seconds\nhbase(main):003:0> put 'student','s001','name','zhangsan'\nTook 0.0057 seconds\nhbase(main):004:0> scan 'student'\nROW                        COLUMN+CELL\n s001                      column=name:, timestamp=1679058447572, value=zhangsan\n s001                      column=no:, timestamp=1679058447550, value=2015001\n1 row(s)\nTook 0.0179 seconds\n```\n\n#### 查看整行\n\n```\nhbase(main):001:0> get 'student','s001'\nCOLUMN                     CELL\n name:                     timestamp=1679058447572, value=zhangsan\n no:                       timestamp=1679058447550, value=2015001\n1 row(s)\nTook 0.2910 seconds\n```\n\n#### 查看单元格\n\n```\nhbase(main):008:0> get 'student','s001','name'\nCOLUMN                     CELL\n name:                     timestamp=1679058447572, value=zhangsan\n1 row(s)\nTook 0.0053 seconds\n```\n\n### 订单例子\n\n![image-20230317212813880](../img/Hadoop组件部署/7105ba3fd997598b9d7de8368254d5aaf24c1aec.png)\n\n#### 创建order表\n\n```\ncreate 'order','userinfo','orderinfo'\nlist\nput 'order','1','userinfo:name','sw'\nput 'order','1','userinfo:age','24'\nput 'order','1','orderinfo:id','23333'\nput 'order','1','orderinfo:money','30'\nscan 'order'\n-----------------------------------------------------------\nhbase(main):017:0* create 'order','userinfo','orderinfo'\nCreated table order\nTook 2.3102 seconds\n=> Hbase::Table - order\nhbase(main):018:0> list\nTABLE\norder\nstudent\n2 row(s)\nTook 0.0104 seconds\n=> [\"order\", \"student\"]\nhbase(main):019:0> put 'order','1','userinfo:name','sw'\nTook 0.0326 seconds\nhbase(main):020:0> put 'order','1','userinfo:age','24'\nTook 0.0031 seconds\nhbase(main):021:0> put 'order','1','orderinfo:id','23333'\nTook 0.0036 seconds\nhbase(main):022:0> put 'order','1','orderinfo:money','30'\nTook 0.0031 seconds\nhbase(main):023:0> scan 'order'\nROW                        COLUMN+CELL\n 1                         column=orderinfo:id, timestamp=1679060732699, value=23333\n 1                         column=orderinfo:money, timestamp=1679060732711, value=30\n 1                         column=userinfo:age, timestamp=1679060732685, value=24\n 1                         column=userinfo:name, timestamp=1679060732667, value=sw\n1 row(s)\nTook 0.0116 seconds\n```\n\n### 修改数据\n\n```\nhbase(main):001:0> put 'student','s001','name','zhangxiaosan'\nTook 0.2879 seconds\nhbase(main):002:0> get 'student','s001','name'\nCOLUMN                     CELL\n name:                     timestamp=1679061655288, value=zhangxiaosan\n1 row(s)\nTook 0.0280 seconds\n```\n\n### 时间戳\n\n#数据添加到HBase的时候都会被记录一个时间戳，这个时间戳被我们当做一个版本。\n\n当修改某一条的时候，本质上是往里边新增一条数据，记录的版本加一。\n\n![image-20230317220909473](../img/Hadoop组件部署/41ae96ec2b636400a97d0c0377d7ba5f7e4467f6.png)\n\n#现在要把这条记录的值改为40，实际上就是多添加一条记录，在读的时候按照时间戳读最新的记录\n\n![image-20230317221537086](../img/Hadoop组件部署/b5b87b734906aa507db9aa8474c02f6856295bca.png)\n\n```\nput 'order','1','orderinfo:money','40'\nget 'order','1','orderinfo:money'\n\nhbase(main):008:0> put 'order','1','orderinfo:money','40'\nTook 0.0190 seconds\nhbase(main):009:0> get 'order','1','orderinfo:money'\nCOLUMN                     CELL\n orderinfo:money           timestamp=1679064515487, value=40\n1 row(s)\nTook 0.0096 seconds\n\n```\n\n### 删除数据\n\nname一定要加个`:`\n\n```\nscan 'student'\ndelete 'student','s001','name:'\nget 'student','s001','name'\n```\n\n### 删除表\n\n```\ndisable 'student'\ndescribe 'student'\ndrop 'student'\n```\n\n### 访问网页\n\nip:16010\n\n## NoSQL数据库安装\n\n（Redis键值对非关系型数据库）\n\n### 安装redis\n\n```\ntar -xf redis-5.0.5.tar.gz\nmv redis-5.0.5 /opt/redis\ncd /opt/redis\nyum install -y gcc automake autoconf libtool\n#编译安装\nmake && make install\ncd src\n[root@yjx48 src]# ./redis-server\n5861:C 30 Mar 2023 08:49:48.699 # oO0OoO0OoO0Oo Redis is starting oO0OoO0OoO0Oo\n5861:C 30 Mar 2023 08:49:48.699 # Redis version=5.0.5, bits=64, commit=00000000, modified=0, pid=5861, just started\n5861:C 30 Mar 2023 08:49:48.699 # Warning: no config file specified, using the default config. In order to specify a config file use ./redis-server /path/to/redis.conf\n5861:M 30 Mar 2023 08:49:48.699 * Increased maximum number of open files to 10032 (it was originally set to 1024).\n                _._\n           _.-``__ ''-._\n      _.-``    `.  `_.  ''-._           Redis 5.0.5 (00000000/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._\n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 5861\n  `-._    `-._  `-./  _.-'    _.-'\n |`-._`-._    `-.__.-'    _.-'_.-'|\n |    `-._`-._        _.-'_.-'    |           http://redis.io\n  `-._    `-._`-.__.-'_.-'    _.-'\n |`-._`-._    `-.__.-'    _.-'_.-'|\n |    `-._`-._        _.-'_.-'    |\n  `-._    `-._`-.__.-'_.-'    _.-'\n      `-._    `-.__.-'    _.-'\n          `-._        _.-'\n              `-.__.-'\n\n5861:M 30 Mar 2023 08:49:48.700 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n```\n\n```\n#另开一个会话\n[root@yjx48 ~]# cd /opt/redis/src\n[root@yjx48 src]# ./redis-cli\n127.0.0.1:6379> set hello world\nOK\n127.0.0.1:6379> get hello\n\"world\"\n127.0.0.1:6379> exit\n[root@yjx48 src]#\n```\n\n### 数据库管理\n\n![image-20230330112542140](../img/Hadoop组件部署/23833340d878c73b11cf4064c0a4ab51ecc4b4d3.png)\n\n### redis语法\n\n```\n#插入数据\nset student:2015001:sname zhangsan\nget student:2015001:sname\nset student:2015001:sex male\nget student:2015001:sex\n#修改数据\nset student:2015001:sname zhangxiaosan\nget student:2015001:sname\n#删除数据\nget set student:2015001:sname\ndel set student:2015001:sname\nget set student:2015001:sname\n#没数据了\n```\n\n### Hash数据库\n\nstudent表\n\n```\n2015001={\n\tname=zhangsan\n\tsex=male\n\tage=23\n}\n```\n\n插入和查询数据\n\n```\nhset student:2015001 name zhangsan\nhset student:2015001 sex male\nhset student:2015001 age 23\nhget student:2015001 name \nhget student:2015001 sex\nhgetall student:2015001\n```\n\n修改数据\n\n```\nhset student:2015001 sex female\nhget student:2015001 sex female\n```\n\n删除数据\n\n```\nhdel student:2015001 sex\nhget student:2015001 sex\n#无数据\n```\n\n## MongoDB\n\n​\t\tMongodb是一个基于分布式文件存储的文档数据库，介于关系数据库和非关系数据库之间，是非关系数\n据库当中功能最丰富、最像关系数据库的一种 NOSQL数据库。\n​\t\tMongo最大的特点是支持的查询语言非常强大，语法有点类似于面向对象的查询语言，几乎可以实现类\n似关系数据库单表查询的绝大部分功能，而且还支持对数据建立索引。\n​\t\tMongodb支持的数据结构非常松散，是类似json的bson格式，因此可以存储比较复杂的数据类型。\n\n### JSON语法\n\nJSON 语法是 JavaScript 语法的子集。\n\n#### JSON 数字\n\nJSON 数字可以是整型或者浮点型：\n{ \"age\":30 }\n\n#### JSON 对象\n\nJSON 对象在大括号 {} 中书写：\n对象可以包含多个名称/值对：\n\n#### JSON 数组\n\nJSON 数组在中括号 [] 中书写：\n数组可包含多个对象：\n\n```\n[\n{ key1 : value1-1 , key2:value1-2 },\n{ key1 : value2-1 , key2:value2-2 },\n{ key1 : value3-1 , key2:value3-2 },\n...\n{ key1 : valueN-1 , key2:valueN-2 },\n]\n\n{\n\t\"sites\": [\n        { \"name\":\"菜鸟教程\" , \"url\":\"www.runoob.com\" },\n        { \"name\":\"google\" , \"url\":\"www.google.com\" },\n        { \"name\":\"微博\" , \"url\":\"www.weibo.com\" }\n       ]\n}\n```\n\n在上面的例子中，对象 sites 是包含三个对象的数组。每个对象代表一条关于某个网站（name、url）\n的记录。\n\n#### JSON 布尔值\n\nJSON 布尔值可以是 true 或者 false：\n\n```\n{ \"flag\":true }\n```\n\n#### JSON null\n\nJSON 可以设置 null 值：\n\n```\n{ \"runoob\":null }\n```\n\n### MongoDB安装\n\n```\ntar -xf mongodb-linux-x86_64-rhel70-5.0.5.tgz \nmv mongodb-linux-x86_64-rhel70-5.0.5 /opt/mongodb\ncd /opt/mongodb/bin\n./mongo -version\n\n#默认情况下 MongoDB 启动后会初始化以下两个目录，事先创建好：\n#数据存储目录：/var/lib/mongodb\n#日志文件目录：/var/log/mongodb\nmkdir -p /var/lib/mongo\nmkdir -p /var/log/mongodb\n#启动mongodb服务\ncd /opt/mongodb/bin\n./mongod --dbpath /var/lib/mongo --logpath /var/log/mongodb/mongod.log --fork\nps ax | grep mongod\n./mongo\n```\n\n### 数据库管理\n\n#### 常用命令\n\n#列出所有数据库\n\n```\n>show dbs\nadmin 0.000GB\nconfig 0.000GB\nlocal 0.000GB\n```\n\n#切换数据库\n\n```\n>use admin\nswitched to db admin\n```\n\n#显示当前数据库的所有集合\n\n```\n>show collections\nsystem.version\n```\n\n#显示集合的所有数据\n\n```\n>db.system.version.find()\n{ \"_id\" : \"featureCompatibilityVersion\", \"version\" : \"5.0\" }\n```\n\n#### 创建数据库和集合\n\n```\n#mongodb没有创建数据库命令\n> use school\nswitched to db school\n#创建集合，同时会自动创建以上的数据库\n> db.createCollection('student')\n{ \"ok\" : 1 }\n> show dbs\nadmin 0.000GB\nconfig 0.000GB\nlocal 0.000GB\nschool 0.000GB\n> show collections\nStudent\n```\n\n#### 插入数据\n\n```\n#两种方法插入数据：insert和save\n#_id可以手动输入，否则会自动生成\n>db.student.insert({\n  sno: 2015001,\n  name: \"zhangsan\",\n  sex: \"male\",\n  age: 23\n})\nWriteResult({ \"nInserted\" : 1 })\n\n> db.student.find()\n{ \"_id\" : ObjectId(\"642e21279c9d145e592fda70\"), \"sno\" : 2015001, \"name\" : \"zhangsan\", \"sex\" : \"male\", \"age\" : 23 }\n\n> db.student.save({sno:2015002,name:'marry',sex:'female',age:22})\nWriteResult({ \"nInserted\" : 1 })\n\n> db.student.find()\n{ \"_id\" : ObjectId(\"642e259014c45ed3f90756c0\"), \"sno\" : 2015001, \"name\" : \"zhangsan\", \"sex\" : \"male\", \"age\" : 23 }\n{ \"_id\" : ObjectId(\"642e259614c45ed3f90756c1\"), \"sno\" : 2015002, \"name\" : \"marry\", \"sex\" : \"female\", \"age\" : 22 }\n```\n\n```\n#insert和save区别：手动插入一行时，如_id已经存在，insert则出错，save则替代原值。\n> db.student.insert({\"_id\": ObjectId(\"642e259014c45ed3f90756c0\"),   \"sno\": 2015001,   \"name\": \"zhangsan\",   \"sex\": \"male\",   \"age\": 23 })\n\nWriteResult({\n        \"nInserted\" : 0,\n        \"writeError\" : {\n                \"code\" : 11000,\n                \"errmsg\" : \"E11000 duplicate key error collection: test.student index: _id_ dup key: { _id: ObjectId('642e21279c9d145e592fda70') }\"\n        }\n})\n#更改年龄23→24\n> db.student.save({\"_id\": ObjectId(\"642e259014c45ed3f90756c0\"),   \"sno\": 2015001,   \"name\": \"zhangsan\",   \"sex\": \"male\",   \"age\": 24 })\nWriteResult({ \"nMatched\" : 1, \"nUpserted\" : 0, \"nModified\" : 1 })\n\n> db.student.find()\n{ \"_id\" : ObjectId(\"642e259014c45ed3f90756c0\"), \"sno\" : 2015001, \"name\" : \"zhangsan\", \"sex\" : \"male\", \"age\" : 24 }\n{ \"_id\" : ObjectId(\"642e259614c45ed3f90756c1\"), \"sno\" : 2015002, \"name\" : \"marry\", \"sex\" : \"female\", \"age\" : 22 }\n```\n\n#### 查找数据\n\n```\n#查询\n#查询格式：find([query],[fields]，类似于sql的select语句，query相当于where，fields相当\n于显示的列\n#查询名字为zhangsan的数据\n> db.student.find({name:'zhangsan'})\n{ \"_id\" : ObjectId(\"642e259014c45ed3f90756c0\"), \"sno\" : 2015001, \"name\" : \"zhangsan\", \"sex\" : \"male\", \"age\" : 24 }\n#查询名字为zhangsan的人的性别\n> db.student.find({name:'zhangsan'},{name:1,sex:1})\n{ \"_id\" : ObjectId(\"642e259014c45ed3f90756c0\"), \"name\" : \"zhangsan\", \"sex\" : \"male\" }\n#不显示_id\n> db.student.find({name:'zhangsan'},{_id:0,name:1,sex:1})\n{ \"name\" : \"zhangsan\", \"sex\" : \"male\" }\n#查询指定列\n> db.student.find({},{name:1})\n{ \"_id\" : ObjectId(\"642e259014c45ed3f90756c0\"), \"name\" : \"zhangsan\" }\n{ \"_id\" : ObjectId(\"642e259614c45ed3f90756c1\"), \"name\" : \"marry\" }\n#and查询条件 \n> db.student.find({name:'zhangsan',sex:'female'})\n> db.student.find({name:'zhangsan',sex:'male'})\n{ \"_id\" : ObjectId(\"642e259014c45ed3f90756c0\"), \"sno\" : 2015001, \"name\" : \"zhangsan\", \"sex\" : \"male\", \"age\" : 24 }\n>db.student.find({$or:[{age:24},{age:22}]})\n#or查询\n> db.student.find({  $or:[{age:24},{age:22}]  })\n{ \"_id\" : ObjectId(\"642e259014c45ed3f90756c0\"), \"sno\" : 2015001, \"name\" : \"zhangsan\", \"sex\" : \"male\", \"age\" : 24 }\n{ \"_id\" : ObjectId(\"642e259614c45ed3f90756c1\"), \"sno\" : 2015002, \"name\" : \"marry\", \"sex\" : \"female\", \"age\" : 22 }\n```\n\n#### 修改数据\n\n#格式：update( query, <update object or pipeline>[, upsert_bool, multi_bool] )\n#query : update的查询条件，类似sql update查询内where后面的。\n#update : update的对象和一些更新的操作符（如$,$inc...）等，也可以理解为sql update查询内\nset后面的\n#upsert : 可选，这个参数的意思是，如果不存在update的记录，是否插入objNew,true为插入，默认是\nfalse，不插入。\n#multi : 可选，mongodb 默认是false,只更新找到的第一条记录，如果这个参数为true,就把按条件查\n出来多条记录全部更新。\n\n```\n> db.student.update({name:'zhangsan'},{$set:{age:23}})\nWriteResult({ \"nMatched\" : 1, \"nUpserted\" : 0, \"nModified\" : 1 })\n\n> db.student.find()\n{ \"_id\" : ObjectId(\"642e259014c45ed3f90756c0\"), \"sno\" : 2015001, \"name\" : \"zhangsan\", \"sex\" : \"male\", \"age\" : 23 }\n{ \"_id\" : ObjectId(\"642e259614c45ed3f90756c1\"), \"sno\" : 2015002, \"name\" : \"marry\", \"sex\" : \"female\", \"age\" : 22 }\n```\n\n#### 删除数据\n\n```\n> db.student.remove({name:'zhangsan'})\nWriteResult({ \"nRemoved\" : 1 })\n> db.student.find()\n{ \"_id\" : ObjectId(\"642e259614c45ed3f90756c1\"), \"sno\" : 2015002, \"name\" : \"marry\", \"sex\" : \"female\", \"age\" : 22 }\n```\n\n#### 删除集合\n\n```\n> db.createCollection('course')\n{ \"ok\" : 1 }\n> show collections\ncourse\nstudent\n> db.course.drop()\ntrue\n> show collections\nstudent\n\n```\n\n## Hive数据仓库安装\n\nhive 是一种底层封装了Hadoop 的数据仓库处理工具，使用类SQL 的hiveSQL 语言实现数据查询，所有hive 的数据都存储在Hadoop 兼容的文件系统、(例如，[Amazon S3](https://baike.baidu.com/item/Amazon S3/10809744)、HDFS)中。hive 在加载数据过程中不会对数据进行任何的修改，只是将数据移动到HDFS 中hive 设定的目录下，因此，hive 不支持对数据的改写和添加，所有的数据都是在加载的时候确定的。\n\n**用户接口Client**\n\n用户接口主要有三个：CLI，Client 和 WUI。其中最常用的是 Cli，Cli启动的时候，会同时启动一个 hive 副本。Client 是 hive 的客户端，用户连接至 hive Server。在启动 Client 模式的时候，需要指出 hive Server 所在节点，并且在该节点启动 hive Server。 WUI 是通过浏览器访问 hive。\n\n**元数据存储 Metastore**\n\nhive 将元数据存储在数据库中，如 mysql、derby。hive 中的元数据包括表的名字，表的列和分区及其属性，表的属性（是否为外部表等），表的数据所在目录等。\n\n**驱动器：Driver 解释器、编译器、优化器、执行器**\n\n解释器、编译器、优化器完成 HQL 查询语句从词法分析、语法分析、编译、优化以及查询计划的生成。生成的查询计划存储在 HDFS 中，并在随后由 MapReduce 调用执行。\n\n**Hadoop**\n\nhive 的数据存储在 HDFS 中，大部分的查询由 MapReduce 完成（不包含 * 的查询，比如 select * from tbl 不会生成 MapReduce 任务）。\n\n![image-20230413095240448](../img/Hadoop组件部署/f79d1b048d8f3badd95b31cb952d9b151e4db804.png)\n\n![image-20230413095305455](../img/Hadoop组件部署/9a7cd6b9a3e1e3b57b9dde839c2a59cb113cdec9.png)\n\n### 安装hive\n\n```\ntar -xf apache-hive-3.1.2-bin.tar.gz\nmv apache-hive-3.1.2-bin /usr/local/hive\necho \"export HIVE_HOME=/usr/local/hive\" >> /etc/profile\necho \"export PATH=\\$HIVE_HOME/bin:\\$PATH\" >> /etc/profile\nsource /etc/profile\ncd /usr/local/hive/conf/\ncp hive-default.xml.template hive-default.xml\nvi hive-site.xml\n<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n<?xml-stylesheet type=\"text/xsl\" href=\"configuration.xsl\"?>\n<configuration>\n  <property>\n    <name>javax.jdo.option.ConnectionURL</name>\n    <value>jdbc:mysql://yjx48:3306/hive?useSSL=false</value>\n    <description>JDBC connect string for a JDBC metastore</description>\n  </property>\n  <property>\n    <name>javax.jdo.option.ConnectionDriverName</name>\n    <value>com.mysql.jdbc.Driver</value>\n    <description>Driver class name for a JDBC metastore</description>\n  </property>\n  <property>\n    <name>javax.jdo.option.ConnectionUserName</name>\n    <value>root</value>\n    <description>username to use against metastore database</description>\n  </property>\n  <property>\n    <name>javax.jdo.option.ConnectionPassword</name>\n    <value>Yjx@666.</value>\n    <description>password to use against metastore database</description>\n  </property>\n  <property>\n    <name>hive.exec.mode.local.auto</name>\n    <value>true</value>\n  </property>\n</configuration>\n```\n\n其中Yjx@666.是mysql密码\n\n### 安装mysql\n\n```\ncd\nyum remove mariadb-libs.x86_64 -y\nyum install -y net-tools\nmkdir mysql\ntar -xf mysql-5.7.37-1.el7.x86_64.rpm-bundle.tar -C mysql\ncd mysql\nrpm -ivh mysql-community-common-5.7.37-1.el7.x86_64.rpm\nrpm -ivh mysql-community-libs-5.7.37-1.el7.x86_64.rpm\nrpm -ivh mysql-community-libs-compat-5.7.37-1.el7.x86_64.rpm\nrpm -ivh mysql-community-client-5.7.37-1.el7.x86_64.rpm\nrpm -ivh mysql-community-devel-5.7.37-1.el7.x86_64.rpm\nrpm -ivh mysql-community-server-5.7.37-1.el7.x86_64.rpm\nsystemctl enable --now mysqld\ngrep  'temporary password' /var/log/mysqld.log\nmysqladmin -uroot -p'darm4hb.2Rsy' password 'Yjx@666.'\nmysql -uroot -pYjx@666.\n#给root用户授权\ngrant all privileges on *.* to 'root'@'localhost' identified by 'Yjx@666.' with grant option;\ngrant all privileges on *.* to 'root'@'%' identified by 'Yjx@666.' with grant option;\nflush privileges;\ncreate database hive;\nexit\n```\n\n### 配置和启动hive\n\n```\ncd\ntar -xf mysql-connector-java-5.1.40.tar.gz\ncp mysql-connector-java-5.1.40/mysql-connector-java-5.1.40-bin.jar /usr/local/hive/lib/\nmv /usr/local/hive/lib/guava-19.0.jar{,.bak}\ncp /usr/local/hadoop/share/hadoop/common/lib/guava-27.0-jre.jar  /usr/local/hive/lib\nstart-all.sh \nschematool -dbType mysql -initSchema\nhive\n```\n\n### Hive数据类型\n\n|          类型          |                 描述                  |     示例     |\n| :--------------------: | :-----------------------------------: | :----------: |\n|   TINYINT（tinyint）   | 一个字节（8位）有符号整数，  -128~127 |      1       |\n|  SMALLINT（smallint）  | 2字节（16位）有符号整数，-32768~32767 |      1       |\n|       INT（int）       |        4字节（32位）有符号整数        |      1       |\n|    BIGINT（bigint）    |        8字节（64位）有符号整数        |      1       |\n|     FLOAT（float）     |       4字节（32位）单精度浮点数       |      1       |\n|    DOUBLE（double）    |       8字节（64位）双精度浮点数       |      1       |\n|    DECIMAL(decimal)    |         任意精度的带符号小数          |      1       |\n|   BOOLEAN（boolean）   |              true/false               |  true/false  |\n|    STRING（string）    |             字符串，变长              | ‘a’,‘b’,‘1’  |\n|   VARCHAR（varchar）   |              变长字符串               |     ‘a’      |\n|      CHAR（char）      |            固定长度字符串             |     ‘a’      |\n|    BINANY（binany）    |               字节数组                |   无法表示   |\n| TIMESTAMP（timestamp） |           时间戳，纳秒精度            | 1.22327E+11  |\n|      DATE（date）      |                 日期                  | ‘2016-03-29’ |\n\n### hive的集合数据类型\n\n|  类型  |                             描述                             |       示例        |\n| :----: | :----------------------------------------------------------: | :---------------: |\n| ARRAY  |                 有序数组，字段的类型必须相同                 |   Array（1，2）   |\n|  MAP   | 一组无序的键值对，键的类型必须是原始数据类型，他的值可以是任何类型，同一个映射的键的类型必须相同，值得类型也必须相同 |   Map（‘a’,1）    |\n| STRUCT |               一组命名的字段,字段类型可以不同                | Struct（‘a’,1,2.0 |\n| UNION  | UNION则类似于C语言中的UNION结构，在给定的任何一个时间点，UNION类型可以保存指定数据类型中的任意一种 |                   |\n\n### 基本命令\n\n#### 创建数据库和表\n\n```\ncreate database hive;\nuse hive;\ncreate table usr(id int,name string,age int);\n```\n\n#### 查看和描述数据库和表\n\n```\nshow databases;\nshow tables;\ndescribe database hive;\ndescribe hive.usr;\n```\n\n#### 向表中装载数据\n\n```\ninsert into usr values(1,'sina',20);\n\n#从linux读取数据\n[root@yjx48 ~]# echo \"2,zhangsan,22\" >> /opt/data\nhive> use hive;\ncreate table usr1(id int,name string,age int) row format delimited fields terminated by \",\";\nload data local inpath '/opt/data' overwrite into table usr1;\n```\n\n#### 从hdfs中读取数据\n\n```\necho \"3,lisi,25\" >> /opt/test.txt\nhdfs dfs -put /opt/test.txt /\nhive\nload data inpath 'hdfs://yjx48:9000/test.txt' overwrite into table usr1;\n```\n\n#### 从别的表中读取数据\n\n```\nhive> select * from usr;\nOK\n1       sina    20\n\nhive> select * from usr1;\nOK\n3       lisi    25\n#读取usr1的id=3的数据到usr\ninsert overwrite table usr select * from usr1 where id=3;\n\nhive> select * from usr;\nOK\n3       lisi    25\n```\n\n#### 查询表中数据\n\n```\nselect * from usr1;\n```\n\n### Hive实验：词频统计\n\n#### 在linux上创建输入目录：/opt/input；\n\n```\nmkdir /opt/input\n```\n\n#### 在以上输入目录中添加多个文本文件，其中文件中包含单词：姓名学号，例如：yjx48；\n\n```\necho \"hello1 yjx48\" >> /opt/input/text1.txt\necho \"hello2 yjx48\" >> /opt/input/text2.txt\necho \"hello3 yjx48\" >> /opt/input/text3.txt\n```\n\n#### 在Hive中创建表“docs”，并把输入目录的文件数据加载到该表中；\n\n```\nhive\nuse hive;\ncreate table docs(line string);\nload data local inpath '/opt/input' overwrite into table docs;\nselect * from docs;\n```\n\n#### 编写HiveQL语句对输入目录的文本进行词频统计，统计单词“姓名学号”出现的次数。\n\n```\ncreate table word_count as\nselect word,count(1) as count from\n(select explode(split(line,' ')) as word from docs) w\ngroup by word\norder by word;\n\nselect * from word_count;\ndescribe word_count;\n```\n\n![image-20230413214018276](../img/Hadoop组件部署/d20f98bec8ed685fde8bfd0e4db5fb446cc84539.png)\n\n<div class=\"tbsm\" style=\"margin-top:54px;\">\n<div class=\"tbsm-top\"><span><svg t=\"1674654360507\" class=\"icon\" viewBox=\"0 0 1024 1024\" version=\"1.1\" xmlns=\"http://www.w3.org/2000/svg\" p-id=\"987\" data-spm-anchor-id=\"a313x.7781069.0.i0\" width=\"35\" height=\"35\"><path d=\"M410.49 97.74H155.08a56.74 56.74 0 0 0-56.84 56.73V410a56.84 56.84 0 0 0 56.84 56.84h255.41A56.83 56.83 0 0 0 467.32 410V154.58a56.83 56.83 0 0 0-56.83-56.84zM410.49 558.74H155.08a56.74 56.74 0 0 0-56.84 56.73V871a56.84 56.84 0 0 0 56.84 56.84h255.41A56.83 56.83 0 0 0 467.32 871V615.58a56.83 56.83 0 0 0-56.83-56.84zM871.49 558.74H616.08a56.74 56.74 0 0 0-56.84 56.73V871a56.84 56.84 0 0 0 56.84 56.84h255.41A56.83 56.83 0 0 0 928.32 871V615.58a56.83 56.83 0 0 0-56.83-56.84z\" fill=\"#66EEFF\" p-id=\"988\"></path><path d=\"M410.49 558.74h-4.14A475 475 0 0 0 299.52 859.6a481.16 481.16 0 0 0 4.84 68.22h106.13A56.83 56.83 0 0 0 467.32 871V615.58a56.83 56.83 0 0 0-56.83-56.84zM871.49 558.74H616.08a56.74 56.74 0 0 0-56.84 56.73V871a56.84 56.84 0 0 0 56.84 56.84h255.41A56.83 56.83 0 0 0 928.32 871V615.58a56.83 56.83 0 0 0-56.83-56.84z\" fill=\"#C2F8FF\" p-id=\"989\"></path></svg></span><span style=\"font-size:30px;\"> 特别声明</span></div>\n<div class=\"tbsm-wz\">千屹博客旗下的所有文章，是通过本人课堂学习和课外自学所精心整理的知识巨著<br/>难免会有出错的地方<br/>如果细心的你发现了小失误，可以在下方评论区告诉我，或者私信我！<br />非常感谢大家的热烈支持！</div>\n</div>","tags":["Hadoop","Zookeeper","HBase","NoSQL","MongoDB","Hive"],"categories":["运维"]},{"title":"OpenStack-Train双节点部署","url":"/posts/56647/","content":"\n<meta name=\"referrer\" content=\"no-referrer\"/>\n\n# OpenStack-Train双节点部署\n\n## 节点架构图（最小配置）\n\n|    主机名     |  ip1（NAT）   | ip2（仅主机）  | 硬盘 | 内存 |\n| :-----------: | :-----------: | :------------: | :--: | :--: |\n| controller-48 | 192.168.48.10 | 192.168.148.10 | 100G |  8G  |\n|  computer-48  | 192.168.48.20 | 192.168.148.20 | 100G |  3G  |\n\n双节点均采用[CentOS-7-x86_64-DVD-2009.iso](../img/http://mirrors.aliyun.com/centos/7.9.2009/isos/x86_64/CentOS-7-x86_64-DVD-2009.iso?spm=a2c6h.25603864.0.0.60196aeaV18bmR)英文最小化安装，安装过程不做解释\n\n<font color='cornflowerred'>Computer-48需要特别注意加硬盘</font>\n\nc<font color='red'>omputer-48需要勾选处理器虚拟化</font>\n\n![image-20240301134940011](../img/OpenStack-Train%E5%8F%8C%E8%8A%82%E7%82%B9%E9%83%A8%E7%BD%B2/image-20240301134940011-1709275202729-27.png)\n\n### 网络设置\n\n<font color='red'>控制节点网络设置</font>\n\n<font color='red'>ens33</font>\n\n![image-20240301140048584](../img/OpenStack-Train%E5%8F%8C%E8%8A%82%E7%82%B9%E9%83%A8%E7%BD%B2/image-20240301140048584-1709275708072-155.png)\n\n<font color='red'>ens36</font>\n\n![image-20240301140239316](../img/OpenStack-Train%E5%8F%8C%E8%8A%82%E7%82%B9%E9%83%A8%E7%BD%B2/image-20240301140239316-1709275708073-156.png)\n\n\n\n<font color='red'>计算节点</font>\n\n原理和控制节点一样，第二张网卡不用设置网关\n\n<font color='red'>ens33</font>\n\n![image-20240301140500814](../img/OpenStack-Train%E5%8F%8C%E8%8A%82%E7%82%B9%E9%83%A8%E7%BD%B2/image-20240301140500814-1709275708073-157.png)\n\nens36\n\n![image-20240301140612238](../img/OpenStack-Train%E5%8F%8C%E8%8A%82%E7%82%B9%E9%83%A8%E7%BD%B2/image-20240301140612238-1709275708073-158.png)\n\n<font color='red'>温馨提示（小贴士）</font>\n\n>   这里就说一下为什么第二张仅主机网卡不用设置网关，因为我们本意是通过NAT进行与外网做数据交换和获取外网资源可以连接互联网的，仅主机仅仅只是用于进行虚拟机内部资源的数据交换，不具备与外网连接的作用，是无法访问互联网的，如果两张网卡同时设置了网关，可能会造成无法访问openstack里创建的虚拟机无法访问互联网，或者本机无法访问互联网的情况，原因是默认路由可能会以仅主机网卡的网络进行与外网链接，但是没办法联网。所以请不要在第二块网卡设置网关\n\n\n\n版本对照表\n\n|   OpenStack 版本    | CentOS 版本 |\n| :-----------------: | :---------: |\n|   Train 以及更早    |      7      |\n| Ussuri and Victoria |      8      |\n|   Wallaby 到 Yoga   |  Stream 8   |\n\n## 安全性\n\n### 基本用户信息\n\nOpenStack 各组件都需要在控制节点数据库中注册专属账户以存放数据信息，故需要设置密码，强烈建议各组件的密码以及宿主机密码各不相同。\n\n|    OpenStack 组件     |         密码          |\n| :-------------------: | :-------------------: |\n|     控制节点 root     |        123456         |\n|     计算节点 root     |        123456         |\n|  Metadata 元数据密钥  |    METADATA_SECRET    |\n|   Mariadb root 账户   |     MARIADB_PASS      |\n|     RabbitMQ 服务     |      RABBIT_PASS      |\n|    OpenStack admin    |      ADMIN_PASS       |\n|    Placement 服务     |    PLACEMENT_PASS     |\n|    Keystone 数据库    |    KEYSTONE_DBPASS    |\n|      Glance 服务      |      GLANCE_PASS      |\n|     Glance 数据库     |     GLANCE_DBPASS     |\n|       Nova 服务       |       NOVA_PASS       |\n|      Nova 数据库      |      NOVA_DBPASS      |\n|     Neutron 服务      |     NEUTRON_PASS      |\n|    Neutron 数据库     |    NEUTRON_DBPASS     |\n|      Cinder 服务      |      CINDER_PASS      |\n|     Cinder 数据库     |     CINDER_DBPASS     |\n|    Horizon 数据库     |      DASH_DBPASS      |\n|       Swift服务       |      SWIFT_PASS       |\n|       Heat服务        |       HEAT_PASS       |\n|    Heat数据库服务     |      HEAT_DBPASS      |\n| heat_domain_admin用户 | HEAT_DOMAIN_USER_PASS |\n\n### 身份验证\n\n控制节点管理 OpenStack 服务时需要进行身份认证，可将认证信息导入到控制节点环境变量中，方便后续安装配置使用。\nadmin-openrc.sh 文件需提前编写并放入控制节点中，后续安装将不再说明由来\n\n```\ncat >> admin-openrc.sh << EOF\nexport OS_PROJECT_DOMAIN_NAME=Default\nexport OS_USER_DOMAIN_NAME=Default\nexport OS_PROJECT_NAME=admin\nexport OS_USERNAME=admin\nexport OS_PASSWORD=123456\nexport OS_AUTH_URL=http://controller-48:5000/v3\nexport OS_IDENTITY_API_VERSION=3\nexport OS_IMAGE_API_VERSION=2\nEOF\n\ncat >> user_dog-openrc.sh << EOF\nexport OS_USERNAME=user_dog\nexport OS_PASSWORD=123456\nexport OS_PROJECT_NAME=Train\nexport OS_USER_DOMAIN_NAME=RegionOne\nexport OS_PROJECT_DOMAIN_NAME=RegionOne\nexport OS_AUTH_URL=http://controller-48:5000/v3\nexport OS_IDENTITY_API_VERSION=3\nexport OS_IMAGE_API_VERSION=2\nEOF\n\n# OS_USERNAME  登录 OpenStack 服务的用户名\n# OS_PASSWORD  登录 OpenStack 服务的用户密码\n# OS_PROJECT_NAME 登录时进入的项目名\n# OS_USER_DOMAIN_NAME  登录时进入的域名\n# OS_PROJECT_DOMAIN_NAME  登录时进入的项目域名\n# OS_AUTH_URL 指定 Keystone（身份认证服务）的 URL  \n# 如未部署 DNS 服务器，则需要在 hosts中指定 controller-48 映射，或将 controller-48 用控制节点 IP 替代\n# OS_IDENTITY_API_VERSION 身份认证服务的 API 版本号 \n# OS_IMAGE_API_VERSION 镜像服务的 API 版本号\n```\n\n### 测试用户\n\n| 用户    | 密码   |\n| ------- | ------ |\n| admin   | 123456 |\n| use_dog | 123456 |\n\n### 物理节点关闭顺序\n\n给每台机都加上两个脚本\n\n```\ncat >> stop.sh << EOF\n#!/bin/bash\n# 关闭所有 OpenStack 节点\n# 依次关闭计算节点、网络节点、控制节点\nfor server in \\$(openstack server list -f value -c ID); do\n    openstack server stop \\$server\ndone\n# 关闭计算节点\necho \"Stopping compute services...\"\nsystemctl stop openstack-nova-compute.service\nsystemctl stop libvirtd.service\n# 关闭网络节点\necho \"Stopping network services...\"\nsystemctl stop openvswitch.service\nsystemctl stop neutron-server.service\nsystemctl stop neutron-linuxbridge-agent.service\nsystemctl stop neutron-dhcp-agent.service\nsystemctl stop neutron-metadata-agent.service\nsystemctl stop neutron-l3-agent.service\n# 关闭控制节点\necho \"Stopping control services...\"\nsystemctl stop mariadb.service\nsystemctl stop rabbitmq-server.service\nsystemctl stop memcached.service\nsystemctl stop httpd.service\nsystemctl stop openstack-glance-api.service\nsystemctl stop openstack-glance-registry.service\nsystemctl stop openstack-cinder-api.service\nsystemctl stop openstack-cinder-scheduler.service\nsystemctl stop openstack-cinder-volume.service\nsystemctl stop openstack-nova-api.service\nsystemctl stop openstack-nova-scheduler.service\nsystemctl stop openstack-nova-conductor.service\nsystemctl stop openstack-nova-novncproxy.service\nsystemctl stop openstack-nova-consoleauth.service\nsystemctl stop openstack-keystone.service\nsystemctl stop openstack-heat-api.service\nsystemctl stop openstack-heat-api-cfn.service\nsystemctl stop openstack-heat-engine.service\nsystemctl stop openstack-swift-proxy.service\nsystemctl stop openstack-swift-account.service\nsystemctl stop openstack-swift-container.service\nsystemctl stop openstack-swift-object.service\necho \"Stopping all services...\"\nsystemctl stop --all\n# 关闭电源\necho \"Shutting down the system...\"\npoweroff\nEOF\n\ncat >> start.sh << EOF\n#!/bin/bash\n# 重新启动 OpenStack 服务\n# 依次启动控制节点、网络节点、计算节点\n# 启动控制节点\necho \"Starting control services...\"\nsystemctl start mariadb.service\nsystemctl start rabbitmq-server.service\nsystemctl start memcached.service\nsystemctl start httpd.service\nsystemctl start openstack-glance-api.service\nsystemctl start openstack-glance-registry.service\nsystemctl start openstack-cinder-api.service\nsystemctl start openstack-cinder-scheduler.service\nsystemctl start openstack-cinder-volume.service\nsystemctl start openstack-nova-api.service\nsystemctl start openstack-nova-scheduler.service\nsystemctl start openstack-nova-conductor.service\nsystemctl start openstack-nova-novncproxy.service\nsystemctl start openstack-nova-consoleauth.service\nsystemctl start openstack-keystone.service\nsystemctl start openstack-heat-api.service\nsystemctl start openstack-heat-api-cfn.service\nsystemctl start openstack-heat-engine.service\nsystemctl start openstack-swift-proxy.service\nsystemctl start openstack-swift-account.service\nsystemctl start openstack-swift-container.service\nsystemctl start openstack-swift-object.service\n# 启动网络节点\necho \"Starting network services...\"\nsystemctl start openvswitch.service\nsystemctl start neutron-server.service\nsystemctl start neutron-linuxbridge-agent.service\nsystemctl start neutron-dhcp-agent.service\nsystemctl start neutron-metadata-agent.service\nsystemctl start neutron-l3-agent.service\n# 启动计算节点\necho \"Starting compute services...\"\nsystemctl start libvirtd.service\nsystemctl start openstack-nova-compute.service\nEOF\n```\n\n<font color='red'>（先给两个计算节点执行-最后等计算节点完全关闭，再给控制节点执行）</font>\n\n```\n关闭物理机的时候运行\nsh stop.sh\n(运行的时候可能会提示你有些服务找不到，报错，这个没关系，一般情况下是没问题的\n```\n\n### 物理节点开启顺序\n\n> <font color='red'>先给controller-48运行start.sh再给计算节点运行start.sh</font>\n>\n> sh start.sh\n\n## 基础环境\n\n### 修改主机名和防火墙\n\ncontroller-48节点\n\n```\nhostnamectl set-hostname controller-48 && bash\nsystemctl disable firewalld --now\nsed -i 's/SELINUX=enforcing/SELINUX=disabled/g' /etc/sysconfig/selinux\nsed -i 's/SELINUX=enforcing/SELINUX=disabled/g' /etc/selinux/config\necho \"192.168.48.10 controller-48\" >> /etc/hosts\necho \"192.168.48.20 computer-48\" >> /etc/hosts\nsetenforce 0\nreboot\n```\n\ncomputer-48节点\n\n```\nhostnamectl set-hostname computer-48 && bash\nsystemctl disable firewalld --now\nsed -i 's/SELINUX=enforcing/SELINUX=disabled/g' /etc/sysconfig/selinux\nsed -i 's/SELINUX=enforcing/SELINUX=disabled/g' /etc/selinux/config\necho \"192.168.48.10 controller-48\" >> /etc/hosts\necho \"192.168.48.20 computer-48\" >> /etc/hosts\nsetenforce 0\nreboot\n```\n\n### 修改yum\n\ncontroller-48和computer-48节点\n\n```\nrm -rf /etc/yum.repos.d/*\ncurl -o /etc/yum.repos.d/epel.repo http://mirrors.aliyun.com/repo/epel-7.repo\ncurl -o /etc/yum.repos.d/CentOS-Base.repo http://mirrors.aliyun.com/repo/Centos-7.repo\ncat >>/etc/yum.repos.d/openstack.repo<<EOF\n[openstack]\nname=openstack\nbaseurl=https://mirrors.aliyun.com/centos/7/cloud/x86_64/openstack-train/\ngpgcheck=0 \nenabled=1\nEOF\nyum clean all && yum makecache\nyum update -y\n```\n\n### SSH免密\n\n```\n#各节点\nyum install -y sshpass \ncat > sshmianmi.sh << \"EOF\"\n#!/bin/bash\n# 目标主机列表\nhosts=(\"controller-48\" \"computer-48\")\n# 密码（注意修改）\npassword=\"123456\"\n# 生成 SSH 密钥对\nssh-keygen -t rsa -N \"\" -f ~/.ssh/id_rsa\n\n# 循环遍历目标主机\nfor host in \"${hosts[@]}\"\ndo\n    # 复制公钥到目标主机\n    sshpass -p \"$password\" ssh-copy-id -o StrictHostKeyChecking=no \"$host\"\n    \n    # 验证免密登录\n    sshpass -p \"$password\" ssh -o StrictHostKeyChecking=no \"$host\" \"echo '免密登录成功'\"\ndone\nEOF\n\nsh sshmianmi.sh\n```\n\n## 安装OpenStack包\n\n```\n#各节点\nyum -y install openstack-utils openstack-selinux python-openstackclient\nyum upgrade\n```\n\n## 依赖组件\n\n四个组件安装在controller-48节点上\n\n### Mariadb数据库\n\n```\nyum install mariadb mariadb-server python2-PyMySQL -y\ncat >>/etc/my.cnf.d/openstack.cnf<<EOF\n[mysqld]\nbind-address =192.168.48.10\ndefault-storage-engine = innodb\ninnodb_file_per_table = on\nmax_connections =4096\ncollation-server = utf8_general_ci\ncharacter-set-server = utf8\nEOF\nsystemctl enable mariadb --now\nmysql_secure_installation\nEnter current password for root (enter for none): 回车\nSet root password? [Y/n] y\n# 将要求输入数据库 root 账户密码 MARIADB_PASS\nRemove anonymous users? [Y/n] y\nDisallow root login remotely? [Y/n] n\nRemove test database and access to it? [Y/n] y\nReload privilege tables now? [Y/n] y\n# 验证\nmysql -u root -pMARIADB_PASS\n```\n\n### Rabbitmq\n\n```\nyum install rabbitmq-server -y\nsystemctl enable rabbitmq-server --now\nrabbitmqctl add_user openstack RABBIT_PASS\n# 注意将 RABBIT_PASS  修改为 Rabbitmq消息队列密码\nrabbitmqctl set_permissions openstack \".*\" \".*\" \".*\"\n```\n\n### Memcached\n\n```\nyum install memcached python-memcached -y\nsed -i \"s/OPTIONS=\\\"-l 127.0.0.1,::1\\\"/OPTIONS=\\\"-l 127.0.0.1,::1,controller-48\\\"/g\" /etc/sysconfig/memcached\nsystemctl enable memcached --now\n```\n\n注意这里的-l 127.0.0.1,::1,controller-48中controller-48是你的主机名，后续不做解释\n\n### etcd\n\n```\nyum install -y etcd\nmv /etc/etcd/etcd.conf{,.bak} \ncat >> /etc/etcd/etcd.conf << EOF\n#[Member]\nETCD_DATA_DIR=\"/var/lib/etcd/default.etcd\"\nETCD_LISTEN_PEER_URLS=\"http://192.168.48.10:2380\"\nETCD_LISTEN_CLIENT_URLS=\"http://192.168.48.10:2379\"\nETCD_NAME=\"controller-48\"\n#controller-48是你的主机名\n#[Clustering]\nETCD_INITIAL_ADVERTISE_PEER_URLS=\"http://192.168.48.10:2380\"\nETCD_ADVERTISE_CLIENT_URLS=\"http://192.168.48.10:2379\"\nETCD_INITIAL_CLUSTER=\"controller-48=http://192.168.48.10:2380\"\nETCD_INITIAL_CLUSTER_TOKEN=\"etcd-cluster-01\"\nETCD_INITIAL_CLUSTER_STATE=\"new\"\nEOF\nsystemctl enable etcd --now\n```\n\n## Keystone(身份验证服务)\n\n```\n#controller-48节点\nmysql -u root -pMARIADB_PASS\nCREATE DATABASE keystone;\nGRANT ALL PRIVILEGES ON keystone.* TO 'keystone'@'localhost' IDENTIFIED BY 'KEYSTONE_DBPASS';\nGRANT ALL PRIVILEGES ON keystone.* TO 'keystone'@'%' IDENTIFIED BY 'KEYSTONE_DBPASS';\nflush privileges;\nexit\n# KEYSTONE_DBPASS  为 Keystone 数据库密码\nyum -y install yum-utils\nyum -y install qpid-proton-c-0.26.0-2.el7.x86_64\nyum install -y openstack-keystone httpd mod_wsgi \nmv /etc/keystone/keystone.conf{,.bak}\ncat>> /etc/keystone/keystone.conf << EOF\n[database]\nconnection = mysql+pymysql://keystone:KEYSTONE_DBPASS@controller-48/keystone\n[token]\nprovider = fernet\nEOF\n#同步服务器\nsu -s /bin/sh -c \"keystone-manage db_sync\" keystone\n#查看是否成功\nmysql -u keystone -p\"KEYSTONE_DBPASS\"\nuse keystone;\nshow tables;\nexit\n#有表就行\n\n#配置\nkeystone-manage fernet_setup --keystone-user keystone --keystone-group keystone\nkeystone-manage credential_setup --keystone-user keystone --keystone-group keystone\nkeystone-manage bootstrap --bootstrap-password 123456 \\\n  --bootstrap-admin-url http://controller-48:5000/v3/ \\\n  --bootstrap-internal-url http://controller-48:5000/v3/ \\\n  --bootstrap-public-url http://controller-48:5000/v3/ \\\n  --bootstrap-region-id RegionOne\n# 123456 为 admin 账户密码\n\ncp /etc/httpd/conf/httpd.conf{,.bak}\nsed -i \"s/#ServerName www.example.com:80/ServerName controller-48/g\" /etc/httpd/conf/httpd.conf\nln -s /usr/share/keystone/wsgi-keystone.conf /etc/httpd/conf.d/\nsystemctl enable httpd  --now\n\n#创建域、项目、用户、角色\nsource admin-openrc.sh\n# service 项目 创建在 default 用于 OpenStack 服务\nopenstack project create --domain default \\\n  --description \"Service Project\" service\n# 创建一个 RegionOne 域名作为后续云实例创建域名\nopenstack domain create --description \"RegionOne Domain\" RegionOne\n# 在 RegionOne 域中创建一个 Train 项目\nopenstack project create --domain RegionOne \\\n  --description \"Train Project\" Train\n# 在 RegionOne 域中创建普通用户 user_dog \nopenstack user create --domain RegionOne \\\n  --password 123456 user_dog\n# 创建普通用户 user_dog  的规则 user_dog_role\nopenstack role create user_dog_role\n# 将规则与用户绑定\nopenstack role add --project Train --user user_dog user_dog_role\n# 注：可以重复上边步骤以创建更多项目、用户及规则\n\n# 验证服务可用性\n# 卸载 admin 用户的环境\nunset OS_AUTH_URL OS_PASSWORD\n# 验证 admin 用户可用性\nopenstack --os-auth-url http://controller-48:5000/v3 \\\n  --os-project-domain-name Default --os-user-domain-name Default --os-project-name admin --os-username admin token issue\n# 输入后将要求输入 管理员 admin 的密码\n# 返回  token 信息则服务正常\n\n# 验证 user_dog 用户可用性\nopenstack --os-auth-url http://controller-48:5000/v3 \\\n  --os-project-domain-name RegionOne --os-user-domain-name RegionOne --os-project-name Train --os-username user_dog token issue\n\nsource admin-openrc.sh\n# 列举当前所有域名\nopenstack domain list\n+----------------------------------+-----------+---------+--------------------+\n| ID                               | Name      | Enabled | Description        |\n+----------------------------------+-----------+---------+--------------------+\n| 7fcb64a8c47f40a48265a9db94f0c963 | RegionOne | True    | RegionOne Domain   |\n| default                          | Default   | True    | The default domain |\n+----------------------------------+-----------+---------+--------------------+\n```\n\n## Glance(镜像服务)\n\n```\n#控制节点\nmysql -u root -pMARIADB_PASS\nCREATE DATABASE glance;\nGRANT ALL PRIVILEGES ON glance.* TO 'glance'@'localhost' \\\n  IDENTIFIED BY 'GLANCE_DBPASS';\nGRANT ALL PRIVILEGES ON glance.* TO 'glance'@'%' \\\n  IDENTIFIED BY 'GLANCE_DBPASS';\nflush privileges;\nexit\n#将 GLANCE_DBPASS 替换为 glance数据库服务的密码\nsource admin-openrc.sh\n#创建用户服务和api端点\nopenstack user create --domain default --password GLANCE_PASS glance\n#GLANCE_PASS 为 glance 服务的密码\n\n# 为 Glance 用户添加 admin 规则到系统项目 service\nopenstack role add --project service --user glance admin\n# 没有输出内容\n\n# 为 Glance 添加管理镜像的服务\nopenstack service create --name glance \\\n  --description \"OpenStack Image\" image\n\n# 为 RegionOne 域名添加服务接口\nopenstack endpoint create --region RegionOne \\\n  image public http://controller-48:9292\n\nopenstack endpoint create --region RegionOne \\\n  image internal http://controller-48:9292\n\nopenstack endpoint create --region RegionOne \\\n  image admin http://controller-48:9292\n\n#安装glance服务\nyum install openstack-glance -y\nmv /etc/glance/glance-api.conf{,.bak}\ncat >>/etc/glance/glance-api.conf << EOF\n[DEFAULT]\nuse_keystone_quotas = True\nlog_file = /var/log/glance/glance.log\n[database]\nconnection = mysql+pymysql://glance:GLANCE_DBPASS@controller-48/glance\n# GLANCE_DBPASS 为 Glance 服务的数据库账户密码\n[keystone_authtoken]\nwww_authenticate_uri  = http://controller-48:5000\nauth_url = http://controller-48:5000\nmemcached_servers = controller-48:11211\nauth_type = password\nproject_domain_name = Default\nuser_domain_name = Default\nproject_name = service\nusername = glance\npassword = GLANCE_PASS\nservice_token_roles_required = true\n# GLANCE_PASS 为 Glance 服务的数据库账户密码\n[paste_deploy]\nflavor = keystone\n[glance_store]\nstores = file,http\ndefault_store = file\ndefault_backend = {'store_one': 'http', 'store_two': 'file'}\nfilesystem_store_datadir = /var/lib/glance/images/\nEOF\n# 同步 Glance 数据到数据库\nsu -s /bin/sh -c \"glance-manage db_sync\" glance\nsystemctl enable openstack-glance-api  --now\n# 验证服务可用性\nsource admin-openrc.sh\nwget https://download.cirros-cloud.net/0.3.3/cirros-0.3.3-x86_64-disk.img\n#可能会拉取失败，可以自行复制网址，去浏览器下载，然后上传到/root/目录下\n\nglance image-create --name \"cirros\" \\\n  --file cirros-0.3.3-x86_64-disk.img \\\n  --disk-format qcow2 --container-format bare \\\n  --visibility=public\n\nopenstack image list\n# +--------------------------------------+--------+--------+\n# | ID                                   | Name   | Status |\n# +--------------------------------------+--------+--------+\n# | 4e022193-03c2-40c4-872f-0adb606f31e4 | cirros | active |\n# +--------------------------------------+--------+--------+\n```\n\n## Placement（资源调度）\n\n```\nmysql -u root -pMARIADB_PASS\nCREATE DATABASE placement;\nGRANT ALL PRIVILEGES ON placement.* TO 'placement'@'localhost'  IDENTIFIED BY 'PLACEMENT_DBPASS';\nGRANT ALL PRIVILEGES ON placement.* TO 'placement'@'%' IDENTIFIED BY 'PLACEMENT_DBPASS';\nflush privileges;\nexit\n#PLACEMENT_DBPASS 为 placement 服务的密码\nsource admin-openrc.sh\nopenstack user create --domain default --password PLACEMENT_PASS placement\nopenstack role add --project service --user placement admin\nopenstack service create --name placement \\\n  --description \"Placement API\" placement\nopenstack endpoint create --region RegionOne \\\n  placement public http://controller-48:8778\nopenstack endpoint create --region RegionOne \\\n  placement internal http://controller-48:8778\nopenstack endpoint create --region RegionOne \\\n  placement admin http://controller-48:8778\nyum install openstack-placement-api -y\nmv /etc/placement/placement.conf{,.bak}\ncat >> /etc/placement/placement.conf << EOF\n[placement_database]\nconnection = mysql+pymysql://placement:PLACEMENT_DBPASS@controller-48/placement\n# PLACEMENT_DBPASS 为 placement 服务的数据库账户密码\n[api]\nauth_strategy = keystone\n[keystone_authtoken]\nauth_url = http://controller-48:5000/v3\nmemcached_servers = controller-48:11211\nauth_type = password\nproject_domain_name = Default\nuser_domain_name = Default\nproject_name = service\nusername = placement\npassword = PLACEMENT_PASS\n# PLACEMENT_PASS 为 placement 服务的密码\nEOF\n\n#同步数据库\nsu -s /bin/sh -c \"placement-manage db sync\" placement\ncp /etc/httpd/conf.d/00-placement-api.conf{,.bak}\ncat >> /etc/httpd/conf.d/00-placement-api.conf << EOF\n#在#SSLCertificateKeyFile ...下添加\n<Directory /usr/bin>\n<IfVersion >= 2.4>\n\tRequire all granted\n</IfVersion>\n<IfVersion < 2.4>\n\tOrder allow,deny\t\n\tAllow from all\n</IfVersion>\n</Directory>\nEOF\nsystemctl restart httpd\n\n# 验证服务\nsource admin-openrc.sh\nplacement-status upgrade check\n#安装pip osc组件验证资源\nyum install python-pip -y\npip install osc-placement==2.2.0\nsystemctl restart httpd\n\n# 验证\nopenstack --os-placement-api-version 1.2 resource class list --sort-column name\n# +----------------------------------------+\n# | name                                   |\n# +----------------------------------------+\n# | DISK_GB                                |\n......\n\nopenstack --os-placement-api-version 1.6 trait list --sort-column name\n# +---------------------------------------+\n# | name                                  |\n# +---------------------------------------+\n# | computer-48_ACCELERATORS                  |\n# | computer-48_ARCH_AARCH64                  |\n# ...\n```\n\n## Nova(计算服务)\n\n### 控制节点\n\n```\n#控制节点controller-48\nmysql -u root -pMARIADB_PASS\nCREATE DATABASE nova_api;\nCREATE DATABASE nova;\nCREATE DATABASE nova_cell0;\nGRANT ALL PRIVILEGES ON nova_api.* TO 'nova'@'localhost' \\\n  IDENTIFIED BY 'NOVA_DBPASS';\nGRANT ALL PRIVILEGES ON nova_api.* TO 'nova'@'%' \\\n  IDENTIFIED BY 'NOVA_DBPASS';\nGRANT ALL PRIVILEGES ON nova.* TO 'nova'@'localhost' \\\n  IDENTIFIED BY 'NOVA_DBPASS';\nGRANT ALL PRIVILEGES ON nova.* TO 'nova'@'%' \\\n  IDENTIFIED BY 'NOVA_DBPASS';\nGRANT ALL PRIVILEGES ON nova_cell0.* TO 'nova'@'localhost' \\\n  IDENTIFIED BY 'NOVA_DBPASS';\nGRANT ALL PRIVILEGES ON nova_cell0.* TO 'nova'@'%' \\\n  IDENTIFIED BY 'NOVA_DBPASS';\nflush privileges;\nexit\n\n# NOVA_DBPASS 为 nova 服务的密码\n\nsource admin-openrc.sh\nopenstack user create --domain default --password NOVA_PASS nova\nopenstack role add --project service --user nova admin\nopenstack service create --name nova \\\n  --description \"OpenStack Compute\" compute\nopenstack endpoint create --region RegionOne \\\n  compute public http://controller-48:8774/v2.1\nopenstack endpoint create --region RegionOne \\\n  compute internal http://controller-48:8774/v2.1\nopenstack endpoint create --region RegionOne \\\n  compute admin http://controller-48:8774/v2.1\nmv /etc/yum.repos.d/epel.repo{,.bak} \nyum install -y \\\n    openstack-nova-api \\\n    openstack-nova-scheduler \\\n    openstack-nova-conductor \\\n    openstack-nova-novncproxy\nmv /etc/yum.repos.d/epel.repo{.bak,} \nmv /etc/nova/nova.conf{,.bak}\ncat >> /etc/nova/nova.conf <<EOF\n[DEFAULT]\nenabled_apis = osapi_compute,metadata\ntransport_url = rabbit://openstack:RABBIT_PASS@controller-48:5672/\n# RABBIT_PASS为 rabbitmq 密码\nmy_ip = 192.168.48.10\n# 控制节点控制网络的 IP\nlog_file = /var/log/nova/nova-controller.log\nrootwrap_config = /etc/nova/rootwrap.conf\n[api_database]\nconnection = mysql+pymysql://nova:NOVA_DBPASS@controller-48/nova_api\n# NOVA_DBPASS 为数据库 Nova 账户密码\n[database]\nconnection = mysql+pymysql://nova:NOVA_DBPASS@controller-48/nova\n# NOVA_DBPASS 为数据库 Nova 账户密码\n[api]\nauth_strategy = keystone\n[keystone_authtoken]\nwww_authenticate_uri = http://controller-48:5000/\nauth_url = http://controller-48:5000/\nmemcached_servers = controller-48:11211\nauth_type = password\nproject_domain_name = Default\nuser_domain_name = Default\nproject_name = service\nusername = nova\npassword =NOVA_PASS\n# NOVA_PASS 为 Nova 服务的密码\n[vnc]\nenabled = true\nserver_listen = \\$my_ip\nserver_proxyclient_address = \\$my_ip\n[glance]\napi_servers = http://controller-48:9292\n[oslo_concurrency]\nlock_path = /var/run/nova\n[placement]\nregion_name = RegionOne\nproject_domain_name = Default\nproject_name = service\nauth_type = password\nuser_domain_name = Default\nauth_url = http://controller-48:5000/v3\nusername = placement\npassword = PLACEMENT_PASS\n# PLACEMENT_PASS 为 placement 服务的密码\nEOF\nsu -s /bin/sh -c \"nova-manage api_db sync\" nova\nsu -s /bin/sh -c \"nova-manage cell_v2 map_cell0\" nova\nsu -s /bin/sh -c \"nova-manage cell_v2 create_cell --name=cell1 --verbose\" nova\nsu -s /bin/sh -c \"nova-manage db sync\" nova\n\n# 验证\n\nsu -s /bin/sh -c \"nova-manage cell_v2 list_cells\" nova\n\nsystemctl enable --now \\\n    openstack-nova-api.service \\\n    openstack-nova-scheduler.service \\\n    openstack-nova-conductor.service \\\n    openstack-nova-novncproxy.service\n    \nsystemctl status \\\n    openstack-nova-api.service \\\n    openstack-nova-scheduler.service \\\n    openstack-nova-conductor.service \\\n    openstack-nova-novncproxy.service\n    \n```\n\n### 计算节点\n\n```\n##computer-48计算节点\ncat >>/etc/yum.repos.d/CentOS-Base.repo<<EOF\n[Virt]\nname=CentOS-\\$releasever - Base\nbaseurl=http://mirrors.aliyun.com/centos/7.9.2009/virt/x86_64/kvm-common/\ngpgcheck=0\ngpgkey=file:///etc/pki/rpm-gpg/RPM-GPG-KEY-CentOS-7\nEOF\nyum install qpid-proton-c-0.26.0-2.el7.x86_64 -y\nyum install openstack-nova-compute -y\nmv /etc/nova/nova.conf{,.bak}\ncat >> /etc/nova/nova.conf <<EOF\n[DEFAULT]\nenabled_apis = osapi_compute,metadata\ntransport_url = rabbit://openstack:RABBIT_PASS@controller-48\nmy_ip = 192.168.48.20\ncompute_driver=libvirt.LibvirtDriver\nlog_file = /var/log/nova/nova-compute.log\n# 192.168.48.20替换为 计算节点管理网络 IP 地址\n[api]\nauth_strategy = keystone\n[keystone_authtoken]\nwww_authenticate_uri = http://controller-48:5000/\nauth_url = http://controller-48:5000/\nmemcached_servers = controller-48:11211\nauth_type = password\nproject_domain_name = Default\nuser_domain_name = Default\nproject_name = service\nusername = nova\npassword = NOVA_PASS\n#NOVA_PASS为nova服务密码\n[vnc]\nenabled = true\nserver_listen = 0.0.0.0\nserver_proxyclient_address = \\$my_ip\nnovncproxy_base_url = http://192.168.48.10:6080/vnc_auto.html\n# 将 192.168.48.10修改为控制节点管理网络 IP \n[glance]\napi_servers = http://controller-48:9292\n[oslo_concurrency]\nlock_path = /var/lib/nova/tmp\n[placement]\nregion_name = RegionOne\nproject_domain_name = Default\nproject_name = service\nauth_type = password\nuser_domain_name = Default\nauth_url = http://controller-48:5000/v3\nusername = placement\npassword = PLACEMENT_PASS\n#PLACEMENT_PASS 为 Placement 服务密码\n[neutron]\nauth_url = http://controller-48:5000\nauth_type = password\nproject_domain_name = default\nuser_domain_name = default\nregion_name = RegionOne\nproject_name = service\nusername = neutron\npassword = NEUTRON_PASS\n# NEUTRON_PASS 为 Neutron 服务密码\nEOF\n\negrep -c '(vmx|svm)' /proc/cpuinfo\n---------------------------------------------------------------------------------\n# 如果返回值大于 1 则说明已经开启硬件虚拟化，无需配置 qemu\n# 如等于 0 ，则需要配置 qemu 以代替默认的 kvm\nvi /etc/nova/nova.conf\n[libvirt]\n# ...\nvirt_type = qemu\n\n# 以上配置仅当 egrep -c '(vmx|svm)' /proc/cpuinfo 结果为 0 时才进行配置\n---------------------------------------------------------------------------------\nsystemctl enable libvirtd.service openstack-nova-compute.service --now\nsystemctl status libvirtd.service openstack-nova-compute.service \n```\n\n### 控制节点验证\n\n```\n# 在控制节点执行验证\nsource admin-openrc.sh\nopenstack compute service list --service nova-compute\n+----+--------------+----------+------+---------+-------+----------------------------+\n| ID | Binary       | Host     | Zone | Status  | State | Updated At                 |\n+----+--------------+----------+------+---------+-------+----------------------------+\n| 10 | nova-computer | computer-48 | nova | enabled | up    | 2023-04-02T17:17:08.000000 |\n+----+--------------+----------+------+---------+-------+----------------------------+\n\n# 在控制节点执行验证\nsu -s /bin/sh -c \"nova-manage cell_v2 discover_hosts --verbose\" nova\n####\nFound 2 cell mappings.\nSkipping cell0 since it does not contain hosts.\nGetting computer-48s from cell 'cell1': 89e02b18-2a3c-437a-8dd5-15deb98676a4\nChecking host mapping for computer-48 host 'computer-48r-48': e862bd61-8f56-4d3a-a2b2-21ab7db90ede\nCreating host mapping for computer-48 host 'computer-48r-48': e862bd61-8f56-4d3a-a2b2-21ab7db90ede\nFound 1 unmapped computer-48s in cell: 89e02b18-2a3c-437a-8dd5-15deb98676a4\n\n\nopenstack compute service list\n[root@controller-48 ~]# openstack compute service list\n+----+----------------+---------------+----------+---------+-------+----------------------------+\n| ID | Binary         | Host          | Zone     | Status  | State | Updated At                 |\n+----+----------------+---------------+----------+---------+-------+----------------------------+\n|  1 | nova-conductor | controller-48 | internal | enabled | up    | 2023-05-27T17:44:38.000000 |\n|  4 | nova-scheduler | controller-48 | internal | enabled | up    | 2023-05-27T17:44:40.000000 |\n|  5 | nova-compute   | computer-48   | nova     | enabled | up    | 2023-05-27T17:44:43.000000 |\n+----+----------------+---------------+----------+---------+-------+----------------------------+\n\nopenstack catalog list\n+-----------+-----------+----------------------------------------------------------------------+\n| Name      | Type      | Endpoints                                                            |\n+-----------+-----------+----------------------------------------------------------------------+\n| placement | placement | RegionOne                                                            |\n|           |           |   internal: http://controller-48:8778                                   |\n|           |           | RegionOne                                                            |\n|           |           |   admin: http://controller-48:8778                                      |\n|           |           | RegionOne                                                            |\n|           |           |   public: http://controller-48:8778                                     |\n|           |           |                                                                      |\n| keystone  | identity  | RegionOne                                                            |\n|           |           |   admin: http://controller-48:5000/v3/                                  |\n|           |           | RegionOne                                                            |\n|           |           |   internal: http://controller-48:5000/v3/                               |\n|           |           | RegionOne                                                            |\n|           |           |   public: http://controller-48:5000/v3/                                 |\n|           |           |                                                                      |\n| neutron   | network   | RegionOne                                                            |\n|           |           |   public: http://controller-48:9696                                     |\n|           |           | RegionOne                                                            |\n|           |           |   internal: http://controller-48:9696                                   |\n|           |           | RegionOne                                                            |\n|           |           |   admin: http://controller-48:9696                                      |\n|           |           |                                                                      |\n| glance    | image     | RegionOne                                                            |\n|           |           |   admin: http://controller-48:9292                                      |\n|           |           | RegionOne                                                            |\n|           |           |   internal: http://controller-48:9292                                   |\n|           |           | RegionOne                                                            |\n|           |           |   public: http://controller-48:9292                                     |\n|           |           |                                                                      |\n| nova      | computer-48   | RegionOne                                                            |\n|           |           |   admin: http://controller-48:8774/v2.1                                 |\n|           |           | RegionOne                                                            |\n|           |           |   internal: http://controller-48:8774/v2.1                              |\n|           |           | RegionOne                                                            |\n|           |           |   public: http://controller-48:8774/v2.1                                |\n|           |           |                                                                      |\n|           |           |                                                                      |\n+-----------+-----------+----------------------------------------------------------------------+\n\nopenstack image list\n+--------------------------------------+--------+--------+\n| ID                                   | Name   | Status |\n+--------------------------------------+--------+--------+\n| 4e022193-03c2-40c4-872f-0adb606f31e4 | cirros | active |\n+--------------------------------------+--------+--------+\n\n\nnova-status upgrade check\n[root@controller-48 ~]# nova-status upgrade check\n+--------------------------------+\n| Upgrade Check Results          |\n+--------------------------------+\n| Check: Cells v2                |\n| Result: Success                |\n| Details: None                  |\n+--------------------------------+\n| Check: Placement API           |\n| Result: Success                |\n| Details: None                  |\n+--------------------------------+\n| Check: Ironic Flavor Migration |\n| Result: Success                |\n| Details: None                  |\n+--------------------------------+\n| Check: Cinder API              |\n| Result: Success                |\n| Details: None                  |\n+--------------------------------+\n\n#在控制节点修改自动注册nova-computer-48节点\ncat >> /etc/nova/nova.conf << EOF\n[scheduler]\ndiscover_hosts_in_cells_interval = 300\nEOF\n\n```\n\n## Neutron（网络服务）\n\n### 控制节点\n\n```\n##控制节点controller-48\nmysql -u root -pMARIADB_PASS\nCREATE DATABASE neutron;\nGRANT ALL PRIVILEGES ON neutron.* TO 'neutron'@'localhost' \\\n  IDENTIFIED BY 'NEUTRON_DBPASS';\nGRANT ALL PRIVILEGES ON neutron.* TO 'neutron'@'%' \\\n  IDENTIFIED BY 'NEUTRON_DBPASS';\nflush privileges;\nexit\nsource admin-openrc.sh\nopenstack user create --domain default --password NEUTRON_PASS neutron\nopenstack role add --project service --user neutron admin\nopenstack service create --name neutron \\\n  --description \"OpenStack Networking\" network\nopenstack endpoint create --region RegionOne \\\n  network public http://controller-48:9696\nopenstack endpoint create --region RegionOne \\\n  network internal http://controller-48:9696\nopenstack endpoint create --region RegionOne \\\n  network admin http://controller-48:9696\n# 选择安装 大二层 网络\nyum install openstack-neutron openstack-neutron-ml2 \\\n  openstack-neutron-linuxbridge ebtables -y\n\nmv /etc/neutron/neutron.conf{,.bak}\ncat >> /etc/neutron/neutron.conf <<EOF\n[database]\nconnection = mysql+pymysql://neutron:NEUTRON_DBPASS@controller-48/neutron\n#NEUTRON_DBPASS为 数据库 neutron 账户密码\n[DEFAULT]\ncore_plugin = ml2\nservice_plugins = router\nallow_overlapping_ips = true\ntransport_url = rabbit://openstack:RABBIT_PASS@controller-48\nauth_strategy = keystone\nnotify_nova_on_port_status_changes = true\nnotify_nova_on_port_data_changes = true\n# RABBIT_PASS 为 消息队列密码\n[keystone_authtoken]\nwww_authenticate_uri = http://controller-48:5000\nauth_url = http://controller-48:5000\nmemcached_servers = controller-48:11211\nauth_type = password\nproject_domain_name = default\nuser_domain_name = default\nproject_name = service\nusername = neutron\npassword = NEUTRON_PASS\n# NEUTRON_PASS为 neutron 服务密码\n[nova]\nauth_url = http://controller-48:5000\nauth_type = password\nproject_domain_name = default\nuser_domain_name = default\nregion_name = RegionOne\nproject_name = service\nusername = nova\npassword = NOVA_PASS\n# [nova]  没有则添加\n# NOVA_PASS为 Nova 服务密码\n[oslo_concurrency]\nEOF\n\nmv /etc/neutron/plugins/ml2/ml2_conf.ini{,.bak}\ncat >> /etc/neutron/plugins/ml2/ml2_conf.ini << EOF\n[ml2]\ntype_drivers = flat,vlan,vxlan\ntenant_network_types = vxlan\nmechanism_drivers = linuxbridge,l2population\nextension_drivers = port_security\n[ml2_type_flat]\nflat_networks = provider\n[ml2_type_vxlan]\nvni_ranges = 1:1000\n[securitygroup]\nenable_ipset = true\nEOF\n\nmv /etc/neutron/plugins/ml2/linuxbridge_agent.ini{,.bak}\ncat >> /etc/neutron/plugins/ml2/linuxbridge_agent.ini <<EOF\n[linux_bridge]\nphysical_interface_mappings = provider:ens33\n# ens33 为第一块网卡名称\n[vxlan]\nenable_vxlan = true\nlocal_ip = 192.168.48.10\nl2_population = true\n# 192.168.48.10 为管理网络 控制节点的 IP  即 controller-48 IP\n[securitygroup]\nenable_security_group = true\nfirewall_driver = neutron.agent.linux.iptables_firewall.IptablesFirewallDriver\nEOF\n\nmv /etc/neutron/l3_agent.ini{,.bak}\ncat >> /etc/neutron/l3_agent.ini << EOF\n[DEFAULT]\ninterface_driver = linuxbridge\nEOF\n\nmv /etc/neutron/dhcp_agent.ini{,.bak}\ncat >> /etc/neutron/dhcp_agent.ini << EOF\n[DEFAULT]\ninterface_driver = linuxbridge\ndhcp_driver = neutron.agent.linux.dhcp.Dnsmasq\nenable_isolated_metadata = true\nEOF\n\n----------------------\nmodprobe br_netfilter\ncat >>/etc/rc.sysinit<<EOF\n#!/bin/bash\nfor file in /etc/sysconfig/modules/*.modules ; do\n[ -x $file ] && $file\ndone\nEOF\necho \"modprobe br_netfilter\" >/etc/sysconfig/modules/br_netfilter.modules\nchmod 755 /etc/sysconfig/modules/br_netfilter.modules\nsysctl -a | grep net.bridge.bridge-nf-call\n----------------------\nmv /etc/neutron/metadata_agent.ini{,.bak}\ncat >> /etc/neutron/metadata_agent.ini << EOF\n[DEFAULT]\nnova_metadata_host = controller-48\nmetadata_proxy_shared_secret = METADATA_SECRET\n# METADATA_SECRET 为 元数据 的密钥\nEOF\n\n-------------------\ncat >> /etc/nova/nova.conf << EOF\n#追加在末尾\n[neutron]\nauth_url = http://controller-48:5000\nauth_type = password\nproject_domain_name = default\nuser_domain_name = default\nregion_name = RegionOne\nproject_name = service\nusername = neutron\npassword = NEUTRON_PASS\nservice_metadata_proxy = true\nmetadata_proxy_shared_secret = METADATA_SECRET\n# NEUTRON_PASS  为 neutron 服务的密码\n# METADATA_SECRET 为上边设置的元数据密钥\nEOF\n\n-------------------\nln -s /etc/neutron/plugins/ml2/ml2_conf.ini /etc/neutron/plugin.ini\n\nsu -s /bin/sh -c \"neutron-db-manage --config-file /etc/neutron/neutron.conf --config-file /etc/neutron/plugins/ml2/ml2_conf.ini upgrade head\" neutron\n\nsudo ip route del default\nsudo ip route add default via 192.168.48.2 dev ens33\n#192.168.48.2为ens33网关\n\nsystemctl enable --now neutron-server.service neutron-linuxbridge-agent.service neutron-dhcp-agent.service neutron-metadata-agent.service neutron-l3-agent.service\n\nsystemctl status neutron-server.service  neutron-linuxbridge-agent.service neutron-dhcp-agent.service   neutron-metadata-agent.service  neutron-l3-agent.service\n\n```\n\n### 计算节点\n\n```\n###compute计算节点\nyum install openstack-neutron-linuxbridge ebtables ipset -y \n\nmv /etc/neutron/neutron.conf{,.bak}\ncat >> /etc/neutron/neutron.conf << EOF\n[DEFAULT]\ntransport_url = rabbit://openstack:RABBIT_PASS@controller-48\n#RABBIT_PASS为 控制节点 消息队列 密码\nauth_strategy = keystone\n[keystone_authtoken]\nwww_authenticate_uri = http://controller-48:5000\nauth_url = http://controller-48:5000\nmemcached_servers = controller-48:11211\nauth_type = password\nproject_domain_name = default\nuser_domain_name = default\nproject_name = service\nusername = neutron\npassword = NEUTRON_PASS\n# NEUTRON_PASS  为控制节点 neutron 服务密码\n[oslo_concurrency]\nlock_path = /var/lib/neutron/tmp\nEOF\n\nmv /etc/neutron/plugins/ml2/linuxbridge_agent.ini{,.bak}\ncat >> /etc/neutron/plugins/ml2/linuxbridge_agent.ini <<EOF\n[linux_bridge]\nphysical_interface_mappings = provider:ens36\n# ens36 为 第二块网卡名字\n[vxlan]\nenable_vxlan = true\nlocal_ip = 192.168.48.20\nl2_population = true\n# 192.168.48.20  为 计算节点 管理网络的 IP 地址\n[securitygroup]\nenable_security_group = true\nfirewall_driver = neutron.agent.linux.iptables_firewall.IptablesFirewallDriver\nEOF\n-------------------\nmodprobe br_netfilter\ncat >>/etc/rc.sysinit<<EOF\n#!/bin/bash\nfor file in /etc/sysconfig/modules/*.modules ; do\n[ -x $file ] && $file\ndone\nEOF\necho \"modprobe br_netfilter\" >/etc/sysconfig/modules/br_netfilter.modules\nchmod 755 /etc/sysconfig/modules/br_netfilter.modules\nsysctl -a | grep net.bridge.bridrge-nf-call\n-------------------\n\nsystemctl enable neutron-linuxbridge-agent.service --now\nsystemctl restart openstack-nova-compute.service neutron-linuxbridge-agent.service\nsystemctl status neutron-linuxbridge-agent.service\n\n```\n\n### 控制节点验证\n\n```\n# 验证\n# 控制节点执行\nsource admin-openrc.sh\nopenstack network agent list\n###等几分钟\n[root@controller-48 ~]# openstack network agent list\n+--------------------------------------+--------------------+---------------+-------------------+-------+-------+---------------------------+\n| ID                                   | Agent Type         | Host          | Availability Zone | Alive | State | Binary                    |\n+--------------------------------------+--------------------+---------------+-------------------+-------+-------+---------------------------+\n| 201870b9-aac0-4830-9788-03da13b125c7 | Metadata agent     | controller-48 | None              | :-)   | UP    | neutron-metadata-agent    |\n| 55ae2391-4cd6-4cd1-bf4f-4465f1b561a1 | L3 agent           | controller-48 | nova              | :-)   | UP    | neutron-l3-agent          |\n| bae3fe77-a005-4cdf-aee6-8cfe3cf918ba | Linux bridge agent | controller-48 | None              | :-)   | UP    | neutron-linuxbridge-agent |\n| f0bd6fbc-2889-4558-80fa-8f2a08989b74 | Linux bridge agent | computer-48   | None              | :-)   | UP    | neutron-linuxbridge-agent |\n| f5546196-9950-4c5a-b709-060a1bba5944 | DHCP agent         | controller-48 | nova              | :-)   | UP    | neutron-dhcp-agent        |\n+--------------------------------------+--------------------+---------------+-------------------+-------+-------+---------------------------+\n\n# 确保以上五个 Agent 都为 :-) 及 UP\n\n```\n\n## Horizon(Web管理页面)\n\n```\nsystemctl restart neutron* openstack-nova*\n###控制节点\nyum install openstack-dashboard -y\ncp /etc/openstack-dashboard/local_settings{,.bak}\n#注释以下信息\nsed -i 's/^ALLOWED_HOSTS/#&/' /etc/openstack-dashboard/local_settings\nsed -i 's/^OPENSTACK_HOST/#&/' /etc/openstack-dashboard/local_settings\nsed -i 's/^OPENSTACK_KEYSTONE_URL/#&/' /etc/openstack-dashboard/local_settings\nsed -i 's/^TIME_ZONE/#&/' /etc/openstack-dashboard/local_settings\n\n追加内容\ncat >> /etc/openstack-dashboard/local_settings <<EOF\nALLOWED_HOSTS = ['*']\nSESSION_ENGINE = 'django.contrib.sessions.backends.cache'\nCACHES = {\n    'default': {\n         'BACKEND': 'django.core.cache.backends.memcached.MemcachedCache',\n         'LOCATION': 'controller-48:11211',\n    }\n}\nOPENSTACK_HOST = \"controller-48\"\nOPENSTACK_KEYSTONE_URL = \"http://%s:5000/identity/v3\" % OPENSTACK_HOST\nOPENSTACK_KEYSTONE_MULTIDOMAIN_SUPPORT = True\nOPENSTACK_API_VERSIONS = {\n    \"identity\": 3,\n    \"image\": 2,\n    \"volume\": 3,\n}\nOPENSTACK_KEYSTONE_DEFAULT_DOMAIN = \"Default\"\nOPENSTACK_KEYSTONE_DEFAULT_ROLE = \"user\"\nTIME_ZONE = \"Asia/Shanghai\"\n# 有则修改没有则添加\nEOF\n\ncp /etc/httpd/conf.d/openstack-dashboard.conf{,.bak}\ncat >> /etc/httpd/conf.d/openstack-dashboard.conf << EOF\nWSGIApplicationGroup %{GLOBAL}\nEOF\n------------------------------------------------------------------------------------\n#把下面所有文件里面有WEBROOT = '/' 中的 / 改成 /dashboard\nsed -i.bak \"s#WEBROOT\\s*=.*#WEBROOT = '/dashboard'#\" /usr/share/openstack-dashboard/openstack_dashboard/defaults.py\nsed -i.bak \"s#WEBROOT\\s*=.*#WEBROOT = '/dashboard'#\"  /usr/share/openstack-dashboard/openstack_dashboard/test/settings.py\nsed -i.bak 's|WEBROOT\\s*=.*|WEBROOT = \"/dashboard\"|' /usr/share/openstack-dashboard/static/dashboard/js/1453ede06e9f.js\n#如果第三条不行，注意一下1453ede06e9f.js是否存在，若不存在，则看下面三个文件中有WEBROOT = '/'替换文件名即可\n[root@controller-48 ~]# cd /usr/share/openstack-dashboard/static/dashboard/js/\n[root@controller-48 js]# ll\ntotal 2472   #以下几个文件也要改 ，我这里就一个文件有\n-rw-r--r-- 1 root root  606959 May 17  2021 1453ede06e9f.js\n-rw-r--r-- 1 root root 1659039 May 17  2021 b5e88d434bd1.js\n-rw-r--r-- 1 root root  254022 May 17  2021 eb687af7228a.js\n------------------------------------------------------------------------------------\nsystemctl restart httpd memcached\nsystemctl status httpd memcached\n\n\n# 验证\n# 访问 http://192.168.48.10/dashboard  （控制节点ip）\n# 登录用户密码 可使用 admin 或 user_dog\n# 域名 使用 Default\n```\n\n![image-20230402220424221](../img/OpenStack-Train%E5%8F%8C%E8%8A%82%E7%82%B9%E9%83%A8%E7%BD%B2/bf319a6ff702ffea01d5eb18616705db479b66b2-1709275202730-28.png)\n\n## cinder（块存储服务）\n\n### 控制节点\n\n```\n###控制节点\nmysql -u root -pMARIADB_PASS\nCREATE DATABASE cinder;\nGRANT ALL PRIVILEGES ON cinder.* TO 'cinder'@'localhost' \\\n  IDENTIFIED BY 'CINDER_DBPASS';\nGRANT ALL PRIVILEGES ON cinder.* TO 'cinder'@'%' \\\n  IDENTIFIED BY 'CINDER_DBPASS';\nexit\n# CINDER_DBPASS 为 cinder 数据库账户密码\nsource admin-openrc.sh\nopenstack user create --domain default --password CINDER_PASS cinder\nopenstack role add --project service --user cinder admin\n  openstack service create --name cinderv3 \\\n  --description \"OpenStack Block Storage\" volumev3\nopenstack endpoint create --region RegionOne \\\n  volumev3 public http://controller-48:8776/v3/%\\(project_id\\)s\nopenstack endpoint create --region RegionOne \\\n  volumev3 internal http://controller-48:8776/v3/%\\(project_id\\)s\nopenstack endpoint create --region RegionOne \\\n  volumev3 admin http://controller-48:8776/v3/%\\(project_id\\)s\n\nyum install openstack-cinder -y\nmv /etc/cinder/cinder.conf{,.bak}\ncat >> /etc/cinder/cinder.conf << EOF\n[DEFAULT]\ntransport_url = rabbit://openstack:RABBIT_PASS@controller-48\nauth_strategy = keystone\nmy_ip = 192.168.48.10\n# 控制节点管理网络 IP\n[database]\nconnection = mysql+pymysql://cinder:CINDER_DBPASS@controller-48/cinder\n# CINDER_DBPASS 为数据库 Cinder 账户密码\n[keystone_authtoken]\nwww_authenticate_uri = http://controller-48:5000\nauth_url = http://controller-48:5000\nmemcached_servers = controller-48:11211\nauth_type = password\nproject_domain_name = default\nuser_domain_name = default\nproject_name = service\nusername = cinder\npassword = CINDER_PASS\n# CINDER_PASS 为 Cinder 服务密码\n[oslo_concurrency]\nlock_path = /var/lib/cinder/tmp\nEOF\n\nsu -s /bin/sh -c \"cinder-manage db sync\" cinder\n\ncat >> /etc/nova/nova.conf << EOF\n[cinder]\nos_region_name = RegionOne\nEOF\n\nsystemctl restart openstack-nova-api.service\nsystemctl status openstack-nova-api.service\nsystemctl enable --now openstack-cinder-api.service openstack-cinder-scheduler.service\nsystemctl status openstack-cinder-api.service openstack-cinder-scheduler.service\n\n```\n\n### 计算节点\n\n```\n###computer-48节点\n\n添加一块物理磁盘\n[root@computer-48 ~]# lsblk\nNAME            MAJ:MIN RM  SIZE RO TYPE MOUNTPOINT\nsda               8:0    0  100G  0 disk\n├─sda1            8:1    0    1G  0 part /boot\n└─sda2            8:2    0   99G  0 part\n  ├─centos-root 253:0    0   50G  0 lvm  /\n  ├─centos-swap 253:1    0  3.6G  0 lvm  [SWAP]\n  └─centos-home 253:2    0 45.4G  0 lvm  /home\nsdb               8:16   0  100G  0 disk\nsr0              11:0    1 1024M  0 rom\n\nyum install lvm2 device-mapper-persistent-data -y\nsystemctl enable lvm2-lvmetad.service --now\n# 如显示不存在则说明系统默认安装了 lvm  以上步骤可忽略\n\n#创建/dev/sdb卷组\npvcreate /dev/sdb\n# Physical volume \"/dev/sdb\" successfully created.\n\nvgcreate cinder-volumes /dev/sdb\n# Volume group \"cinder-volumes\" successfully created\n# sdb 为划分给块存储使用的磁盘\n# 如有多个磁盘，则需重复以上两个命令\n\n\ncp /etc/lvm/lvm.conf{,.bak}\nsed -i '130 a\\filter = [ \"a/sdb/\",\"r/.*/\"]' /etc/lvm/lvm.conf\n#sdb是上面添加的新的物理磁盘\n# 如有多个磁盘，则将磁盘编号以固定格式添加到过滤设备中，例如有两个磁盘 sdb sdc ，则为 filter = [ \"a/sdb/\", \"a/sdc/\",\"r/.*/\"]\n\n\nyum install openstack-cinder targetcli python-keystone -y\nmv /etc/cinder/cinder.conf{,.bak}\ncat >> /etc/cinder/cinder.conf << EOF\n[DEFAULT]\ntransport_url = rabbit://openstack:RABBIT_PASS@controller-48\nauth_strategy = keystone\nmy_ip = 192.168.48.20\nenabled_backends = lvm\nglance_api_servers = http://controller-48:9292\n# 192.168.48.20  为块存储节点 computer-48管理网络 的接口IP\n[database]\nconnection = mysql+pymysql://cinder:CINDER_DBPASS@controller-48/cinder\n# CINDER_DBPASS 为数据库 Cinder 账户密码\n[keystone_authtoken]\nwww_authenticate_uri = http://controller-48:5000\nauth_url = http://controller-48:5000\nmemcached_servers = controller-48:11211\nauth_type = password\nproject_domain_name = default\nuser_domain_name = default\nproject_name = service\nusername = cinder\npassword = CINDER_PASS\n# CINDER_PASS 为 cinder 数据库账户密码\n[lvm]\nvolume_driver = cinder.volume.drivers.lvm.LVMVolumeDriver\nvolume_group = cinder-volumes\ntarget_protocol = iscsi\ntarget_helper = lioadm\n# [lvm]  没有则新建\n[oslo_concurrency]\nlock_path = /var/lib/cinder/tmp\nEOF\n\nsystemctl enable openstack-cinder-volume.service target.service --now\nsystemctl status openstack-cinder-volume.service target.service\n\n```\n\n### 控制节点验证\n\n```\n# 验证\n# 控制节点执行\nsource admin-openrc.sh\nopenstack volume service list\nsystemctl restart httpd memcached\n[root@controller-48 ~]# openstack volume service list\n+------------------+-------------+------+---------+-------+----------------------------+\n| Binary           | Host        | Zone | Status  | State | Updated At                 |\n+------------------+-------------+------+---------+-------+----------------------------+\n| cinder-scheduler | controller-48  | nova | enabled | up    | 2023-05-24T08:24:18.000000 |\n| cinder-volume    | computer-48@lvm | nova | enabled | up    | 2023-05-24T08:24:17.000000 |\n+------------------+-------------+------+---------+-------+----------------------------+\n\n```\n\n\n\n## Swift（对象存储）\n\n### 控制节点\n\n```\n###控制节点\nsource admin-openrc.sh\nopenstack user create --domain default --password SWIFT_PASS swift\nopenstack role add --project service --user swift admin\n#创建swift服务实体：\nopenstack service create --name swift \\\n  --description \"OpenStack Object Storage\" object-store\n#创建swift服务实体：\nopenstack endpoint create --region RegionOne \\\nobject-store public http://controller-48:8080/v1/AUTH_%\\(project_id\\)s\n\nopenstack endpoint create --region RegionOne \\\nobject-store internal http://controller-48:8080/v1/AUTH_%\\(project_id\\)s\n\nopenstack endpoint create --region RegionOne \\\nobject-store admin http://controller-48:8080/v1\n\n#安装swift组件\nyum install -y openstack-swift-proxy python-swiftclient \\\n  python-keystoneclient python-keystonemiddleware \\\n  Memcached\n\nmv /etc/swift/proxy-server.conf{,.bak}\ncat> /etc/swift/proxy-server.conf<<EOF\n[DEFAULT]\nbind_ip = 0.0.0.0\nbind_port = 8080\nuser = swift\n[pipeline:main]\npipeline = catch_errors gatekeeper healthcheck proxy-logging cache container_sync bulk ratelimit authtoken keystoneauth container-quotas account-quotas slo dlo versioned_writes proxy-logging proxy-server\n[app:proxy-server]\nuse = egg:swift#proxy\nallow_account_management = true\naccount_autocreate = true\n#Keystone auth info\n[filter:authtoken]\npaste.filter_factory = keystonemiddleware.auth_token:filter_factory\nwww_authenticate_uri = http://controller-48:5000\nauth_url = http://controller-48:5000/v3\nmemcached_servers = controller-48:11211\nauth_type = password\nproject_domain_name = default\nuser_domain_name = default\nproject_name = service\nusername = swift\npassword = SWIFT_PASS\ndelay_auth_decision = true\nservice_token_roles_required = True\n[filter:keystoneauth]\nuse = egg:swift#keystoneauth\noperator_roles = admin,user\n[filter:healthcheck]\nuse = egg:swift#healthcheck\n[filter:cache]\nuse = egg:swift#memcache\nmemcache_servers = controller-48:11211\n[filter:ratelimit]\nuse = egg:swift#ratelimit\n[filter:domain_remap]\nuse = egg:swift#domain_remap\n[filter:catch_errors]\nuse = egg:swift#catch_errors\n[filter:cname_lookup]\nuse = egg:swift#cname_lookup\n[filter:staticweb]\nuse = egg:swift#staticweb\n[filter:tempurl]\nuse = egg:swift#tempurl\n[filter:formpost]\nuse = egg:swift#formpost\n[filter:name_check]\nuse = egg:swift#name_check\n[filter:list-endpoints]\nuse = egg:swift#list_endpoints\n[filter:proxy-logging]\nuse = egg:swift#proxy_logging\n[filter:bulk]\nuse = egg:swift#bulk\n[filter:slo]\nuse = egg:swift#slo\n[filter:dlo]\nuse = egg:swift#dlo\n[filter:container-quotas]\nuse = egg:swift#container_quotas\n[filter:account-quotas]\nuse = egg:swift#account_quotas\n[filter:gatekeeper]\nuse = egg:swift#gatekeeper\n[filter:container_sync]\nuse = egg:swift#container_sync\n[filter:xprofile]\nuse = egg:swift#xprofile\n[filter:versioned_writes]\nuse = egg:swift#versioned_writes\nEOF\n```\n\n### computer-48\n\n添加4张硬盘\n\n![image-20230527155112604](../img/OpenStack-Train%E5%8F%8C%E8%8A%82%E7%82%B9%E9%83%A8%E7%BD%B2/65a2b757e9272dea0844d5ed3b29915a881521da-1709275202730-29.png)\n\n![image-20230524083115643](../img/OpenStack-Train%E5%8F%8C%E8%8A%82%E7%82%B9%E9%83%A8%E7%BD%B2/9f33d320e2c43241ab5a4c74f10441445310ecd2-1709275202730-30.png)\n\n```\n#conpute节点\nyum install xfsprogs rsync -y\n\nlsblk\n#将/dev/sdb和/dev/sdc设备格式化为XFS：\nmkfs.xfs /dev/sdc\nmkfs.xfs /dev/sdd\nmkfs.xfs /dev/sde\nmkfs.xfs /dev/sdf\n#创建安装点目录结构：\nmkdir -p /srv/node/sdc\nmkdir -p /srv/node/sdd\nmkdir -p /srv/node/sde\nmkdir -p /srv/node/sdf\n\ncat >> /etc/fstab << EOF\n/dev/sdc /srv/node/sdc xfs noatime,nodiratime,nobarrier,logbufs=8 0 2\n/dev/sdd /srv/node/sdd xfs noatime,nodiratime,nobarrier,logbufs=8 0 2\n/dev/sde /srv/node/sde xfs noatime,nodiratime,nobarrier,logbufs=8 0 2\n/dev/sdf /srv/node/sdf xfs noatime,nodiratime,nobarrier,logbufs=8 0 2\nEOF\n\n#安装设备\nmount /srv/node/sdc\nmount /srv/node/sdd\nmount /srv/node/sde\nmount /srv/node/sdf\n\ncat>/etc/rsyncd.conf<<EOF\nuid = swift\ngid = swift\nlog file = /var/log/rsyncd.log\npid file = /var/run/rsyncd.pid\naddress = 192.168.148.20\n\n[account]\nmax connections = 2\npath = /srv/node/\nread only = False\nlock file = /var/lock/account.lock\n\n[container]\nmax connections = 2\npath = /srv/node/\nread only = False\nlock file = /var/lock/container.lock\n\n[object]\nmax connections = 2\npath = /srv/node/\nread only = False\nlock file = /var/lock/object.lock\nEOF\n\n#重启服务\nsystemctl enable rsyncd.service\nsystemctl start rsyncd.service\n\n#安装swift组件\nyum install -y openstack-swift-account openstack-swift-container \\\n  openstack-swift-object\n  \nmv /etc/swift/account-server.conf{,.bak}\ncat> /etc/swift/account-server.conf<<EOF\n[DEFAULT]\nbind_ip = 192.168.148.20\nbind_port = 6202\nuser = swift\nswift_dir = /etc/swift\ndevices = /srv/node\nmount_check = true\n[pipeline:main]\npipeline = healthcheck recon account-server\n[app:account-server]\nuse = egg:swift#account\n[filter:healthcheck]\nuse = egg:swift#healthcheck\n[filter:recon]\nuse = egg:swift#recon\nrecon_cache_path = /var/cache/swift\n[account-replicator]\n[account-auditor]\n[account-reaper]\n[filter:xprofile]\nuse = egg:swift#xprofile\nEOF\n\nmv /etc/swift/container-server.conf{,.bak}\ncat> /etc/swift/container-server.conf<<EOF\n[DEFAULT]\nbind_ip = 192.168.148.20\nbind_port = 6201\nuser = swift\nswift_dir = /etc/swift\ndevices = /srv/node\nmount_check = true\n[pipeline:main]\npipeline = healthcheck recon container-server\n[app:container-server]\nuse = egg:swift#container\n[filter:healthcheck]\nuse = egg:swift#healthcheck\n[filter:recon]\nuse = egg:swift#recon\n[container-replicator]\n[container-updater]\n[container-auditor]\n[container-sync]\n[filter:xprofile]\nuse = egg:swift#xprofile\n[container-sharder]\nEOF\n\nmv /etc/swift/object-server.conf{,.bak}\ncat> /etc/swift/object-server.conf<<EOF\n[DEFAULT]\nbind_ip = 0.0.0.0\nbind_port = 6200\nuser = swift\nswift_dir = /etc/swift\ndevices = /srv/node\nmount_check = true\n[pipeline:main]\npipeline = healthcheck recon object-server\n[app:object-server]\nuse = egg:swift#object\nrecon_cache_path = /var/cache/swift\nrecon_lock_path = /var/lock\n[filter:healthcheck]\nuse = egg:swift#healthcheck\n[filter:recon]\nuse = egg:swift#recon\n[object-replicator]\n[object-reconstructor]\n[object-updater]\n[object-expirer]\n[filter:xprofile]\nuse = egg:swift#xprofile\n[object-relinker]\n[object-auditor]\nlog_name = object-auditor\nlog_facility = LOG_LOCAL0\nlog_level = INFO\nlog_address=/dev/log   \nEOF\n#确保对安装点目录结构拥有适当的所有权：\nchown -R swift:swift /srv/node\n\n#创建recon目录并确保对其拥有适当的所有权：\n mkdir -p /var/cache/swift\n chown -R root:swift /var/cache/swift\n chmod -R 775 /var/cache/swift\n \n# 在防火墙中启用必要的访问(实验忽略)\nfirewall-cmd --permanent --add-port=6200/tcp\nfirewall-cmd --permanent --add-port=6201/tcp\nfirewall-cmd --permanent --add-port=6202/tcp\n\n```\n\n### 创建和分发初始环 controller-48\n\n```\n#控制节点\n转到/etc/swift目录。(所以操作在此目录，执行)\n创建用户环account.builder文件：\ncd /etc/swift\n##第一部分（6202）创建用户环\nswift-ring-builder account.builder create 10 3 1\nswift-ring-builder account.builder add \\\n   --region 1 --zone 1 --ip 192.168.148.20 --port 6202 --device sdc --weight 100\nswift-ring-builder account.builder add \\\n   --region 1 --zone 1 --ip 192.168.148.20 --port 6202 --device sdd --weight 100\nswift-ring-builder account.builder add \\\n   --region 1 --zone 2 --ip 192.168.148.20 --port 6202 --device sde --weight 100\nswift-ring-builder account.builder add \\\n   --region 1 --zone 2 --ip 192.168.148.20 --port 6202 --device sdf --weight 100\nswift-ring-builder account.builder\n##重新平衡环且验证\nswift-ring-builder account.builder rebalance\nswift-ring-builder account.builder\n\n\n##第二部分（6201）创建容器环\nswift-ring-builder container.builder create 10 3 1\nswift-ring-builder container.builder add \\\n   --region 1 --zone 1 --ip 192.168.148.20 --port 6201 --device sdc --weight 100\nswift-ring-builder container.builder add \\\n   --region 1 --zone 1 --ip 192.168.148.20 --port 6201 --device sdd --weight 100\nswift-ring-builder container.builder add \\\n   --region 1 --zone 2 --ip 192.168.148.20 --port 6201 --device sde --weight 100\nswift-ring-builder container.builder add \\\n   --region 1 --zone 2 --ip 192.168.148.20 --port 6201 --device sdf --weight 100\nswift-ring-builder container.builder\nswift-ring-builder container.builder rebalance\n\n##第三部分（6200）创建对象环\nswift-ring-builder object.builder create 10 3 1\nswift-ring-builder object.builder add \\\n   --region 1 --zone 1 --ip 192.168.148.20 --port 6200 --device sdc --weight 100\nswift-ring-builder object.builder add \\\n   --region 1 --zone 1 --ip 192.168.148.20 --port 6200 --device sdd --weight 100\nswift-ring-builder object.builder add \\\n   --region 1 --zone 2 --ip 192.168.148.20 --port 6200 --device sde --weight 100\nswift-ring-builder object.builder add \\\n   --region 1 --zone 2 --ip 192.168.148.20 --port 6200 --device sdf --weight 100\nswift-ring-builder object.builder\nswift-ring-builder object.builder rebalance\n\n将swift目录下生成三个.gz文件复制到存储节点的swift目录下\nscp account.ring.gz container.ring.gz object.ring.gz 192.168.148.20:/etc/swift\n\n##完成安装 controller-48\nmv  /etc/swift/swift.conf{,.bak}\ncat> /etc/swift/swift.conf<<EOF\n[swift-hash]\nswift_hash_path_suffix = swift\nswift_hash_path_prefix = swift\n[storage-policy:0]\nname = Policy-0\ndefault = yes\nEOF\n\n#复制到存储节点\nscp swift.conf 192.168.148.20:/etc/swift\nswift_hash_path_suffix和swift_hash_path_prefix作为哈希算法的一部分用于确定数据在集群中的位置。\n这些值应该保持机密，并且在部署集群之后不能更改丢失。可自定义\n在所有节点确保对配置目录拥有适当的所有权：\n####存储节点与控制节点同时执行（注意！！！！两个节点同时执行）\nchown -R root:swift /etc/swift \n在控制器节点和任何其他运行代理服务的节点上，启动对象存储代理服务及其相关性，并将它们配置为在系统启动时启动(存储节点无代理服务)\n\n#重启服务\nsystemctl enable openstack-swift-proxy.service memcached.service --now\nsystemctl restart openstack-swift-proxy.service memcached.service\n```\n\n### 计算节点\n\n```\n在存储节点启动所有服务\n systemctl enable openstack-swift-account.service openstack-swift-account-auditor.service \\\n  openstack-swift-account-reaper.service openstack-swift-account-replicator.service\n systemctl start openstack-swift-account.service openstack-swift-account-auditor.service \\\n  openstack-swift-account-reaper.service openstack-swift-account-replicator.service\n systemctl enable openstack-swift-container.service \\\n  openstack-swift-container-auditor.service openstack-swift-container-replicator.service \\\n  openstack-swift-container-updater.service\n systemctl start openstack-swift-container.service \\\n  openstack-swift-container-auditor.service openstack-swift-container-replicator.service \\\n  openstack-swift-container-updater.service\n systemctl enable openstack-swift-object.service openstack-swift-object-auditor.service \\\n  openstack-swift-object-replicator.service openstack-swift-object-updater.service\n systemctl start openstack-swift-object.service openstack-swift-object-auditor.service \\\n  openstack-swift-object-replicator.service openstack-swift-object-updater.service\n```\n\n### 验证\n\n```\n[root@controller-48 swift]# swift stat\n               Account: AUTH_07a1ce96dca54f1bb0d3b968f1343617\n            Containers: 0\n               Objects: 0\n                 Bytes: 0\n       X-Put-Timestamp: 1684919814.32783\n           X-Timestamp: 1684919814.32783\n            X-Trans-Id: txd6f3affa0140455b935ff-00646dd605\n          Content-Type: text/plain; charset=utf-8\nX-Openstack-Request-Id: txd6f3affa0140455b935ff-00646dd605\n[root@controller-48 swift]# cd\n[root@controller-48 ~]# swift upload demo cirros-0.5.2-x86_64-disk.img --object-name image\nimage\n\n##重启nova服务\nsudo systemctl restart openstack-nova*\n\n```\n\n## Heat（编排）\n\n### 控制节点\n\n```\n#创建heat数据库和用户\nmysql -u root -pMARIADB_PASS\nCREATE DATABASE heat;\nGRANT ALL PRIVILEGES ON heat.* TO 'heat'@'localhost' \\\n  IDENTIFIED BY 'HEAT_DBPASS';\nGRANT ALL PRIVILEGES ON heat.* TO 'heat'@'%' \\\n  IDENTIFIED BY 'HEAT_DBPASS';\nflush privileges;\nexit\n\nsource admin-openrc.sh\nopenstack user create --domain default --password HEAT_PASS heat\n#添加 admin 角色到 heat 用户上\nopenstack role add --project service --user heat admin\n##创建heat和 heat-cfn 服务实体\nopenstack service create --name heat \\\n  --description \"Orchestration\" orchestration\nopenstack service create --name heat-cfn \\\n  --description \"Orchestration\"  cloudformation  \n##创建 Orchestration 服务的 API 端点\nopenstack endpoint create --region RegionOne \\\n  orchestration public http://controller-48:8004/v1/%\\(tenant_id\\)s\nopenstack endpoint create --region RegionOne \\\n  orchestration internal http://controller-48:8004/v1/%\\(tenant_id\\)s\nopenstack endpoint create --region RegionOne \\\n  orchestration admin http://controller-48:8004/v1/%\\(tenant_id\\)s\n\nopenstack endpoint create --region RegionOne \\\n  cloudformation public http://controller-48:8000/v1\nopenstack endpoint create --region RegionOne \\\n  cloudformation internal http://controller-48:8000/v1\nopenstack endpoint create --region RegionOne \\\n  cloudformation admin http://controller-48:8000/v1\n```\n\n为了管理栈，在认证服务中Orchestration需要更多信息\n\n```\n#控制节点\n#为栈创建 heat 包含项目和用户的域\nopenstack domain create --description \"Stack projects and users\" heat\n\n#在 heat 域中创建管理项目和用户的heat_domain_admin用户：\nopenstack user create --domain heat --password=HEAT_DOMAIN_USER_PASS heat_domain_admin\n\n#)添加admin角色到 heat 域 中的heat_domain_admin用户，启用heat_domain_admin用户#管理栈的管理权限\nopenstack role add --domain heat --user-domain heat --user heat_domain_admin admin\n\n#为栈创建 heat 包含项目和用户的域\nopenstack role create heat_stack_owner\n\n#添加heat_stack_owner 角色到demo 项目和用户，启用demo 用户管理栈。\nopenstack role add --project demo --user demo heat_stack_owner\n#必须添加 heat_stack_owner 角色到每个管理栈的用户。\n\n#heat_stack_user 角色\nopenstack role create heat_stack_user\n\n```\n\n安装并配置Heat组件相关软件\n\n```\n#控制节点\nyum install openstack-heat-api openstack-heat-api-cfn \\\n  openstack-heat-engine -y\n\nmv /etc/heat/heat.conf{,.bak}\ncat >> /etc/heat/heat.conf << EOF\n[database]\nconnection = mysql+pymysql://heat:HEAT_DBPASS@controller-48/heat  \n#HEAT_DBPASS是HEAT数据库密码\n[DEFAULT]\ntransport_url = rabbit://openstack:RABBIT_PASS@controller-48\n#RABBIT_PASS为Rabbitmq服务密码 用户名是openstack\n[keystone_authtoken]\nwww_authenticate_uri = http://controller-48:5000\nauth_url = http://controller-48:5000\nmemcached_servers = controller-48:11211\nauth_type = password\nproject_domain_name = default\nuser_domain_name = default\nproject_name = service\nusername = heat\npassword = HEAT_PASS\n#HEAT_PASS是heat用户密码\n[trustee]\nauth_type = password\nauth_url = http://controller-48:5000\nusername = heat\npassword = HEAT_PASS\n#HEAT_PASS是heat用户密码\nuser_domain_name = default\n[clients_keystone]\nauth_uri = http://controller-48:5000\n[DEFAULT]\nheat_metadata_server_url = http://controller-48:8000\nheat_waitcondition_server_url = http://controller-48:8000/v1/waitcondition\n[DEFAULT]\nstack_domain_admin = heat_domain_admin\nstack_domain_admin_password = HEAT_DOMAIN_USER_PASS\nstack_user_domain_name = heat\nEOF\n\nsu -s /bin/sh -c \"heat-manage db_sync\" heat\n##启动 Orchestration 编排服务heat组件并将其设置为随系统启动\nsystemctl enable openstack-heat-api.service \\\n  openstack-heat-api-cfn.service openstack-heat-engine.service\n\nsystemctl restart openstack-heat-api.service \\\n  openstack-heat-api-cfn.service openstack-heat-engine.service\n  \n[root@controller-48 ~]# systemctl list-unit-files |grep openstack-heat*\nopenstack-heat-api-cfn.service                enabled\nopenstack-heat-api.service                    enabled\nopenstack-heat-engine.service                 enabled\n\n```\n\n### 验证\n\n```\ncd\nsource admin-openrc.sh\nopenstack service list\nopenstack orchestration service list\n该输出显示表明在控制节点上有应该四个heat-engine组件。\n\n[root@controller-48 ~]# openstack orchestration service list\n+------------+-------------+--------------------------------------+------------+--------+----------------------------+--------+\n| Hostname   | Binary      | Engine ID                            | Host       | Topic  | Updated At                 | Status |\n+------------+-------------+--------------------------------------+------------+--------+----------------------------+--------+\n| controller-48 | heat-engine | 230ae8e8-3c9f-4b82-b0ca-caef3d5497f1 | controller-48 | engine | 2023-05-27T14:42:52.000000 | up     |\n| controller-48 | heat-engine | 626e74a4-918b-46b8-8993-d6db92eb861e | controller-48 | engine | 2023-05-27T14:42:52.000000 | up     |\n| controller-48 | heat-engine | f648e766-cdb9-4e06-b190-a713baf33df8 | controller-48 | engine | 2023-05-27T14:42:52.000000 | up     |\n| controller-48 | heat-engine | 2cb3dfd3-0636-432c-8d59-f22d850510d5 | controller-48 | engine | 2023-05-27T14:42:52.000000 | up     |\n+------------+-------------+--------------------------------------+------------+--------+----------------------------+--------+\n\n```\n\n## 创建实例\n\n### 创建实例类型\n\n左侧选择管理员，点击计算，点击实例类型，右侧点击创建实例类型。\n\n![image-20240106230035149](../img/OpenStack-Train%E5%8F%8C%E8%8A%82%E7%82%B9%E9%83%A8%E7%BD%B2/55d5112b942c438d89818b728d7d3062697559838-1709275708073-159.png)\n\n根据以上图片步骤依次填入：实例名称、VCPU数量、内存大小、根磁盘大小，确认无误后点击创建实例类型。\n\n### 创建镜像\n\n测试镜像：https://download.cirros-cloud.net/0.6.2/cirros-0.6.2-x86_64-disk.img\n\n<font color='red'>有两种上传方式（二选一）！！！</font>\n\n<font color='red'>1.Windows上传镜像方式</font>\n\n左侧选择管理员，点击计算，点击镜像，右侧点击创建镜像。\n\nWindows下载到本地即可\n\n![image-20240106230649633](../img/OpenStack-Train%E5%8F%8C%E8%8A%82%E7%82%B9%E9%83%A8%E7%BD%B2/f2ea42f3b57b4b7a5fb9bd242f78e526697559838-1709275708073-160.png)\n\n根据以上图片步骤依次填入：镜像名称、选择文件、镜像格式，确认无误后点击创建镜像。\n**注**：演示上传的 img 镜像格式需选用 QCOW2 - QEMU模拟器 才可正常加载。\n\n\n\n<font color='red'>2.Linux上传镜像方式</font>\n\n```\nsource admin-openrc\nwget https://download.cirros-cloud.net/0.6.2/cirros-0.6.2-x86_64-disk.img\n#可能会下载不到，可以复制链接到浏览器下载，然后移到/root/目录下\nglance image-create --name \"cirros\" \\\n  --file cirros-0.6.2-x86_64-disk.img \\\n  --disk-format qcow2 --container-format bare \\\n  --visibility=public\n\nopenstack image list\n\n[root@controller-1 ~]# openstack image list\n+--------------------------------------+--------+--------+\n| ID                                   | Name   | Status |\n+--------------------------------------+--------+--------+\n| 627761da-7f8c-4780-842a-e50e62f5c464 | cirros | active |\n+--------------------------------------+--------+--------+\n\n```\n\n### 创建内部网络\n\n左侧选择管理员，点击网络，点击网络，右侧点击创建网络。\n\n![image-20240106231124036](../img/OpenStack-Train%E5%8F%8C%E8%8A%82%E7%82%B9%E9%83%A8%E7%BD%B2/cea509bcbba7395e7c5710616943c0bd697559838-1709275708073-161.png)\n\n![image-20240106231151367](../img/OpenStack-Train%E5%8F%8C%E8%8A%82%E7%82%B9%E9%83%A8%E7%BD%B2/6bab28f65a2c56a624df71c4b9866347697559838-1709275708073-162.png)\n\n![image-20240106231323081](../img/OpenStack-Train%E5%8F%8C%E8%8A%82%E7%82%B9%E9%83%A8%E7%BD%B2/0b1b24f8d99f5c3f49662532c68ac046697559838-1709275708073-163.png)\n\n### 创建外部网络\n\n左侧选择管理员，点击网络，点击网络，右侧点击创建网络。\n\n<font color='red'>如果你是按照本文档搭建的，就填provider</font>\n\n![image-20240106231633793](../img/OpenStack-Train%E5%8F%8C%E8%8A%82%E7%82%B9%E9%83%A8%E7%BD%B2/5fbbf082bc66e60949bdd81825facd02697559838-1709275708073-164.png)\n\n![image-20240106231854446](../img/OpenStack-Train%E5%8F%8C%E8%8A%82%E7%82%B9%E9%83%A8%E7%BD%B2/070d5393f9a1b8dd7dee9d2fea10086e697559838-1709275708073-165.png)\n\n![image-20240106232011057](../img/OpenStack-Train%E5%8F%8C%E8%8A%82%E7%82%B9%E9%83%A8%E7%BD%B2/d0a471b28e40019c7fc79bc8918cda04697559838-1709275708074-166.png)\n\n### 创建路由\n\n左侧选择管理员，点击网络，点击路由，右侧点击创建路由。\n\n![image-20240106232138022](../img/OpenStack-Train%E5%8F%8C%E8%8A%82%E7%82%B9%E9%83%A8%E7%BD%B2/31d170f9b1e99be47760fd014bb6809d697559838-1709275708074-167.png)\n\n\n\n![image-20240106232201129](../img/OpenStack-Train%E5%8F%8C%E8%8A%82%E7%82%B9%E9%83%A8%E7%BD%B2/cb31565a3cfeb2dc853ac38cded0043e697559838-1709275708074-168.png)\n\n![image-20240106232242376](../img/OpenStack-Train%E5%8F%8C%E8%8A%82%E7%82%B9%E9%83%A8%E7%BD%B2/ce7823ed963eca1a54ca8b97f14928e5697559838-1709275708074-169.png)\n\n### 添加安全组规则\n\n![image-20240106232342515](../img/OpenStack-Train%E5%8F%8C%E8%8A%82%E7%82%B9%E9%83%A8%E7%BD%B2/757fee2ef006d00f258da6008163fe91697559838-1709275708074-170.png)\n\n![image-20240106232725982](../img/OpenStack-Train%E5%8F%8C%E8%8A%82%E7%82%B9%E9%83%A8%E7%BD%B2/b99fadf3fe10a6ddba4ba221b3c2ff87697559838-1709275708074-171.png)\n\n最后效果长这样\n\n![image-20240106232758711](../img/OpenStack-Train%E5%8F%8C%E8%8A%82%E7%82%B9%E9%83%A8%E7%BD%B2/485233affd839f8fbce7ea1c0ae2765d697559838-1709275708074-172.png)\n\n### 创建实例\n\n![image-20240106232939110](../img/OpenStack-Train%E5%8F%8C%E8%8A%82%E7%82%B9%E9%83%A8%E7%BD%B2/0105c7af8682dc647d6cf79473cd9fbc697559838-1709275708074-173.png)\n\n![image-20240106233038731](../img/OpenStack-Train%E5%8F%8C%E8%8A%82%E7%82%B9%E9%83%A8%E7%BD%B2/86ffdba6219b46e5a387f8b67fa5edf7697559838-1709275708074-174.png)\n\n![image-20240106233101509](../img/OpenStack-Train%E5%8F%8C%E8%8A%82%E7%82%B9%E9%83%A8%E7%BD%B2/8bf413d2923a38d956d41f905d1a4f6b697559838-1709275708074-175.png)\n\n![image-20240106233129659](../img/OpenStack-Train%E5%8F%8C%E8%8A%82%E7%82%B9%E9%83%A8%E7%BD%B2/3083c4669cd60df3c5a53b7b5f661629697559838-1709275708074-176.png)\n\n然后点击创建实例\n\n分配浮动ip\n\n![image-20240106233251169](../img/OpenStack-Train%E5%8F%8C%E8%8A%82%E7%82%B9%E9%83%A8%E7%BD%B2/bfb7b78b90815059f8171048bcb0683b697559838-1709275708074-177.png)\n\n![image-20240106233418787](../img/OpenStack-Train%E5%8F%8C%E8%8A%82%E7%82%B9%E9%83%A8%E7%BD%B2/f584f2ac4bb92bb8043c2c07c670dbf4697559838-1709275708075-178.png)\n\n<font color='red'>结论：创建实例成功</font>\n\n<div class=\"tbsm\" style=\"margin-top:54px;\">\n<div class=\"tbsm-top\"><span><svg t=\"1674654360507\" class=\"icon\" viewBox=\"0 0 1024 1024\" version=\"1.1\" xmlns=\"http://www.w3.org/2000/svg\" p-id=\"987\" data-spm-anchor-id=\"a313x.7781069.0.i0\" width=\"35\" height=\"35\"><path d=\"M410.49 97.74H155.08a56.74 56.74 0 0 0-56.84 56.73V410a56.84 56.84 0 0 0 56.84 56.84h255.41A56.83 56.83 0 0 0 467.32 410V154.58a56.83 56.83 0 0 0-56.83-56.84zM410.49 558.74H155.08a56.74 56.74 0 0 0-56.84 56.73V871a56.84 56.84 0 0 0 56.84 56.84h255.41A56.83 56.83 0 0 0 467.32 871V615.58a56.83 56.83 0 0 0-56.83-56.84zM871.49 558.74H616.08a56.74 56.74 0 0 0-56.84 56.73V871a56.84 56.84 0 0 0 56.84 56.84h255.41A56.83 56.83 0 0 0 928.32 871V615.58a56.83 56.83 0 0 0-56.83-56.84z\" fill=\"#66EEFF\" p-id=\"988\"></path><path d=\"M410.49 558.74h-4.14A475 475 0 0 0 299.52 859.6a481.16 481.16 0 0 0 4.84 68.22h106.13A56.83 56.83 0 0 0 467.32 871V615.58a56.83 56.83 0 0 0-56.83-56.84zM871.49 558.74H616.08a56.74 56.74 0 0 0-56.84 56.73V871a56.84 56.84 0 0 0 56.84 56.84h255.41A56.83 56.83 0 0 0 928.32 871V615.58a56.83 56.83 0 0 0-56.83-56.84z\" fill=\"#C2F8FF\" p-id=\"989\"></path></svg></span><span style=\"font-size:30px;\"> 特别声明</span></div>\n<div class=\"tbsm-wz\">千屹博客旗下的所有文章，是通过本人课堂学习和课外自学所精心整理的知识巨著<br/>难免会有出错的地方<br/>如果细心的你发现了小失误，可以在下方评论区告诉我，或者私信我！<br />非常感谢大家的热烈支持！</div>\n</div>","tags":["Centos 7","OpenStack"],"categories":["云原生"]},{"title":"Docker笔记","url":"/posts/27092/","content":"\n<meta name=\"referrer\" content=\"no-referrer\"/>\n\n# Docker笔记\n\n结合[Centos 8部署Docker - 严千屹博客 (qianyios.top)](https://blog.qianyios.top/posts/51253/)搭建的Docker实现本次笔记的所有内容及例子\n\n也可以使用以下Centos7部署Docker CE 19.03实现本实验的所有例子\n\n## Centos7部署Docker CE 19.03\n\n（2023年4月8日01点00分）当前最常用的 Docker 版本是 Docker CE 19.03。这是 Docker 社区版（Community Edition）的最新版本，它包括一些更新和新功能，如多阶段构建、Dockerfile 中的 ARG 和 FROM 指令以及与 Kubernetes 的更好集成等。另外，Docker CE 19.03 支持 Windows、MacOS 和 Linux 操作系统。\n\n### 卸载旧版本\n\n```\nsudo yum -y remove docker \\\n                  docker-client \\\n                  docker-client-latest \\\n                  docker-common \\\n                  docker-latest \\\n                  docker-latest-logrotate \\\n                  docker-logrotate \\\n                  docker-selinux \\\n                  docker-engine-selinux \\\n                  docker-engine\nsudo yum remove docker-ce docker-ce-cli containerd.io docker-compose docker-machine docker-swarm\nsudo rm /etc/yum.repos.d/docker-ce.repo\nsudo rm -rf /var/lib/docker\n```\n\n### 安装docker\n\n```\nsudo yum install -y yum-utils device-mapper-persistent-data lvm2\nsudo yum-config-manager --add-repo https://download.docker.com/linux/centos/docker-ce.repo\nsudo yum install docker-ce docker-ce-cli containerd.io -y\nsudo systemctl start docker\ndocker version\nsudo curl -L \"https://github.com/docker/compose/releases/download/1.28.6/docker-compose-$(uname -s)-$(uname -m)\" -o /usr/local/bin/docker-compose\nsudo chmod +x /usr/local/bin/docker-compose\ndocker-compose --version\n```\n\n## Docker的常用命令\n\n```\ndocker version\t\t   # 显示docker的版本信息\ndocker info\t\t\t   # 显示docker的系统信息,包括镜像和容器的数量\ndocker 命令 --help \t   # 帮助命令\n```\n\n## 镜像命令\n\n### 镜像命令\n\n```\ndocker images\t\t# 查看所有本地的主机上的镜像\n-a,--al1\t# 列出所有镜像\n-q,--quiet\t# 只显示镜像的id\n# 解释\nREPOSITORY        TAG         IMAGE ID        CREATED          SIZE\n镜像的仓库源      镜像的标签  镜像的id        镜像的创建时间   镜像的大小\n```\n\n### 搜索命令\n\n```\n[root@docker ~]# docker search centos\nNAME    DESCRIPTION    STARS                               OFFICIAL  AUTOMATED\ncentos  DEPRECATED;    The official build of CentOS.       7537      [OK]\n检索Docker仓库中的Ubuntu镜像\n```\n\n### 拉取镜像\n\n```\n[root@docker ~]# docke pull 镜像名[:tag]\t\t#下载镜像\n# 如果不写tag，默认就是latest\n\n[root@docker ~]# docker pull centos\nUsing default tag: latest\nlatest: Pulling from library/centos\na1d0c7532777: Pull complete\nDigest: sha256:a27fd8080b517143cbbbab9dfb7c8571c40d67d534bbdee55bd6c473f432b177\nStatus: Downloaded newer image for centos:latest\ndocker.io/library/centos:latest\n从docker库拉去centos镜像\n[root@docker ~]# docker images\nREPOSITORY   TAG       IMAGE ID       CREATED         SIZE\ncentos       latest    5d0da3dc9764   18 months ago   231MB\n\n```\n\n### 删除镜像\n\n```\ndocker rmi -f 镜像名/id\t\t# 删除指定镜像\ndocker rmi -f 镜像名1 镜像名2 镜像名3\t # 一次删除指定多个镜像\ndocker rmi -f $(docker images -aq)\t\t# 删除全部容器\n\n[root@docker ~]# docker images\nREPOSITORY   TAG       IMAGE ID       CREATED         SIZE\ncentos       latest    5d0da3dc9764   18 months ago   231MB\n[root@docker ~]# docker rmi 5d0\nUntagged: centos:latest\n。。。。。。\n（一般情况下 删除镜像id 只需要输入前面3个字符就行了）\n```\n\n### 查看镜像分层\n\n```\n[root@docker ~]# docker image inspect 镜像id\n```\n\n### 镜像资源包\n\n```\ncurl -O http://mirrors.douxuedu.com/cloud/docker.zip\nunzip docker.zip\ndocker load < 镜像名.tar\n例如：\n[root@localhost ~]# docker load < docker/centos_latest.tar\n```\n\n## 容器命令\n\n### 新建容器并启动\n\n```\ndocker run [可选参数] 镜像名\t\t# 新建容器并启动\n--name=Name\t\t# 容器名字用来区分容器\n-d\t\t\t\t# 后台方式运行\n-it\t\t\t\t# 使用交互方式运行，进入容器查看内容\n-p\t\t\t\t# 指定容器的端口-p 8080:8080\n-P\t\t\t\t# 随机指定端口\n进入容器\n[root@docker ~]# docker run -it --name test centos\n[root@4018f9ac2f33 /]# pwd\n/\nexit         # 退出\nCtrl+P+Q     # 容器不停止退出\n```\n\n### 查看容器列表\n\n```\n查看容器列表   （若加 -a可以查看所有容器包括为运行的）\n[root@docker ~]# docker ps [可选参数]\nCONTAINER ID   IMAGE     COMMAND       CREATED              STATUS              PORTS     NAMES\n4018f9ac2f33   centos    \"/bin/bash\"   About a minute ago   Up About a minute             test\n[可选参数]\n-a\t\t\t# 列出当前正在运行的容器+带出历史运行过的容器\n-n=?\t\t# 显示最近创建的容器\n-q\t\t\t# 只显示容器的编号\n```\n\n### 删除容器\n\n```\n（一般情况下 删除容器id 只需要输入前面3个字符就行了）\ndocker rm 容器id\t# 删除指定的容器，不能删除正在运行的容器，如果要强制删除 rm -f\ndocker rm -f $ (docker ps -aq)\t\t# 强制删除所有的容器\ndocker ps -a -q|xargs docker rm\t\t# 删除所有的容器\n```\n\n### 启动和停止容器\n\n```\ndocker start 容器id\t\t# 启动容器\ndocker restart 容器id\t\t# 重启容器\ndocker stop 容器id\t\t# 停止当前正在运行的容器\ndocker kill 容器id\t\t# 强制停止当前容器\n```\n\n### 进入正在运行的容器\n\n```\n进入容器后开启一个新的终端，可以在里面操作\ndocker exec -it 容器id /bin/bash\n进入容器正在执行的终端，不会启动新的进程\ndocker attach 容器id\n```\n\n### 拷贝容器内的文件到主机上\n\n```\ndocker cp 容器id:容器内路径 目的主机路径\n\n[root@docker ~]# docker exec -it 401 /bin/bash\n[root@4018f9ac2f33 /]# echo \"11\" > test.txt\n[root@4018f9ac2f33 /]# cat test.txt\n11\nCtrl+P+Q     # 容器不停止退出\n[root@docker ~]# docker cp 401:test.txt /root/\nPreparing to copy...\nSuccessfully copied 2.048kB to /root/\n[root@docker ~]# cat test.txt\n11\n\n```\n\n### 停止容器，将容器打包成新镜像\n\n```\n[root@docker ~]# docker commit [可选参数] 容器id REPOSITORY:TAG\n[可选参数]：\n-a :提交的镜像作者；\n-c :使用Dockerfile指令来创建镜像；\n-m :提交时的说明文字；\n-p :在commit时，将容器暂停。\n\n\n[root@localhost ~]# docker commit -a qianyios -m \"创建了test.txt\" 401 test/centos:v1\nsha256:29ffb8423a78853c5a49918c99e8d513239f9c3365cca06e1fc0027f589b7f59\n[root@localhost ~]# docker images\nREPOSITORY    TAG       IMAGE ID       CREATED         SIZE\ntest/centos   v1        29ffb8423a78   3 seconds ago   233MB\ncentos        latest    5d0da3dc9764   18 months ago   231MB\n\n```\n\n## Docker数据卷\n\n- 数据卷用途：使容器内部的文件跟容器外面的文件同步\n- 数据卷的特点:\n  1. 数据卷可在容器之间共享或重用数据\n  2. 卷中的更改可以直接生效\n  3. 数据卷中的更改不会包含在镜像的更新中\n  4. 数据卷的生命周期一直持续到没有容器使用它为止\n\n### 数据卷基本命令\n\n```\ndocker volume ls\t\t# 查看所有挂载的数据卷\ndocker volume inspect 卷名\t# 查看数据卷所在的路径\n```\n\n### 指定路径挂载\n\n```\ndocker run -v 主机目录:容器内目录\n```\n\n### 卷名挂载\n\n```\ndocker run -v 卷名(不是目录了):容器内 目录\n```\n\n### 匿名挂载\n\n```\ndocker run -v 容器内目录\n```\n\n### 数据卷权限\n\n```\ndocker run -v 主机目录:容器内目录:ro\t\t# ro readonly 只读\ndocker run -v 主机目录:容器内目录:rw\t\t# rw readwrite 可读可写\n# ro只能在主机上面来操作目录，容器无法操作\n```\n\n### 数据卷容器\n\n```\n--volumes-from 要同步文件的容器\t\t\t# 实现多个容器的数据同步与共享\n```\n\n- 例子：三个MySQL同步数据\n\n1、数据库1使用的命令\n\n```\ndocker run -d -p 主机端口:3306 /\n-v /etc/mysql/conf.d -v /var/1ib/mysql /\n-e MYSQL_ROOT_PASSWORD=数据库密码 --name mysql01 mysql\n```\n\n2、数据库2使用的命令\n\n```\ndocker run -d -p 主机端口:3306 /\n--volumes-from mysql01 /\n-e MYSQL_ROOT_PASSWORD=数据库密码 --name mysql02 mysql\nCopy\n```\n\n3、数据库3使用的命令\n\n```\ndocker run -d -p 主机端口:3306 /\n--volumes-from mysql01 /\n-e MYSQL_ROOT_PASSWORD=数据库密码 --name mysql03 mysql\n```\n\n## DockerFile\n\nDockerFile是用来构建Docker镜像的构建文件。\n\n### <span style=\"color:red\">!</span>注意事项\n\n- 1、每个保留关键字（指令）都是必须是大写字母\n- 2、执行从上到下顺序执行\n- 3、#表示注释\n- 4、每一个指令都会创建提交一个新的镜像层，并提交\n\n<img src=\"../img/Docker node/2009e0e056c3fe3dbff4bae26643fd5eb7e965c6.png\" alt=\"image-20230325152651663\" style=\"zoom: 50%;\" />\n\n### DockerFile命令\n\n```\nFROM          # 基础镜镜像,—切从这里开始构建\nMAINTAINER    # 镜像的作者,姓名<邮箱>\nRUN           # 镜像构建的时候需要运行的命令\nADD           # 添加内容，添加压缩包会自动解压\nWORKDIR\t\t # 镜像的工作目录\nVOLUME        # 挂载的目录\nEXPOSE        # 保留端口配置\nCMD\t\t\t# 指定这个容器启动的时候要运行的命令,只有最后一个会生效，可被替代\nENTRYPOINT    # 指定这个容器启动的时候要运行的命令,可以追加命令\nONBUILD\t\t # 当构建一个被继承DockerFile这个时候就会运行ONBUILD 的指令。触发指令。\nCOPY          # 类似ADD ，将我们文件拷贝到镜像中\nENV           # 构建的时候设置环境变量!\n```\n\n### 用DockerFile文件创建镜像\n\n```\ndocker build -f DockerFile文件名 -t 镜像名:版本号 .\n# -f指定Dockfile文件，若Dockerfile文件名就是Dockerfile，则不用-f再指定。系统则自动判定此文件是Dockerfile文件。\n# 最后一个是 . 一定加上\n```\n\n例子：\n\n```\n[root@docker ~]# mkdir centos\n[root@docker ~]# cd centos/\n[root@docker centos]# touch DockerFile\n[root@docker centos]# vi DockerFile\n#基础镜像信息\nFROM centos:latest\n#维护者信息\nMAINTAINER qianyios xiaoohu2002@163.com\n#镜像操作指令\nRUN sed -i 's/mirrorlist/#mirrorlist/g' /etc/yum.repos.d/CentOS-*\nRUN sed -i 's|#baseurl=http://mirror.centos.org|baseurl=http://vault.centos.org|g' /etc/yum.repos.d/CentOS-*\nRUN yum install -y wget\nRUN wget -O /etc/yum.repos.d/CentOS-Base.repo https://mirrors.aliyun.com/repo/Centos-vault-8.5.2111.repo\nRUN yum clean all && yum makecache\nRUN mkdir /test \nRUN echo 'test' > /test/test.txt\n\n[root@docker centos]# docker build -f /root/centos/DockerFile -t centos-test:v1 .\n[root@docker centos]# docker images\nREPOSITORY    TAG       IMAGE ID       CREATED         SIZE\ncentos-test   v1        b1f4c91e59ee   2 minutes ago   328MB\n#此时已经有一个镜像了\n```\n\n用这个镜像创建容器，且将容器中的/test挂载到主机目录下的/opt/test\n\nb1f是镜像id前三个字符\n\n```\ndocker run -it -v /opt/test:/test --name test -p 80:80 b1f /bin/bash\nexit\n退出exit之后查看/opt/test是否有test.txt文件\n[root@docker ~]# cat /opt/test/test.txt\ntest\n成功！！！\n```\n\n## 配置镜像加速器\n\n```\n# 设置 Docker 镜像加速器\ncat > /etc/docker/daemon.json << EOF\n{\n  \"registry-mirrors\": [\n    \"http://hub-mirror.c.163.com\",\n    \"https://docker.mirrors.ustc.edu.cn/\"\n  ],\n  \"insecure-registries\": [],\n  \"debug\": false,\n  \"experimental\": false,\n  \"features\": {\n    \"buildkit\": true\n  }\n}\nEOF\n\nsudo systemctl daemon-reload\nsudo systemctl restart docker\n```\n\n## Docker 网络\n\ndocker网络主要是解决容器联网问题，也是我们使用容器中最重要的一个环节，如果容器没有网络则无法向网络中提供服务。\n\n### 网络管理命令：docker network\n\n```\n[root@docker ~]# docker network --help\nUsage:\tdocker network COMMAND\nManage networks\nCommands:\n  connect        连接容器到网络\n  create          创建网络\n  disconnect    断开容器与网络的连接\n  inspect         显示一个或多个网络的详细信息\n  ls                 列表网络\n  prune           删除所有未使用的网络\n  rm               删除一个或多个网络\n```\n\n### docker网络类型\n\n创建容器的时候可以通过—network命令来指定容器的网络，网络类型有以下四种\n\n- bridge\n- host\n- none\n- 容器网络或联盟网络\n\n#### bridge\n\n桥接网络是指容器通过桥接的方式将**容器网卡**桥接到**宿主机的docker0网桥**，然后在通过宿主机防火墙的NAT表实现与外网的联系。\n\n#### 宿主机docker0网桥\n\n```\n[root@docker ~]# ifconfig \n#docker0网桥\ndocker0: flags=4163<UP,BROADCAST,RUNNING,MULTICAST>  mtu 1500\n        inet 172.17.0.1  netmask 255.255.0.0  broadcast 172.17.255.255\n        inet6 fe80::42:c7ff:fe37:8e8  prefixlen 64  scopeid 0x20<link>\n        ether 02:42:c7:37:08:e8  txqueuelen 0  (Ethernet)\n        RX packets 6618  bytes 277975 (271.4 KiB)\n        RX errors 0  dropped 0  overruns 0  frame 0\n        TX packets 8152  bytes 24675021 (23.5 MiB)\n        TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0\n\n.....省略了本机的网卡信息\n#容器网卡，每创建一个桥接网络的容器就会生成一个对应的网卡\nvethf75a942: flags=4163<UP,BROADCAST,RUNNING,MULTICAST>  mtu 1500\n        inet6 fe80::9085:f5ff:fe34:77b5  prefixlen 64  scopeid 0x20<link>\n        ether 92:85:f5:34:77:b5  txqueuelen 0  (Ethernet)\n        RX packets 2850  bytes 158484 (154.7 KiB)\n        RX errors 0  dropped 0  overruns 0  frame 0\n        TX packets 3397  bytes 11613136 (11.0 MiB)\n        TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0\n        \n        \n        \n如果想看更清楚一下  可以使用  ip  add  show命令\n[root@docker ~]# ip add show\n\n4: docker0: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc noqueue state UP group default \n    link/ether 02:42:c7:37:08:e8 brd ff:ff:ff:ff:ff:ff\n    inet 172.17.0.1/16 brd 172.17.255.255 scope global docker0\n       valid_lft forever preferred_lft forever\n    inet6 fe80::42:c7ff:fe37:8e8/64 scope link \n       valid_lft forever preferred_lft forever\n\n容器网卡\n14: vethf75a942@if13: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc noqueue master docker0 state UP group default \n    link/ether 92:85:f5:34:77:b5 brd ff:ff:ff:ff:ff:ff link-netnsid 1\n    inet6 fe80::9085:f5ff:fe34:77b5/64 scope link \n       valid_lft forever preferred_lft forever\n\n\n注意：\n这里的vethf75a942@if13指的就是容器网卡，V代表虚拟网卡的意思，eth 以太网卡，f75a942网卡编号，if13指的是宿主机网桥(docekr0)的一个端口，对应容器的网卡编号加一。\n所以容器内的网卡编号应该是 eth0@if14\n\n通过在容器中执行命令  ip add show 也可以看到\n[root@docker ~]# docker exec a5f ip add show\n1: lo: <LOOPBACK,UP,LOWER_UP> mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1000\n    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00\n    inet 127.0.0.1/8 scope host lo\n       valid_lft forever preferred_lft forever\n13: eth0@if14: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc noqueue state UP group default \n    link/ether 02:42:ac:11:00:03 brd ff:ff:ff:ff:ff:ff link-netnsid 0\n    inet 172.17.0.3/16 brd 172.17.255.255 scope global eth0\n       valid_lft forever preferred_lft forever\n```\n\n#### 防火墙的NAT表内容\n\n```\n[root@docker ~]# iptables -t nat -L\nChain PREROUTING (policy ACCEPT)\ntarget     prot opt source               destination         \nDOCKER     all  --  anywhere             anywhere             ADDRTYPE match dst-type LOCAL\n\nChain INPUT (policy ACCEPT)\ntarget     prot opt source               destination         \n\nChain OUTPUT (policy ACCEPT)\ntarget     prot opt source               destination         \nDOCKER     all  --  anywhere            !loopback/8           ADDRTYPE match dst-type LOCAL\n\nChain POSTROUTING (policy ACCEPT)\ntarget     prot opt source               destination         \nMASQUERADE  all  --  172.17.0.0/16        anywhere            \n\nChain DOCKER (2 references)\ntarget     prot opt source               destination         \nRETURN     all  --  anywhere             anywhere        \n```\n\n#### docker0 与容器网卡桥接\n\n```\n通过brctl show命令可以看到容器网卡和docker0网卡的桥接信息\n[root@docker ~]# brctl show\nbridge name\tbridge id\t\tSTP enabled\tinterfaces\ndocker0\t\t8000.0242c73708e8\tno\t\tvethf75a942\n```\n\n**创建一个网络为bridge类型的容器，不指定默认也是这个类型**\n\n```\n[root@docker ~]# docker run -d --network bridge --name centos1 baishuming2020/centos_nginx\n```\n\n### host\n\n**容器和真机共用网卡及对应的端口，缺点就是同一个端口只能宿主机或者某个容器使用，其他容器不能用。**\n\n```\n创建一个网络类型host的容器\n[root@docker ~]# docker run -d --network host --name centos2 baishuming2020/centos_nginx\n```\n\n### none\n\n**容器仅有lo网卡，是一个不能联网的本地容器**\n\n```\n创建一个网络类型为lo的容器\n[root@docker ~]# docker run -d --network none --name centos3 baishuming2020/centos_nginx\n```\n\n### 实现网桥网络\n\n目的：不同的服务容器组应用不同的网桥，避免同一网络内容器太多，保持容器网络独立性。\n\n关于新网桥联网问题：创建网桥后，宿主机会自动帮你做NAT，所以不用担心联网问题\n\n#### 查看网络-ls\n\n```\n[root@docker ~]# docker network ls\nNETWORK ID          NAME                DRIVER              SCOPE\n80982d2613cd        bridge              bridge              local\n40c179ab420a        docker1             bridge              local\n04aadb7475c0        docker100           bridge              local\nce79e9d7525a        host                host                local\n8f0358469e57        none                null                local\n\nNETWORK ID     网桥ID   \nNAME          \t 名称\nDRIVER        \t 网络类型  \nSCOPE\t   \t   作用范围\n```\n\n#### 创建网桥-create\n\n```\n[root@docker ~]# docker network create -d bridge --subnet 192.168.148.0/24 --gateway 192.168.148.2 a1\n6a410e27b66ea587142d967f7dff6f36c04ced3c27116a79831412f3743aba56\n\n[root@docker ~]# docker network ls\nNETWORK ID          NAME                DRIVER              SCOPE\n6ee1e928b710        bridge              bridge              local\nce79e9d7525a        host                host                local\n6a410e27b66e        mydocker0           bridge              local\n8f0358469e57        none                null                local\n\n\n修改docker网桥名字\n1、修改名字\n[root@docker ~]# docker network rename old_name new_name\n2、重启docker服务\n[root@docker ~]# systemctl restart docker\n```\n\n#### 删除未使用的网桥-prune\n\n```\n[root@docker ~]# docker network prune \nWARNING! This will remove all networks not used by at least one container.\nAre you sure you want to continue? [y/N] y\nDeleted Networks:\ndocker1\n```\n\n#### 删除某个网桥-rm\n\n```\n[root@docker ~]# docker network rm docker100\ndocker100\n\n注意：\n不能被活动容器占用\n```\n\n#### 容器连接到网桥\n\n前提是该容器是桥接网络\n\n```\ndocker network connect 网卡 容器\n[root@docker ~]# docker network connect docker1 centos1\n[root@docker ~]# docker exec centos1 ifconfig\neth0: flags=4163<UP,BROADCAST,RUNNING,MULTICAST>  mtu 1500\n        inet 172.17.0.2  netmask 255.255.0.0  broadcast 172.17.255.255\n        ether 02:42:ac:11:00:02  txqueuelen 0  (Ethernet)\n        RX packets 8  bytes 656 (656.0 B)\n        RX errors 0  dropped 0  overruns 0  frame 0\n        TX packets 0  bytes 0 (0.0 B)\n        TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0\n发现centos1容器多了一块网卡，使用的正是docker1的网段\neth1: flags=4163<UP,BROADCAST,RUNNING,MULTICAST>  mtu 1500\n        inet 192.168.1.2  netmask 255.255.255.0  broadcast 192.168.1.255\n        ether 02:42:c0:a8:01:02  txqueuelen 0  (Ethernet)\n        RX packets 16  bytes 1312 (1.2 KiB)\n        RX errors 0  dropped 0  overruns 0  frame 0\n        TX packets 0  bytes 0 (0.0 B)\n        TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0\n\nlo: flags=73<UP,LOOPBACK,RUNNING>  mtu 65536\n        inet 127.0.0.1  netmask 255.0.0.0\n        loop  txqueuelen 1000  (Local Loopback)\n        RX packets 0  bytes 0 (0.0 B)\n        RX errors 0  dropped 0  overruns 0  frame 0\n        TX packets 0  bytes 0 (0.0 B)\n        TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0\n```\n\n#### 容器断开网桥\n\n```\n将centos1容器的网络从docker1网桥断开\n[root@docker ~]# docker network disconnect docker1 centos1\n```\n\n### 常见故障\n\n#### FAQ1：使用改名后的新网桥的容器可能无法解析域名\n\n原因：没有配置新网桥的DNS\n\n解决方法：为容器手动配置一个DNS地址即可\n\n#### FAQ2：Networking will not work\n\n```\n[root@docker ~]# docker run -d --network docker100 --name centos4 baishuming2020/centos_nginx\nWARNING: IPv4 forwarding is disabled. Networking will not work.\n67f2c276123c993cd66b9d7a99ba22402331a13f9ea8817e57324a934896b805\n\n解决方案\n1、打开转发\n[root@docker ~]# echo \"net.ipv4.ip_forward=1\" >>  /usr/lib/sysctl.d/00-system.conf\n\n2、重启网络\n[root@docker ~]# systemctl restart network\n```\n\n### 不同主机间的容器通信\n\n#### macvlan\n\n在 Docker 中，macvlan 是众多 Docker 网络模型中的一种，并且是一种跨主机的网络模型，作为一种驱动启用，Docker macvlan 只支持 bridge 模式\n\n```\n#macvlan 需要一块独立的网卡来进行使用，所以我们需要新添加一块网卡\n\ndocker network create -d macvlan --subnet=172.16.10.0/24 --gateway=172.16.10.1  -o parent=ens224  mtacvlan-1\n\n-o parent=网卡名称  指定用来给 macvlan 网络使用的物理网卡\n\n注意，要在所有需要运行 macvlan 的主机上执行这条命令，但是要记得更改网关的地址，避免造成IP冲突\n\ndocker run -itd --network macvlan-1 centos /bin/bash\n```\n\n#### overlay\n\n在 Docker 中，overlay 是众多 Docker 网络模型中的一种，并且是一种跨主机的全局网络模型，有一个数据库专门的来存储网络分配信息，避免 IP 冲突，同时内部还有一个小型的 DNS 我们可以直接通过主机名进行访问\n\n```\nconsul 服务端：\ndocker run -itd -h consul --name consul --restart=always -p 8500:8500 progrium/consul -server -bootstrap\n\n-h \t\t\t\t主机名\n–name \t\t\t容器名\n–restart=always 重启策略\nprogrium/consul 镜像名称\n-server \t\t以服务节点启动\n-bootstrap\t\t预期的启动节点数：自举\n\n在浏览器内输入 IP地址+端口号 可以看到 web 页面\n\n在所有主机上编辑 daemon.json 文件：\n{\n\"hosts\": [\"tcp://0.0.0.0:2375\",\"unix:///var/run/docker.sock\"]， 监听相关端口\n\"cluster-store\":\"consul://192.168.1.150:8500\",\t\t   集群的主机地址\n\"cluster-advertise\":\"192.168.1.150:2375”\t\t宣告自己的地址 \n}\n\n重启 docker 服务\n\n创建 overlay 网络（全局网络）：一台主机上创建自动同步\n\n\tdocker network create -d overlay overlay-1\n\n启动容器测试：\n\n\tdocker run -it --name docker-1 --network=overlay-1 centos /bin/bash\n\t\n\tdocker run -it --name docker-2 --network=overlay-1 centos /bin/bash\n\t\n验证：ping docker-1\n```\n\n### 常见故障\n\n如发现各容器内分配的ip之间相互ping不通\n\n```\n原因：可能由于防火墙问题引起的,默认forward链是drop状态，需要打开才可以\n\n\n解决方案:\n执行下面操作，保证INPUT  FORWARD链都是ACCEPT状态\n清除其他规则\n[root@docker_node1 ~]# iptables -P INPUT ACCEPT\n[root@docker_node1 ~]# iptables -P FORWARD ACCEPT\n[root@docker_node1 ~]# iptables -F\n[root@docker_node1 ~]# iptables -L -n\n\n\n[root@docker_node2 ~]# iptables -P INPUT ACCEPT\n[root@docker_node2 ~]# iptables -P FORWARD ACCEPT\n[root@docker_node2 ~]# iptables -F\n[root@docker_node2 ~]# iptables -L -n\n```\n\n## Docker私有仓库\n\n在Docker中，当我们执行 docker pull xxx 的时候 ，它实际上是从 hub.docker.com 这个地址去查找，这就是 Docker 公司为我们提供的公共仓库。在工作中，我们不可能把企业项目 push 到公有仓库进行管理。所以为了更好的管理镜像，Docker 不仅提供了一个中央仓库，同时也允许我们搭建本地私有仓库。\n\ndocker容器镜像仓库分类：\n\n- 公网仓库：docker hub\n- 私网仓库: registry、harbor\n\n### 部署步骤\n\n拉取registry镜像\n\n```\ndocker pull registry \n```\n\n创建registry仓库容器\n\n```\n1、创建持久化存储，将容器镜像存储目录/var/lib/registry\n挂载到本地/opt/qyck下：\n\nmkdir /opt/qyck\n\n2、创建 registry 容器：\n\ndocker run -itd -p 5000:5000 \\\n-v /opt/qyck:/var/lib/registry  \\\n--restart=always registry:latest\n\n3、查看容器是否运行\n[root@qyck ~]# docker ps\nCONTAINER ID   IMAGE             COMMAND                  CREATED          STATUS         PORTS                                       NAMES\nd1ea79cc023f   registry:latest   \"/entrypoint.sh /etc…\"   10 seconds ago   Up 9 seconds   0.0.0.0:5000->5000/tcp, :::5000->5000/tcp   trusting_gates\n\n```\n\n测试容器应用\n\n```\n[root@zutuanxue_manage01 ~]# curl 192.168.48.128:5000/v2/_catalog\n{\"repositories\":[]}\n\n显示仓库中没有任何镜像\n```\n\n### 上传镜像\n\n测试：拉取nginx镜像\n\n```\ndocker pull nginx\n[root@qyck ~]# docker images\nREPOSITORY   TAG       IMAGE ID       CREATED       SIZE\nregistry     latest    65f3b3441f04   9 days ago    24MB\nnginx        latest    448a08f1d2f9   2 weeks ago   142MB\n\n```\n\n设置docker仓库为registry本地仓库\n\n```\n#1、修改docker进程启动文件，修改其启动方式，目的是为了让通过docker配置文件启动\n[root@qyck ~]# sed -i.bak '/^ExecStart=/c\\ExecStart=\\/usr\\/bin\\/dockerd' /usr/lib/systemd/system/docker.service\n\n#2、设置docker 守护进程的配置文件 /etc/docker/daemon.json,默认没有该文件\n[root@qyck ~]# cat /etc/docker/daemon.json \n{\n \"insecure-registries\": [\"http://192.168.48.128:5000\"]\n}\n\ninsecure-registries 指定非安全的仓库地址，多个用逗号隔开\n\n#3、重启docker生效配置文件\nsystemctl daemon-reload\nsystemctl restart docker\n```\n\n将镜像打tag\n\n```\n[root@qyck ~]# docker tag nginx:latest 192.168.48.128:5000/nginx:v1\n[root@qyck ~]# docker images\nREPOSITORY                  TAG       IMAGE ID       CREATED       SIZE\n192.168.48.128:5000/nginx   v1        448a08f1d2f9   2 weeks ago   142MB\n```\n\n推送镜像到仓库\n\n```\n[root@qyck ~]# docker push 192.168.48.128:5000/nginx:v1\nThe push refers to repository [192.168.48.128:5000/nginx]\n1040838fe30e: Pushed\n93ee76f39c97: Pushed\n5684be535bf1: Pushed\n6bc8ae8fb3cf: Pushed\na29cc9587af6: Pushed\n8553b91047da: Pushed\nv1: digest: sha256:3f01b0094e21f7d55b9eb7179d01c49fdf9c3e1e3419d315b81a9e0bae1b6a90 size: 1570\n\n\n#2、查看上传\n[root@qyck ~]# curl http://192.168.48.128:5000/v2/_catalog\n{\"repositories\":[\"nginx\"]}\n\n#查看存储文件夹\n[root@qyck ~]# ls /opt/qyck/docker/registry/v2/repositories/\nnginx\n\n```\n\n### 拉取镜像\n\n在另外一台机拉取nginx镜像\n\n```\n#1、设置docker启动文件\n[root@zutuanxue_node1 ~]# sed -i.bak '/^ExecStart=/c\\ExecStart=\\/usr\\/bin\\/dockerd' /usr/lib/systemd/system/docker.service\n\n#2、设置docker配置文件\n[root@zutuanxue_node1 ~]# cat  /etc/docker/daemon.json \n{\n \"insecure-registries\": [\"http://192.168.48.128:5000\"]\n}\n\nsystemctl daemon-reload\nsystemctl restart docker\n```\n\n拉取镜像\n\n```\n[root@qyck ~]# docker pull 192.168.48.128:5000/nginx:v1\nv1: Pulling from nginx\n9e3ea8720c6d: Pull complete\nbf36b6466679: Pull complete\n15a97cf85bb8: Pull complete\n9c2d6be5a61d: Pull complete\n6b7e4a5c7c7a: Pull complete\n8db4caa19df8: Pull complete\nDigest: sha256:3f01b0094e21f7d55b9eb7179d01c49fdf9c3e1e3419d315b81a9e0bae1b6a90\nStatus: Downloaded newer image for 192.168.48.128:5000/nginx:v1\n192.168.48.128:5000/nginx:v1\n[root@qyck ~]# docker images\nREPOSITORY                  TAG       IMAGE ID       CREATED       SIZE\nregistry                    latest    65f3b3441f04   9 days ago    24MB\n192.168.48.128:5000/nginx   v1        448a08f1d2f9   2 weeks ago   142MB\n\n\n```\n\n\n\n## Docker学习总结\n\n![1](../img/Docker node/f8242ed25c3cc4a0f16a604d1d53b5f885684b49.png)\n\n## docker run 参数解析\n\n```\n-d: 后台运行容器，并返回容器ID；\n\n-i: 以交互模式运行容器，通常与 -t 同时使用；\n\n-P: 随机端口映射，容器内部端口随机映射到主机的端口\n\n-p: 指定端口映射，格式为：主机(宿主)端口:容器端口\n\n-t: 为容器重新分配一个伪输入终端，通常与 -i 同时使用；\n\n--name=\"nginx-lb\": 为容器指定一个名称；\n\n--dns 8.8.8.8: 指定容器使用的DNS服务器，默认和宿主一致；\n\n--dns-search example.com: 指定容器DNS搜索域名，默认和宿主一致；\n\n-h \"mars\": 指定容器的hostname；\n\n-e username=\"ritchie\": 设置环境变量；\n\n--env-file=[]: 从指定文件读入环境变量；\n\n--cpuset=\"0-2\" or --cpuset=\"0,1,2\": 绑定容器到指定CPU运行；\n\n-m :设置容器使用内存最大值；\n\n--net=\"bridge\": 指定容器的网络连接类型，支持 bridge/host/none/container: 四种类型；\n\n--link=[]: 添加链接到另一个容器；\n\n--expose=[]: 开放一个端口或一组端口；\n\n--volume , -v: 绑定一个卷\n```\n\n\n\n此笔记参考 [开摆工作室](https://blog.kbai.cc/)/[Docker基础](https://blog.kbai.cc/2022/04/25/Docker%20%E5%9F%BA%E7%A1%80/#%F0%9F%9A%80Docker%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80%E6%80%BB%E7%BB%93)精心整理\n\n<div class=\"tbsm\" style=\"margin-top:54px;\">\n<div class=\"tbsm-top\"><span><svg t=\"1674654360507\" class=\"icon\" viewBox=\"0 0 1024 1024\" version=\"1.1\" xmlns=\"http://www.w3.org/2000/svg\" p-id=\"987\" data-spm-anchor-id=\"a313x.7781069.0.i0\" width=\"35\" height=\"35\"><path d=\"M410.49 97.74H155.08a56.74 56.74 0 0 0-56.84 56.73V410a56.84 56.84 0 0 0 56.84 56.84h255.41A56.83 56.83 0 0 0 467.32 410V154.58a56.83 56.83 0 0 0-56.83-56.84zM410.49 558.74H155.08a56.74 56.74 0 0 0-56.84 56.73V871a56.84 56.84 0 0 0 56.84 56.84h255.41A56.83 56.83 0 0 0 467.32 871V615.58a56.83 56.83 0 0 0-56.83-56.84zM871.49 558.74H616.08a56.74 56.74 0 0 0-56.84 56.73V871a56.84 56.84 0 0 0 56.84 56.84h255.41A56.83 56.83 0 0 0 928.32 871V615.58a56.83 56.83 0 0 0-56.83-56.84z\" fill=\"#66EEFF\" p-id=\"988\"></path><path d=\"M410.49 558.74h-4.14A475 475 0 0 0 299.52 859.6a481.16 481.16 0 0 0 4.84 68.22h106.13A56.83 56.83 0 0 0 467.32 871V615.58a56.83 56.83 0 0 0-56.83-56.84zM871.49 558.74H616.08a56.74 56.74 0 0 0-56.84 56.73V871a56.84 56.84 0 0 0 56.84 56.84h255.41A56.83 56.83 0 0 0 928.32 871V615.58a56.83 56.83 0 0 0-56.83-56.84z\" fill=\"#C2F8FF\" p-id=\"989\"></path></svg></span><span style=\"font-size:30px;\"> 特别声明</span></div>\n<div class=\"tbsm-wz\">千屹博客旗下的所有文章，是通过本人课堂学习和课外自学所精心整理的知识巨著<br/>难免会有出错的地方<br/>如果细心的你发现了小失误，可以在下方评论区告诉我，或者私信我！<br />非常感谢大家的热烈支持！</div>\n</div>","tags":["Docker"],"categories":["笔记"]},{"title":"Hadoop部署","url":"/posts/32436/","content":"\n<meta name=\"referrer\" content=\"no-referrer\"/>\n\n# Hadoop部署\n\n本笔记分伪分布和分布式两大块，但建议从头开始观看\n\n文章所需资源可[点击这里](https://pan.quark.cn/s/a2886f170a7f)下载\n\n## 伪分布\n\n单节点 masteryjx48 （Centos 7.9）\n\n| 名称        | ip1（NAT）    | 内存 | 硬盘 |\n| ----------- | ------------- | ---- | ---- |\n| masteryjx48 | 192.168.48.11 | 5G   | 100G |\n\n### 基本配置\n\n本地yum配置，自行挂载本地Centos7.9镜像\n\n```\nmkdir repo.bak\nmv /etc/yum.repos.d/* repo.bak/\nmount /dev/cdrom /mnt\ncat >>/etc/yum.repos.d/local.repo<<EOF\n[local]\nname=local\nbaseurl=file:///mnt\ngpgcheck=0\nenabled=1\nEOF\nyum clean all && yum makecache\nsystemctl disable firewalld --now\nsed -i 's/SELINUX=enforcing/SELINUX=disabled/g' /etc/sysconfig/selinux\n```\n\n### 更改hosts\n\n```\necho \"192.168.48.11 masteryjx48\" >> /etc/hosts\n```\n\n### 配置主机名\n\n```\nhostnamectl set-hostname masteryjx48 && bash\n```\n\n### 配置ssh免密登入\n\n```\nssh-keygen -t rsa\ncat ~/.ssh/id_rsa.pub >> ~/.ssh/authorized_keys\nssh-copy-id masteryjx48\nssh masteryjx48\nexit\n```\n\n### 安装JAVA环境\n\n```\nmkdir /usr/lib/jvm\ntar -xf /root/jdk-8u162-linux-x64.tar.gz -C /usr/lib/jvm\necho \"export JAVA_HOME=/usr/lib/jvm/jdk1.8.0_162\" >> /etc/profile\necho \"export PATH=\\$JAVA_HOME/bin:\\$PATH\" >> /etc/profile\nsource /etc/profile\njava -version\n```\n\n### 安装Hadoop\n\n```\ntar -zxf hadoop-3.1.3.tar.gz -C /usr/local\nmv /usr/local/hadoop-3.1.3/ /usr/local/hadoop\necho \"export HADOOP_HOME=/usr/local/hadoop\" >> /etc/profile\necho \"export PATH=\\$HADOOP_HOME/bin/:\\$HADOOP_HOME/sbin/:\\$PATH\" >> /etc/profile\nsource /etc/profile\nhadoop version\n```\n\n打个快照，方便做分布式部署,做分布式的直接跳到2.分布式\n\n### 编写配置文件\n\n#### 编写cort-site.yaml文件\n\n```\n[root@masteryjx48 ~]# cat /usr/local/hadoop/etc/hadoop/core-site.xml\n<configuration>\n    <property>\n        <name>hadoop.tmp.dir</name>\n        <value>file:/usr/local/hadoop/tmp</value>\n        <description>Abase for other temporary directories.</description>\n    </property>\n    <property>\n        <name>fs.defaultFS</name>\n        <value>hdfs://masteryjx48:9000</value>\n    </property>\n</configuration>\n```\n\n#### 编写hdfs-site.xml\n\n```\n[root@masteryjx48 ~]# cat /usr/local/hadoop/etc/hadoop/hdfs-site.xml\n<configuration>\n    <property>\n        <name>dfs.replication</name>\n        <value>1</value>\n    </property>\n    <property>\n        <name>dfs.namenode.name.dir</name>\n        <value>file:/usr/local/hadoop/tmp/dfs/name</value>\n    </property>\n    <property>\n        <name>dfs.datanode.data.dir</name>\n        <value>file:/usr/local/hadoop/tmp/dfs/data</value>\n    </property>\n</configuration>\n```\n\n### 启动hdfs服务\n\n```\nhdfs namenode -format\n```\n\n### 添加环境变量\n\n```\necho \"export HDFS_NAMENODE_USER=root\" >> /etc/profile\necho \"export HDFS_DATANODE_USER=root\" >> /etc/profile\necho \"export HDFS_SECONDARYNAMENODE_USER=root\" >> /etc/profile\necho \"export YARN_RESOURCEMANAGER_USER=root\" >> /etc/profile\necho \"export YARN_NODEMANAGER_USER=root\" >> /etc/profile\nsource /etc/profile\n```\n\n### 修改hadoop配置文件\n\n```\necho \"export JAVA_HOME=/usr/lib/jvm/jdk1.8.0_162\" >> /usr/local/hadoop/etc/hadoop/hadoop-env.sh\n```\n\n### 启动hadoop服务\n\n```\n[root@masteryjx48 ~]# start-all.sh\nStarting namenodes on [masteryjx48]\nLast login: Thu Mar  9 07:12:02 CST 2023 on pts/0\nStarting datanodes\nLast login: Thu Mar  9 07:14:08 CST 2023 on pts/0\nStarting secondary namenodes [masteryjx48]\nLast login: Thu Mar  9 07:14:11 CST 2023 on pts/0\nStarting resourcemanager\nLast login: Thu Mar  9 07:14:15 CST 2023 on pts/0\nStarting nodemanagers\nLast login: Thu Mar  9 07:14:20 CST 2023 on pts/0\n\n```\n\n关闭hadoop服务  stop-dfs.sh \n\n### 启动historyserver服务\n\n```\nmr-jobhistory-daemon.sh start historyserver\n```\n\n### 查看java进程\n\n```\n[root@masteryjx48 ~]# jps\n9280 ResourceManager\n8785 DataNode\n9443 NodeManager\n9014 SecondaryNameNode\n8599 NameNode\n11127 Jps\n11034 JobHistoryServer\n```\n\n### 访问网页ip:9870查看hdfs\n\n![image-20230308231858685](../img/Hadoop/cb7e7cebcd11b82c8393eb37e88631c1087202ed.png)\n\n### 访问网页ip:8088查看hadoop\n\n![image-20230308232003637](../img/Hadoop/afb72b93d2cbcea5b9201e4809dc3b738bcf4a88.png)\n\n## 分布式\n\n❗❗❗❗这里就克隆前面创建好的快照（1.6步骤），修改好ip\n\n| 主机   | ip            | 系统和软件        | 内存 |\n| ------ | ------------- | ----------------- | ---- |\n| master | 192.168.48.11 | Centos7.9、Hadoop | 5G   |\n| slave1 | 192.168.48.12 | Centos7.9、Hadoop | 5G   |\n\n### 环境配置\n\n修改hosts 把之前添加的删掉\n\nmaster\n\n```\nhostnamectl set-hostname master\nbash\n```\n\nslave1\n\n```\nhostnamectl set-hostname slave1\nbash\necho \"192.168.48.11 master\" >> /etc/hosts\necho \"192.168.48.12 slave1\" >> /etc/hosts\nscp /etc/hosts root@master:/etc/hosts\n```\n\n### SSH免密登入设置\n\nmaster\n\n```\nssh-keygen -t rsa\ncat ~/.ssh/id_rsa.pub >> ~/.ssh/authorized_keys\nssh master\nexit\nssh-copy-id -i root@slave1\nssh slave1\nll\nexit\n```\n\nslave1\n\n```\nssh-keygen -t rsa\ncat ~/.ssh/id_rsa.pub >> ~/.ssh/authorized_keys\nssh slave1\nexit\nssh-copy-id -i root@master\nssh master\nll\nexit\n```\n\n### 检查java和hadoop环境\n\n```\nmaster\n[root@master ~]# java -version\njava version \"1.8.0_162\"\nJava(TM) SE Runtime Environment (build 1.8.0_162-b12)\nJava HotSpot(TM) 64-Bit Server VM (build 25.162-b12, mixed mode)\n[root@master ~]# hadoop version\nHadoop 3.1.3\nSource code repository https://gitbox.apache.org/repos/asf/hadoop.git -r ba631c436b806728f8ec2f54ab1e289526c90579\nCompiled by ztang on 2019-09-12T02:47Z\nCompiled with protoc 2.5.0\nFrom source with checksum ec785077c385118ac91aadde5ec9799\nThis command was run using /usr/local/hadoop/share/hadoop/common/hadoop-common-3.1.3.jar\n\nslave1\n\n[root@slave1 ~]# java -version\njava version \"1.8.0_162\"\nJava(TM) SE Runtime Environment (build 1.8.0_162-b12)\nJava HotSpot(TM) 64-Bit Server VM (build 25.162-b12, mixed mode)\n\n[root@slave1 ~]# hadoop version\nHadoop 3.1.3\nSource code repository https://gitbox.apache.org/repos/asf/hadoop.git -r ba631c436b806728f8ec2f54ab1e289526c90579\nCompiled by ztang on 2019-09-12T02:47Z\nCompiled with protoc 2.5.0\nFrom source with checksum ec785077c385118ac91aadde5ec9799\nThis command was run using /usr/local/hadoop/share/hadoop/common/hadoop-common-3.1.3.jar\n```\n\n### 修改配置文件\n\n修改workers配置文件\n\n```\n[root@master hadoop]# cd /usr/local/hadoop/etc/hadoop\n[root@master hadoop]# cat workers\nslave1\n```\n\n修改core-site.xml\n\n```\n[root@master hadoop]# cat core-site.xml\n<configuration>\n        <property>\n                <name>fs.defaultFS</name>\n                <value>hdfs://master:9000</value>\n        </property>\n        <property>\n                <name>hadoop.tmp.dir</name>\n                <value>file:/usr/local/hadoop/tmp</value>\n                <description>Abase for other temporary directories.</description>\n        </property>\n</configuration>\n```\n\n修改hdfs-site.xml\n\n```\n[root@master hadoop]# cat hdfs-site.xml\n<configuration>\n        <property>\n                <name>dfs.namenode.secondary.http-address</name>\n                <value>master:50090</value>\n        </property>\n        <property>\n                <name>dfs.replication</name>\n                <value>1</value>\n        </property>\n        <property>\n                <name>dfs.namenode.name.dir</name>\n                <value>file:/usr/local/hadoop/tmp/dfs/name</value>\n        </property>\n        <property>\n                <name>dfs.datanode.data.dir</name>\n                <value>file:/usr/local/hadoop/tmp/dfs/data</value>\n        </property>\n</configuration>\n```\n\n修改mapred-site.xml配置文件\n\n```\n[root@master hadoop]# cat mapred-site.xml\n<configuration>\n        <property>\n                <name>mapreduce.framework.name</name>\n                <value>yarn</value>\n        </property>\n        <property>\n                <name>mapreduce.jobhistory.address</name>\n                <value>master:10020</value>\n        </property>\n        <property>\n                <name>mapreduce.jobhistory.webapp.address</name>\n                <value>master:19888</value>\n        </property>\n        <property>\n<name>yarn.app.mapreduce.am.env</name>\n<value>HADOOP_MAPRED_HOME=/usr/local/hadoop</value>\n</property>\n<property>\n<name>mapreduce.map.env</name>\n<value>HADOOP_MAPRED_HOME=/usr/local/hadoop</value>\n</property>\n<property>\n<name>mapreduce.reduce.env</name>\n<value>HADOOP_MAPRED_HOME=/usr/local/hadoop</value>\n</property>\n</configuration>\n```\n\n修改yarn-site.xml文件\n\n```\n[root@master hadoop]# cat yarn-site.xml\n<configuration>\n        <property>\n                <name>yarn.resourcemanager.hostname</name>\n                <value>master</value>\n        </property>\n        <property>\n                <name>yarn.nodemanager.aux-services</name>\n                <value>mapreduce_shuffle</value>\n        </property>\n</configuration>\n```\n\n### 将上述配置拷贝到slave1上\n\nmaster\n\n```\ncd /usr/local/hadoop/etc/hadoop/\nscp core-site.xml slave1:/usr/local/hadoop/etc/hadoop/\nscp hdfs-site.xml slave1:/usr/local/hadoop/etc/hadoop/\nscp mapred-site.xml slave1:/usr/local/hadoop/etc/hadoop/\nscp workers slave1:/usr/local/hadoop/etc/hadoop/\nscp yarn-site.xml slave1:/usr/local/hadoop/etc/hadoop/\n```\n\n### 修改环境变量拷贝到slave1\n\nmaster\n\n```\necho \"export HDFS_NAMENODE_USER=root\" >> /etc/profile\necho \"export HDFS_DATANODE_USER=root\" >> /etc/profile\necho \"export HDFS_SECONDARYNAMENODE_USER=root\" >> /etc/profile\necho \"export YARN_RESOURCEMANAGER_USER=root\" >> /etc/profile\necho \"export YARN_NODEMANAGER_USER=root\" >> /etc/profile\nsource /etc/profile\nscp /etc/profile slave1:/etc/profile\nsource /etc/profile\n```\n\n### 修改**hadoop**环境配置文件并将配置文件拷贝到slave1\n\n```\necho \"export JAVA_HOME=/usr/lib/jvm/jdk1.8.0_162\" >> /usr/local/hadoop/etc/hadoop/hadoop-env.sh\n\nscp /usr/local/hadoop/etc/hadoop/hadoop-env.sh slave1:/usr/local/hadoop/etc/hadoop/hadoop-env.sh\n```\n\n### 集群配置启动\n\nmaster初始化\n\n```\nhdfs namenode -format\n```\n\n### 启动hadoop\n\n```\nstart-all.sh\n```\n\n### 启动historyserver\n\n```\nmr-jobhistory-daemon.sh start historyserver\n```\n\n### 查看java进程\n\n```\n[root@master hadoop]# jps\n35863 ResourceManager\n2841 JobHistoryServer\n39065 NameNode\n39771 Jps\n35597 SecondaryNameNode\n```\n\n```\n[root@slave1 ~]# jps\n5587 NodeManager\n5492 DataNode\n6215 Jps\n```\n\n\n\n![image-20230309000335285](../img/Hadoop/a4c2ec34465b36c3404a54688306cca6070cba87.png)\n\n![image-20230309002207394](../img/Hadoop/a8202fe3fd3b0a107d68473e2086601457d6aac4.png)\n\n<div class=\"tbsm\" style=\"margin-top:54px;\">\n<div class=\"tbsm-top\"><span><svg t=\"1674654360507\" class=\"icon\" viewBox=\"0 0 1024 1024\" version=\"1.1\" xmlns=\"http://www.w3.org/2000/svg\" p-id=\"987\" data-spm-anchor-id=\"a313x.7781069.0.i0\" width=\"35\" height=\"35\"><path d=\"M410.49 97.74H155.08a56.74 56.74 0 0 0-56.84 56.73V410a56.84 56.84 0 0 0 56.84 56.84h255.41A56.83 56.83 0 0 0 467.32 410V154.58a56.83 56.83 0 0 0-56.83-56.84zM410.49 558.74H155.08a56.74 56.74 0 0 0-56.84 56.73V871a56.84 56.84 0 0 0 56.84 56.84h255.41A56.83 56.83 0 0 0 467.32 871V615.58a56.83 56.83 0 0 0-56.83-56.84zM871.49 558.74H616.08a56.74 56.74 0 0 0-56.84 56.73V871a56.84 56.84 0 0 0 56.84 56.84h255.41A56.83 56.83 0 0 0 928.32 871V615.58a56.83 56.83 0 0 0-56.83-56.84z\" fill=\"#66EEFF\" p-id=\"988\"></path><path d=\"M410.49 558.74h-4.14A475 475 0 0 0 299.52 859.6a481.16 481.16 0 0 0 4.84 68.22h106.13A56.83 56.83 0 0 0 467.32 871V615.58a56.83 56.83 0 0 0-56.83-56.84zM871.49 558.74H616.08a56.74 56.74 0 0 0-56.84 56.73V871a56.84 56.84 0 0 0 56.84 56.84h255.41A56.83 56.83 0 0 0 928.32 871V615.58a56.83 56.83 0 0 0-56.83-56.84z\" fill=\"#C2F8FF\" p-id=\"989\"></path></svg></span><span style=\"font-size:30px;\"> 特别声明</span></div>\n<div class=\"tbsm-wz\">千屹博客旗下的所有文章，是通过本人课堂学习和课外自学所精心整理的知识巨著<br/>难免会有出错的地方<br/>如果细心的你发现了小失误，可以在下方评论区告诉我，或者私信我！<br />非常感谢大家的热烈支持！</div>\n</div>","tags":["Centos 7","Hadoop"],"categories":["运维"]},{"title":"Shell","url":"/posts/24229/","content":"\n<meta name=\"referrer\" content=\"no-referrer\"/>\n\n# Shell\n\n## 概述\n\nShell是一个<span style=\"color:red;\">命令行解释器</span>，他接收应用程序/用户命令，然后调用操作系统内核\n\n![image-20230125165047995](../img/Shell/b8682c9a5af9d2af835aa15626c8789178af345a.png)\n\nShell还是一个功能相当强大的编辑语言，易编写，易调试，灵活性强。\n\n## Shell解析器\n\n### Linux提供的Shell解析器有6种：\n\n```\n[root@Shell ~]# cat /etc/Shells\n/bin/sh\n/bin/bash\n/usr/bin/sh\n/usr/bin/bash\n/bin/tcsh\n/bin/csh\n```\n\n### bash和sh的关系是\n\n```\n[root@Shell ~]# ll /bin/ | grep bash\n-rwxr-xr-x. 1 root root     964536 4月   1 2020 bash\nlrwxrwxrwx. 1 root root          4 9月  28 07:56 sh -> bash\n软连接\n```\n\n### Centos默认的解析器是bash\n\n```\n[root@Shell ~]# echo $Shell\n/bin/bash\n```\n\n## Shell脚本入门\n\n### 脚本格式\n\n脚本以<span style=\"color:red;\">#!/bin/bash</span>开头（指向解析器）\n\n### 第一个Shell脚本：helloworld\n\n需求：创建一个Shell脚本，输出helloworld\n\n实例操作：\n\n```\n[root@Shell ~]# mkdir datas          ---创建一个脚本文件夹\n[root@Shell ~]# cd datas/            ---以后所有脚本放在这\n[root@Shell datas]# touch helloworld.sh\n[root@Shell datas]# vi helloworld.sh\n#!/bin/bash\necho \"helloworld  严千屹\"\n~\n[root@Shell datas]# sh helloworld.sh        ---相对路径\nhelloworld  严千屹\n[root@Shell ~]# bash datas/helloworld.sh    ---绝对路径\nhelloworld  严千屹\n#上面都是bash和sh帮你执行脚本，脚本本身不需要执行权限。\n#下面本质是脚本需要自己执行，所以需要执行权限\n[root@Shell datas]# ./helloworld.sh\n-bash: ./helloworld.sh: 权限不够\n[root@shell datas]# chmod 777 helloworld.sh   ---给予权限\n[root@shell datas]# ./helloworld.sh\nhelloworld  严千屹\n```\n\n### 第二个Shell脚本：多命令处理\n\n需求：\n\n在/root/datas/目录下创建一个qianyi.txt,在 qianyi.txt 文件中增加“qianyios”\n\n```\n[root@shell datas]# touch qy.sh\n[root@shell datas]# vi qy.sh\n#!/bin/bash\ncd /root/datas/\ntouch qianyi.txt\necho \"qianyios\" >> qianyi.txt\n[root@shell datas]# bash qy.sh\n#执行完成后会出现qianyi.txt\n[root@shell datas]# ll\n总用量 12\n-rwxrwxrwx 1 root root 43 1月  25 17:06 helloworld.sh\n-rw-r--r-- 1 root root  9 1月  25 17:22 qianyi.txt\n-rw-r--r-- 1 root root 76 1月  25 17:22 qy.sh\n[root@shell datas]# cat qianyi.txt\nqianyios\n```\n\n## Shell中的变量\n\n### 常用的系统变量\n\n​\t$HOME   $PWD   $SHELL  $USER等\n\n### 实例操作\n\n查看系统变量的值\n\n```\n[root@shell datas]# echo $HOME\n/root\n显示家目录\n```\n\n显示当前Shell中所有的变量：set\n\n```\n[root@shell datas]# set\nABRT_DEBUG_LOG=/dev/null\nBASH=/usr/bin/bash\nBASH_ALIASES=()\nBASH_ARGC=()\nBASH_ARGV=()\nBASH_CMDS=()\n......\n```\n\n### 自定义变量\n\n#### 基本语法\n\n1. 定义变量：变量=值\n2. 撤销变量：unset 变量\n3. 声明静态变量：readonly 变量   注意不能unset\n\n#### 变量定义规则\n\n1. 变量名称可以有字母，数字和下划线组成，但是不能以数字开头，<span style=\"color:red;\">环境变量名建议全部大写</span>\n2. <span style=\"color:red;\">等号两侧不能有空格</span>\n3. 在bash中，变量默认类型都是字符串类型，无法直接进行数值运算\n4. 变量的值如果有<span style=\"color:red;\">空格</span>，需要使用双引号或单引号括起来\n\n#### 实例操作\n\n```\n#自定义变量\n[root@shell ~]# QY=qianyi\n[root@shell ~]# echo $QY\nqianyi\n[root@shell ~]# QY=\"qian yi\"\n[root@shell ~]# echo $QY\nqian yi\n\n变量为空和未定义变量是两个不同的概念\n[root@shell ~]# echo $age      ---未定义\n\n[root@shell ~]# age=\"\"\n[root@shell ~]# echo $age      ---已定义\n\n#两个没办法辨认\n[root@shell ~]# set -u        ---调用为声明变量会报错\n[root@shell ~]# echo $add\n-bash: add: unbound variable\n[root@shell ~]# add=123\n[root@shell ~]# echo $add\n123\n#删除变量  不需要加$add\n[root@shell ~]# echo $add\n123\n[root@shell ~]# unset add\n[root@shell ~]# echo $add\n-bash: add: unbound variable\n```\n\n### 环境变量\n\n1. 环境变量设置\n\n```\n[root@shell ~]# export qyage=\"18\"\n#使用export声明的变量即是环境变量\n```\n\n2. 环境变量查询  set可以查看所有变量，env只能查看环境变量\n\n```\n[root@shell ~]# env | grep qyage\nqyage=18\n```\n\n3. 系统默认环境变量\n\n```\n[root@shell ~]# env\nXDG_SESSION_ID=10\nHOSTNAME=shell\nTERM=xterm\nSHELL=/bin/bash\nHISTSIZE=1000\nqyage=18\n```\n\n4. PATH变量：系统查找命令的路径\n\n先查询下PATH环境变量的值：\n\n```\n[root@shell ~]# echo $PATH\n/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/root/bin\n\n```\n\n  PATH 变量的值是用“:”分割的路径，这些路径就是系统查找命令的路径。也就是说当我们输入了一个程序名，如果没有写入路径，系统就会到 PATH 变量定义的路径中去寻找，是否有可以执行的程序。如果找到则执行，否则会报“命令没有发现”的错误。\n\n  那么是不是我们把自己的脚本拷贝到 PATH 变量定义的路径中，我们自己写的脚本也可以不输入路径而直接运行呢?\n\n```\n[root@shell ~]# cp datas/helloworld.sh /usr/bin/\n[root@shell ~]# helloworld.sh\nhelloworld  严千屹\n[root@shell ~]# rm -rf /usr/bin/helloworld.sh\n[root@shell ~]# helloworld.sh\n-bash: /usr/bin/helloworld.sh: 没有那个文件或目录\n```\n\n那么我们是不是可以修改 PATH变量的值，而不是把程序脚本复制到/bin/目录中。当然是可以的,我们通过变量的叠加就可以实现了:\n\n```\n[root@shell ~]# PATH=\"$PATH\":/root/datas\n[root@shell ~]# echo $PATH\n/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/root/bin:/root/datas\n[root@shell ~]# helloworld.sh\nhelloworld  严千屹\n```\n\n### PS1变量：命令提示符设置\n\nPS1是一个很有意思的变量，是用来定义命令行的提示符，可以安装我们自己的需求来定义自己喜欢的提示符。PS1可以支持以下这些选项：\n\n```\n\\d ：#代表日期，格式为weekday month date，例如：\"Mon Aug 1\"   \n\\H ：#完整的主机名称。   \n\\h ：#仅取主机的第一个名字。 \n\\t ：#显示时间为24小时格式，如：HH：MM：SS   \n\\T ：#显示时间为12小时格式   \n\\A ：#显示时间为24小时格式：HH：MM   \n\\u ：#当前用户的账号名称   \n\\v ：#BASH的版本信息   \n\\w ：#完整的工作目录名称。家目录会以 ~代替   \n\\W ：#利用basename取得工作目录名称，所以只会列出最后一个目录 \n\\# ：#下达的第几个命令   \n\\$ ：#提示字符，如果是root时，提示符为：# ，普通用户则为：$  \n```\n\n```\n格式 PS1='[ ]\\$ '     \\$空格'  有个空格  一定要单引号\n```\n\n```\n[root@shell ~]# echo $PS1\n[\\u@\\h \\W]\\$\n[root@shell ~]# PS1='[\\u@\\t \\w]\\$ '\n[root@20:14:51 ~]# cd datas/\n[root@20:14:54 ~/datas]#\n```\n\n### 位置参数变量\n\n| 位置参数变量 | 作用                                                         |\n| ------------ | ------------------------------------------------------------ |\n| $n           | 表示第n个参数，$1则表示第一个参数，$2表示第二个参数……如果有10以上的参数用${10} |\n| $0           | 当前程序的名称，也就是命令本身。                             |\n| $*           | 传递给程序的所有参数组成的字符串（参数）。                   |\n| $@           | 以“参数1”、“参数2”……保存所有的参数。                         |\n| $#           | 代表命令行中所有参数个数                                     |\n| $?           | 上一个代码或者Shell程序在Shell中退出的情况，如果正常退出则返回0，否则返回非0值。 |\n| $$           | 本程序的（进程ID）PID。                                      |\n| $!           | 上一个命令的PID。                                            |\n\n#### 实例操作\n\n```\n[root@shell datas]# vi count.sh\n#!/bin/bash\na=$1\nb=$2\nsum=$(($a+$b))\n#$((  ))双小括号才能进行数字运算，$( )运行命令\necho $sum\necho $0\n[root@shell datas]# chmod 755 count.sh\n[root@shell datas]# ./count.sh 22 33\n55\n./count.sh       #$0输出命令本身\n```\n\n```\n[root@shell datas]# vi para.sh\n#!/bin/bash\necho \"\\$* is $*\"\necho \"\\$@ is $@\"\necho \"\\$# is $#\"\n[root@shell datas]# chmod 777 para.sh\n[root@shell datas]# ./para.sh 11 22 33 44\n$* is 11 22 33 44   #{11 22 33 44}看成一个整体 \n$@ is 11 22 33 44   #{11},{22},{33},{44}\n$# is 4             #个数\n验证过程\n[root@shell datas]# vi para2.sh\n#!/bin/bash\n#for循环，有多少次出现多少次\nfor i in  \"$*\"\n      do\n        echo $i\n      done\necho \"------------------\"\nfor y in  \"$@\"\n        do\n         echo $y\n      done\n[root@shell datas]# ./para2.sh 11 22 33 44\n11 22 33 44             #整体，循环1次\n------------------\n11                      #4个，循环4次\n22\n33\n44\n```\n\n### 预定义变量\n\n| $?   | 最后一次执行的命令的返回状态。如果这个变量的值为 0，证明上一个命令正确执行:如果这个变量的值为非 0(具体是哪个数，由命令自己来决定)，则证明上一个命令执行不正确了。 |\n| ---- | ------------------------------------------------------------ |\n| $$   | 当前进程的进程号(PID)                                        |\n| $!   | 后台运行的最后一个进程的进程号(PID)                          |\n\n```\n[root@shell ~]# ls\nanaconda-ks.cfg  bin  datas  repo.bak\n[root@shell ~]# echo $?\n0\n[root@shell ~]# sjkdhasjkd\n-bash: sjkdhasjkd: 未找到命令\n[root@shell ~]# echo $?\n127\n```\n\n## read键盘接收\n\n### 定义\n\n[root@shell datas]# read --help\n-bash: read: --: 无效选项\nread: 用法:   read [选项] [变量名]\n\nread [-ers]\n\n[-a 数组] \n\n[-d 分隔符] \n\n[-i 缓冲区文字] \n\n[-n 读取字符数] \n\n[-N 读取字符数] \n\n[-p 提示符] \n\n[-t 超时] \n\n[-u 文件描述符] \n\n[名称 ...]名称指的是变量名\n\n```\n[root@shell datas]# vi count2.sh\n#!/bin/bash\nread -t 30 -p \"请输入第一个数字：\" num1\nread -t 30 -p \"请输入第二个数字：\" num2\nsum=$(($num1+$num2))\necho $sum\n[root@shell datas]# chmod 777 count2.sh\n[root@shell datas]# ./count2.sh\n请输入第一个数字：1\n请输入第二个数字：1\n2\n\n\n#########前者需要回车，下面的不需要回车\n[root@shell datas]# vi count2.sh\n#!/bin/bash\nread -n 1 -t 30 -p \"请输入第一个数字：\" num1   #-n 1 限制输入1个字符数\necho -e \"\\n\"\nread -s -t 30 -p \"请输入第二个数字：\" num2     #-s 是隐藏\necho -e \"\\n\"\nsum=$(($num1+$num2))\necho $sum\n[root@shell datas]# ./count2.sh\n请输入第一个数字：1\n\n请输入第二个数字：         #我这里输入的是12\n\n13\n```\n\n## declare声明变量类型\n\n### 定义\n\n既然所有变量的默认类型是字符串型，那么只要我们把变量声明为整数型不就可以运算了吗？\n\n> -:给变量设定类型属性\n>\n> +:取消变量的类型属性\n>\n> -a:将变量声明为数组型\n>\n> -i:将变量声明为整数型(integer)\n>\n> -x:将变量声明为环境变量\n>\n> -r:将变量声明为只读变量，注意，一旦设置为只读变量，既不能修改变量的值，也不能删除变量，甚至不能通过+r取消只读属性\n>\n> -p:显示指定变量的被声明的类型、\n\n### 声明数值进行运算\n\n```\n[root@shell datas]# a=1\n[root@shell datas]# b=2\n[root@shell datas]# c=$a+$b\n[root@shell datas]# echo $c\n1+2\n[root@shell datas]# declare -i c=$a+$b      #声明整数类型才可以进行数值运行\n[root@shell datas]# echo $c\n3\n```\n\n### 数组\n\n```\n[root@shell datas]# declare -a name[0]=\"qy\"  #声明数组\n[root@shell datas]# name[1]=\"qy1\"   #也可以不用declare，就知道你在声明数组\n[root@shell datas]# name[2]=\"qy2\"\n[root@shell datas]# echo ${name[*]}\nqy qy1 qy2\n```\n\n### 环境变量\n\n```\n两个声明变量作用一样\n[root@shell datas]# export test\n[root@shell datas]# declare -x test=\"123\"\n```\n\n### 只读属性\n\n注意，一旦设置为只读变量，既不能修改变量的值，也不能删除变量，甚至不能通过+r取消只读属性\n\n```\n[root@shell datas]# declare -r test        #添加只读属性\n[root@shell datas]# declare -p\n......\ndeclare -rx test=\"123\"\n[root@shell datas]# echo $test\n123\n[root@shell datas]# test=1           #无法改值\n-bash: test: 只读变量\n[root@shell datas]# unset test        #无法删除变量\n-bash: unset: test: 无法反设定: 只读 variable\n[root@shell datas]# declare +r test      #无法删除属性\n-bash: declare: test: 只读变量\n```\n\n不过好在这个变量是命令行声明的，所以重启或重新登入，这个变量就会消失\n\n## 数值运算\n\n### 使用expr或let数值运算工具\n\n```\n[root@shell ~]# aa=11\n[root@shell ~]# bb=22\n[root@shell ~]# dd=$(expr $aa + $bb)\n[root@shell ~]# echo $dd\n33\n#dd的值是aa和bb的和。注意“+”号两侧比有空格\n#如果是let呢\n[root@shell ~]# let e=$aa+$bb\n[root@shell ~]# echo $e\n33\n```\n\n### 使用双小括号 $((运算式子))  或$[运算式子] 的方式运算 （看个人习惯，看你喜欢用哪种）\n\n> 区分单小括号$(  )调用的是系统命令  双小括号是计算数学运算的\n\n```\n[root@shell ~]# aa=11\n[root@shell ~]# bb=22\n[root@shell ~]# ff=$(($aa+$bb))\n[root@shell ~]# echo $ff\n33\n[root@shell ~]# gg=$[$aa+$bb]\n[root@shell ~]# echo $gg\n33\n```\n\n### Shell常用运算符\n\n| 优先级 | 运算符                             | 说明                               |\n| ------ | ---------------------------------- | ---------------------------------- |\n| 13     | -，+                               | 单目负，单目正                     |\n| 12     | !,~                                | 逻辑非，按位取反或补码             |\n| 11     | *,/,%                              | 乘、除、取模                       |\n| 10     | +,-                                | 加、减                             |\n| 9      | <<,>>                              | 按位左移，按位右移                 |\n| 8      | < = ,> = ,< , >                    | 小于或等于、大于或等于、小于、大于 |\n| 7      | ==, !=                             | 等于                               |\n| 6      | &                                  | 按位与                             |\n| 5      | ^                                  | 按位异或                           |\n| 4      | \\|                                 | 按位或                             |\n| 3      | &&                                 | 逻辑与                             |\n| 2      | \\|\\|                               | 逻辑或                             |\n| 1      | =,*=,-=,*=,/=,%=,&=,^=,\\|=,<<=,>>= | 赋值，运算且赋值                   |\n\n### 取模运算\n\n```\n[root@shell ~]# bb=$((14%5))\n[root@shell ~]# echo $bb\n4\n#14不能被5整除，余数是4\n```\n\n### 逻辑与\n\n```\n[root@shell ~]# cc=$((1&&0))\n[root@shell ~]# echo $cc\n0\n逻辑与运算只有想与的两边都是1，与的结果才是1，否则与的结果是0\n```\n\n### 四则运算练习\n\n```\n[root@shell ~]# vi count3.sh\n#!/bin/bash\nvaule=$(($1 $2 $3))\necho $vaule\n[root@shell ~]# ./count3.sh 11 + 11\n22\n[root@shell ~]# ./count3.sh 11 / 11\n1\n```\n\n但是上面会有bug不能用\n\n```\n[root@shell datas]# vi count4.sh\n#!/bin/bash\nread -t 30 -p \"please input num1:\" num1\nread -t 30 -p \"please input num2:\" num2\nread -n 1 -t 30 -p \"please inpute operato[+-*/]:\" oper\necho -e “\\n”\n[ \"$oper\" == \"+\" ] && echo \"$(($num1 + $num2))\" && exit\n[ \"$oper\" == \"-\" ] && echo \"$(($num1 - $num2))\" && exit\n[ \"$oper\" == \"*\" ] && echo \"$(($num1 * $num2))\" && exit\n[ \"$oper\" == \"/\" ] && echo \"$(($num1 / $num2))\" && exit\n\necho \"please input right oper\"\n[空格\"$oper\"空格==空格\"+\"空格]\n```\n\n## 变量的测试与内容置换\n\n| 变量置换方式 | 变量y没有设置                  | 变量y为空值            | 变量y设置值 |\n| ------------ | ------------------------------ | ---------------------- | ----------- |\n| x=${y-新值}  | x= 新值                        | x 为空                 | x=$y        |\n| x=${y:-新值} | x= 新值                        | x= 新值                | x=$y        |\n| x=${y+新值}  | x 为空                         | x= 新值                | x=新值      |\n| x=${y:+新值} | x 为空                         | x 为空                 | x=新值      |\n| x=${y=新值}  | x= 新值                        | x 为空                 | x=$y        |\n| 同上         | y= 新值                        | y 值不变               | y值不变     |\n| x=${y:=新值} | x= 新值                        | X= 新值                | x=$y        |\n| 同上         | y= 新值                        | y= 新值                | y值不变     |\n| x=${y?新值}  | 新值输出到标准错误输出（屏幕） | x 为空                 | x=$y        |\n| x=${y:?新值} | 新值输出到标准错误输出         | 新值输出到标准错误输出 | x=$y        |\n\n假设我们要测b变量，现在b变量我们从来没有设置过\n\n```\n以下可以判断变b不存在\n[root@shell ~]# x=${b-new}\n[root@shell ~]# echo $x\nnew\n以下可以判断是否为空\n[root@shell ~]# b=\"\"\n[root@shell ~]# x=${b-new}\n[root@shell ~]# echo $x\n以下可以判断是否有值\n[root@shell ~]# b=123\n[root@shell ~]# x=${b-new}\n[root@shell ~]# echo $x\n123\n```\n\n## 环境变量配置文件\n\n1、让环境变量生效的命令  source 配置文件  或  . 配置文件\n\n2、环境变量配置文件\n\n登录时生效的环境变量配置文件\n\n在 Linux 系统登录时主要生效的环境变量配置文件有以下五个:\n\n/etc/profile\n\n/etc/profile.d/*.sh\n\n/etc/bashrc\n\n~/.bash_profile\n\n~/.bashrc\n\n写在前三个的配置文件对所有用户生效，写在最后两个对当前用户生效\n\n## 基础正则\n\n基础正则表达式\n\n| 元字符  | 作\t用                                                     |\n| ------- | :----------------------------------------------------------- |\n| *       | 前一个字符匹配 0 次或任意多次。                              |\n| .       | 匹配除了换行符外任意一个字符。                               |\n| ^       | 匹配行首。例如：^hello 会匹配以 hello 开头的行。             |\n| $       | 匹配行尾。例如：hello&会匹配以 hello 结尾的行。              |\n| []      | 匹配中括号中指定的任意一个字符，只匹配一个字符。例如：[aoeiu] 匹配任意一个元音字母，[0-9] 匹配任意一位数字，[a-z][0-9]匹配小写字和一位数字构成的两位字符。 |\n| [^]     | 匹配除中括号的字符以外的任意一个字符。例如：[^0-9] 匹配任意一位非数字字符，[^a-z] 表示任意一位非小写字母。 |\n| \\       | 转义符。用于取消讲特殊符号的含义取消。                       |\n| \\{n\\}   | 表示其前面的字符恰好出现 n 次。例如：[0-9]\\{4\\} 匹配 4 位数字，[1][3-8][0-9]\\{9\\} 匹配手机号码。 |\n| \\{n,\\}  | 表示其前面的字符出现不小于 n 次。例如： [0-9]\\{2,\\} 表示两位及以上的数字。 |\n| \\{n,m\\} | 表示其前面的字符至少出现n 次，最多出现m 次。例如：[a-z]\\{6,8\\}匹配 6 到 8 位的小写字母。 |\n\n### ~/.bashrc 文件中建立这个别名：\n\n实现grep能显示颜色\n\n```\necho \"alias grep=\\'grep --color=auto\\'\" >> /root/.bashrc \n```\n\n建立练习文档\n\n```\n[root@shell datas]# vi test.txt\nMr. Li Ming said:\nhe was the most honest man.\n123despise him.\ngoogle\ngooooogle\nggle\ngogle\nsoooooid\nBut since Mr. shen Chao came, he never saaaid those words. 5555nice!\nbecause,actuaaaally,\nMr. Shen Chao is the most honest man\nLater,Mr. Li ming soid his hot body.\nhello is\nhello was\n```\n\n\n\n练习*号\n\n```\n# a*意思是最少包含0个a或无数个a\n[root@shell datas]# grep \"a*\" test.txt\nMr. Li Ming said:\nhe was the most honest man.\n123despise him.\nBut since Mr. shen Chao came, he never saaaid those words. 5555nice!\nbecause,actuaaaally,\nMr. Shen Chao is the most honest man\nLater,Mr. Li ming soid his hot body.\n\n# aa*意思是最少包含1个a或无数个a\n[root@shell datas]# grep \"aa*\" test.txt\nMr. Li Ming said:\nhe was the most honest man.\nBut since Mr. shen Chao came, he never saaaid those words. 5555nice!\nbecause,actuaaaally,\nMr. Shen Chao is the most honest man\nLater,Mr. Li ming soid his hot body.\n\n# aaa*意思是最少包含2个a或无数个a\n[root@shell datas]# grep \"aaa*\" test.txt\nBut since Mr. shen Chao came, he never saaaid those words. 5555nice!\nbecause,actuaaaally,\n\ngrep \"a\" count4.sh   也行\n\n```\n\n练习 . 号   正则表达式“.”只能匹配一个字符，这个字符可以是任意字符\n\n```\n[root@shell datas]# grep \"s..d\" test.txt\nMr. Li Ming said:\nLater,Mr. Li ming soid his hot body.\n```\n\n[root@shell datas]# grep \"s.*d\" test.txt\nMr. Li Ming **said**:\nBut **since Mr. shen Chao came, he never saaaid those word**s. 5555nice!\nLater,Mr. Li ming **soid his hot bod**y.\n\n\n\n“[]”会匹配中括号中指定任意一个字符，注意只能匹配一个字符。比如[ao]要不会匹配一个 a\n\n字符，要不会匹配一个 o 字符：\n\n```\n[root@shell datas]# grep \"s[ao]id\" test.txt\nMr. Li Ming said:\nLater,Mr. Li ming soid his hot body.\n[root@shell datas]# grep \"[0-9]\" test.txt\n123despise him.\nBut since Mr. shen Chao came, he never saaaid those words. 5555nice!\n```\n\n## 扩展正则\n\n| 扩展元字符 | 作\t用                                                     |\n| ---------- | ------------------------------------------------------------ |\n| +          | 前一个字符匹配 1 次或任意多次。如“go+gle”会匹配“gogle”、“google”或“gooogle”，当然如果“o”有更多个，也能匹配。 |\n| ？         | 前一个字符匹配 0 次或 1 次。如“colou?r”可以匹配“colour”或“color”。 |\n| \\|         | 匹配两个或多个分支选择。如“was\\|his”会匹配既包含“was”的行，也匹配包含“his”的行。 |\n| （）       | 匹配其整体为一个字符，即模式单元。可以理解为由多个单个字符组成的大字符。<br />如“(dog)+”会匹配“dog”、“dogdog”、“dogdogdog”等，因为被（）包含的字符会当成一个整体。但“hello （world\\|earth）”会匹配“hello world”及“hello earth”。 |\n\n## grep 参数列表\n\n1. `-i` : 忽略大小写\n2. `-v` : 查找不包含指定字符串的所有行（取反）\n3. `-r` : 递归查找文件夹下的文件\n4. `-n` : 显示匹配行所在位置（行号）\n5. `-l` : 只显示包含搜索字符串的文件名，而非每个匹配行\n6. `-c` : 统计符合条件的行数\n7. `-e pattern` : 指定要查找的正则表达式模式\n8. `-w` : 匹配整个单词，即只匹配独立的单词而非单词内的字符\n9. `-A num` : 输出匹配行后 N 行内容\n10. `-B num` : 输出匹配行前 N 行内容\n11. `-C[num]` 或者 `--context[=num]`: 输出匹配行前后总共 N 行内容。\n12. `--exclude` : 排除指定文件类型，多个文件类型用 \",\" 隔开\n\n```\n[root@localhost sh]# grep -E \"go*gle\" test.txt\ngoogle\ngooooogle\nggle\ngogle\n[root@localhost sh]# grep -E \"go+gle\" test.txt\ngoogle\ngooooogle\ngogle\n[root@localhost sh]# grep -E \"go?gle\" test.txt\nggle\ngogle\n[root@localhost sh]# grep -E \"go+\" test.txt\ngoogle\ngooooogle\ngogle\n[root@localhost sh]# grep -E \"g(oo)+\" test.txt\ngoogle\ngooooogle\n[root@localhost sh]# grep -E \"g(ooo)+\" test.txt\ngooooogle\n[root@localhost sh]# grep -E \"hello (was|is)\" test.txt\nhello is\nhello was\n\n```\n\n匹配邮箱\n\n```\ngrep -E \"[0-9a-zA-Z_]+@[0-9a-zA-Z_]+(\\.[0-9a-zA-Z_]+){1,3}\" test.txt\n```\n\n## 字符截取和替换命令\n\n```\n[root@localhost ~]# cut [选项] 文件名选项：\n-f 列号：          提取第几列\n-d 分隔符：\t     按照指定分隔符分割列\n-c 字符范围：    不依赖分隔符来区分列，而是通过字符范围（行首为 0）来进行字段提取。“n-”表示从第 n 个字符到行尾；“n-m”从第 n 个字符到第 m个字符；“-m”表示从第 1 个字符到第 m 个字符。\n```\n\n测试文件\n\n```\n[root@localhost ~]# cat student.txt\nID      Name    gender  Mark\n1       Liming  M       86\n2       Sc      M       90\n3       Tg      M       83\n用tab键隔开所有列，不要空格\n```\n\n测试\n\n```\n[root@localhost ~]# cut -f 2 student.txt\nName\nLiming\nSc\nTg\n#提取多列\n[root@localhost ~]# cut -f 2,3 student.txt\nName    gender\nLiming  M\nSc        M\nTg       M\n##cut 可以按照字符进行提取，需要注意“8-”代表的是提取所有行的第八个字符开始到行尾，而 “10-20”代表提取所有行的第十个字符到第二十个字符，而“-8”代表提取所有行从行首到第八个\n字符：\n[root@localhost ~]# cut -c 9- student.txt\ngender Mark\n M 86\n0\n3\n[root@localhost ~]# cut -c -9 student.txt\nID Name g\n1 Liming\n2 Sc M 90\n3 Tg M 83\n\n```\n\n## awk编程\n\n### printf 格式化输出\n\n```\n[root@localhost ~]# printf ‘输出类型输出格式’ 输出内容输出类型：\n%ns：\t输出字符串。n 是数字指代输出几个字符\n%ni：\t输出整数。n 是数字指代输出几个数字\n%m.nf：\t输出浮点数。m 和 n 是数字，指代输出的整数位数和小数位数。如%8.2f代表  共输出 8 位数，其中 2 位是小数，6 位是整数。\n输出格式：\n\\a:\t输出警告声音\n\\b:\t输出退格键，也就是 Backspace 键\n\\f:\t清除屏幕\n\\n:\t换行\n\\r:\t回车，也就是 Enter 键\n\\t:\t水平输出退格键，也就是 Tab 键\n\\v:\t垂直输出退格键，也就是 Tab 键\n```\n\n建立测试文件\n\n```\nvi student.txt\nID       Name    PHP     Linux   MySQL   Average\n1        Liming   82      95      86      87.66\n2        Sc        74      96      87      85.66\n3        Tg        99      83      93      91.66\n```\n\n不指定格式输出\n\n```\n[root@localhost ~]# printf '%s' $(cat student.txt)\nIDNamePHPLinuxMySQLAverage1Liming82958687.662Sc74968785.663Tg99839391.66\n#乱作一锅粥\n```\n\n指定格式输出\n\n```\n[root@localhost ~]# printf '%s\\t %s\\t %s\\t %s\\t %s\\t %s\\t \\n' $(cat student.txt)\nID       Name    PHP     Linux   MySQL   Average\n1        Liming  82      95      86      87.66\n2        Sc      74      96      87      85.66\n3        Tg      99      83      93      91.66\n\n```\n\n### awk条件\n\n```\n[root@localhost ~]# awk '条件 1{动作 1} 条件 2{动作 2}…' 文件名\n```\n\nawk条件（Pattern）\n\n一般使用关系表达式作为条件。这些关系表达式非常多，具体参考表 12-3 所示，例如：\n\nx > 10 判断变量 x 是否大于 10\n\nx == y 判断变量 x 是否等于变量 y\n\nA ~ B\t判断字符串 A 中是否包含能匹配 B 表达式的子字符串\n\nA !~ B 判断字符串 A 中是否不包含能匹配 B 表达式的子字符串\n\n动作（Action）：\n\n格式化输出 流程控制语句\n\n![image-20230421143849290](../img/Shell/205fa6cf17277f79e65555cc1c7a9afe7819b814.png)\n\nawk内置变量\n\n![image-20230421190306772](../img/Shell/2e8746e3feacb88db27cc8f033f27d3b5b52f28a.png)\n\n例子：\n\n```\n[root@localhost ~]# awk '{printf $2 \"\\t\" $6 \"\\n\"}' student.txt\n#输出第二列和第六列\n```\n\n```\n假设我要提取根分区/dev/sda1 第五列的使用率\n[root@localhost ~]# df -h\nFilesystem               Size  Used Avail Use% Mounted on\ndevtmpfs                 475M     0  475M   0% /dev\ntmpfs                    487M     0  487M   0% /dev/shm\ntmpfs                    487M  7.7M  479M   2% /run\ntmpfs                    487M     0  487M   0% /sys/fs/cgroup\n/dev/mapper/centos-root   50G  1.5G   49G   3% /\n/dev/mapper/centos-home   47G   33M   47G   1% /home\n/dev/sda1               1014M  141M  874M  14% /boot\ntmpfs                     98M     0   98M   0% /run/user/0\n[root@localhost ~]# df -h | grep \"/dev/sda1\"| awk '{print $5}'| cut -d \"%\" -f 1\n14\n```\n\nBegin\n\n```\n[root@localhost ~]# awk 'BEGIN{printf \"11111111\\n\" } {printf $2 \"\\t\" $6 \"\\n\"}' student.txt\n11111111\nName    Average\nLiming  87.66\nSc      85.66\nTg      91.66\n```\n\nEnd\n\n```\n[root@localhost ~]# awk 'END{printf \"111111111\\n\" } {printf $2 \"\\t\" $6 \"\\n\"}' student.txt\nName    Average\nLiming  87.66\nSc      85.66\nTg      91.66\n111111111\n```\n\n假设我想看看平均成绩大于等于 87 分的学员是谁\n\n```\n[root@localhost ~]# cat student.txt\nID      Name    PHP     Linux   MySQL   Average\n1       Liming  82      95      86      87.66\n2       Sc      74      96      87      85.66\n3       Tg      99      83      93      91.66\n[root@localhost ~]# cat student.txt | grep -v \"Name\" | awk '$6 >= 87{print $2}'\nLiming\nTg\n\n```\n\n> 加入了条件之后，只有条件成立动作才会执行，如果条件不满足，则动作则不运行。通过这个实验，大家可以发现，虽然 awk 是列提取命令，但是也要按行来读入的。这个命令的执行过程是这样的：\n>\n> 1） 如果有 BEGIN 条件，则先执行 BEGIN 定义的动作\n>\n> 2） 如果没有 BEGIN 条件，则读入第一行，把第一行的数据依次赋予$0、$1、$2 等变量。其中$0代表此行的整体数据，$1 代表第一字段，$2 代表第二字段。\n>\n> 3） 依据条件类型判断动作是否执行。如果条件符合，则执行动作，否则读入下一行数据。如果没有条件，则每行都执行动作。\n>\n> 4） 读入下一行数据，重复执行以上步骤。\n\n```\n例子 2：\n[root@localhost ~]# awk '$2 ~ /Sc/ {printf $6 \"\\n\"}' student.txt\n#如果第二字段中输入包含有“Sc”字符，则打印第六字段数据\n85.66\n```\n\n这里要注意在 awk 中，使用“//”包含的字符串，awk 命令才会查找。也就是说字符串必须用“//”包含，awk 命令才能正确识别。\n如果要想让 awk 识别字符串，必须使用“//”包含，例如：\n\n```\n[root@localhost ~]# awk '/Liming/ {print}' student.txt\n1       Liming  82      95      86      87.66\n#打印 Liming 的成绩\n```\n\n当使用 df 命令查看分区使用情况是，如果我只想查看真正的系统分区的使用状况，而不想查看光盘和临时分区的使用状况，则可以：\n\n```\n[root@localhost ~]# df -h | awk '/sda[0-9]/ {printf $1 \"\\t\" $5 \"\\n\"} '\n/dev/sda1       14%\n#查询包含有 sda 数字的行，并打印第一字段和第五字段\n```\n\n\n\n查看/etc/passwd文件\n\n```\n[root@localhost ~]# useradd user1\n[root@localhost ~]# useradd user2\n[root@localhost ~]# cat /etc/passwd | grep \"/bin/bash\"\nroot:x:0:0:root:/root:/bin/bash\nuser1:x:1000:1000::/home/user1:/bin/bash\nuser2:x:1001:1001::/home/user2:/bin/bash\n[root@localhost ~]# cat /etc/passwd | grep \"/bin/bash\" |  awk '{FS=\":\"} {print $1}'\nroot:x:0:0:root:/root:/bin/bash\nuser1\nuser2\n#第一行root好像没有以冒号为分割读取第一列\n是因为awk 先把第一行数据读取了\n才进行{FS=\":\"}\n直到上一步之后，才发现要以冒号作为分隔符\n后面的user1 user2 才正常\n###所以正确写法是BEGIN {FS=\":\"}  在读取数据之前，先执行{FS=\":\"}\n[root@localhost ~]# cat /etc/passwd | grep \"/bin/bash\" |  awk 'BEGIN {FS=\":\"} {print $1}'\nroot\nuser1\nuser2\n```\n\n```\n[root@localhost ~]# cat /etc/passwd | grep \"/bin/bash\" | awk 'BEGIN{FS=\":\"} $3==\"1000\" {print $1}'\nuser1\n判断是否相等 要用双＝号\n```\n\n```\n[root@localhost ~]# cat /etc/passwd | grep \"/bin/bash\" | \\\n> awk 'BEGIN {FS=\":\"} {printf $1 \"\\t\" $3 \"\\t 行号：\" NR \"\\t 字段数：\" NF \"\\n\"}'\nroot    0        行号：1         字段数：7\nuser1   1000     行号：2         字段数：7\nuser2   1001     行号：3         字段数：7\n\n#如果我只想看sshd\n[root@localhost ~]# cat /etc/passwd | awk 'BEGIN {FS=\":\"} $1==\"sshd\" {printf $1 \"\\t\" $3 \"\\t 行号：\"NR \"\\t 字段数：\"NF \"\\n\"}'\nsshd    74       行号：20        字段数：7\n```\n\n## Sed\n\nsed命令\n\n```\n[root@localhost ~]# sed [选项] ‘[动作]’ 文件名\n选项：\n-n：  一般 sed 命令会把所有数据都输出到屏幕，如果加入此选择，则只会把经过 sed 命令处理\t\t的行输出到屏幕。\n-e：\t允许对输入数据应用多条 sed 命令编辑。\n-f     脚本文件名： 从 sed 脚本中读入 sed 操作。和 awk 命令的-f 非常类似。\n-r：\t在 sed 中支持扩展正则表达式。\n-i：\t用 sed 的修改结果直接修改读取数据的文件，而不是由屏幕输出动作：\na \\： 追加，在当前行后添加一行或多行。添加多行时，除最后 一行外，\n每行末尾需要用“\\”代表数据未完结。\nc \\： 行替换，用 c 后面的字符串替换原数据行，替换多行时，除最后一行外，每行末尾需用“\\”代表数据未完结。\ni \\：插入，在当期行前插入一行或多行。插入多行时，除最后 一行外，每行末尾需要用“\\”代表数据未完结。\nd：删除，删除指定的行。\n```\n\n打印p\n\n```\n[root@localhost ~]# sed 2p student.txt\nID      Name    PHP     Linux   MySQL   Average\n1       Liming  82      95      86      87.66\n1       Liming  82      95      86      87.66\n2       Sc      74      96      87      85.66\n3       Tg      99      83      93      91.66\n#你会发现第二行多打印了一遍，只有加-n才不会\n[root@localhost ~]# sed -n '2p' student.txt\n1       Liming  82      95      86      87.66\n```\n\n删除d（删除2到4行）\n\n此操作并不会写入文件中，只是输出的时候删除了\n\n```\n[root@localhost ~]# sed '2,4d' student.txt\nID      Name    PHP     Linux   MySQL   Average\n[root@localhost ~]# cat student.txt\nID      Name    PHP     Linux   MySQL   Average\n1       Liming  82      95      86      87.66\n2       Sc      74      96      87      85.66\n3       Tg      99      83      93      91.66\n若想直接修改读取数据到文件的话加入 -i\n[root@localhost ~]# sed -i '2,4d' student.txt\n[root@localhost ~]# cat student.txt\nID      Name    PHP     Linux   MySQL   Average\n\n```\n\n前追加i\n\n```\n#在第二行前面插入内容\n[root@localhost ~]# sed '2i 前面新内容1  \\\n> 前面新内容（大量） 2222222222222222222 ' student.txt\nID      Name    PHP     Linux   MySQL   Average\n前面新内容1\n前面新内容（大量） 2222222222222222222\n1       Liming  82      95      86      87.66\n2       Sc      74      96      87      85.66\n3       Tg      99      83      93      91.66\n```\n\n后追加a\n\n```\n在第二行后追加内容\n[root@localhost ~]# sed -i '2a 新内容' student.txt\n[root@localhost ~]# cat student.txt\nID      Name    PHP     Linux   MySQL   Average\n1       Liming  82      95      86      87.66\n新内容\n2       Sc      74      96      87      85.66\n3       Tg      99      83      93      91.66\n```\n\n替换c\n\n```\n#把2行新内容替换为其他数据\n[root@localhost ~]# cat student.txt\nID      Name    PHP     Linux   MySQL   Average\n1       Liming  82      95      86      87.66\n2       Sc      74      96      87      85.66\n3       Tg      99      83      93      91.66\n[root@localhost ~]# sed '2c 0 xiaoshan 83 55 11 44.2' student.txt\nID      Name    PHP     Linux   MySQL   Average\n0 xiaoshan 83 55 11 44.2\n2       Sc      74      96      87      85.66\n3       Tg      99      83      93      91.66\n#我前面是空格，若对齐用\\t且\\t后没有空格\n[root@localhost ~]# sed '2c 0 \\txiaos\\t83 \\t55 \\t11 \\t44.2' student.txt\nID      Name    PHP     Linux   MySQL   Average\n0       xiaos   83      55      11      44.2\n2       Sc      74      96      87      85.66\n3       Tg      99      83      93      91.66\n```\n\n多命令执行e\n\n```\n[root@localhost ~]# cat student.txt\nID      Name    PHP     Linux   MySQL   Average\n前面新内容1\n前面新内容1\n1       Liming  82      95      86      87.66\n2       Sc      74      96      87      85.66\n3       Tg      99      83      93      91.66\n##同时删除第二和第三行\n[root@localhost ~]# sed  -i -e '2d;3d' student.txt\n[root@localhost ~]# cat student.txt\nID      Name    PHP     Linux   MySQL   Average\n1       Liming  82      95      86      87.66\n2       Sc      74      96      87      85.66\n3       Tg      99      83      93      91.66\n```\n\n替换字符串 s/旧内容/新内容/g\n\n```\n#替换Liming为Lm\n[root@localhost ~]# sed -i 's/Liming/Lm/g' student.txt\n[root@localhost ~]# cat student.txt\nID      Name    PHP     Linux   MySQL   Average\n1       Lm      82      95      86      87.66\n2       Sc      74      96      87      85.66\n3       Tg      99      83      93      91.66\n#多命令执行，分号隔开\n[root@localhost ~]# sed -i 's/Sc/sc1/g; s/Tg/Eg/g' student.txt\n[root@localhost ~]# cat student.txt\nID      Name    PHP     Linux   MySQL   Average\n1       Lm      82      95      86      87.66\n2       sc1     74      96      87      85.66\n3       Eg      99      83      93      91.66\n#也可以多行执行\n[root@localhost ~]# sed -i 's/Sc/sc1/g\ns/Tg/Eg/g' student.txt\n#替换字符串为空值\n[root@localhost ~]# sed -i 's/Lm//g' student.txt\n[root@localhost ~]# cat student.txt\nID      Name    PHP     Linux   MySQL   Average\n1                 82      95      86      87.66\n2       sc1     74      96      87      85.66\n3       Eg      99      83      93      91.66\n\n```\n\n## 字符串处理命令\n\nsort排序命令\n\n```\n[root@localhost ~]# sort [选项] 文件名选项：\n-f：\t忽略大小写\n-b：\t忽略每行前面的空白部分\n-n：\t以数值型进行排序，默认使用字符串型排序\n-r：\t反向排序\n-u：\t删除重复行。就是 uniq 命令\n-t：\t指定分隔符，默认是分隔符是制表符\n-k n[,m]： 按照指定的字段范围排序。从第 n 字段开始，m 字段结束（默认到行尾）\n```\n\n```\n#默认按开头字符排序\n[root@localhost ~]# sort /etc/passwd\nabrt:x:173:173::/etc/abrt:/sbin/nologin\nadm:x:3:4:adm:/var/adm:/sbin/nologin\nbin:x:1:1:bin:/bin:/sbin/nologin\nchrony:x:997:995::/var/lib/chrony:/sbin/nologin\n#反向排序\n[root@localhost ~]# sort -r /etc/passwd\nuser2:x:1001:1001::/home/user2:/bin/bash\nuser1:x:1000:1000::/home/user1:/bin/bash\ntcpdump:x:72:72::/:/sbin/nologin\nsystemd-network:x:192:192:systemd Network Management:/:/sbin/nologin\nsync:x:5:0:sync:/sbin:/bin/sync\n```\n\n指定字段排序\n\n```\n#如UID\n[root@localhost ~]# sort -t \":\" -k 3,3 /etc/passwd\nroot:x:0:0:root:/root:/bin/bash\nbin:x:1:1:bin:/bin:/sbin/nologin\nuser1:x:1000:1000::/home/user1:/bin/bash\nuser2:x:1001:1001::/home/user2:/bin/bash\noperator:x:11:0:operator:/root:/sbin/nologin\ngames:x:12:100:games:/usr/games:/sbin/nologin\nftp:x:14:50:FTP User:/var/ftp:/sbin/nologin\nabrt:x:173:173::/etc/abrt:/sbin/nologin\nsystemd-network:x:192:192:systemd Network Management:/:/sbin/nologin\ndaemon:x:2:2:daemon:/sbin:/sbin/nologin\nadm:x:3:4:adm:/var/adm:/sbin/nologin\n#你会发现他先排第一位数字1，再排2。、\n#就是1  12  13  到  2  22 23 并没有123456排下去\n#所以要加上 -n    -n：以数值型进行排序，默认使用字符串型排序\n[root@localhost ~]# sort -nt \":\" -k 3,3 /etc/passwd\nroot:x:0:0:root:/root:/bin/bash\nbin:x:1:1:bin:/bin:/sbin/nologin\ndaemon:x:2:2:daemon:/sbin:/sbin/nologin\nadm:x:3:4:adm:/var/adm:/sbin/nologin\nlp:x:4:7:lp:/var/spool/lpd:/sbin/nologin\nsync:x:5:0:sync:/sbin:/bin/sync\nshutdown:x:6:0:shutdown:/sbin:/sbin/shutdown\nhalt:x:7:0:halt:/sbin:/sbin/halt\nmail:x:8:12:mail:/var/spool/mail:/sbin/nologin\noperator:x:11:0:operator:/root:/sbin/nologin\ngames:x:12:100:games:/usr/games:/sbin/nologin\n```\n\nuniq取消重复行\n\nuniq 命令是用来取消重复行的命令，其实和“sort -u”选项是一样的。命令格式如下\n\n```\n[root@localhost ~]# uniq [选项] 文件名选项：\n-i：\t忽略大小写\n```\n\n```\n[root@localhost ~]# cat student.txt\nID      Name    PHP     Linux   MySQL   Average\n1               82      95      86      87.66\n1               82      95      86      87.66\n2       sc1     74      96      87      85.66\n3       Eg      99      83      93      91.66\n[root@localhost ~]# uniq student.txt\nID      Name    PHP     Linux   MySQL   Average\n1               82      95      86      87.66\n2       sc1     74      96      87      85.66\n3       Eg      99      83      93      91.66\n```\n\nwc统计命令\n\n```\n[root@localhost ~]# wc [选项] 文件名选项：\n-l：\t只统计行数\n-w：\t只统计单词数\n-m：\t只统计字符数\n```\n\n```\n[root@localhost ~]# cat student.txt\nID      Name    PHP     Linux   MySQL   Average\n1               82      95      86      87.66\n1               82      95      86      87.66\n2       sc1     74      96      87      85.66\n3       Eg      99      83      93      91.66\n[root@localhost ~]# wc -l student.txt\n5 student.txt\n[root@localhost ~]# wc -w student.txt\n28 student.txt\n[root@localhost ~]# wc -m student.txt\n109 student.txt\n\n```\n\n## 条件判断（test命令）\n\n1. 按照文件类型进行判断(test)\n\n| 测试选项 | 作\t用                                                     |\n| -------- | ------------------------------------------------------------ |\n| -b 文件  | 判断该文件是否存在，并且是否为块设备文件（是块设备文件为真） |\n| -c 文件  | 判断该文件是否存在，并且是否为字符设备文件（是字符设备文件为真） |\n| -d 文件  | 判断该文件是否存在，并且是否为目录文件（是目录为真）         |\n| -e 文件  | 判断该文件是否存在（存在为真）                               |\n| -f 文件  | 判断该文件是否存在，并且是否为普通文件（是普通文件为真）     |\n| -L 文件  | 判断该文件是否存在，并且是否为符号链接文件（是符号链接文件为真） |\n| -p 文件  | 判断该文件是否存在，并且是否为管道文件（是管道文件为真）     |\n| -s 文件  | 判断该文件是否存在，并且是否为非空（非空为真）               |\n| -S 文件  | 判断该文件是否存在，并且是否为套接字文件（是套接字文件为真） |\n\n```\n[root@localhost ~]# ls\nanaconda-ks.cfg  file.txt  file.txtn  netstart.bak  student.txt\n第一种格式：#-e 判断该文件是否存在（存在为真）\n[root@localhost ~]# test -e file.txt\n#输出为0即为真\n[root@localhost ~]# echo $?\n0\n第一种格式：#-e 判断不存在的文件\n[root@localhost ~]# [ -e abc ]\n[root@localhost ~]# echo $?\n1\n#输出为非0即为假\n```\n\n```\n###判断该文件是否存在，并且是否为目录文件\n[root@localhost ~]# [ -d student.txt ] && echo yes || echo no\nno\n###判断该文件是否存在，并且是否为普通文件\n[root@localhost ~]# [ -f student.txt ] && echo yes || echo no\nyes\n\n```\n\n```\n###判断文件是否有数据\n[root@localhost ~]# [ -s abc ] && echo yes || echo no\nno\n[root@localhost ~]# echo 111 >> abc\n[root@localhost ~]# [ -s abc ] && echo yes || echo no\nyes\n```\n\n2. 按照文件权限判断\n\n| 测试选项 | 作    用                                                     |\n| -------- | ------------------------------------------------------------ |\n| -r 文件  | 判断该文件是否存在，并且是否该文件拥有读权限（有读权限为真） |\n| -w 文件  | 判断该文件是否存在，并且是否该文件拥有写权限（有写权限为真） |\n| -x 文件  | 判断该文件是否存在，并且是否该文件拥有执行权限（有执行权限为真） |\n| -u 文件  | 判断该文件是否存在，并且是否该文件拥有  SUID 权限（有 SUID 权限为真） |\n| -g 文件  | 判断该文件是否存在，并且是否该文件拥有  SGID 权限（有 SGID 权限为真） |\n| -k 文件  | 判断该文件是否存在，并且是否该文件拥有  SBit 权限（有 SBit 权限为真） |\n\n```\n##判断文件是否有写的权限\n[root@localhost ~]# [ -w abc ] && echo yes || echo no\nyes\n[root@localhost ~]# [ -u abc ] && echo yes || echo no\nno\n##判断文件是否有SUID的权限\n[root@localhost ~]# chmod u+s abc\n[root@localhost ~]# [ -u abc ] && echo yes || echo no\nyes\n[root@localhost ~]# ll\ntotal 24\n-rwSr--r--  1 root root    4 May  2 03:02 abc\n\n```\n\n3. 两个文件之间进行比较\n\n| 测试选项          | 作    用                                                     |\n| :---------------- | ------------------------------------------------------------ |\n| 文件 1 -nt 文件 2 | 判断文件 1 的修改时间是否比文件 2 的新（如果新则为真）       |\n| 文件 1 -ot 文件 2 | 判断文件 1 的修改时间是否比文件 2 的旧（如果旧则为真）       |\n| 文件 1 -ef 文件 2 | 判断文件 1 是否和文件 2 的 Inode 号一致，可以理解为两个文件是否  为同一个文件。这个判断用于判断硬链接是很好的方法 |\n\n```\n##判断两个文件是否是硬链接\n[root@localhost ~]# ln /root/abc /tmp/abc\n[root@localhost ~]# ll /tmp/abc\n-rw-r--r-- 2 root root 4 May  2 03:02 /tmp/abc\n\n[root@localhost ~]# [ /root/abc -ef /tmp/abc ] && echo yes || echo no\nyes\n\n```\n\n4. 两个整数之间比较\n\n| 测试选项          | 作    用                                      |\n| ----------------- | --------------------------------------------- |\n| 整数 1 -eq 整数 2 | 判断整数 1 是否和整数 2 相等（相等为真）      |\n| 整数 1 -ne 整数 2 | 判断整数 1 是否和整数 2 不相等（不相等位置）  |\n| 整数 1 -gt 整数 2 | 判断整数 1 是否大于整数 2（大于为真）         |\n| 整数 1 -lt 整数 2 | 判断整数 1 是否小于整数 2（小于位置）         |\n| 整数 1 -ge 整数 2 | 判断整数 1 是否大于等于整数 2（大于等于为真） |\n| 整数 1 -le 整数 2 | 判断整数 1 是否小于等于整数 2（小于等于为真） |\n\n-eq: equal : 相等               -ne: not equal : 不相等\n\n-gt: greater than : 大于       -lt: less than : 小于\n\n```\n##判断整数1是否等于整数2\n[root@localhost ~]# [ 22 -eq 22 ] && echo yes || echo no\nyes\n##判断整数1是否小于整数2\n[root@localhost ~]# [ 22 -lt 22 ] && echo yes || echo no\nno\n[root@localhost ~]# [ 21 -lt 22 ] && echo yes || echo no\nyes\n\n```\n\n5. 字符串判断\n\n| 测试选项         | 作    用                                            |\n| ---------------- | --------------------------------------------------- |\n| -z 字符串        | 判断字符串是否为空（为空返回真）                    |\n| -n 字符串        | 判断字符串是否为非空（非空返回真）                  |\n| 字串 1 ==字串 2  | 判断字符串  1 是否和字符串 2 相等（相等返回真）     |\n| 字串 1 != 字串 2 | 判断字符串  1 是否和字符串 2 不相等（不相等返回真） |\n\n```\n##判断两个字符串相等\n[root@localhost ~]# aa=11\n[root@localhost ~]# bb=22\n[root@localhost ~]# [ \"$aa\" == 8 ] && echo yes || echo no\nno\n[root@localhost ~]# [ $aa == $bb ] && echo yes || echo no\nno\n[root@localhost ~]# [ \"$aa\" == 11 ] && echo yes || echo no\nyes\n##判断字符是否为空\n[root@localhost ~]# name=xx\n[root@localhost ~]# [ -z $name ] && echo yes || echo no\nno\n```\n\n6. 多重条件判断\n\n| 测试选项         | 作    用                                              |\n| ---------------- | ----------------------------------------------------- |\n| 判断 1 -a 判断 2 | 逻辑与，判断  1 和判断 2 都成立，最终的结果才为真     |\n| 判断 1 -o 判断 2 | 逻辑或，判断  1 和判断 2 有一个成立，最终的结果就为真 |\n| ！判断           | 逻辑非，使原始的判断式取反                            |\n\n```\n#先给aa赋值\n[root@localhost ~]# aa=24\n#-n先判断是否为空，明显不为空则为真，真就继续判断是否大于23\n[root@localhost ~]# [ -n \"$aa\" -a \"$aa\" -gt 23 ] && echo yes || echo no\nyes\n```\n\n```\n##逻辑非\n[root@localhost ~]# [ ! -n \"$aa\" ] && echo \"yes\" || echo \"no\"\nno\n#本来“-n”选项是变量 aa 不为空，返回值就是真。\n#加入！之后，判断值就会取反，所以当变量 aa 有值时，返回值是假\n\n```\n\n## 流程控制\n\n### if条件判断\n\n1. 单分支 if 条件语句\n\n单分支条件语句最为简单，就是只有一个判断条件，如果符合条件则执行某个程序，否则什么事情都不做。语法如下：\n\n```\nif [ 条件判断式 ];then\n     程序\nfi\n```\n\n单分支条件语句需要注意几个点：\n\n·if 语句使用 fi 结尾，和一般语言使用大括号结尾不同\n\n· [ 条件判断式 ]就是使用 test 命令判断，所以中括号和条件判断式之间必须有空格\n\n· then 后面跟符合条件之后执行的程序，可以放在[]之后，用“；”分割。也可以换行写入，就不需要“；”了，比如单分支 if 语句还可以这样写：\n\n```\nif [ 条件判断式 ]\n   then\n     程序\nfi\n```\n\n例子：判断sda1并设置警告信息\n\n```\n[root@localhost ~]# df -h\nFilesystem               Size  Used Avail Use% Mounted on\n/dev/sda1               1014M  141M  874M  14% /boot\n[root@localhost ~]# df -h | grep \"/dev/sda1\" | awk '{print $5}' | cut -d \"%\" -f 1\n14\n\n\n[root@localhost ~]# vi if1.sh\n#!/bin/bash\n#统计分区使用率\nrate=$(df -h | grep \"/dev/sda1\" | awk '{print $5}'| cut -d \"%\" -f 1)\n\n#把根分区使用率作为变量值赋予变量rate\nif [ $rate -ge 14 ]\n#判断 rate 的值如果大于等于 14，则执行then 程序\nthen\necho \"Warning! /dev/sda1 快满了!\"\n#打印警告信息。在实际工作中，也可以向管理员发送邮件。\nfi\n[root@localhost ~]# sh if1.sh\nWarning! /dev/sda1 快满了!\n```\n\n2. 双分支if语句\n\n```\nif [ 条件判断式 ]\n       then\n\t\t条件成立时，执行的程序\n\telse\n\t\t条件不成立时，执行的另一个程序\nfi\n```\n\n数据备份的例子\n\n```\n#备份mysql数据库（并不完善，但可以使用）\n[root@localhost ~]# vi sh/bakmysql.sh \n#!/bin/bash\n#备份 mysql 数据库。\n#同步系统时间\nntpdate asia.pool.ntp.org &>/dev/null\n#把当前系统时间按照“年月日”格式赋予变量date\ndate=$(date +%y%m%d)\n#统计 mysql 数据库的大小，并把大小赋予size 变量\nsize=$(du -sh /var/lib/mysql)\n\nif [ -d /tmp/dbbak ]\n    #判断备份目录是否存在，是否为目录\n  then\n    #如果判断为真，执行以下脚本\n\techo \"Date : $date!\" > /tmp/dbbak/dbinfo.txt\n\t#把当前日期写入临时文件\n\techo \"Data size : $size\" >> /tmp/dbbak/dbinfo.txt\n\t#把数据库大小写入临时文件\n\tcd /tmp/dbbak\n\t#进入备份目录\n\ttar -zcf mysql-lib-$date.tar.gz /var/lib/mysql dbinfo.txt &>/dev/null\n\t#打包压缩数据库与临时文件，把所有输出丢入垃圾箱（不想看到任何输出）\n\trm -rf /tmp/dbbak/dbinfo.txt\n\t#删除临时文件\n  else\n\tmkdir /tmp/dbbak\n\t#如果判断为假，则建立备份目录\n\techo \"Date : $date!\" > /tmp/dbbak/dbinfo.txt echo \"Data size : $size\" >> /tmp/dbbak/dbinfo.txt #把日期和数据库大小保存如临时文件\n\tcd /tmp/dbbak\n\ttar -zcf mysql-lib-$date.tar.gz dbinfo.txt /var/lib/mysql &>/dev/null\n\t#压缩备份数据库与临时文件\n\trm -rf /tmp/dbbak/dbinfo.txt\n\t#删除临时文件\nfi\n\n```\n\n\n\n\n\n## 常用字符表\n\n### echo\n\n在 echo 命令中如果使用了“-e”选项，则可以支持控制字符，如表 11-2 所示：\n\n| 控制字符 | 作\t用                                                     |\n| -------- | ------------------------------------------------------------ |\n| \\\\       | 输出\\本身                                                    |\n| \\a       | 输出警告音                                                   |\n| \\b       | 退格键，也就是向左删除键                                     |\n| \\c       | 取消输出行末的换行符。和“-n”选项一致                         |\n| \\e       | ESCAPE 键                                                    |\n| \\f       | 换页符                                                       |\n| \\n       | 换行符                                                       |\n| \\r       | 回车键                                                       |\n| \\t       | 制表符，也就是 Tab 键                                        |\n| \\v       | 垂直制表符                                                   |\n| \\0nnn    | 按照八进制 ASCII 码表输出字符。其中 0 为数字零，nnn 是三位八进制数 |\n| \\xhh     | 按照十六进制 ASCII 码表输出字符。其中 hh 是两位十六进制数    |\n\n### Bash常用快捷键\n\n| 快捷键     | 作\t用                                                     |\n| ---------- | ------------------------------------------------------------ |\n| ctrl+A     | 把光标移动到命令行开头。如果我们输入的命令过长，想要把光标移动到命令行开头时使用。 |\n| ctrl+E     | 把光标移动到命令行结尾。                                     |\n| **ctrl+C** | 强制终止当前的命令。                                         |\n| **ctrl+L** | 清屏，相当于 clear 命令。                                    |\n| **ctrl+U** | 删除或剪切光标之前的命令。我输入了一行很长的命令，不用使用退格键一个一个字符的删除，使用这个快捷键会更加方便 |\n| ctrl+K     | 删除或剪切光标之后的内容。                                   |\n| **ctrl+Y** | 粘贴 ctrl+U 或 ctrl+K 剪切的内容。                           |\n| **ctrl+R** | 在历史命令中搜索，按下ctrl+R 之后，就会出现搜索界面，只要输入搜索内容，就会从历史命令中搜索。 |\n\n| **ctrl+D** | 退出当前终端。                                               |\n| ---------- | ------------------------------------------------------------ |\n| ctrl+Z     | 暂停，并放入后台。这个快捷键牵扯工作管理的内容，我们在系统管理章节详细介绍。 |\n| ctrl+S     | 暂停屏幕输出。                                               |\n| ctrl+Q     | 恢复屏幕输出。                                               |\n\n### 基础正则表达式\n\n| 元字符  | 作\t用                                                     |\n| ------- | :----------------------------------------------------------- |\n| *       | 前一个字符匹配 0 次或任意多次。                              |\n| .       | 匹配除了换行符外任意一个字符。                               |\n| ^       | 匹配行首。例如：^hello 会匹配以 hello 开头的行。             |\n| $       | 匹配行尾。例如：hello&会匹配以 hello 结尾的行。              |\n| []      | 匹配中括号中指定的任意一个字符，只匹配一个字符。例如：[aoeiu] 匹配任意一个元音字母，[0-9] 匹配任意一位数字，[a-z][0-9]匹配小写字和一位数字构成的两位字符。 |\n| [^]     | 匹配除中括号的字符以外的任意一个字符。例如：[^0-9] 匹配任意一位非数字字符，[^a-z] 表示任意一位非小写字母。 |\n| \\       | 转义符。用于取消讲特殊符号的含义取消。                       |\n| \\{n\\}   | 表示其前面的字符恰好出现 n 次。例如：[0-9]\\{4\\} 匹配 4 位数字，[1][3-8][0-9]\\{9\\} 匹配手机号码。 |\n| \\{n,\\}  | 表示其前面的字符出现不小于 n 次。例如： [0-9]\\{2,\\} 表示两位及以上的数字。 |\n| \\{n,m\\} | 表示其前面的字符至少出现n 次，最多出现m 次。例如：[a-z]\\{6,8\\}匹配 6 到 8 位的小写字母。 |\n\n### 扩展正则\n\n| 扩展元字符 | 作\t用                                                     |\n| ---------- | ------------------------------------------------------------ |\n| +          | 前一个字符匹配 1 次或任意多次。如“go+gle”会匹配“gogle”、“google”或“gooogle”，当然如果“o”有更多个，也能匹配。 |\n| ？         | 前一个字符匹配 0 次或 1 次。如“colou?r”可以匹配“colour”或“color”。 |\n| \\|         | 匹配两个或多个分支选择。如“was\\|his”会匹配既包含“was”的行，也匹配包含“his”的行。 |\n| （）       | 匹配其整体为一个字符，即模式单元。可以理解为由多个单个字符组成的大字符。<br />如“(dog)+”会匹配“dog”、“dogdog”、“dogdogdog”等，因为被（）包含的字符会当成一个整体。但“hello （world\\|earth）”会匹配“hello world”及“hello earth”。 |\n\n### grep 参数列表\n\n1. `-i` : 忽略大小写\n2. `-v` : 查找不包含指定字符串的所有行（取反）\n3. `-r` : 递归查找文件夹下的文件\n4. `-n` : 显示匹配行所在位置（行号）\n5. `-l` : 只显示包含搜索字符串的文件名，而非每个匹配行\n6. `-c` : 统计符合条件的行数\n7. `-e pattern` : 指定要查找的正则表达式模式\n8. `-w` : 匹配整个单词，即只匹配独立的单词而非单词内的字符\n9. `-A num` : 输出匹配行后 N 行内容\n10. `-B num` : 输出匹配行前 N 行内容\n11. `-C[num]` 或者 `--context[=num]`: 输出匹配行前后总共 N 行内容。\n12. `--exclude` : 排除指定文件类型，多个文件类型用 \",\" 隔开\n\n### cut\n\n```\n[root@localhost ~]# cut [选项] 文件名选项：\n-f 列号：          提取第几列\n-d 分隔符：\t     按照指定分隔符分割列\n-c 字符范围：    不依赖分隔符来区分列，而是通过字符范围（行首为 0）来进行字段提取。“n-”表示从第 n 个字符到行尾；“n-m”从第 n 个字符到第 m个字符；“-m”表示从第 1 个字符到第 m 个字符。\n```\n\n### awk条件（Pattern）\n\n![image-20230421143849290](../img/Shell/205fa6cf17277f79e65555cc1c7a9afe7819b814.png)\n\n### awk内置变量\n\n![image-20230421190306772](../img/Shell/2e8746e3feacb88db27cc8f033f27d3b5b52f28a.png)\n\n\n\n<div class=\"tbsm\" style=\"margin-top:54px;\">\n<div class=\"tbsm-top\"><span><svg t=\"1674654360507\" class=\"icon\" viewBox=\"0 0 1024 1024\" version=\"1.1\" xmlns=\"http://www.w3.org/2000/svg\" p-id=\"987\" data-spm-anchor-id=\"a313x.7781069.0.i0\" width=\"35\" height=\"35\"><path d=\"M410.49 97.74H155.08a56.74 56.74 0 0 0-56.84 56.73V410a56.84 56.84 0 0 0 56.84 56.84h255.41A56.83 56.83 0 0 0 467.32 410V154.58a56.83 56.83 0 0 0-56.83-56.84zM410.49 558.74H155.08a56.74 56.74 0 0 0-56.84 56.73V871a56.84 56.84 0 0 0 56.84 56.84h255.41A56.83 56.83 0 0 0 467.32 871V615.58a56.83 56.83 0 0 0-56.83-56.84zM871.49 558.74H616.08a56.74 56.74 0 0 0-56.84 56.73V871a56.84 56.84 0 0 0 56.84 56.84h255.41A56.83 56.83 0 0 0 928.32 871V615.58a56.83 56.83 0 0 0-56.83-56.84z\" fill=\"#66EEFF\" p-id=\"988\"></path><path d=\"M410.49 558.74h-4.14A475 475 0 0 0 299.52 859.6a481.16 481.16 0 0 0 4.84 68.22h106.13A56.83 56.83 0 0 0 467.32 871V615.58a56.83 56.83 0 0 0-56.83-56.84zM871.49 558.74H616.08a56.74 56.74 0 0 0-56.84 56.73V871a56.84 56.84 0 0 0 56.84 56.84h255.41A56.83 56.83 0 0 0 928.32 871V615.58a56.83 56.83 0 0 0-56.83-56.84z\" fill=\"#C2F8FF\" p-id=\"989\"></path></svg></span><span style=\"font-size:30px;\"> 特别声明</span></div>\n<div class=\"tbsm-wz\">千屹博客旗下的所有文章，是通过本人课堂学习和课外自学所精心整理的知识巨著<br/>难免会有出错的地方<br/>如果细心的你发现了小失误，可以在下方评论区告诉我，或者私信我！<br />非常感谢大家的热烈支持！</div>\n</div>","tags":["Shell"],"categories":["笔记"]},{"title":"基于Docker部署Hexo框架","url":"/posts/25850/","content":"\n# 基于Docker部署Hexo框架\n\n## 创建dockerfile文件夹\n\n```\nmkdir dockerfile\n```\n\n## 使用vim创建和编辑Dockerfile\n\nvim dockerfile/Dockerfile\n\n```\n# 使用最新的node镜像作为基础环境  \nFROM node:latest  \n# 设置临时工作目录  \nWORKDIR /usr/blog\n# 配置 npm 镜像站点  \nRUN npm config set registry https://registry.npm.taobao.org  \n# 安装 hexo-cli  \nRUN npm install hexo-cli -g  \n# 初始化 hexo blog  \nRUN hexo init  \n# hexo 默认端口号 4000  \nEXPOSE 4000\n```\n\n## 构建镜像\n\n```\ndocker build -t hexo-image /root/dockerfile/\n```\n\n## 创建容器\n\n```\ndocker run -itd -v /root/blog:/usr/blog -p 4000:4000 --name hexo-blog hexo-image\n```\n\n-v /root/blog:/usr/blog  可以实现把容器中的/usr/blog挂载到宿主机的/root/blog，非常方便\n\n```\ndocker update hexo-blog --restart=always \n#增加开机自启动属性\n```\n\n## 查看容器id\n\n```\ndocker ps -a\n```\n\n## 加入容器\n\n```\ndocker exec -it 容器id /bin/bash\n#也可以是名字\ndocker exec -it hexo-blog /bin/bash\n```\n\n## 开启服务\n\n```\nhexo s\n```\n\n<div class=\"tbsm\" style=\"margin-top:54px;\">\n<div class=\"tbsm-top\"><span><svg t=\"1674654360507\" class=\"icon\" viewBox=\"0 0 1024 1024\" version=\"1.1\" xmlns=\"http://www.w3.org/2000/svg\" p-id=\"987\" data-spm-anchor-id=\"a313x.7781069.0.i0\" width=\"35\" height=\"35\"><path d=\"M410.49 97.74H155.08a56.74 56.74 0 0 0-56.84 56.73V410a56.84 56.84 0 0 0 56.84 56.84h255.41A56.83 56.83 0 0 0 467.32 410V154.58a56.83 56.83 0 0 0-56.83-56.84zM410.49 558.74H155.08a56.74 56.74 0 0 0-56.84 56.73V871a56.84 56.84 0 0 0 56.84 56.84h255.41A56.83 56.83 0 0 0 467.32 871V615.58a56.83 56.83 0 0 0-56.83-56.84zM871.49 558.74H616.08a56.74 56.74 0 0 0-56.84 56.73V871a56.84 56.84 0 0 0 56.84 56.84h255.41A56.83 56.83 0 0 0 928.32 871V615.58a56.83 56.83 0 0 0-56.83-56.84z\" fill=\"#66EEFF\" p-id=\"988\"></path><path d=\"M410.49 558.74h-4.14A475 475 0 0 0 299.52 859.6a481.16 481.16 0 0 0 4.84 68.22h106.13A56.83 56.83 0 0 0 467.32 871V615.58a56.83 56.83 0 0 0-56.83-56.84zM871.49 558.74H616.08a56.74 56.74 0 0 0-56.84 56.73V871a56.84 56.84 0 0 0 56.84 56.84h255.41A56.83 56.83 0 0 0 928.32 871V615.58a56.83 56.83 0 0 0-56.83-56.84z\" fill=\"#C2F8FF\" p-id=\"989\"></path></svg></span><span style=\"font-size:30px;\"> 特别声明</span></div>\n<div class=\"tbsm-wz\">千屹博客旗下的所有文章，是通过本人课堂学习和课外自学所精心整理的知识巨著<br/>难免会有出错的地方<br/>如果细心的你发现了小失误，可以在下方评论区告诉我，或者私信我！<br />非常感谢大家的热烈支持！</div>\n</div>","tags":["Centos 8","Hexo"],"categories":["Hexo"]},{"title":"Mysql笔记","url":"/posts/43761/","content":"\n# Mysql笔记\n\n## 数据库的创建和管理\n\n### 创建数据库 \n\n```\ncreate database 数据库名字\ndefault character set 字符集名字\nDefault collate 排序规则名 ;\n例子：\ncreate database webinfo\ndefault character set utf8mb4\nDefault collate utf8mb4_general_ci;\n```\n\n### 显示当前所有的数据库列表 \n\n```\nShow databases;\n```\n\n### 指定默认的数据库列表 \n\nUse 数据库名字;\n\n```\nuse stuinfo;\n```\n\n### 使用alter database 语句修改数据库 \n\n```\nAlter database 数据库名字\nDefault character set 字符集名\nDefault collate 排序规则名字;\n例子：\nAlter database stuinfo\nDefault character set utf8\nDefault collate utf8_general_ci;\n```\n\n### 删除数据库\n\n```\nDrop database 数据库名字;\n```\n\n## 数据表的创建和管理\n\n### 使用create table 语句创建数据表 \n\n```\nCreate table 表名 (\n字段名1 数据类型 \\[属性\\] \\[索引\\] ,\n字段名1 数据类型 \\[属性\\] \\[索引\\],\n.......\n字段名1 数据类型 \\[属性\\] \\[索引\\]\n);\n例子：\n\nCreate table student (\nId int unsigned not null auto_increment comment '学生ID',\nsNo char(10) not null comment '学号',\nsName varchar(20) not null comment '姓名',\nsex char(1) not null default '男' comment '性别',\nbirthday Date not null comment '出生日期',\ndepyName varchar(30) not null comment '班级名称',\nremark Varchar(80) comment '备注',\nprimary key (id), /    \\*设置id为主键\\*/\nunique (sNo), /        \\*设置sNo为唯一性索引\\*/\nindex (sName) /         \\*设置sName为普通索引\\*/\n); ENGINE=InnoDB;\n```\n\nNot null 不为空 unsigned无符号 auto_increment自动增加\n\n### 查看数据表 \n\n```\nShow tables;\n```\n\n### 复制数据表 \n\n```\nCreate table 新表名 like 旧表名;\n```\n\n### 创建临时表 \n\n新建之后，当mysql关闭后会自动删除\n\n```\nCreate temporary table student (\nId int unsigned not null auto_increment comment '学生ID',\nsNo char(10) not null comment '学号',\nsName varchar(20) not null comment '姓名',\nsex char(1) not null default '男' comment '性别',\nbirthday Date not null comment '出生日期',\ndepyName varchar(30) not null comment '班级名称',\nremark Varchar(80) comment '备注',\nprimary key (id), /            \\*设置id为主键\\*/\nunique (sNo), /                \\*设置sNo为唯一性索引\\*/\nindex (sName) /                \\*设置sName为普通索引\\*/\n); ENGINE=InnoDB;\n```\n\nNot null 不为空 unsigned无符号 auto_increment自动增加\n\n### 查看表结构 \n\nDescribe \\| desc 表名;\n\n例子：\n\n```\ndesc 表名;\n```\n\n### 查看表的结构  sql语句\n\n```\nShow create table 表名;\n```\n\n## 修改表结构\n\n### 使用alter table 修改表结构 \n\nAlter table 表名\n\nAdd字段名 数据类型 \\[属性\\] \\[索引\\] \\[First \\| after 字段名\\] --添加新字段\n\nModify 字段名 数据类型 \\[属性\\] \\[索引\\] \\-\\--更改指定数据类型\n\nChange 字段名 新字段名 数据类型 \\[属性\\] \\[索引\\] \\-\\--更改指定数据类型同时更改名字\n\nDrop 字段名 \\-\\-\\--删除指定字段\n\nRename as 新表名 \\-\\--用来给数据表重新命名\n\n例子：\n\n![](../img/mysql/8b6f5da2799c869593bdbc5522d2685dd2381ca7.png)\n\n### 使用insert操作表中数据\n\nInsert into 表名 (字段名1，字段名2，字段名3)\n\nValues (值1, 值2, 值3 ), (值1, 值2, 值3 ), (值1, 值2, 值3 )\n\n例子：\n\n![](../img/mysql/870d7fcb430882fa05e29c2babcf653dbf65ba4c.png)\n\n\n\n![](../img/mysql/03291da3b57489d326e70ed42cccd7b74fe47ff0.png)\n\n![](../img/mysql/8d5d3502faf255bf0994763b7e5265d08fdb4ea0.png)\n\n### 使用update修改表中数据 \n\nUpdate 表名\n\nSet 字段名1=值1 , 字段名2=值2\\[,...\\]\n\n\\[where 条件\\]\n\n![](../img/mysql/829ab7cd4862fa144d806ef85ec5bcb1355c0294.png)\n\n### 使用delete删除表中数据\n\nDelete from 表名\n\n\\[where 条件\\]\n\n例子：\n\n```\nDelete from student where sNo='1308013105';\n```\n\n> 会删除所在字段（sNo）的那一行的数据，不是只单单删除sNo\n>\n\n### 使用truncate语句清空表中数据 \n\nTruncate \\[table\\] 表名\n\n### 删除表 \n\n```\nUse 数据库名字;\nDrop table 表名;\n```\n\n## 创建索引\n\n### 定义\n\nMySQL 的索引类型主要有以下几种。\n\n• 普通索引（NDEX）：最基本的索引，它没有任何限制，是用来提升数据库性能、提高\n\n数据查询效率的一项重要的技术。\n\n• 唯一性索引（UNIQUE)）：索引列的值必须唯一，但允许有空值。一张表中可以有多个\n\n唯一性索引。如果是组合索引，则列值的组合必须唯一。\n\n• 主键索引（PRIMARY KEY)：一种特殊的唯一性索引，但不允许有空值。一张表中只能\n\n有一个主键。为了有效实现数据的管理，每张表都应该有自己的主键，一般是在建表的\n\n同时创建主键索引。\n\n• 全文索引（FULLITEXT)：主要用来查找文本中的关键字，而不是直接与索引中的值相\n\n比较。全文索引跟其他索引大不相同，它更像是一个搜索引擎，而不是简单的 WHERE\n\n语句的参数匹配。全文索引配合 MATCH AGAINST 操作使用，而不是一般的 WHERE\n\n语句加 LIKE。目前只有 CHAR、VARCHAR、TEXT 列上可以创建全文索引。\n\n### 在create table创建索引 \n\nCreate table 表名 (\n\n字段名1 \\| 索引项...,\n\n)\n\n索引项的语法：\n\nPrimary key 索引名 (字段名)\n\nUnique 索引名 (字段名)\n\nIndex \\| key 索引名 (字段名)\n\nFulltext 索引名 (字段名)\n\n例子\n\n```\nCreate table student (\nId int unsigned not null auto_increment comment '学生ID',\nsNo char(10) not null comment '学号',\nsName varchar(20) not null comment '姓名',\nsex char(1) not null default '男' comment '性别',\nbirthday Date not null comment '出生日期',\ndepyName varchar(30) not null comment '班级名称',\nremark Varchar(80) comment '备注',\nprimary key (id), /         \\*设置id为主键\\*/\nunique (sNo), /             \\*设置sNo为唯一性索引\\*/\nindex (sName) /             \\*设置sName为普通索引\\*/\n); ENGINE=InnoDB;\n```\n\nNot null 不为空 unsigned无符号 auto_increment自动增加\n\n### 使用alter table 语句创建索引 \n\nAlter table 表名\n\n​\tAdd 索引项;\n\n例子:\n\n```\nAlter table course \n   Add unique ux_cNo(cNo),\n   Add index ix_cName(cName);\n```\n\n### 使用create index语句创建索引 \n\nCreate \\[unique\\] \\| \\[fulltext\\] index 索引名\n\nOn 表名 (字段名)\n\n例子：\n\n在成绩表上创建唯一性索引（组合索引）\n\n```\nCreate unique index ux_sId_cId\n  ON score (sId,cId);\n```\n\n### 使用Show index 语句查看索引 \n\nShow index from \\<表名\\> \\[from \\<数据库名字\\>\\]\n\n例子：\n\n```\nShow index from student;\n```\n\n查看学生表中的索引\n\n## Select查询\n\n应该是到这会用到sql语句，[[点此下载]](https://blog.qianyios.top/img/mysql/mysql.sql)\n\n### 选择字段进行查询 \n\nSelect 字段1 \\[,字段2,字段3\\] from 表名;\n\n例子：\n\n```\nSelect deptname,name,sNo,sex from student;\n```\n\n### 定义字段别名 \n\n```\nSelect sNo AS '学号' , sName AS '姓名' from student;\n```\n\n### 条件查询\n\n![](../img/mysql/02b82bb8513212355e8b349a521dd61352fa83ab.png)\n\n![](../img/mysql/0869742823f759f5ef48ea5f6a8f212372a07306.png)\n\n![](../img/mysql/dc7ea9e3a84db07ccd8c1d472ef16f831fad3426.png)\n\n### 使用like模糊查询 \n\n![](../img/mysql/6bbc28deea707327f633a79a9ac2ea993492b6f5.png)\n\n### 使用in 进行范围查询 \n\n![](../img/mysql/4b38a89d27f92c66b4f55b09b22571b41b2ff6c3.png)\n\n### 使用order by 子句对查询结果 \n\n降序\n\n![](../img/mysql/c4e74778d15b3e25dcb87ad2ec9b04c019c599b6.png)\n\n中文名拼音排序\n\n![](../img/mysql/48dc17ccb73d158d933bf667457f976eabe78571.png)\n\n先按班级升序排列，同一个班级内出生日期降序排列\n\n![](../img/mysql/4129c38cb1145c4c31a10e67a4bdbf53ab912a02.png)\n\n### 使用limit子句限制返回记录的行数 \n\n![](../img/mysql/6ef0e0ae9356a9bd35a73381331280a84b5f36e8.png)\n\n### 使用distinct关键字过滤重复记录 \n\n![](../img/mysql/3da439822e837155ff79dd886f279e0e092a401c.png)\n\n### 内连接 \n\n![](../img/mysql/74f1484406a0109e04a42774390fc77908378d87.png)\n\n### 使用统计函数对数据进行统计汇总\n\n![](../img/mysql/edbb900f843983091f50c8678b3fa4f25f54a9c0.png)\n\n![](../img/mysql/1936d5b3fc30d96fd6504fad3971c68a7a68ff62.png)\n\n### 使用group by进行分组查询\n\n![](../img/mysql/54660d6d3fde2a35c69acba916a16fa91ed11f36.png)\n\n### 使用having子句对分组汇总结果进行筛选\n\n![](../img/mysql/3db2b7135bda4f3f009cc75b3c23b318902d822f.png)\n\n### 使用exists关键字创建子查询\n\n查询选修课程的女生名单\n\n![](../img/mysql/0a0f67652b270bf9a6c44bf15441c4d79703f59d.png)\n\n## 薄弱盲区\n\n### 复制表到新表\n\n![](../img/mysql/94311847f82a568ae2d73e53970b45e5af4a22b5.png)\n\n### 向表中插入子查询结果 \n\n![](../img/mysql/92a788abdb0eb28c8a3e5f874ea5f55f6d16e5cf.png)\n\n### 带子查询的修改语句\n\n![](../img/mysql/e479bfcdbf3598eb81b216d7dc9dde78ba16a96b.png)\n\n### 带子查询的删除语句\n\n![](../img/mysql/a4b432f0b05697044d85067e2da30284ed5e1f2d.png)\n\n<div class=\"tbsm\" style=\"margin-top:54px;\">\n<div class=\"tbsm-top\"><span><svg t=\"1674654360507\" class=\"icon\" viewBox=\"0 0 1024 1024\" version=\"1.1\" xmlns=\"http://www.w3.org/2000/svg\" p-id=\"987\" data-spm-anchor-id=\"a313x.7781069.0.i0\" width=\"35\" height=\"35\"><path d=\"M410.49 97.74H155.08a56.74 56.74 0 0 0-56.84 56.73V410a56.84 56.84 0 0 0 56.84 56.84h255.41A56.83 56.83 0 0 0 467.32 410V154.58a56.83 56.83 0 0 0-56.83-56.84zM410.49 558.74H155.08a56.74 56.74 0 0 0-56.84 56.73V871a56.84 56.84 0 0 0 56.84 56.84h255.41A56.83 56.83 0 0 0 467.32 871V615.58a56.83 56.83 0 0 0-56.83-56.84zM871.49 558.74H616.08a56.74 56.74 0 0 0-56.84 56.73V871a56.84 56.84 0 0 0 56.84 56.84h255.41A56.83 56.83 0 0 0 928.32 871V615.58a56.83 56.83 0 0 0-56.83-56.84z\" fill=\"#66EEFF\" p-id=\"988\"></path><path d=\"M410.49 558.74h-4.14A475 475 0 0 0 299.52 859.6a481.16 481.16 0 0 0 4.84 68.22h106.13A56.83 56.83 0 0 0 467.32 871V615.58a56.83 56.83 0 0 0-56.83-56.84zM871.49 558.74H616.08a56.74 56.74 0 0 0-56.84 56.73V871a56.84 56.84 0 0 0 56.84 56.84h255.41A56.83 56.83 0 0 0 928.32 871V615.58a56.83 56.83 0 0 0-56.83-56.84z\" fill=\"#C2F8FF\" p-id=\"989\"></path></svg></span><span style=\"font-size:30px;\"> 特别声明</span></div>\n<div class=\"tbsm-wz\">千屹博客旗下的所有文章，是通过本人课堂学习和课外自学所精心整理的知识巨著<br/>难免会有出错的地方<br/>如果细心的你发现了小失误，可以在下方评论区告诉我，或者私信我！<br />非常感谢大家的热烈支持！</div>\n</div>","tags":["Mysql"],"categories":["笔记"]},{"title":"Centos 8部署Docker","url":"/posts/51253/","content":"\n# Centos 8部署Docker\n\n## 基础信息\n\n| 系统       | ip  (NAT)     | 内存 | 硬盘 |\n| ---------- | ------------- | ---- | ---- |\n| Centos 8.5 | 192.168.48.10 | 2G   | 40G  |\n\n基本配置好可以访问互联网即可\n\n### 切换阿里yum\n\n```\nmkdir repo.bak\ncp /etc/yum.repos.d/* repo.bak/\nrename '.repo' '.repo.bak' /etc/yum.repos.d/*.repo\nwget -O /etc/yum.repos.d/CentOS-Base.repo https://mirrors.aliyun.com/repo/Centos-vault-8.5.2111.repo\nyum clean all && yum makecache\nsystemctl disable --now firewalld\nsed -i 's/^SELINUX=.*/SELINUX=disabled/' /etc/selinux/config\n```\n\n## 安装Docker\n\n### 删除旧版docker\n\n```\nsudo yum remove docker docker-client docker-client-latest docker-common docker-latest docker-latest-logrotate docker-logrotate docker-engine -y\n```\n\n### 安装依赖\n\n```\nyum install -y yum-utils device-mapper-persistent-data lvm2\n```\n\n### 添加阿里docker存储库\n\n```\ndnf config-manager --add-repo=https://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo\nyum clean all && yum makecache \n```\n\n### 安装docker软件\n\n```\nyum install -y --allowerasing docker-ce docker-ce-cli\n```\n\n### 启动docker服务\n\n```\nsystemctl enable docker --now\n```\n\n### 验证是否安装成功\n\n```\n[root@Docker ~]# docker run hello-world\n#未检测到hello-world镜像\nUnable to find image 'hello-world:latest' locally\n#从远程的DockerHub仓库拉取镜像\nlatest: Pulling from library/hello-world\n2db29710123e: Pull complete\nDigest: sha256:aa0cc8055b82dc2509bed2e19b275c8f463506616377219d9642221ab53cf9fe\nStatus: Downloaded newer image for hello-world:latest\n#出现下面说明docker运行成功\nHello from Docker!  -------\nThis message shows that your installation appears to be working correctly.\n\nTo generate this message, Docker took the following steps:\n 1. The Docker client contacted the Docker daemon.\n 2. The Docker daemon pulled the \"hello-world\" image from the Docker Hub.\n    (amd64)\n 3. The Docker daemon created a new container from that image which runs the\n    executable that produces the output you are currently reading.\n 4. The Docker daemon streamed that output to the Docker client, which sent it\n    to your terminal.\nTo try something more ambitious, you can run an Ubuntu container with:\n $ docker run -it ubuntu bash\nShare images, automate workflows, and more with a free Docker ID:\n https://hub.docker.com/\nFor more examples and ideas, visit:\n https://docs.docker.com/get-started/\n\n```\n\n## 安装docker compose\n\n```\n# 设置 Docker 镜像加速器\nsudo mkdir -p /etc/docker\nsudo tee /etc/docker/daemon.json <<-'EOF'\n{\n  \"registry-mirrors\": [\"https://registry.docker-cn.com\"]\n}\nEOF\nsudo systemctl daemon-reload\nsudo systemctl restart docker\n\n# 安装 Docker Compose\nsudo curl -L \"https://get.daocloud.io/docker/compose/releases/download/1.29.2/docker-compose-$(uname -s)-$(uname -m)\" -o /usr/local/bin/docker-compose\nsudo chmod +x /usr/local/bin/docker-compose\nsudo systemctl enable docker --now\nsudo systemctl restart docker\n\nsudo usermod -aG docker $USER\n```\n\n## 使用Docker创建新的镜像\n\n### 检索Docker仓库中的Ubuntu镜像\n\n```\n[root@Docker ~]# docker search ubuntu\nNAME                             DESCRIPTION                                     STARS     OFFICIAL   AUTOMATED\nubuntu                           Ubuntu is a Debian-based Linux operating sys…   15464     [OK]     \n......\n```\n\n### 获取Ubuntu镜像\n\n```\n[root@Docker ~]# docker pull ubuntu\nUsing default tag: latest\nlatest: Pulling from library/ubuntu\n6e3729cf69e0: Pull complete\nDigest: sha256:27cb6e6ccef575a4698b66f5de06c7ecd61589132d5a91d098f7f3f9285415a9\nStatus: Downloaded newer image for ubuntu:latest\ndocker.io/library/ubuntu:latest\n```\n\n### 查看本地Docker镜像\n\n```\n[root@Docker ~]# docker images\nREPOSITORY    TAG       IMAGE ID       CREATED         SIZE\nubuntu        latest    6b7dfa7e8fdb   5 weeks ago     77.8MB\nhello-world   latest    feb5d9fea6a5   16 months ago   13.3kB\n```\n\n> ```\n> Docker镜像列表选项字段说明如下。\n> REPOSITORY  镜像的名称\n> TAG   \t\t    镜像的标签\n> IMAGE ID      镜像的ID\n> CREATED       镜像创建时间\n> SIZE             镜像大小\n> ```\n\n### 启动docker容器\n\n> ```\n> 使用docker run 命令可启动容器，Docker 启动时其执行过程如下。\n> · 检查本地是否存在指定的Docker 镜像，如果不存在将从Docker仓库下载。\n> · 使用Docker 镜像创建并启动Docker 容器。\n> · 为Docker容器分配一个文件系统，并在只读的镜像层外面挂载一层可读写层。\n> · 从Docker宿主机中配置的网桥接口中桥接一个虚拟接口到容器。\n> · 从Docker 网络的地址池中分配一个IP地址给当前容器。\n> · 执行用户指定的程序。\n> ` 执行完毕后终止容器。\n> ```\n\n```\n创建基于本地ubuntu镜像的docker容器\n[root@Docker ~]# docker run -it ubuntu /bin/bash\nroot@136156e4c448:/#\nroot@136156e4c448:/# exit\nexit\n[root@Docker ~]#\n```\n\n### 更新并创建Docker镜像\n\n#### 更新ubuntu镜像添加ping\n\n```\n当本地的镜像不能满足日常需求，可从已创建的容器中更新并提交镜像。最新版的ubuntu没有安装ping，本步骤将在ubuntu安装ping，并建立新的镜像\n#启动 ubuntu容器，每次创建容器会产生新的id（9eac21a09449）要记录好\n[root@Docker ~]# docker run -t -i  ubuntu:latest /bin/bash\nroot@9eac21a09449:/# apt update\nGet:1 http://security.ubuntu.com/ubuntu jammy-security InRelease [110 kB]\n......\nroot@9eac21a09449:/# ping jd.com\nbash: ping: command not found\n#安装ping\nroot@9eac21a09449:/# apt-get install -y iputils-ping\nReading package lists... Done\nroot@9eac21a09449:/# ping -c 2 jd.com\nPING jd.com (111.13.149.108) 56(84) bytes of data.\n64 bytes from 111.13.149.108 (111.13.149.108): icmp_seq=1 ttl=127 time=43.7 ms\n64 bytes from 111.13.149.108: icmp_seq=2 ttl=127 time=44.6 ms\n#退出\nroot@9eac21a09449:/# exit\nexit\n#操作完成后可基于该docker容器创建新的docker镜像\n#创建新的docker镜像\n[root@Docker ~]# docker commit -m 'ubuntu增加ping命令' -a 'docker' 9eac21a09449 ping/ubuntu:v2\nsha256:7655d7758bcfa635dde3cf8064602a32ac625100a1b7763e7856ff6052c8abee\n[root@Docker ~]# docker images\nREPOSITORY    TAG       IMAGE ID       CREATED          SIZE\nping/ubuntu   v2        7655d7758bcf   10 seconds ago   120MB\nubuntu        latest    6b7dfa7e8fdb   5 weeks ago      77.8MB\nhello-world   latest    feb5d9fea6a5   16 months ago    13.3kB\n#运行新创建的容器，测试ping\n[root@Docker ~]# docker run -it ping/ubuntu:v2 /bin/bash\nroot@7015378380d7:/# ping jd.com -c 3\nPING jd.com (111.13.149.108) 56(84) bytes of data.\n64 bytes from 111.13.149.108 (111.13.149.108): icmp_seq=1 ttl=127 time=44.1 ms\n64 bytes from 111.13.149.108 (111.13.149.108): icmp_seq=2 ttl=127 time=44.9 ms\n64 bytes from 111.13.149.108: icmp_seq=3 ttl=127 time=45.1 ms\n\n```\n\n#### 使用dockerfile创建镜像\n\n```\nDockerfile是由一系列命令和参数脚本构成的脚本，这些命令可在基础镜像上一次执行，最终创建一个新的Docker镜像\n```\n\n编辑dockerfile\n\n```\n[root@Docker ~]# vi /root/Dockerfile\n#基础镜像信息\nFROM ubuntu\n#维护者信息\nMAINTAINER book_user book@123.com\n#镜像操作指令\nRUN apt update\nRUN apt-get install -y iputils-ping\n#容器启动时执行的命令\nCMD cd /opt\nCMD echo 'new docker' > readme.txt\n```\n\n> Dockerfile中每一个指令都会在镜像上创建一个新的镜像层，每一个指令的前缀都必须是大写的，其创建过程如下\n\n使用docker build 命令从dockerfile文件创建镜像\n\n```\n[root@Docker ~]# docker build -t \"book/ubuntu:v3\" .\n#末尾小数点别忘了，接下来，他就会按照dockerfile文件中的命令一一执行\n\n[root@Docker ~]# docker images\nREPOSITORY    TAG       IMAGE ID       CREATED          SIZE\nbook/ubuntu   v3        90bbd384b2a3   59 seconds ago   120MB\nping/ubuntu   v2        7655d7758bcf   17 minutes ago   120MB\nubuntu        latest    6b7dfa7e8fdb   5 weeks ago      77.8MB\nhello-world   latest    feb5d9fea6a5   16 months ago    13.3kB\n\n#删除本地的docker镜像\n[root@Docker ~]# docker rmi hello-world\nError response from daemon: conflict: unable to remove repository reference \"hello-world\" (must force) - container 5542ae3caafa is using its referenced image feb5d9fea6a5\n出现报错说明container使用到了这个images，删除镜像前需要删除基于此镜像创建的容器\n\n#查询容器列表\n[root@Docker ~]# docker ps -a\nCONTAINER ID   IMAGE            COMMAND       CREATED          STATUS                        PORTS     NAMES\n7015378380d7   ping/ubuntu:v2   \"/bin/bash\"   19 minutes ago   Exited (127) 15 minutes ago             nervous_lamarr\n37ac7bf75dbc   ping/ubuntu:v2   \"/bin/bash\"   19 minutes ago   Exited (0) 19 minutes ago               peaceful_galois\n9eac21a09449   ubuntu:latest    \"/bin/bash\"   32 minutes ago   Exited (130) 26 minutes ago             angry_golick\n136156e4c448   ubuntu           \"/bin/bash\"   34 minutes ago   Exited (130) 33 minutes ago             intelligent_proskuriakova\n5542ae3caafa   hello-world      \"/hello\"      46 minutes ago   Exited (0) 46 minutes ago               pensive_newton\n#删除容器\n[root@Docker ~]# docker rm 5542ae3caafa\n5542ae3caafa\n删除镜像\n[root@Docker ~]# docker rmi hello-world\nUntagged: hello-world:latest\nUntagged: hello-world@sha256:aa0cc8055b82dc2509bed2e19b275c8f463506616377219d9642221ab53cf9fe\nDeleted: sha256:feb5d9fea6a5e9606aa995e879d862b825965ba48de054caab5ef356dc6b3412\nDeleted: sha256:e07ee1baac5fae6a26f30cabfe54a36d3402f96afda318fe0a96cec4ca393359\n\n```\n\n<div class=\"tbsm\" style=\"margin-top:54px;\">\n<div class=\"tbsm-top\"><span><svg t=\"1674654360507\" class=\"icon\" viewBox=\"0 0 1024 1024\" version=\"1.1\" xmlns=\"http://www.w3.org/2000/svg\" p-id=\"987\" data-spm-anchor-id=\"a313x.7781069.0.i0\" width=\"35\" height=\"35\"><path d=\"M410.49 97.74H155.08a56.74 56.74 0 0 0-56.84 56.73V410a56.84 56.84 0 0 0 56.84 56.84h255.41A56.83 56.83 0 0 0 467.32 410V154.58a56.83 56.83 0 0 0-56.83-56.84zM410.49 558.74H155.08a56.74 56.74 0 0 0-56.84 56.73V871a56.84 56.84 0 0 0 56.84 56.84h255.41A56.83 56.83 0 0 0 467.32 871V615.58a56.83 56.83 0 0 0-56.83-56.84zM871.49 558.74H616.08a56.74 56.74 0 0 0-56.84 56.73V871a56.84 56.84 0 0 0 56.84 56.84h255.41A56.83 56.83 0 0 0 928.32 871V615.58a56.83 56.83 0 0 0-56.83-56.84z\" fill=\"#66EEFF\" p-id=\"988\"></path><path d=\"M410.49 558.74h-4.14A475 475 0 0 0 299.52 859.6a481.16 481.16 0 0 0 4.84 68.22h106.13A56.83 56.83 0 0 0 467.32 871V615.58a56.83 56.83 0 0 0-56.83-56.84zM871.49 558.74H616.08a56.74 56.74 0 0 0-56.84 56.73V871a56.84 56.84 0 0 0 56.84 56.84h255.41A56.83 56.83 0 0 0 928.32 871V615.58a56.83 56.83 0 0 0-56.83-56.84z\" fill=\"#C2F8FF\" p-id=\"989\"></path></svg></span><span style=\"font-size:30px;\"> 特别声明</span></div>\n<div class=\"tbsm-wz\">千屹博客旗下的所有文章，是通过本人课堂学习和课外自学所精心整理的知识巨著<br/>难免会有出错的地方<br/>如果细心的你发现了小失误，可以在下方评论区告诉我，或者私信我！<br />非常感谢大家的热烈支持！</div>\n</div>","tags":["Centos 8","Docker"],"categories":["运维"]},{"title":"Centos 8 stream 部署 kvm","url":"/posts/17511/","content":"\n# Centos 8 stream 部署 kvm\n\n## 环境部署\n\n| 网卡模式 | NAT模式       |\n| -------- | :------------ |\n| ip       | 192.168.48.10 |\n| 内存     | 4G            |\n| 核心     | 4             |\n| 硬盘     | 100G          |\n| 功能     | AMD-V         |\n\n### 设置主机名\n\n```\n[root@localhost ~]# hostnamectl set-hostname KVM && bash\n[root@KVM ~]#\n```\n\n### 设置网络\n\n#### 设置虚拟机网络（ens160是NAT模式）\n\n```\n[root@KVM ~]# vi /etc/sysconfig/network-scripts/ifcfg-ens160\nBOOTPROTO=static\nONBOOT=yes\nIPADDR=192.168.48.10\nPREFIX=24\nGATEWAY=192.168.48.2\nDNS1=192.168.48.2\nDOMAIN=114.114.114.114\n[root@KVM ~]# nmcli c reload\n[root@KVM ~]# nmcli c up ens160\nConnection successfully activated (D-Bus active path: /org/freedesktop/NetworkManager/ActiveConnection/4)\n[root@KVM ~]# ip a\n1: lo: <LOOPBACK,UP,LOWER_UP> mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1000\n    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00\n    inet 127.0.0.1/8 scope host lo\n       valid_lft forever preferred_lft forever\n    inet6 ::1/128 scope host\n       valid_lft forever preferred_lft forever\n2: ens160: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc mq state UP group default qlen 1000\n    link/ether 00:0c:29:ce:a9:48 brd ff:ff:ff:ff:ff:ff\n    altname enp3s0\n    inet 192.168.48.10/24 brd 192.168.48.255 scope global noprefixroute ens160\n       valid_lft forever preferred_lft forever\n    inet6 fe80::20c:29ff:fece:a948/64 scope link noprefixroute\n       valid_lft forever preferred_lft forever\n[root@KVM ~]# ping -c 4 jd.com\nPING jd.com (111.13.149.108) 56(84) bytes of data.\n64 bytes from 111.13.149.108 (111.13.149.108): icmp_seq=1 ttl=48 time=47.8 ms\n64 bytes from 111.13.149.108 (111.13.149.108): icmp_seq=2 ttl=48 time=48.2 ms\n64 bytes from 111.13.149.108 (111.13.149.108): icmp_seq=3 ttl=48 time=48.2 ms\n64 bytes from 111.13.149.108 (111.13.149.108): icmp_seq=4 ttl=48 time=48.3 ms\n\n--- jd.com ping statistics ---\n4 packets transmitted, 4 received, 0% packet loss, time 6077ms\nrtt min/avg/max/mdev = 47.845/48.146/48.297/0.235 ms\n```\n\n### 检查虚拟机是否支持虚拟化\n\n#### 勾选cpu虚拟化（宿主机是amd芯片）\n\n![image-20230209225201606](../img/KVM/fbd0cd3b97a357db355dd55a12499b7aa272a7bd.png)\n\n#### 查看虚拟化是否支持\n\n```\n[root@KVM ~]# lscpu\nVirtualization:      AMD-V\n说明已支持虚拟化\n```\n\n### 设置阿里yum源\n\n```\n[root@KVM ~]# cp /etc/yum.repos.d/CentOS-Stream-BaseOS.repo /etc/yum.repos.d/CentOS-Stream-BaseOS.repo.bak\n[root@KVM ~]# sed -i 's/mirrorlist/#mirrorlist/' /etc/yum.repos.d/CentOS-Stream-BaseOS.repo\n[root@KVM ~]# sed -i 's/#baseurl=http:\\/\\/mirror.centos.org/baseurl=http:\\/\\/mirrors.aliyun.com/g' /etc/yum.repos.d/CentOS-Stream-BaseOS.repo\n[root@KVM ~]# yum clean all && yum makecache\n0 files removed\nCentOS Stream 8 - AppStream                                        14 MB/s |  27 MB     00:01\nCentOS Stream 8 - BaseOS                                          4.0 MB/s |  26 MB     00:06\nCentOS Stream 8 - Extras                                           28 kB/s |  18 kB     00:00\nCentOS Stream 8 - Extras common packages                          8.2 kB/s | 5.2 kB     00:00\nMetadata cache created.\n[root@KVM ~]#\n```\n\n## 安装kvm\n\n### 安装kvm及其工具\n\n```\n[root@KVM ~]# yum install qemu-kvm qemu-img  virt-manager libvirt virt-manager libvirt-client virt-install virt-viewer -y\nWaiting for process with pid 8674 to finish.\nLast metadata expiration check: 0:00:05 ago on Sun 08 Jan 2023 06:03:34 AM EST.\nPackage qemu-kvm-15:6.2.0-20.module_el8.7.0+1218+f626c2ff.1.x86_64 is already installed.\nPackage qemu-img-15:6.2.0-20.module_el8.7.0+1218+f626c2ff.1.x86_64 is already installed.\nPackage virt-manager-3.2.0-4.el8.noarch is already installed.\nPackage libvirt-8.0.0-10.module_el8.7.0+1218+f626c2ff.x86_64 is already installed.\nPackage libvirt-client-8.0.0-10.module_el8.7.0+1218+f626c2ff.x86_64 is already installed.\nPackage virt-install-3.2.0-4.el8.noarch is already installed.\nPackage virt-viewer-9.0-11.el8.x86_64 is already installed.\nDependencies resolved.\nNothing to do.\nComplete!\n```\n\n### 启动libvirtd服务\n\n启动服务并设置韦开机自启动，查看状态\n\n```\n[root@KVM ~]# systemctl enable --now libvirtd\n[root@KVM ~]# systemctl status libvirtd\n● libvirtd.service - Virtualization daemon\n   Loaded: loaded (/usr/lib/systemd/system/libvirtd.service; enabled; vendor preset: enabled)\n   Active: active (running) since Sun 2023-01-08 06:05:12 EST; 12s ago\n     Docs: man:libvirtd(8)\n           https://libvirt.org\n```\n\n### 验证是否已加载kvm模块\n\n```\n[root@KVM ~]# lsmod | grep kvm\nkvm_amd               143360  0\nccp                   106496  1 kvm_amd\nkvm                   942080  1 kvm_amd\nirqbypass              16384  1 kvm\n```\n\n```\n[root@KVM ~]# virsh list\n Id   Name   State\n--------------------\n说明kvm安装成功\n```\n\n##  设置宿主机网络（kvm这个机子）\n\n### 查看网络情况\n\nKVN软件安装后默认以NAT方式实现网络通信。为了让KVM虚拟机能够与宿主机、本地主机、互联网相互通信，需将宿主机（KVM这个机子）网络设置为bridge方式。\n\n```\nip a\n```\n\nlo为回环接口，该接口不从外界接收和发送数据包，仅在操作系统内部接收和发送数据包\n\nens160是以太网接口，与网卡对应，每个硬件网卡对应一个以太网接口\n\nvirbr0为虚拟网络接口，由kvm创建，为连接其上的kvm虚拟机网络提供访问外部网络的功能\n\n### 创建bridge\n\n创建 bridge 时需使用nmcli命令创建 br0，并将其绑定到可以正常工作的网络接口上，同时让br0成为连接宿主机与互联网的接口。\n\n```\n[root@KVM ~]# nmcli connection add type bridge con-name br0 ifname br0 autoconnect yes\n\nConnection 'br0' (ac3429bc-907c-4ad1-bd54-bbf39d853a53) successfully added.\n查看是否创建成功\n[root@KVM ~]# nmcli c\nNAME    UUID                                  TYPE      DEVICE\nbr0     ac3429bc-907c-4ad1-bd54-bbf39d853a53  bridge    br0\nens160  0d45e631-b256-4e08-b8d8-2c42b9481594  ethernet  ens160\nvirbr0  7075d19e-a20c-43da-b161-e7c7519febdb  bridge    virbr0\n网桥创建成功后会自动生成配置文件\n[root@KVM ~]# ls -l /etc/sysconfig/network-scripts/\n-rw-r--r--. 1 root root 312 Jan  8 06:20 ifcfg-br0\n-rw-r--r--. 1 root root 365 Jan  8 05:40 ifcfg-ens160\n```\n\n### 设置br0和ens160网卡\n\n将br0桥接到ens160\n\n```\n[root@KVM ~]# vi /etc/sysconfig/network-scripts/ifcfg-br0\nBOOTPROTO=static\nIPADDR=192.168.48.10\nGATEWAY=192.168.48.2\nPREFIX=24\nDNS=114.114.114.114\n[root@KVM ~]# vi /etc/sysconfig/network-scripts/ifcfg-ens160\nBOOTPROTO=none\nBRIDGE=br0\n[root@KVM ~]# nmcli c reload\n[root@KVM ~]# nmcli c drow br0r\n此时如果你是用ssh工具连着的，你会断开，此时你要去vm那里输入\n[root@KVM ~]# nmcli c up br0\n[root@KVM ~]# nmcli c up ens160\n然后等1分钟左右，就可以连上ssh工具了\n```\n\n\n\n```\n测试网络连通性\n[root@KVM ~]# ping -c 2 jd.com\nPING jd.com (211.144.24.218) 56(84) bytes of data.\n64 bytes from 211.144.24.218 (211.144.24.218): icmp_seq=1 ttl=128 time=50.7 ms\n64 bytes from 211.144.24.218 (211.144.24.218): icmp_seq=2 ttl=128 time=51.9 ms\n\n--- jd.com ping statistics ---\n2 packets transmitted, 2 received, 0% packet loss, time 1002ms\nrtt min/avg/max/mdev = 50.683/51.286/51.890/0.644 ms\n[root@KVM ~]#\n```\n\n## 创建kvm虚拟机\n\n| 存储池  | 存放目录  | 内容规划            |\n| ------- | --------- | ------------------- |\n| disk    | /opt/disk | 存放KVM磁盘文件     |\n| 存放iso | /opt/iso  | 存放待安装的ISO文件 |\n\n### 创建iso存储池\n\n```\n[root@KVM ~]# mkdir -p /opt/iso\n[root@KVM ~]# chown root:root /opt/iso/\n[root@KVM ~]# chmod 777 /opt/iso/\n[root@KVM ~]# virsh pool-define-as iso --type dir --target /opt/iso/ \nPool iso--type defined\n#名称为iso的存储池定义成功\n如果名字打错 用\nvirsh pool-destroy [名字]\nvirsh pool-undefine [名字] 删除\n[root@KVM ~]# virsh pool-list --all\n Name   State      Autostart\n------------------------------\n iso    inactive   no\n\n[root@KVM ~]# virsh pool-build iso\nPool iso built\n#创建名为iso的存储池\n[root@KVM ~]# virsh pool-start iso\nPool iso started\n#启动iso存储池\n[root@KVM ~]# virsh pool-autostart iso\nPool iso marked as autostarted\n#设置iso存储池自启动\n查看iso信息\n[root@KVM ~]# virsh pool-info iso\nName:           iso\nUUID:           a966995e-2722-4a3f-a318-e158a642439e\nState:          running\nPersistent:     yes\nAutostart:      yes\nCapacity:       63.84 GiB\nAllocation:     2.75 GiB\nAvailable:      61.09 GiB\n```\n\n### 创建disk存储池\n\n```\n[root@KVM ~]# mkdir -p /opt/disk\n[root@KVM ~]# chown root:root /opt/disk/\n[root@KVM ~]# chmod 777 /opt/disk/\n[root@KVM ~]# virsh pool-define-as disk --type dir --target /opt/disk/ \nPool disk defined\n\n[root@KVM ~]# virsh pool-build disk\nPool disk built\n\n[root@KVM ~]# virsh pool-start disk\nPool disk started\n\n[root@KVM ~]# virsh pool-autostart disk\nPool disk marked as autostarted\n\n[root@KVM ~]# virsh pool-info disk\nName:           disk\nUUID:           30d784dc-386b-46e6-a22b-79a3b3447354\nState:          running\nPersistent:     yes\nAutostart:      yes\nCapacity:       63.84 GiB\nAllocation:     2.75 GiB\nAvailable:      61.09 GiB\n```\n\n### 获取Centos7\n\n#### 下载Centos7最小化版本到ISO目录下（网络方式）\n\n```\n[root@KVM ~]# yum install -y wget\n[root@KVM ~]# wget -O /opt/iso/Centos7.iso https://mirrors.aliyun.com/centos/7.9.2009/isos/x86_64/CentOS-7-x86_64-Minimal-2009.iso\n--2023-01-08 08:09:00--  https://mirrors.aliyun.com/centos/7.9.2009/isos/x86_64/CentOS-7-x86_64-Minimal-2009.iso\nResolving mirrors.aliyun.com (mirrors.aliyun.com)... 120.241.238.243, 120.241.238.242, 120.241.238.241, ...\nConnecting to mirrors.aliyun.com (mirrors.aliyun.com)|120.241.238.243|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 1020264448 (973M) [application/x-cd-image]\nSaving to: ‘/opt/iso/Centos7.iso’\n\n/opt/iso/Centos7.iso     100%[================================>] 973.00M  1.53MB/s    in 10m 54s\n\n2023-01-08 08:19:54 (1.49 MB/s) - ‘/opt/iso/Centos7.iso’ saved [1020264448/1020264448]\n[root@KVM ~]# ll /opt/iso\ntotal 996352\n-rw-r--r--. 1 root root 1020264448 Nov  3  2020 Centos7.iso\n```\n\n#### 也可以本地下载好后，上传至iso目录（本地方式）\n\n下载连接：https://mirrors.aliyun.com/centos/7.9.2009/isos/x86_64/CentOS-7-x86_64-Minimal-2009.iso\n\n```\n[root@KVM ~]# ll /opt/iso\ntotal 996352\n-rw-r--r--. 1 root root 1020264448 Nov  3  2020 Centos7.iso\n```\n\n### 安装Centos7\n\n#### 无界面安装Centos7\n\n```\n[root@KVM ~]# virt-install --virt-type=kvm --name=Centos7 --vcpus=1 --memory=2048 --network bridge=br0,model=virtio --os-type=linux --os-variant=rhel7.7 --location=/opt/iso/Centos7.iso --disk /opt/disk/Centos7.qcow2,format=qcow2,size=10 --console=pty,target_type=serial --graphics=none --extra-args=\"console=tty0 console=ttyS0\"\n\nStarting install...\nRetrieving file vmlinuz...                                                 | 6.5 MB  00:00:00\nRetrieving file initrd.img...                                              |  53 MB  00:00:00\nAllocating 'Centos7.qcow2'                                                 |  10 GB  00:00:00\nRunning text console command: virsh --connect qemu:///system console Centos7\nConnected to domain 'Centos7'\n......\n进入安装界面\n\nConnected to domain 'Centos7'\n  Please make your choice from above ['q' to quit | 'b' to begin installation |\n  'r' to refresh]:   Please make your choice from above ['q' to quit | 'b' to begin installation |\n================================================================================\n================================================================================\nInstallation\n\n 1) [x] Language settings                 2) [!] Time settings\n        (English (United States))                (Timezone is not set.)\n 3) [x] Installation source               4) [x] Software selection\n        (Local media)                            (Minimal Install)\n 5) [!] Installation Destination          6) [x] Kdump\n        (No disks selected)                      (Kdump is enabled)\n 7) [ ] Network configuration             8) [!] Root password\n        (Not connected)                          (Password is not set.)\n 9) [!] User creation\n        (No user will be created)\n  Please make your choice from above ['q' to quit | 'b' to begin installation |\n  'r' to refresh]:   Please make your choice from above ['q' to quit | 'b' to begin installation |\n\n```\n\n#### 输入2设置时区\n\n```\n================================================================================\n================================================================================\nTime settings\n\nTimezone: not set\n\nNTP servers:not configured\n\n 1)  Set timezone\n 2)  Configure NTP servers\n  Please make your choice from above ['q' to quit | 'c' to continue |\n  'r' to refresh]:\n================================================================================\n================================================================================\n按1根据提示选择Asia/shanghai   然后按c\n```\n\n#### 输入5设置磁盘（Installation Destination ）\n\n```\nProbing storage...\nInstallation Destination\n\n[x] 1) : 10 GiB (vda)\n\n1 disk selected; 10 GiB capacity; 10 GiB free ...\n\n  Please make your choice from above ['q' to quit | 'c' to continue |\n  'r' to refresh]:\nAutopartitioning Options\n再按c\n================================================================================\n[ ] 1) Replace Existing Linux system(s)\n\n[x] 2) Use All Space\n\n[ ] 3) Use Free Space\n\nInstallation requires partitioning of your hard drive. Select what space to use\nfor the install target.\n\n  Please make your choice from above ['q' to quit | 'c' to continue |\n  再按c\n================================================================================\nPartition Scheme Options\n\n[ ] 1) Standard Partition\n\n[ ] 2) Btrfs\n\n[x] 3) LVM\n\n[ ] 4) LVM Thin Provisioning\n\nSelect a partition scheme configuration.\n\n  Please make your choice from above ['q' to quit | 'c' to continue |\n  'r' to refresh]: c\nGenerating updated storage configuration\nChecking storage configuration...\n```\n\n#### 按8设置root密码\n\n```\n  'r' to refresh]: 8\n================================================================================\n        (Not connected)\n 9) [!] User creation\n================================================================================\nPlease select new root password. You will have to type it twice.\n\nPassword:\nPassword (confirm):\n================================================================================\n================================================================================\nQuestion\n\nThe password you have provided is weak: The password fails the dictionary check\n- it is too simplistic/systematic.\nWould you like to use it anyway?\n\nPlease respond 'yes' or 'no': yes\n```\n\n#### 全部设置完成后按b确认\n\n```\n  'r' to refresh]: b\n================================================================================\n================================================================================\nProgress\nSetting up the installation environment\n.\nCreating disklabel on /dev/vda\n.\nCreating xfs on /dev/vda1\n.\nCreating lvmpv on /dev/vda2\n.\nCreating swap on /dev/mapper/centos-swap\n.\nCreating xfs on /dev/mapper/centos-root\n.\nRunning pre-installation scripts\n.\nStarting package installation process\n就会开始安装\n```\n\n#### 进入登入界面\n\n```\nCentOS Linux 7 (Core)\nKernel 3.10.0-1160.el7.x86_64 on an x86_64\n\nlocalhost login:\n\n```\n\n## 管理kvm虚拟机\n\n### 连接KVM虚拟机\n\n> ```\n> [root@KVM ~]# virsh console Centos7\n> Connected to domain 'Centos7'\n> Escape character is ^] (Ctrl + ]\n> error: operation failed: Active console session exists for this domain\n> 如果你之前连接过，没有退出，但是你与宿主机的ssh断了，就会出现这种问题，也就是你之前的连接控制台的连接还存在；\n> 每次连接kvm之后要退出 ctrl+] 就可以退出\n> 解决办法：\n> [root@KVM ~]# ps  -ef  |grep virsh\n> root       65402   61750  0 02:26 pts/0    00:00:00 virsh --connect qemu:///system console Centos7\n> root       68540   66569  0 02:35 pts/2    00:00:00 grep --color=auto virsh\n> [root@KVM ~]# kill -9 61750\n> [root@KVM ~]# kill -9 65402\n> ```\n\n#### 查看KVM虚拟机状态\n\n```\n[root@KVM ~]# virsh list\n Id   Name      State\n-------------------------\n 2    Centos7   running\n```\n\n#### 连接虚拟机\n\n```\n[root@KVM ~]# virsh console Centos7\nConnected to domain 'Centos7'\nEscape character is ^] (Ctrl + ]\n\n[root@localhost ~]#\n```\n\n### 初始化KVM虚拟机\n\n#### 设置名字\n\n```\n[root@localhost ~]# hostnamectl set-hostname Centos7 && bash\n[root@centos7 ~]#\n```\n\n#### 设置网络\n\n##### 查看状态\n\n```\n[root@centos7 ~]# ip a\n1: lo: <LOOPBACK,UP,LOWER_UP> mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1000\n    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00\n    inet 127.0.0.1/8 scope host lo\n       valid_lft forever preferred_lft forever\n    inet6 ::1/128 scope host\n       valid_lft forever preferred_lft forever\n2: eth0: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc pfifo_fast state UP group default qlen 1000\n    link/ether 52:54:00:b2:b9:d1 brd ff:ff:ff:ff:ff:ff\n```\n\n##### 编辑配置文件\n\n```\n[root@centos7 ~]# vi /etc/sysconfig/network-scripts/ifcfg-eth0\nTYPE=Ethernet\nPROXY_METHOD=none\nBROWSER_ONLY=no\nBOOTPROTO=static         ---\nDEFROUTE=yes\nIPV4_FAILURE_FATAL=no\nIPV6INIT=yes\nIPV6_AUTOCONF=yes\nIPV6_DEFROUTE=yes\nIPV6_FAILURE_FATAL=no\nIPV6_ADDR_GEN_MODE=stable-privacy\nNAME=eth0\nUUID=b7053508-5183-4ee4-8af5-8d5241f57116\nDEVICE=eth0\nONBOOT=yes                  ---\nIPADDR=192.168.48.11        ---\nPREFIX=24                   ---\nGATEWAY=192.168.48.2        ---\nDNS1=114.114.114.114        ---\n```\n\n##### 查看KVM网络信息\n\n```\n[root@centos7 ~]# systemctl restart network\n[root@centos7 ~]# ip a\n1: lo: <LOOPBACK,UP,LOWER_UP> mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1000\n    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00\n    inet 127.0.0.1/8 scope host lo\n       valid_lft forever preferred_lft forever\n    inet6 ::1/128 scope host\n       valid_lft forever preferred_lft forever\n2: eth0: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc pfifo_fast state UP group default qlen 1000\n    link/ether 52:54:00:b2:b9:d1 brd ff:ff:ff:ff:ff:ff\n    inet 192.168.48.11/24 brd 192.168.48.255 scope global noprefixroute eth0\n       valid_lft forever preferred_lft forever\n    inet6 fe80::85d6:dde0:25ad:9c43/64 scope link noprefixroute\n       valid_lft forever preferred_lft forever\n[root@centos7 ~]#\n```\n\n测试一下ssh工具是不是也可以连（cmd、MobaXterm）\n\n##### 测试连通性\n\n```\nping KVM机子\n[root@centos7 ~]# ping 192.168.48.10 -c 2\nPING 192.168.48.10 (192.168.48.10) 56(84) bytes of data.\n64 bytes from 192.168.48.10: icmp_seq=1 ttl=64 time=0.481 ms\n64 bytes from 192.168.48.10: icmp_seq=2 ttl=64 time=0.254 ms\n\n--- 192.168.48.10 ping statistics ---\n2 packets transmitted, 2 received, 0% packet loss, time 1000ms\nrtt min/avg/max/mdev = 0.254/0.367/0.481/0.115 ms\nping 百度\n[root@centos7 ~]# ping baidu.com -c 2\nPING baidu.com (39.156.66.10) 56(84) bytes of data.\n64 bytes from 39.156.66.10 (39.156.66.10): icmp_seq=1 ttl=128 time=43.5 ms\n64 bytes from 39.156.66.10 (39.156.66.10): icmp_seq=2 ttl=128 time=44.9 ms\n\n--- baidu.com ping statistics ---\n2 packets transmitted, 2 received, 0% packet loss, time 1001ms\nrtt min/avg/max/mdev = 43.599/44.258/44.917/0.659 ms\n[root@centos7 ~]#\n```\n\n#### 设置Centos7虚拟机随KVM宿主机开机自启动\n\n```\n[root@KVM ~]# virsh autostart Centos7\nDomain 'Centos7' marked as autostarted\n\n开机自启动配置后，会在/etc/libvirt/qemu/autostart/目录中增加XML格式\n[root@KVM ~]# ls /etc/libvirt/qemu/autostart/\nCentos7.xml\n```\n\n```\nvirsh autostart --disable 关闭开机自启动\n[root@KVM ~]# virsh autostart --disable Centos7\nDomain 'Centos7' unmarked as autostarted\n```\n\n### 为KVM虚拟机增加CPU\n\n#### 查看Centos7配置信息\n\n```\n[root@KVM ~]# virsh dominfo Centos7\nId:             1\nName:           Centos7\nUUID:           735f1ca1-c82a-4734-81ec-ea3e82e98bae\nOS Type:        hvm\nState:          running\nCPU(s):         1\nCPU time:       17.3s\nMax memory:     2097152 KiB\nUsed memory:    2097152 KiB\nPersistent:     yes\nAutostart:      enable\nManaged save:   no\nSecurity model: selinux\nSecurity DOI:   0\nSecurity label: system_u:system_r:svirt_t:s0:c202,c740 (enforcing)\n```\n\n#### 关闭虚拟机\n\n```\n[root@KVM ~]# virsh shutdown Centos7\nDomain 'Centos7' is being shutdown\n[root@KVM ~]# virsh list --all\n Id   Name      State\n--------------------------\n -    Centos7   shut off\n```\n\n#### 修改Centos7 CPU核心数量\n\n```\n[root@KVM ~]# vi /etc/libvirt/qemu/Centos7.xml\n<domain type='kvm'>\n  <name>Centos7</name>\n  <uuid>735f1ca1-c82a-4734-81ec-ea3e82e98bae</uuid>\n  <metadata>\n    <libosinfo:libosinfo xmlns:libosinfo=\"http://libosinfo.org/xmlns/libvirt/domain/1.0\">\n      <libosinfo:os id=\"http://redhat.com/rhel/7.7\"/>\n    </libosinfo:libosinfo>\n  </metadata>\n  <memory unit='KiB'>2097152</memory>\n  <currentMemory unit='KiB'>2097152</currentMemory>\n  <vcpu placement='static'>2</vcpu>    修改为2\n  <os>\n    <type arch='x86_64' machine='pc-q35-rhel8.6.0'>hvm</type>\n\n```\n\n#### 启动虚拟机并查看配置文件\n\n```\n[root@KVM ~]# virsh start Centos7\nDomain 'Centos7' started\n\n[root@KVM ~]# virsh dominfo Centos7\nId:             1\nName:           Centos7\nUUID:           735f1ca1-c82a-4734-81ec-ea3e82e98bae\nOS Type:        hvm\nState:          running\nCPU(s):         2\nCPU time:       13.4s\nMax memory:     2097152 KiB\nUsed memory:    2097152 KiB\nPersistent:     yes\nAutostart:      enable\nManaged save:   no\nSecurity model: selinux\nSecurity DOI:   0\nSecurity label: system_u:system_r:svirt_t:s0:c414,c924 (enforcing)\n\n[root@KVM ~]#\n```\n\n## 维护虚拟机\n\n### 挂起/恢复虚拟机\n\n```\n[root@KVM ~]# virsh suspend Centos7\nDomain 'Centos7' suspended\n[root@KVM ~]# virsh list --all\n Id   Name      State\n------------------------\n 1    Centos7   paused\n[root@KVM ~]# virsh resume Centos7\nDomain 'Centos7' resumed\n\n[root@KVM ~]# virsh list --all\n Id   Name      State\n-------------------------\n 1    Centos7   running\n```\n\n### 克隆KVM虚拟机\n\n#### 关闭Centos7 并且克隆Centos7为C7\n\n```\n[root@KVM ~]# virsh shutdown Centos7\nDomain 'Centos7' is being shutdown\n\n[root@KVM ~]# virsh list --all\n Id   Name      State\n--------------------------\n -    Centos7   shut off\n\n[root@KVM ~]# virt-clone -o Centos7 -n C7 -f /opt/disk/C7.qcow2\nAllocating 'C7.qcow2'                                                      |  10 GB  00:00:37\n\nClone 'C7' created successfully.\n克隆成功\n[root@KVM ~]# virsh list --all\n Id   Name      State\n--------------------------\n -    C7        shut off\n -    Centos7   shut off\n```\n\n#### 开启C7，登入并且修改主机名为C7\n\n```\n[root@KVM ~]# virsh start C7\nDomain 'C7' started\n\n[root@KVM ~]# virsh console C7\nConnected to domain 'C7'\nEscape character is ^] (Ctrl + ]\nCentOS Linux 7 (Core)\nKernel 3.10.0-1160.el7.x86_64 on an x86_64\n\ncentos7 login: root\nPassword:\nLast login: Mon Jan  9 15:56:16 from 192.168.48.250\n[root@centos7 ~]# hostnamectl set-hostname C7 && bash\n[root@c7 ~]#\n克隆后ip回合Centos7一样，记得后期修改\n```\n\n### 设置Kvm虚拟机快照\n\n#### 登入C7 创建/opt/dev ，关闭虚拟机，创建快照\n\n```\n[root@c7 ~]# mkdir /opt/dev\n[root@c7 ~]# ls /opt\ndev\n按ctrl + ] 退回到KVM宿主机\n[root@KVM ~]# virsh shutdown C7\nDomain 'C7' is being shutdown\n创建快照\n[root@KVM ~]# virsh snapshot-create C7\nDomain snapshot 1673252946 created\n查看C7的快照列表\n[root@KVM ~]# virsh snapshot-list C7\n Name         Creation Time               State\n---------------------------------------------------\n 1673252946   2023-01-09 03:29:06 -0500   shutoff\n```\n\n#### 开启C7 删除/opt/dev ，恢复快照\n\n```\n[root@KVM ~]# virsh start C7\nDomain 'C7' started\n\n[root@KVM ~]# virsh console C7\nConnected to domain 'C7'\n\n[root@c7 ~]# rm -rf /opt/dev\n[root@c7 ~]# ll /opt\ntotal 0\n按ctrl + ] 退回到KVM宿主机\n[root@KVM ~]# virsh snapshot-list C7\n Name         Creation Time               State\n---------------------------------------------------\n 1673252946   2023-01-09 03:29:06 -0500   shutoff\n\n[root@KVM ~]# virsh snapshot-revert C7 1673252946\nvirsh snapshot-revert 虚拟机名字 快照名字 \n```\n\n#### 开启C7,查看是否恢复成功\n\n```\n[root@KVM ~]# virsh start C7\nDomain 'C7' started\n\n[root@KVM ~]# virsh console C7\nConnected to domain 'C7'\nEscape character is ^] (Ctrl + ]\n\nCentOS Linux 7 (Core)\nKernel 3.10.0-1160.el7.x86_64 on an x86_64\n\nc7 login: root\nPassword:\nLast login: Mon Jan  9 16:27:07 on ttyS0\n[root@c7 ~]# ls /opt\ndev\n```\n\n## virsh 命令\n\n```\nvirsh shutdown 关闭KVM虚拟机 \nvirsh destroy 强制关闭KVM虚拟机，不删除虚拟机磁盘，virsh list列表里面看不见，但是磁盘还在，还是可以启动，通过virsh list --all可以查看\nvirsh undefine 彻底删除虚拟机，包括虚拟机存储所在的位置\nvirsh start 开启KVM虚拟机\nvirsh suspend 虚拟机名称 #挂起\nvirsh resume 虚拟机名称 #恢复被挂起的\n```\n\n\n\n<div class=\"tbsm\" style=\"margin-top:54px;\">\n<div class=\"tbsm-top\"><span><svg t=\"1674654360507\" class=\"icon\" viewBox=\"0 0 1024 1024\" version=\"1.1\" xmlns=\"http://www.w3.org/2000/svg\" p-id=\"987\" data-spm-anchor-id=\"a313x.7781069.0.i0\" width=\"35\" height=\"35\"><path d=\"M410.49 97.74H155.08a56.74 56.74 0 0 0-56.84 56.73V410a56.84 56.84 0 0 0 56.84 56.84h255.41A56.83 56.83 0 0 0 467.32 410V154.58a56.83 56.83 0 0 0-56.83-56.84zM410.49 558.74H155.08a56.74 56.74 0 0 0-56.84 56.73V871a56.84 56.84 0 0 0 56.84 56.84h255.41A56.83 56.83 0 0 0 467.32 871V615.58a56.83 56.83 0 0 0-56.83-56.84zM871.49 558.74H616.08a56.74 56.74 0 0 0-56.84 56.73V871a56.84 56.84 0 0 0 56.84 56.84h255.41A56.83 56.83 0 0 0 928.32 871V615.58a56.83 56.83 0 0 0-56.83-56.84z\" fill=\"#66EEFF\" p-id=\"988\"></path><path d=\"M410.49 558.74h-4.14A475 475 0 0 0 299.52 859.6a481.16 481.16 0 0 0 4.84 68.22h106.13A56.83 56.83 0 0 0 467.32 871V615.58a56.83 56.83 0 0 0-56.83-56.84zM871.49 558.74H616.08a56.74 56.74 0 0 0-56.84 56.73V871a56.84 56.84 0 0 0 56.84 56.84h255.41A56.83 56.83 0 0 0 928.32 871V615.58a56.83 56.83 0 0 0-56.83-56.84z\" fill=\"#C2F8FF\" p-id=\"989\"></path></svg></span><span style=\"font-size:30px;\"> 特别声明</span></div>\n<div class=\"tbsm-wz\">千屹博客旗下的所有文章，是通过本人课堂学习和课外自学所精心整理的知识巨著<br/>难免会有出错的地方<br/>如果细心的你发现了小失误，可以在下方评论区告诉我，或者私信我！<br />非常感谢大家的热烈支持！</div>\n</div>","tags":["Centos 8 stream","KVM"],"categories":["运维"]}]