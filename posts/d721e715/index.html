<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0,viewport-fit=cover"><title>大数据hadoop实验 | 严千屹博客</title><meta name="author" content="严千屹"><meta name="copyright" content="严千屹"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="大数据hadoop实验">
<meta property="og:type" content="article">
<meta property="og:title" content="大数据hadoop实验">
<meta property="og:url" content="https://blog.qianyios.top/posts/d721e715/index.html">
<meta property="og:site_name" content="严千屹博客">
<meta property="og:description" content="大数据hadoop实验">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://i0.hdslb.com/bfs/article/daddec263720c95dfc5b4f53b45a96fd55933597.png">
<meta property="article:published_time" content="2025-03-06T10:47:40.000Z">
<meta property="article:modified_time" content="2025-07-12T11:05:14.306Z">
<meta property="article:author" content="严千屹">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://i0.hdslb.com/bfs/article/daddec263720c95dfc5b4f53b45a96fd55933597.png"><script type="application/ld+json">{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "大数据hadoop实验",
  "url": "https://blog.qianyios.top/posts/d721e715/",
  "image": "https://i0.hdslb.com/bfs/article/daddec263720c95dfc5b4f53b45a96fd55933597.png",
  "datePublished": "2025-03-06T10:47:40.000Z",
  "dateModified": "2025-07-12T11:05:14.306Z",
  "author": [
    {
      "@type": "Person",
      "name": "严千屹",
      "url": "https://blog.qianyios.top"
    }
  ]
}</script><link rel="shortcut icon" href="/img/favicon.png"><link rel="canonical" href="https://blog.qianyios.top/posts/d721e715/index.html"><link rel="preconnect"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="/pluginsSrc/@fortawesome/fontawesome-free/css/all.min.css"><link rel="stylesheet" href="/pluginsSrc/node-snackbar/dist/snackbar.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="/pluginsSrc/@fancyapps/ui/dist/fancybox/fancybox.css" media="print" onload="this.media='all'"><script>
    (() => {
      
    const saveToLocal = {
      set: (key, value, ttl) => {
        if (!ttl) return
        const expiry = Date.now() + ttl * 86400000
        localStorage.setItem(key, JSON.stringify({ value, expiry }))
      },
      get: key => {
        const itemStr = localStorage.getItem(key)
        if (!itemStr) return undefined
        const { value, expiry } = JSON.parse(itemStr)
        if (Date.now() > expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return value
      }
    }

    window.btf = {
      saveToLocal,
      getScript: (url, attr = {}) => new Promise((resolve, reject) => {
        const script = document.createElement('script')
        script.src = url
        script.async = true
        Object.entries(attr).forEach(([key, val]) => script.setAttribute(key, val))
        script.onload = script.onreadystatechange = () => {
          if (!script.readyState || /loaded|complete/.test(script.readyState)) resolve()
        }
        script.onerror = reject
        document.head.appendChild(script)
      }),
      getCSS: (url, id) => new Promise((resolve, reject) => {
        const link = document.createElement('link')
        link.rel = 'stylesheet'
        link.href = url
        if (id) link.id = id
        link.onload = link.onreadystatechange = () => {
          if (!link.readyState || /loaded|complete/.test(link.readyState)) resolve()
        }
        link.onerror = reject
        document.head.appendChild(link)
      }),
      addGlobalFn: (key, fn, name = false, parent = window) => {
        if (!false && key.startsWith('pjax')) return
        const globalFn = parent.globalFn || {}
        globalFn[key] = globalFn[key] || {}
        globalFn[key][name || Object.keys(globalFn[key]).length] = fn
        parent.globalFn = globalFn
      }
    }
  
      
      const activateDarkMode = () => {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      const activateLightMode = () => {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }

      btf.activateDarkMode = activateDarkMode
      btf.activateLightMode = activateLightMode

      const theme = saveToLocal.get('theme')
    
          theme === 'dark' ? activateDarkMode() : theme === 'light' ? activateLightMode() : null
        
      
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        document.documentElement.classList.toggle('hide-aside', asideStatus === 'hide')
      }
    
      
    const detectApple = () => {
      if (/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)) {
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
  
    })()
  </script><script>const GLOBAL_CONFIG = {
  root: '/',
  algolia: undefined,
  localSearch: {"path":"/search.json","preload":true,"top_n_per_article":1,"unescape":false,"languages":{"hits_empty":"未找到符合您查询的内容：${query}","hits_stats":"共找到 ${hits} 篇文章"}},
  translate: undefined,
  highlight: {"plugin":"highlight.js","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":200,"highlightFullpage":false,"highlightMacStyle":true},
  copy: {
    success: '复制成功',
    error: '复制失败',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  dateSuffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: {"limitCount":150,"languages":{"author":"作者: 严千屹","link":"链接: ","source":"来源: 严千屹博客","info":"著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。"}},
  lightbox: 'fancybox',
  Snackbar: {"chs_to_cht":"已切换为繁体中文","cht_to_chs":"已切换为简体中文","day_to_night":"已切换为深色模式","night_to_day":"已切换为浅色模式","bgLight":"#49b1f5","bgDark":"#1f1f1f","position":"bottom-left"},
  infinitegrid: {
    js: '/pluginsSrc/@egjs/infinitegrid/dist/infinitegrid.min.js',
    buttonText: '加载更多'
  },
  isPhotoFigcaption: false,
  islazyloadPlugin: false,
  isAnchor: false,
  percent: {
    toc: true,
    rightside: false,
  },
  autoDarkmode: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: '大数据hadoop实验',
  isHighlightShrink: false,
  isToc: true,
  pageType: 'post'
}</script><link rel="stylesheet" href="//at.alicdn.com/t/c/font_1232762_lfyb6ri0kug.css"><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/animate.css/4.1.1/animate.min.css"/><link rel="stylesheet" type="text/css" href="/css/my.css"><meta name="referrer" content="no-referrer"/><meta name="baidu-site-verification" content="codeva-zscxkbTWf7" /><meta name="google-site-verification" content="1zGJFCeeGb41mMQ8kA5KXdLo4_mLIecUtqm5MCX61ZM" /><script defer src="https://cloud.umami.is/script.js" data-website-id="83039d8f-bd3d-4637-bcfa-22c3a2fc0ac1"></script><link rel="stylesheet" href="https://portb.kbai.cc/hexo&amp;kbai/mousezhizhen.css"><script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><meta name="generator" content="Hexo 7.3.0"></head><body><div id="web_bg" style="background-image: url(/img/bg.png);"></div><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img text-center"><img src="/img/fluid.png" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="site-data text-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">54</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">46</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">9</div></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> 友链</span></a></div><div class="menus_item"><span class="site-page group hide"><i class="fa-fw fas fa-list"></i><span> 列表</span><i class="fas fa-chevron-down"></i></span><ul class="menus_item_child"><li><a class="site-page child" href="https://blog.qianyios.top/posts/22484/"><i class="fa-fw iconfont icon-liuyan"></i><span> 公共留言板</span></a></li></ul></div></div></div></div><div class="post" id="body-wrap"><header class="not-top-img" id="page-header"><nav id="nav"><span id="blog-info"><a class="nav-site-title" href="/"><span class="site-name">严千屹博客</span></a><a class="nav-page-title" href="/"><span class="site-name">大数据hadoop实验</span><span class="site-name"><i class="fa-solid fa-circle-arrow-left"></i><span>  返回首页</span></span></a></span><div id="menus"><div id="search-button"><span class="site-page social-icon search"><i class="fas fa-search fa-fw"></i><span> 搜索</span></span></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> 友链</span></a></div><div class="menus_item"><span class="site-page group hide"><i class="fa-fw fas fa-list"></i><span> 列表</span><i class="fas fa-chevron-down"></i></span><ul class="menus_item_child"><li><a class="site-page child" href="https://blog.qianyios.top/posts/22484/"><i class="fa-fw iconfont icon-liuyan"></i><span> 公共留言板</span></a></li></ul></div></div><div id="toggle-menu"><span class="site-page"><i class="fas fa-bars fa-fw"></i></span></div></div></nav></header><main class="layout" id="content-inner"><div id="post"><div id="post-info"><h1 class="post-title">大数据hadoop实验</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2025-03-06T10:47:40.000Z" title="发表于 2025-03-06 18:47:40">2025-03-06</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2025-07-12T11:05:14.306Z" title="更新于 2025-07-12 19:05:14">2025-07-12</time></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-wordcount"><i class="far fa-file-word fa-fw post-meta-icon"></i><span class="post-meta-label">总字数:</span><span class="word-count">22.2k</span><span class="post-meta-separator">|</span><i class="far fa-clock fa-fw post-meta-icon"></i><span class="post-meta-label">阅读时长:</span><span>112分钟</span></span><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title=""><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">浏览量:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div><article class="container post-content" id="article-container"><div id="post-outdate-notice" data="{&quot;limitDay&quot;:365,&quot;messagePrev&quot;:&quot;已经过了&quot;,&quot;messageNext&quot;:&quot;天自上次更新，文章内容可能已过时。&quot;,&quot;postUpdate&quot;:&quot;2025-07-12 19:05:14&quot;}" hidden></div><meta name="referrer" content="no-referrer"/>
<h1 id="大数据hadoop实验">大数据hadoop实验</h1>
<p>镜像下载：<a target="_blank" rel="noopener" href="https://mirrors.aliyun.com/ubuntu-releases/18.04.6/ubuntu-18.04.6-desktop-amd64.iso">ubuntu-18.04.6-desktop-amd64.iso</a></p>
<h2 id="大作业">大作业</h2>
<p>下面两个文档，自己选一个，那个你会用你就用，替换逻辑是一样的</p>
<p>word文档：<a target="_blank" rel="noopener" href="https://alist.qianyios.top/d/%E6%B8%B8%E5%AE%A2/R2/%E4%BD%9C%E4%B8%9A/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%9F%BA%E4%BA%8E%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%B9%B3%E5%8F%B0%E7%9A%84%E9%A1%BE%E5%AE%A2%E8%B4%AD%E4%B9%B0%E8%A1%8C%E4%B8%BA%E8%B6%8B%E5%8A%BF%E5%88%86%E6%9E%90.docx?sign=WsZ6ay6lABomcaX8-x1_5j9nMcyrQp2Iz8stQ0d_4xw=:0">大作业文档</a></p>
<p>markdown文档：<a target="_blank" rel="noopener" href="https://alist.qianyios.top/d/%E6%B8%B8%E5%AE%A2/R2/%E4%BD%9C%E4%B8%9A/%E5%A4%A7%E6%95%B0%E6%8D%AE/markdowan%E5%A4%A7%E4%BD%9C%E4%B8%9A.7z?sign=4bhGZRq7XPtT7js_60e_OdpqaULHor-N2iQ3lQ1ladk=:0">markdown文档</a></p>
<p>下载之后，打开按Ctrl+H进行替换内容</p>
<p>查找内容：<code>student/202206150540/yanjiaxi</code></p>
<p>替换为：<code>student/你的学号/你的名字</code></p>
<p>注意：<code>前后没有斜杠</code></p>
<p>确定之后你就可以自己复制代码运行了</p>
<p>先给自己的虚拟机打快照，在做大作业</p>
<p><img src="/../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/Snipaste_2025-06-03_21-46-51-1749470495094-1.png" alt="Snipaste_2025-06-03_21-46-51"></p>
<h2 id="安装ubuntu系统">安装ubuntu系统</h2>
<p><img src="/../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/ee3dfc4019e734c65139f7592b3d1047697559838-1743071004579-155-1746692007775-376-1747299497349-1-1747900721328-1-1749470495094-2.png" alt="image-20250306172718280"></p>
<p><img src="/../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/f90c48f1768517a761ac0b29e7f1cbd4697559838-1743071004579-156-1746692007776-377-1747299497349-2-1747900721328-2-1749470495094-3.png" alt="image-20250306172858685"></p>
<p><img src="/../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/2ffdc69cf1e6c8963b9d74ebf13149f8697559838-1743071004579-157-1746692007776-378-1747299497349-3-1747900721328-4-1749470495095-4.png" alt="image-20250306172955435"></p>
<p>一路确定就行了</p>
<p><img src="/../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/b9783bd5efab7f47366d1971be6de07b697559838-1743071004579-158-1746692007776-379-1747299497349-4-1747900721328-3-1749470495095-5.png" alt="image-20250306173133874"></p>
<p>设置dhcp模式否则无法联网安装</p>
<p>#dhcp服务</p>
<p><img src="/../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/dfd278fb04265d5ea96ea487ce74d285697559838-1743071004579-159-1746692007776-380-1747299497349-5-1747900721328-5-1749470495095-6.png" alt="image-20250306181204335"></p>
<p>然后开机，然后选择<mark>中文</mark>,然后按提示安装</p>
<p><img src="/../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/1f98e04ec2b7adf765c360075093adc1697559838-1743071004579-160-1746692007776-381-1747299497349-6-1747900721328-6-1749470495095-8.png" alt="image-20250306173400725"></p>
<p><img src="/../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/831b0baf3cb357789b20cbcee155f03b697559838-1743071004579-161-1746692007776-382-1747299497349-7-1747900721328-7-1749470495095-7.png" alt="image-20250306173436631"></p>
<p>然后就开始安装就行了,到后面重启之后，可能会遇到这个界面</p>
<p><img src="/../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/a1b540626e2a073bffee678729200d3c697559838-1743071004579-162-1746692007776-383-1747299497349-8-1747900721328-8-1749470495095-9.png" alt="image-20250308211726292"></p>
<p>解决办法</p>
<p><img src="/../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/001e630863c1f4c32a7f77e9f76eb2a1697559838-1743071004580-163-1746692007776-384-1747299497349-9-1747900721328-9-1749470495095-10.png" alt="image-20250308211858778"></p>
<p>然后你再开机就行了</p>
<p>切换阿里云镜像源</p>
<p><img src="/../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/07352662ff84d9dc914cdd6e0a2a749d697559838-1743071004580-164-1746692007776-385-1747299497349-11-1747900721328-10-1749470495095-12.png" alt="image-20250306182430499"></p>
<p><img src="/../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/dd8381e4110babef193c865e99493d03697559838-1743071004580-165-1746692007776-386-1747299497349-10-1747900721328-11-1749470495095-11.png" alt="image-20250306212359634"></p>
<p>等待更新缓存</p>
<p>到桌面后右键桌面空白处打开终端进行输入下面指令</p>
<p><code>一键安装vm-tools可以实现跨端复制粘贴</code></p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">sudo</span> apt-get install -y wget</span><br><span class="line"><span class="built_in">sudo</span> wget https://resource.qianyios.top/init.sh</span><br><span class="line"><span class="built_in">sudo</span> <span class="built_in">chmod</span> +x init.sh</span><br><span class="line">bash init.sh </span><br></pre></td></tr></table></figure>
<p>接下来重启等待软件生效之后，你就<code>关机</code>，这时候你要<code>打个快照</code>，以便后面做项目出错可以恢复，然后开机</p>
<p><img src="/../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/c91e76a873ad6af429f3fdc1edae8237697559838-1743071004580-166-1746692007776-387-1747299497349-12-1747900721328-12-1749470495095-13.png" alt="image-20250306174127049"></p>
<h2 id="创建hadoop用户">创建hadoop用户</h2>
<p>创建hadoop用户并且设置密码</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sudo useradd -m hadoop -s /bin/bash</span><br><span class="line">sudo passwd hadoop</span><br></pre></td></tr></table></figure>
<p><img src="/../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/8aa05cb5a1b5dc9bf6af23d990b507ca697559838-1743071004580-167-1746692007776-388-1747299497349-13-1747900721328-13-1749470495095-14.png" alt="image-20250306180546505"></p>
<p>给hadoop用户添加sudo权限</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo adduser hadoop sudo</span><br></pre></td></tr></table></figure>
<p><img src="/../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/51d052125ddfbbe9a9005e2a7e8e5dcf697559838-1743071004580-168-1746692007776-389-1747299497349-17-1747900721328-14-1749470495095-18.png" alt="image-20250306180700866"></p>
<p>这时候桌面右上角注销账号切换成hadoop</p>
<p><img src="/../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/387107b5560e971a6f550b631041a66d697559838-1743071004580-169-1746692007776-390-1747299497349-15-1747900721328-15-1749470495095-15.png" alt="image-20250306182143578"></p>
<h2 id="设置ssh免密">设置ssh免密</h2>
<p>一键全部复制，然后粘贴回车就会自动进行免密</p>
<blockquote>
<p>代码中有password=“123456”,记得改成你的hadoop用户的密码</p>
</blockquote>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">sudo</span> <span class="built_in">cat</span> &gt;ssh.sh&lt;&lt;<span class="string">&quot;EOF&quot;</span></span><br><span class="line"><span class="comment">#!/bin/bash</span></span><br><span class="line"><span class="built_in">sudo</span> apt-get install openssh-server -y</span><br><span class="line"><span class="built_in">sudo</span> systemctl <span class="built_in">disable</span> ufw --now</span><br><span class="line"><span class="comment"># 确保 PasswordAuthentication 设置为 yes</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;正在更新 SSH 配置...&quot;</span></span><br><span class="line"><span class="built_in">sudo</span> sed -i <span class="string">&#x27;s/^#*PasswordAuthentication.*/PasswordAuthentication yes/&#x27;</span> /etc/ssh/sshd_config</span><br><span class="line"><span class="built_in">sudo</span> systemctl restart ssh</span><br><span class="line"></span><br><span class="line"><span class="comment"># 安装 sshpass</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;正在安装 sshpass...&quot;</span></span><br><span class="line"><span class="built_in">sudo</span> apt update</span><br><span class="line"><span class="built_in">sudo</span> apt install -y sshpass || &#123; <span class="built_in">echo</span> <span class="string">&quot;安装 sshpass 失败&quot;</span>; <span class="built_in">exit</span> 1; &#125;</span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;sshpass 安装完成。&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建 .ssh 目录并设置权限</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;正在检查 .ssh 目录...&quot;</span></span><br><span class="line"><span class="keyword">if</span> [ ! -d ~/.ssh ]; <span class="keyword">then</span></span><br><span class="line">    <span class="built_in">sudo</span> <span class="built_in">mkdir</span> -p ~/.ssh</span><br><span class="line"><span class="keyword">fi</span></span><br><span class="line"><span class="built_in">sudo</span> <span class="built_in">chmod</span> 700 ~/.ssh</span><br><span class="line"><span class="built_in">sudo</span> <span class="built_in">chown</span> -R hadoop:hadoop ~/.ssh</span><br><span class="line"></span><br><span class="line"><span class="comment"># 目标主机列表</span></span><br><span class="line">hosts=(<span class="string">&quot;localhost&quot;</span>)</span><br><span class="line"><span class="comment"># 密码</span></span><br><span class="line">password=<span class="string">&quot;123456&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 生成 SSH 密钥对</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;正在生成 SSH 密钥对...&quot;</span></span><br><span class="line"><span class="keyword">if</span> [ ! -f ~/.ssh/id_rsa ]; <span class="keyword">then</span></span><br><span class="line">    ssh-keygen -t rsa -N <span class="string">&quot;&quot;</span> -f ~/.ssh/id_rsa || &#123; <span class="built_in">echo</span> <span class="string">&quot;生成 SSH 密钥对失败&quot;</span>; <span class="built_in">exit</span> 1; &#125;</span><br><span class="line"><span class="keyword">fi</span></span><br><span class="line"><span class="built_in">chmod</span> 600 ~/.ssh/id_rsa</span><br><span class="line"><span class="built_in">chmod</span> 644 ~/.ssh/id_rsa.pub</span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;SSH 密钥对已生成。&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 循环遍历目标主机</span></span><br><span class="line"><span class="keyword">for</span> host <span class="keyword">in</span> <span class="string">&quot;<span class="variable">$&#123;hosts[@]&#125;</span>&quot;</span></span><br><span class="line"><span class="keyword">do</span></span><br><span class="line">    <span class="built_in">echo</span> <span class="string">&quot;正在为 <span class="variable">$host</span> 配置免密登录...&quot;</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 确保目标主机的 .ssh 目录存在</span></span><br><span class="line">    sshpass -p <span class="string">&quot;<span class="variable">$password</span>&quot;</span> ssh -o StrictHostKeyChecking=no <span class="string">&quot;<span class="variable">$host</span>&quot;</span> <span class="string">&quot;mkdir -p ~/.ssh &amp;&amp; chmod 700 ~/.ssh&quot;</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 将公钥复制到目标主机</span></span><br><span class="line">    sshpass -p <span class="string">&quot;<span class="variable">$password</span>&quot;</span> ssh-copy-id -i ~/.ssh/id_rsa.pub -o StrictHostKeyChecking=no <span class="string">&quot;<span class="variable">$host</span>&quot;</span> || &#123; <span class="built_in">echo</span> <span class="string">&quot;复制公钥到 <span class="variable">$host</span> 失败&quot;</span>; <span class="built_in">exit</span> 1; &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 验证免密登录是否成功</span></span><br><span class="line">    sshpass -p <span class="string">&quot;<span class="variable">$password</span>&quot;</span> ssh -o StrictHostKeyChecking=no <span class="string">&quot;<span class="variable">$host</span>&quot;</span> <span class="string">&quot;echo &#x27;免密登录成功&#x27;&quot;</span> || &#123; <span class="built_in">echo</span> <span class="string">&quot;验证免密登录失败&quot;</span>; <span class="built_in">exit</span> 1; &#125;</span><br><span class="line"><span class="keyword">done</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;所有配置已完成。&quot;</span></span><br><span class="line">EOF</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>运行脚本</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bash ssh.sh</span><br></pre></td></tr></table></figure>
<p>测试登入localhost是否可以实现无密码登入</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ssh localhost</span><br></pre></td></tr></table></figure>
<p><img src="/../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/f6a283afd9c710caa08e8d0647868159697559838-1743071004580-170-1746692007776-391-1747299497349-14-1747900721328-16-1749470495095-16.png" alt="image-20250306185319755"></p>
<p>成功</p>
<h2 id="安装java和hadoop">安装java和hadoop</h2>
<p>将两个文件复制到下载的目录去</p>
<p><img src="/../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/bf8992440f0c82cf90da81b76c08e388697559838-1743071004580-171-1746692007776-392-1747299497349-16-1747900721328-17-1749470495095-17.png" alt="image-20250306190055853"></p>
<p>然后在这个文件夹下，空白处右键，打开终端</p>
<p><img src="/../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/0efdb8f2156ff61db6acdd5f3d8bc9af697559838-1743071004580-172-1746692007776-393-1747299497349-18-1747900721328-18-1749470495095-19.png" alt="image-20250306190200797"></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">确认一下当前文件夹是不是有这两个文件</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ls</span><br></pre></td></tr></table></figure>
<p><img src="/../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/91661da6fad3b2b9fcc742360031d354697559838-1743071004580-173-1746692007776-394-1747299497349-19-1747900721328-20-1749470495095-20.png" alt="image-20250306190237227"></p>
<p>以下的全部复制运行</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">sudo</span> <span class="built_in">mkdir</span> /usr/lib/jvm</span><br><span class="line"><span class="comment">#安装java8</span></span><br><span class="line"><span class="built_in">sudo</span> tar -xf jdk-8u162-linux-x64.tar.gz  -C /usr/lib/jvm</span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;export JAVA_HOME=/usr/lib/jvm/jdk1.8.0_162&quot;</span> &gt;&gt; ~/.bashrc</span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;export PATH=\$JAVA_HOME/bin:\$PATH&quot;</span> &gt;&gt; ~/.bashrc</span><br><span class="line"><span class="built_in">source</span> ~/.bashrc</span><br><span class="line">java -version</span><br><span class="line"></span><br><span class="line"><span class="comment">#安装hadoop-3.1.3</span></span><br><span class="line"><span class="built_in">sudo</span> tar -zxf hadoop-3.1.3.tar.gz -C /usr/local</span><br><span class="line"><span class="built_in">sudo</span> <span class="built_in">mv</span> /usr/local/hadoop-3.1.3/ /usr/local/hadoop</span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;export HADOOP_HOME=/usr/local/hadoop&quot;</span> &gt;&gt; ~/.bashrc</span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;export PATH=\$HADOOP_HOME/bin/:\$HADOOP_HOME/sbin/:\$PATH&quot;</span> &gt;&gt; ~/.bashrc</span><br><span class="line"><span class="built_in">source</span> ~/.bashrc</span><br><span class="line"><span class="built_in">sudo</span> <span class="built_in">chown</span> -R hadoop /usr/local/hadoop</span><br><span class="line">hadoop version</span><br></pre></td></tr></table></figure>
<blockquote>
<p>这里是作业要截图的地方</p>
</blockquote>
<p><img src="/../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/a160c95403711706a1f827c8e4b2c908697559838-1743071004580-174-1746692007776-395-1747299497350-20-1747900721328-19-1749470495095-22.png" alt="image-20250306191054386"></p>
<p><img src="/../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/1af756c5bb618a59a99925f484d38ba1697559838-1743071004580-175-1746692007776-396-1747299497350-22-1747900721328-21-1749470495095-21.png" alt="image-20250306191150354"></p>
<p>这时候关机打个<code>快照</code>，命名为基础</p>
<h2 id="伪分布安装">伪分布安装</h2>
<h3 id="编写cort-site-yaml文件">编写cort-site.yaml文件</h3>
<p>以下的全部复制运行</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">cat &gt; /usr/local/hadoop/etc/hadoop/core-site.xml&lt;&lt; &quot;EOF&quot;</span><br><span class="line">&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;</span><br><span class="line">&lt;?xml-stylesheet type=&quot;text/xsl&quot; href=&quot;configuration.xsl&quot;?&gt;</span><br><span class="line">&lt;configuration&gt;</span><br><span class="line">    &lt;property&gt;</span><br><span class="line">        &lt;name&gt;hadoop.tmp.dir&lt;/name&gt;</span><br><span class="line">        &lt;value&gt;file:/usr/local/hadoop/tmp&lt;/value&gt;</span><br><span class="line">        &lt;description&gt;Abase for other temporary directories.&lt;/description&gt;</span><br><span class="line">    &lt;/property&gt;</span><br><span class="line">    &lt;property&gt;</span><br><span class="line">        &lt;name&gt;fs.defaultFS&lt;/name&gt;</span><br><span class="line">        &lt;value&gt;hdfs://localhost:9000&lt;/value&gt;</span><br><span class="line">    &lt;/property&gt;</span><br><span class="line">&lt;/configuration&gt;</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure>
<h3 id="编写hdfs-site-xml">编写hdfs-site.xml</h3>
<p>以下的全部复制运行</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">cat &gt;/usr/local/hadoop/etc/hadoop/hdfs-site.xml&lt;&lt;&quot;EOF&quot;</span><br><span class="line">&lt;configuration&gt;</span><br><span class="line">    &lt;property&gt;</span><br><span class="line">        &lt;name&gt;dfs.replication&lt;/name&gt;</span><br><span class="line">        &lt;value&gt;1&lt;/value&gt;</span><br><span class="line">    &lt;/property&gt;</span><br><span class="line">    &lt;property&gt;</span><br><span class="line">        &lt;name&gt;dfs.namenode.name.dir&lt;/name&gt;</span><br><span class="line">        &lt;value&gt;file:/usr/local/hadoop/tmp/dfs/name&lt;/value&gt;</span><br><span class="line">    &lt;/property&gt;</span><br><span class="line">    &lt;property&gt;</span><br><span class="line">        &lt;name&gt;dfs.datanode.data.dir&lt;/name&gt;</span><br><span class="line">        &lt;value&gt;file:/usr/local/hadoop/tmp/dfs/data&lt;/value&gt;</span><br><span class="line">    &lt;/property&gt;</span><br><span class="line">&lt;/configuration&gt;</span><br><span class="line">EOF</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h3 id="启动hhdfs服务">启动hhdfs服务</h3>
<p><code>hdfs初始化</code></p>
<p><code>这条命令只需要运行一次，以后都不要再运行了！！！！！！</code></p>
<p><code>这条命令只需要运行一次，以后都不要再运行了！！！！！！</code></p>
<p><code>这条命令只需要运行一次，以后都不要再运行了！！！！！！</code></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hdfs namenode -format</span><br></pre></td></tr></table></figure>
<p><img src="/../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/00af8b3b067332eed696bb3557ba8acf697559838-1743071004580-176-1746692007776-397-1747299497350-21-1747900721328-22-1749470495095-23.png" alt="image-20250306191818068"></p>
<p>出现这个说明初始化成功</p>
<h3 id="添加hdfs-yarn的环境变量">添加hdfs yarn的环境变量</h3>
<p>以下的全部复制运行</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">echo</span> <span class="string">&quot;export HDFS_NAMENODE_USER=hadoop&quot;</span> &gt;&gt; ~/.bashrc</span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;export HDFS_DATANODE_USER=hadoop&quot;</span> &gt;&gt; ~/.bashrc</span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;export HDFS_SECONDARYNAMENODE_USER=hadoop&quot;</span> &gt;&gt; ~/.bashrc</span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;export YARN_RESOURCEMANAGER_USER=hadoop&quot;</span> &gt;&gt; ~/.bashrc</span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;export YARN_NODEMANAGER_USER=hadoop&quot;</span> &gt;&gt; ~/.bashrc</span><br><span class="line"><span class="built_in">source</span> ~/.bashrc</span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;export JAVA_HOME=/usr/lib/jvm/jdk1.8.0_162&quot;</span> &gt;&gt; /usr/local/hadoop/etc/hadoop/hadoop-env.sh</span><br></pre></td></tr></table></figure>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#开启hadoop的命令</span></span><br><span class="line">start-all.sh</span><br><span class="line"><span class="comment">#当你要关机的时候先运行下面的命令关掉hadoop先，再关机</span></span><br><span class="line">stop-all.sh</span><br></pre></td></tr></table></figure>
<blockquote>
<p>这里是作业要截图的地方</p>
</blockquote>
<p><img src="/../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/6598318c96d7150998b697814614cbe5697559838-1743071004580-177-1746692007776-398-1747299497350-23-1747900721328-23-1749470495095-24.png" alt="image-20250306192423176"></p>
<p>jps命令用来查看进程是否启动，以上是hadoop正常启动的进程，总共有6个</p>
<h3 id="访问hadoop网页">访问hadoop网页</h3>
<p>看看你的ip</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ip a</span><br></pre></td></tr></table></figure>
<p><img src="/../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/5bdaab2f886644715fb131d56b9cc239697559838-1743071004580-178-1746692007776-399-1747299497350-24-1747900721328-24-1749470495095-25.png" alt="image-20250306192632197"></p>
<p>如果你这里没有ip说明你没有开启dhcp服务，自行回到最开始，找开启dhcp的方法，关机开启dhcp，然后开机就会有ip了</p>
<blockquote>
<p>这里是作业要截图的地方</p>
</blockquote>
<p><a target="_blank" rel="noopener" href="http://ip:9870">http://ip:9870</a></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">http://192.168.48.132:9870/</span><br></pre></td></tr></table></figure>
<p><img src="/../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/4dfc296f2ec13a6dfafc20a8f5891d1d697559838-1743071004580-179-1746692007776-400-1747299497350-25-1747900721328-25-1749470495095-27.png" alt="image-20250306192915923"></p>
<p><a target="_blank" rel="noopener" href="http://ip:8088">http://ip:8088</a></p>
<p><img src="/../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/19c347205dca343973b7ee126ce96a6b697559838-1743071004580-180-1746692007777-401-1747299497350-26-1747900721328-26-1749470495095-26.png" alt="image-20250306193032219"></p>
<h3 id="关机步骤">关机步骤</h3>
<p>这时候关闭hadoop集群</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">stop-all.sh</span><br></pre></td></tr></table></figure>
<p>然后关机打快照，命名伪分布</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo poweroff</span><br></pre></td></tr></table></figure>
<p>然后在这里打个快照，命名为伪分布安装成功，等你哪天机子坏了，你就可以恢复快照</p>
<p><img src="/../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/2da7a916c9744aa69041f71f45d21ddc697559838-1743071004580-181-1746692007777-402-1747299497350-27-1747900721328-27-1749470495095-28.png" alt="image-20250318173513618"></p>
<blockquote>
<p>严肃告知，别说我没提醒你，不要直接关机，也不要挂起虚拟机，否则你的虚拟机和hadoop坏了，你就重装吧</p>
<p><img src="/../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/7327d43e46ac634be9f37da89e6d4241697559838-1743071004580-182-1746692007777-403-1747299497350-28-1747900721328-28-1749470495095-29.png" alt="image-20250318173348088"></p>
</blockquote>
<h2 id="第一次实验">第一次实验</h2>
<h3 id="熟悉常用的Linux操作">熟悉常用的Linux操作</h3>
<p>1）cd命令：切换目录</p>
<p>（1） 切换到目录“/usr/local”</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cd /usr/local</span><br></pre></td></tr></table></figure>
<p>（2） 切换到当前目录的上一级目录</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cd ..</span><br></pre></td></tr></table></figure>
<p>（3） 切换到当前登录Linux系统的用户的自己的主文件夹</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cd ~</span><br></pre></td></tr></table></figure>
<p><img src="/../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/c7feb6b1c838be089bc0415e2fee14aa697559838-1743071004581-183-1746692007777-404-1747299497350-29-1747900721328-29-1749470495095-30.png" alt="image-20250313143132503"></p>
<p>2）ls命令：查看文件与目录</p>
<p>查看目录“/usr”下的所有文件和目录</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cd /usr</span><br><span class="line">ls -al</span><br></pre></td></tr></table></figure>
<p><img src="/../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/207e580ee326e3c1ac36d020bb5f9107697559838-1743071004581-184-1746692007777-405-1747299497350-30-1747900721328-30-1749470495095-31.png" alt="image-20250313143140661"></p>
<p>3）mkdir命令：新建目录</p>
<p>（1）进入“/tmp”目录，创建一个名为“a”的目录，并查看“/tmp”目录下已经存在哪些目录</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">cd /tmp</span><br><span class="line">mkdir a</span><br><span class="line">ls -al</span><br></pre></td></tr></table></figure>
<p><img src="/../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/2c3bd5c36f9ab9cef9fd9d0757b816ca697559838-1743071004581-185-1746692007777-406-1747299497350-31-1747900721328-31-1749470495095-32.png" alt="image-20250313143206832"></p>
<p>（2）进入“/tmp”目录，创建目录“a1/a2/a3/a4”</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cd /tmp</span><br><span class="line">mkdir -p a1/a2/a3/a4</span><br></pre></td></tr></table></figure>
<p><img src="/../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/620d448824dba651c9bd4949647ee72a697559838-1743071004581-186-1746692007777-407-1747299497350-32-1747900721328-32-1749470495095-33.png" alt="image-20250313143217857"></p>
<p>4）rmdir命令：删除空的目录</p>
<p>（1）将上面创建的目录a（在“/tmp”目录下面）删除</p>
<p>（2）删除上面创建的目录“a1/a2/a3/a4” （在“/tmp”目录下面），然后查看“/tmp”目录下面存在哪些目录</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">cd /tmp</span><br><span class="line">rmdir a</span><br><span class="line">cd /tmp</span><br><span class="line">rmdir -p a1/a2/a3/a4</span><br><span class="line">ls -al</span><br></pre></td></tr></table></figure>
<p><img src="/../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/d02274363f08a488d8901ebe00e25cca697559838-1743071004581-187-1746692007777-408-1747299497350-33-1747900721328-34-1749470495095-34.png" alt="image-20250313150519301"></p>
<p>5）cp命令：复制文件或目录</p>
<p>（1）将当前用户的主文件夹下的文件.bashrc复制到目录“/usr”下，并重命名为bashrc1</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo cp ~/.bashrc /usr/bashrc1</span><br></pre></td></tr></table></figure>
<p><img src="/../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/97f3fb32f45eb9fc11150ca1cd003f07697559838-1743071004581-188-1746692007777-409-1747299497350-34-1747900721328-33-1749470495095-35.png" alt="image-20250313150547907"></p>
<p>（2）在目录“/tmp”下新建目录test，再把这个目录复制到“/usr”目录下</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">cd /tmp</span><br><span class="line">mkdir test</span><br><span class="line">sudo cp -r /tmp/test /usr</span><br></pre></td></tr></table></figure>
<p><img src="/../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/315577abf317204a01afe6ded7293d3c697559838-1743071004581-189-1746692007777-410-1747299497350-35-1747900721328-35-1749470495095-36.png" alt="image-20250313150608722"></p>
<p>6）mv命令：移动文件与目录，或更名</p>
<p>（1）将“/usr”目录下的文件bashrc1移动到“/usr/test”目录下</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo mv /usr/bashrc1 /usr/test</span><br></pre></td></tr></table></figure>
<p>（2）将“/usr”目录下的test目录重命名为test2</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo mv /usr/test /usr/test2</span><br></pre></td></tr></table></figure>
<p><img src="/../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/b8275a3ec6d53feebd7380e0248c75f0697559838-1743071004581-190-1746692007777-411-1747299497350-36-1747900721328-36-1749470495095-38.png" alt="image-20250313150650543"></p>
<p>7）rm命令：移除文件或目录</p>
<p>（1）将“/usr/test2”目录下的bashrc1文件删除</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo rm /usr/test2/bashrc1</span><br></pre></td></tr></table></figure>
<p>（2）将“/usr”目录下的test2目录删除</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo rm -r /usr/test2</span><br></pre></td></tr></table></figure>
<p><img src="/../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/b447cf3a45829d5e43aaf9a5a59ec0db697559838-1743071004581-191-1746692007777-412-1747299497350-37-1747900721328-37-1749470495095-37.png" alt="image-20250313150701498"></p>
<p>8）cat命令：查看文件内容</p>
<p>查看当前用户主文件夹下的.bashrc文件内容</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cat ~/.bashrc</span><br></pre></td></tr></table></figure>
<p><img src="/../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/a4d6640a8ea734665621d6d9e566704c697559838-1743071004581-192-1746692007777-413-1747299497350-38-1747900721328-38-1749470495095-40.png" alt="image-20250313150717805"></p>
<p>9）tac命令：反向查看文件内容</p>
<p>反向查看当前用户主文件夹下的.bashrc文件的内容</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tac ~/.bashrc</span><br></pre></td></tr></table></figure>
<p><img src="/../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/b6dc096b152e74428be417550aebca41697559838-1743071004581-193-1746692007777-414-1747299497350-39-1747900721329-39-1749470495095-39.png" alt="image-20250313150727016"></p>
<p>10）more命令：一页一页翻动查看</p>
<p>翻页查看当前用户主文件夹下的.bashrc文件的内容</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">more ~/.bashrc</span><br></pre></td></tr></table></figure>
<p><img src="/../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/2b4378e6085504a1a609dab7af2fc4a9697559838-1743071004581-194-1746692007777-415-1747299497350-41-1747900721329-40-1749470495095-41.png" alt="image-20250313150745391"></p>
<p>11）head命令：取出前面几行</p>
<p>（1）查看当前用户主文件夹下.bashrc文件内容前20行</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">head -n 20 ~/.bashrc</span><br></pre></td></tr></table></figure>
<p>（2）查看当前用户主文件夹下.bashrc文件内容，后面50行不显示，只显示前面几行</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">head -n -50 ~/.bashrc</span><br></pre></td></tr></table></figure>
<p><img src="/../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/b8ff8645a0dc3e3577aa7b11982f22c5697559838-1743071004581-195-1746692007777-416-1747299497350-42-1747900721329-41-1749470495095-42.png" alt="image-20250313150813349"></p>
<p>12）tail命令：取出后面几行</p>
<p>（1）查看当前用户主文件夹下.bashrc文件内容最后20行</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tail -n 20 ~/.bashrc</span><br></pre></td></tr></table></figure>
<p>（2）查看当前用户主文件夹下.bashrc文件内容，并且只列出50行以后的数据</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tail -n +50 ~/.bashrc</span><br></pre></td></tr></table></figure>
<p><img src="/../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/c641803b61a67b7b189d1e43dc559178697559838-1743071004581-196-1746692007777-417-1747299497350-40-1747900721329-42-1749470495095-45.png" alt="image-20250313150837188"></p>
<p>13）touch命令：修改文件时间或创建新文件</p>
<p>（1）在“/tmp”目录下创建一个空文件hello，并查看文件时间</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">cd /tmp</span><br><span class="line">touch hello</span><br><span class="line">ls -l hello</span><br></pre></td></tr></table></figure>
<p><img src="/../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/fd031b0f26eb4125f30a4c76b01693fb697559838-1743071004581-197-1746692007777-418-1747299497350-43-1747900721329-43-1749470495095-43.png" alt="image-20250313150847348"></p>
<p>（2）修改hello文件，将文件时间整为5天前</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">touch -d &quot;5 days ago&quot; hello</span><br></pre></td></tr></table></figure>
<p><img src="/../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/c894c82b4795e434fece04c38b09ecc1697559838-1743071004581-198-1746692007777-419-1747299497350-44-1747900721329-44-1749470495095-44.png" alt="image-20250313150952003"></p>
<p>14）chown命令：修改文件所有者权限</p>
<p>将hello文件所有者改为root帐号，并查看属性</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sudo chown root /tmp/hello</span><br><span class="line">ls -l /tmp/hello</span><br></pre></td></tr></table></figure>
<p><img src="/../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/c200b410e0e05a4003ed9d47529f27f8697559838-1743071004581-199-1746692007777-420-1747299497350-47-1747900721329-46-1749470495095-46.png" alt="image-20250313151030899"></p>
<p>15）find命令：文件查找</p>
<p>找出主文件夹下文件名为.bashrc的文件</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">find ~ -name .bashrc</span><br></pre></td></tr></table></figure>
<p><img src="/../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/243db7fb68b2a78a621793f52cf33633697559838-1743071004581-200-1746692007777-421-1747299497350-45-1747900721329-45-1749470495095-48.png" alt="image-20250313151052617"></p>
<p>16）tar命令：压缩命令</p>
<p>（1）在根目录“/”下新建文件夹test，然后在根目录“/”下打包成test.tar.gz</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sudo mkdir /test</span><br><span class="line">sudo tar -zcv -f /test.tar.gz test</span><br></pre></td></tr></table></figure>
<p>（2）把上面的test.tar.gz压缩包，解压缩到“/tmp”目录</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo tar -zxv -f /test.tar.gz -C /tmp</span><br></pre></td></tr></table></figure>
<p><img src="/../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/9a20e406ed55d0e2c113cba8d4e81b5f697559838-1743071004581-201-1746692007778-422-1747299497350-46-1747900721329-47-1749470495095-47.png" alt="image-20250313151121057"></p>
<p>17）grep命令：查找字符串</p>
<p>从“～/.bashrc”文件中查找字符串’examples’</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">grep -n &#x27;examples&#x27; ~/.bashrc</span><br></pre></td></tr></table></figure>
<p><img src="/../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/b4e5f49fa570987ddb3a1a6e32876c11697559838-1743071004581-202-1746692007778-423-1747299497350-48-1747900721329-48-1749470495095-49.png" alt="image-20250313151133044"></p>
<p>18）配置环境变量</p>
<p>（1）请在“～/.bashrc”中设置，配置Java环境变量</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">echo &quot;export JAVA_HOME=/usr/lib/jvm/jdk1.8.0_162&quot; &gt;&gt; ~/.bashrc</span><br><span class="line">echo &quot;export PATH=\$JAVA_HOME/bin:\$PATH&quot; &gt;&gt; ~/.bashrc</span><br><span class="line">source ~/.bashrc</span><br><span class="line">java -version</span><br></pre></td></tr></table></figure>
<p>（2）查看JAVA_HOME变量的值</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">echo $JAVA_HOME</span><br></pre></td></tr></table></figure>
<p><img src="/../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/deef51d65ab888223594404f2c673de1697559838-1743071004581-203-1746692007778-424-1747299497350-49-1747900721329-49-1749470495095-50.png" alt="image-20250313143109134"></p>
<h3 id="熟悉常用的Hadoop操作">熟悉常用的Hadoop操作</h3>
<p>（1）使用hadoop用户登录Linux系统，启动Hadoop（Hadoop的安装目录为“/usr/local/hadoop”），为hadoop用户在HDFS中创建用户目录“/user/hadoop”</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">start-dfs.sh</span><br><span class="line">hdfs dfs -mkdir -p /user/hadoop </span><br></pre></td></tr></table></figure>
<p><img src="/../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/eb9da7727cc112475cfc9c45fb585741697559838-1743071004581-204-1746692007778-425-1747299497350-51-1747900721329-50-1749470495095-51.png" alt="image-20250313151220243"></p>
<p>（2）接着在HDFS的目录“/user/hadoop”下，创建test文件夹，并查看文件列表</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">hdfs dfs -mkdir test</span><br><span class="line">hdfs dfs -ls .</span><br></pre></td></tr></table></figure>
<p><img src="/../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/5b6ce4bdc15610c9f4039ef8f7dbfc91697559838-1743071004581-205-1746692007778-426-1747299497350-50-1747900721329-51-1749470495095-52.png" alt="image-20250313151235040"></p>
<p>（3）将Linux系统本地的“～/.bashrc”文件上传到HDFS的test文件夹中，并查看test</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">hdfs dfs -put ~/.bashrc test</span><br><span class="line">hdfs dfs -ls test</span><br></pre></td></tr></table></figure>
<p><img src="/../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/e501c2993fa20ae4dfefc77cbf50a513697559838-1743071004581-206-1746692007778-427-1747299497350-53-1747900721329-52-1749470495095-54.png" alt="image-20250313151248871"></p>
<p>（4）将HDFS文件夹test复制到Linux系统本地文件系统的“/usr/local/hadoop”目录下</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hdfs dfs -get test ./</span><br></pre></td></tr></table></figure>
<p><img src="/../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/33754f23d00e296f81fd3c3eae2b70f1697559838-1743071004581-207-1746692007778-428-1747299497350-52-1747900721329-53-1749470495095-53.png" alt="image-20250313151433060"></p>
<h2 id="（3-7-3）实验">（3.7.3）实验</h2>
<h3 id="安装eclipse">安装eclipse</h3>
<p>为了提高程序编写和调试效率，本教程采用Eclipse工具编写Java程序。<br>
现在要执行的任务是：假设在目录<code>hdfs://localhost:9000/user/hadoop</code>下面有几个文件，分别是file1.txt、file2.txt、file3.txt、file4.abc和file5.abc，这里需要从该目录中过滤出所有后缀名不为<code>.abc</code>的文件，对过滤之后的文件进行读取，并将这些文件的内容合并到文件<code>hdfs://localhost:9000/user/hadoop/merge.txt</code>中。</p>
<p>要确保HDFS的<code>/user/hadoop</code>目录下已经存在file1.txt、file2.txt、file3.txt、file4.abc和file5.abc，每个文件里面有内容。这里，假设文件内容如下：<br>
file1.txt的内容是： this is file1.txt<br>
file2.txt的内容是： this is file2.txt<br>
file3.txt的内容是： this is file3.txt<br>
file4.abc的内容是： this is file4.abc<br>
file5.abc的内容是： this is file5.abc</p>
<blockquote>
<p>后面我会给命令，上面的内容就先看看</p>
</blockquote>
<p>登入<code>hadoop用户</code>不多说了，启动hadoop集群</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">start-all.sh</span><br></pre></td></tr></table></figure>
<p>下载eclipse安装包到ubuntu的下载目录,然后在空白处右键打开终端</p>
<p><img src="/../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/60c162a765d08e3803ca119480baef99697559838-1743071004582-208-1746692007778-429-1747299497350-54-1747900721329-54-1749470495095-55.png" alt="image-20250318155038350"></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo ls</span><br></pre></td></tr></table></figure>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">sudo</span> tar -zxvf eclipse-4.7.0-linux.gtk.x86_64.tar.gz -C /usr/local </span><br><span class="line"><span class="built_in">sudo</span> <span class="built_in">chown</span> -R hadoop /usr/local/eclipse</span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;export ECLIPSE_HOME=/usr/local/eclipse&quot;</span> &gt;&gt; ~/.bashrc</span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;export PATH=\$ECLIPSE_HOME/:\$PATH&quot;</span> &gt;&gt; ~/.bashrc</span><br><span class="line"><span class="built_in">source</span> ~/.bashrc</span><br></pre></td></tr></table></figure>
<p>启动eclipse</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">eclipse</span><br></pre></td></tr></table></figure>
<h3 id="在Eclipse中创建项目">在Eclipse中创建项目</h3>
<p>启动Eclipse。当Eclipse启动以后，会弹出如下图所示界面，提示设置工作空间（workspace）。</p>
<p><img src="/../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/87b70fbcc1e51f170156e90437e1c0ec697559838-1743071004582-209-1746692007778-430-1747299497350-55-1747900721329-55-1749470495095-56.png" alt="image-20250318160051796"></p>
<p><img src="/../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/065dc77c668bee8eb9fa31623a0bee83697559838-1743071004582-210-1746692007778-431-1747299497350-56-1747900721329-56-1749470495096-57.png" alt="image-20250318160340954"></p>
<p>选择<code>File--&gt;New--&gt;Java Project</code>菜单，开始创建一个Java工程，会弹出如下图所示界面。在<code>Project name</code>后面输入工程名称<code>HDFSExample</code>，选中<code>Use default location</code>，让这个Java工程的所有文件都保存到<code>/home/hadoop/workspace/HDFSExample</code>目录下。在<code>JRE</code>这个选项卡中，可以选择当前的Linux系统中已经安装好的JDK，比如jdk1.8.0_162。然后，点击界面底部的<code>Next&gt;</code>按钮，进入下一步的设置。</p>
<p><img src="/../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/8c4984aa63dd56f996b36b84bc95eabf697559838-1743071004582-211-1746692007778-432-1747299497350-57-1747900721329-57-1749470495096-58.png" alt="image-20250318160434807"></p>
<h3 id="为项目添加需要用到的JAR包">为项目添加需要用到的JAR包</h3>
<p>为了能够运行程序，我们有<code>四个目录</code>的<code>jar包</code>要添加到工程去</p>
<blockquote>
<p>(1)<code>/usr/local/hadoop/share/hadoop/common</code>目录下的所有JAR包，包括</p>
<p><code>hadoop-common-3.1.3.jar</code>、<code>hadoop-kms-3.1.3.jar</code><br>
<code>hadoop-common-3.1.3-tests.jar</code>、<code>hadoop-nfs-3.1.3.jar</code></p>
<p>注意，不包括目录jdiff、lib、sources和webapps；</p>
<hr>
<p>(2)<code>/usr/local/hadoop/share/hadoop/common/lib</code>目录下的所有JAR包；<br>
(3)<code>/usr/local/hadoop/share/hadoop/hdfs</code>目录下的所有JAR包，注意，不包括目录jdiff、lib、sources和webapps；<br>
(4)<code>/usr/local/hadoop/share/hadoop/hdfs/lib</code>目录下的所有JAR包。</p>
</blockquote>
<hr>
<p><code>以下我只演示第一种和第二种!!!!!!!!!</code></p>
<p><code>以下我只演示第一种和第二种!!!!!!!!!</code></p>
<p><code>以下我只演示第一种和第二种!!!!!!!!!</code></p>
<p><code>以下我只演示第一种和第二种!!!!!!!!!</code></p>
<hr>
<p><code>第一种</code></p>
<p><code>/usr/local/hadoop/share/hadoop/common</code>目录下的所有JAR包</p>
<p>点击<code>Add External JARs…</code>按钮，点击其他位置，自己看这个路径定位到这<code>/usr/local/hadoop/share/hadoop/common</code>,选择下面的四个包，然后点击ok</p>
<p><img src="/../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/2472a090934284d0ff7605267cb1e469697559838-1743071004582-212-1746692007778-433-1747299497350-58-1747900721329-58-1749470495096-59.png" alt="image-20250318161304973"></p>
<p><code>第二种</code></p>
<p><code>/usr/local/hadoop/share/hadoop/common/lib</code>目录下的所有JAR包；</p>
<p><img src="/../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/279304c9eac49aaeaeb836fec1d1b792697559838-1743071004582-213-1746692007778-434-1747299497350-59-1747900721329-59-1749470495096-60.png" alt="image-20250318170347078"></p>
<blockquote>
<p>以下两个目录，我就不演示了，如果有文件夹被全选中，你就按住ctrl然后点击文件夹，就可以取消选中了，我们只添加所有后缀名为<code>.jar</code>的包</p>
<p>(3)<code>/usr/local/hadoop/share/hadoop/hdfs</code>目录下的所有JAR包，注意，不包括目录jdiff、lib、sources和webapps；<br>
(4)<code>/usr/local/hadoop/share/hadoop/hdfs/lib</code>目录下的所有JAR包。</p>
</blockquote>
<p>最后是这样的</p>
<p><img src="/../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/6d79a5d1e0a3158a375e0dced25a97bb697559838-1743071004582-214-1746692007778-435-1747299497350-60-1747900721329-60-1749470495096-61.png" alt="image-20250318170435251"></p>
<p><img src="/../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/ea01a0f0daf799e542dd562b75bdbb9c697559838-1743071004582-215-1746692007778-436-1747299497350-61-1747900721329-61-1749470495096-62.png" alt="image-20250318161735778"></p>
<h3 id="编写Java应用程序">编写Java应用程序</h3>
<p><img src="/../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/569602ed23795682d3d79612712be1d3697559838-1743071004582-216-1746692007778-437-1747299497350-62-1747900721329-62-1749470495096-63.png" alt="image-20250318162034984"></p>
<p>在该界面中，只需要在<code>Name</code>后面输入新建的Java类文件的名称，这里采用称<code>MergeFile</code>，其他都可以采用默认设置，然后，点击界面右下角<code>Finish</code>按钮。</p>
<p><img src="/../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/4168e9160a7c8a3163955e0234b253f1697559838-1743071004582-217-1746692007778-438-1747299497350-63-1747900721329-63-1749470495096-64.png" alt="image-20250318162134278"></p>
<p><img src="/../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/0f62d55c83b9297b9ca10da5e0b8a411697559838-1743071004582-218-1746692007778-439-1747299497350-64-1747900721329-64-1749470495096-65.png" alt="image-20250318162458949"></p>
<p>把下面的代码直接写到MergeFile.java,<code>全选复制粘贴</code>，这就不多说了，然后记得<code>Ctrl+S保存</code></p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> java.io.IOException;</span><br><span class="line"><span class="keyword">import</span> java.io.PrintStream;</span><br><span class="line"><span class="keyword">import</span> java.net.URI;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.conf.Configuration;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.fs.*;</span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 过滤掉文件名满足特定条件的文件 </span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">MyPathFilter</span> <span class="keyword">implements</span> <span class="title class_">PathFilter</span> &#123;</span><br><span class="line">     <span class="type">String</span> <span class="variable">reg</span> <span class="operator">=</span> <span class="literal">null</span>; </span><br><span class="line">     MyPathFilter(String reg) &#123;</span><br><span class="line">          <span class="built_in">this</span>.reg = reg;</span><br><span class="line">     &#125;</span><br><span class="line">     <span class="keyword">public</span> <span class="type">boolean</span> <span class="title function_">accept</span><span class="params">(Path path)</span> &#123;</span><br><span class="line">        <span class="keyword">if</span> (!(path.toString().matches(reg)))</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">true</span>;</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">/***</span></span><br><span class="line"><span class="comment"> * 利用FSDataOutputStream和FSDataInputStream合并HDFS中的文件</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">MergeFile</span> &#123;</span><br><span class="line">    <span class="type">Path</span> <span class="variable">inputPath</span> <span class="operator">=</span> <span class="literal">null</span>; <span class="comment">//待合并的文件所在的目录的路径</span></span><br><span class="line">    <span class="type">Path</span> <span class="variable">outputPath</span> <span class="operator">=</span> <span class="literal">null</span>; <span class="comment">//输出文件的路径</span></span><br><span class="line">    <span class="keyword">public</span> <span class="title function_">MergeFile</span><span class="params">(String input, String output)</span> &#123;</span><br><span class="line">        <span class="built_in">this</span>.inputPath = <span class="keyword">new</span> <span class="title class_">Path</span>(input);</span><br><span class="line">        <span class="built_in">this</span>.outputPath = <span class="keyword">new</span> <span class="title class_">Path</span>(output);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">doMerge</span><span class="params">()</span> <span class="keyword">throws</span> IOException &#123;</span><br><span class="line">        <span class="type">Configuration</span> <span class="variable">conf</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Configuration</span>();</span><br><span class="line">        conf.set(<span class="string">&quot;fs.defaultFS&quot;</span>,<span class="string">&quot;hdfs://localhost:9000&quot;</span>);</span><br><span class="line">          conf.set(<span class="string">&quot;fs.hdfs.impl&quot;</span>,<span class="string">&quot;org.apache.hadoop.hdfs.DistributedFileSystem&quot;</span>);</span><br><span class="line">        <span class="type">FileSystem</span> <span class="variable">fsSource</span> <span class="operator">=</span> FileSystem.get(URI.create(inputPath.toString()), conf);</span><br><span class="line">        <span class="type">FileSystem</span> <span class="variable">fsDst</span> <span class="operator">=</span> FileSystem.get(URI.create(outputPath.toString()), conf);</span><br><span class="line">                <span class="comment">//下面过滤掉输入目录中后缀为.abc的文件</span></span><br><span class="line">        FileStatus[] sourceStatus = fsSource.listStatus(inputPath,</span><br><span class="line">                <span class="keyword">new</span> <span class="title class_">MyPathFilter</span>(<span class="string">&quot;.*\\.abc&quot;</span>)); </span><br><span class="line">        <span class="type">FSDataOutputStream</span> <span class="variable">fsdos</span> <span class="operator">=</span> fsDst.create(outputPath);</span><br><span class="line">        <span class="type">PrintStream</span> <span class="variable">ps</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">PrintStream</span>(System.out);</span><br><span class="line">        <span class="comment">//下面分别读取过滤之后的每个文件的内容，并输出到同一个文件中</span></span><br><span class="line">        <span class="keyword">for</span> (FileStatus sta : sourceStatus) &#123;</span><br><span class="line">            <span class="comment">//下面打印后缀不为.abc的文件的路径、文件大小</span></span><br><span class="line">            System.out.print(<span class="string">&quot;路径：&quot;</span> + sta.getPath() + <span class="string">&quot;    文件大小：&quot;</span> + sta.getLen()</span><br><span class="line">                    + <span class="string">&quot;   权限：&quot;</span> + sta.getPermission() + <span class="string">&quot;   内容：&quot;</span>);</span><br><span class="line">            <span class="type">FSDataInputStream</span> <span class="variable">fsdis</span> <span class="operator">=</span> fsSource.open(sta.getPath());</span><br><span class="line">            <span class="type">byte</span>[] data = <span class="keyword">new</span> <span class="title class_">byte</span>[<span class="number">1024</span>];</span><br><span class="line">            <span class="type">int</span> <span class="variable">read</span> <span class="operator">=</span> -<span class="number">1</span>;</span><br><span class="line">            <span class="keyword">while</span> ((read = fsdis.read(data)) &gt; <span class="number">0</span>) &#123;</span><br><span class="line">                ps.write(data, <span class="number">0</span>, read);</span><br><span class="line">                fsdos.write(data, <span class="number">0</span>, read);</span><br><span class="line">            &#125;</span><br><span class="line">            fsdis.close();</span><br><span class="line">        &#125;</span><br><span class="line">        ps.close();</span><br><span class="line">        fsdos.close();</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> IOException &#123;</span><br><span class="line">        <span class="type">MergeFile</span> <span class="variable">merge</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">MergeFile</span>(</span><br><span class="line">                <span class="string">&quot;hdfs://localhost:9000/user/hadoop/&quot;</span>,</span><br><span class="line">                <span class="string">&quot;hdfs://localhost:9000/user/hadoop/merge.txt&quot;</span>);</span><br><span class="line">        merge.doMerge();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="编译运行程序">编译运行程序</h3>
<p>在这里<code>强调一下</code>，如果你没启动hadoop自行启动，我早已在7.1告知启动了</p>
<p>编写测试文件</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">echo</span> <span class="string">&quot;this is file1.txt&quot;</span> &gt; file1.txt</span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;this is file2.txt&quot;</span> &gt; file2.txt</span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;this is file3.txt&quot;</span> &gt; file3.txt</span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;this is file4.abc&quot;</span> &gt; file4.abc</span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;this is file5.abc&quot;</span> &gt; file5.abc</span><br><span class="line">hdfs dfs -<span class="built_in">mkdir</span> -p /user/hadoop</span><br><span class="line">hdfs dfs -put file1.txt /user/hadoop/</span><br><span class="line">hdfs dfs -put file2.txt /user/hadoop/</span><br><span class="line">hdfs dfs -put file3.txt /user/hadoop/</span><br><span class="line">hdfs dfs -put file4.abc /user/hadoop/</span><br><span class="line">hdfs dfs -put file5.abc /user/hadoop/</span><br><span class="line">hdfs dfs -<span class="built_in">ls</span> /user/hadoop</span><br></pre></td></tr></table></figure>
<p><img src="/../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/0acb5d22e3cf68f2eacbdb853adfe764697559838-1743071004582-219-1746692007778-440-1747299497350-65-1747900721329-65-1749470495096-67.png" alt="image-20250318163431895"></p>
<p><img src="/../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/2cb7b57a21bf6cd3bab2afc16a205a93697559838-1743071004582-220-1746692007778-441-1747299497350-66-1747900721329-66-1749470495096-66.png" alt="image-20250318163620255"></p>
<p><img src="/../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/1182eb47d5e3c245b7df9084abc2895e697559838-1743071004582-221-1746692007778-442-1747299497350-67-1747900721329-67-1749470495096-68.png" alt="image-20250318163921782"></p>
<p><img src="/../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/e3d397b4d237e9a0dfec9cd2640d508d697559838-1743071004582-222-1746692007778-443-1747299497350-68-1747900721329-68-1749470495096-69.png" alt="image-20250318171657423"></p>
<p>最后验证是否成功</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hdfs dfs -cat /user/hadoop/merge.txt</span><br></pre></td></tr></table></figure>
<p><img src="/../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/3e1303434798e633dcc66a8275b770ab697559838-1743071004582-223-1746692007778-444-1747299497350-69-1747900721329-69-1749470495096-70.png" alt="image-20250318171722425"></p>
<h3 id="应用程序的部署">应用程序的部署</h3>
<p>因为前面只是在eclipse运行java项目才会生成merge.txt，我们的目的是通过hadoop去执行这个java项目，所以我们要对工程打包</p>
<h4 id="创建myapp目录">创建myapp目录</h4>
<p>目的：用来存放hadoop应用程序目录</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mkdir /usr/local/hadoop/myapp</span><br></pre></td></tr></table></figure>
<h4 id="开始打包程序">开始打包程序</h4>
<p><img src="/../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/6d30b10a743fb22c9d0e7afd672e8659697559838-1743071004582-224-1746692007778-445-1747299497350-70-1747900721329-70-1749470495096-71.png" alt="image-20250318172258928"></p>
<p><code>Launch configuration</code>下拉选择<code>MergeFile-HDFSExample</code></p>
<p><code>Export destination</code>填写 <code>/usr/local/hadoop/myapp/HDFSExample.jar</code></p>
<p><img src="/../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/129b3ca17345b0a0ecf4ab263615f4a0697559838-1743071004582-225-1746692007778-446-1747299497350-71-1747900721329-71-1749470495096-72.png" alt="image-20250318172440560"></p>
<p><img src="/../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/3df4894053094c4a47afb06635f77dd8697559838-1743071004582-226-1746692007779-447-1747299497350-72-1747900721329-72-1749470495096-73.png" alt="image-20250318172512532"></p>
<p><img src="/../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/0d99df2fda8b868a9e76ed3af1bd857b697559838-1743071004582-227-1746692007779-448-1747299497350-73-1747900721329-73-1749470495096-75.png" alt="image-20250318172626710"></p>
<h4 id="查看是否生成">查看是否生成</h4>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ls /usr/local/hadoop/myapp</span><br></pre></td></tr></table></figure>
<p><img src="/../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/1e58d1e9952a02b14a00561e3e864bce697559838-1743071004582-228-1746692007779-449-1747299497350-74-1747900721329-74-1749470495096-74.png" alt="image-20250318172709040"></p>
<h4 id="重新验证项目的运行">重新验证项目的运行</h4>
<p>由于我们在eclipse测试过了项目，之前就在hdfs目录生成了<code>/user/hadoop/merge.txt</code>，为了验证刚刚打包的项目，我们要删掉这个<code>/user/hadoop/merge.txt</code>，等等重新运行项目</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">hdfs dfs -<span class="built_in">rm</span> /user/hadoop/merge.txt</span><br><span class="line">hadoop jar /usr/local/hadoop/myapp/HDFSExample.jar</span><br><span class="line">hdfs dfs -<span class="built_in">cat</span> /user/hadoop/merge.txt</span><br></pre></td></tr></table></figure>
<p><img src="/../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/656a8305fac65693562adc40133628e3697559838-1743071004582-229-1746692007779-450-1747299497350-76-1747900721329-75-1749470495096-76.png" alt="image-20250318173057716"></p>
<p><img src="/../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/4af0f6cf14aa25ff8f53493639441fda697559838-1743071004582-230-1746692007779-451-1747299497350-75-1747900721329-76-1749470495096-77.png" alt="image-20250318173128692"></p>
<p>如果你没事了，要关机了就回到这里<a href="#%E5%85%B3%E6%9C%BA%E6%AD%A5%E9%AA%A4">5.6 关机步骤</a>,去执行关机</p>
<p>顺便把<code>eclipse</code>的窗口关掉</p>
<blockquote>
<p>严肃告知，别说我没提醒你，不要直接关机，也不要挂起虚拟机，否则你的虚拟机和你的hadoop坏了，你就重装，如果你坏了你也可以恢复快照到<code>伪分布安装成功</code>，但是你只是要重新做这周的实验</p>
<p><img src="/../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/7327d43e46ac634be9f37da89e6d4241697559838-1743071004580-182-1746692007777-403-1747299497350-28-1747900721328-28-1749470495095-29.png" alt="image-20250318173348088"></p>
</blockquote>
<h3 id="练习文件">练习文件</h3>
<p>写入文件</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">import org.apache.hadoop.conf.Configuration;  </span><br><span class="line">import org.apache.hadoop.fs.FileSystem;</span><br><span class="line">import org.apache.hadoop.fs.FSDataOutputStream;</span><br><span class="line">import org.apache.hadoop.fs.Path;</span><br><span class="line"> </span><br><span class="line">public class write &#123;    </span><br><span class="line">        public static void main(String[] args) &#123; </span><br><span class="line">                try &#123;</span><br><span class="line">                        Configuration conf = new Configuration();  </span><br><span class="line">                        conf.set(&quot;fs.defaultFS&quot;,&quot;hdfs://localhost:9000&quot;);</span><br><span class="line">                        conf.set(&quot;fs.hdfs.impl&quot;,&quot;org.apache.hadoop.hdfs.DistributedFileSystem&quot;);</span><br><span class="line">                        FileSystem fs = FileSystem.get(conf);</span><br><span class="line">                        byte[] buff = &quot;Hello world&quot;.getBytes(); // 要写入的内容</span><br><span class="line">                        String filename = &quot;gcc-test&quot;; //要写入的文件名</span><br><span class="line">                        FSDataOutputStream os = fs.create(new Path(filename));</span><br><span class="line">                        os.write(buff,0,buff.length);</span><br><span class="line">                        System.out.println(&quot;Create:&quot;+ filename);</span><br><span class="line">                        os.close();</span><br><span class="line">                        fs.close();</span><br><span class="line">                &#125; catch (Exception e) &#123;  </span><br><span class="line">                        e.printStackTrace();  </span><br><span class="line">                &#125;  </span><br><span class="line">        &#125;  </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><img src="/../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/f81d8f19db69bf635b50027d05f3589a697559838-1743071004582-231-1746692007779-452-1747299497350-77-1747900721329-77-1749470495096-78.png" alt="image-20250327152823953"></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">hdfs dfs -ls /user/hadoop</span><br><span class="line">hdfs dfs -cat /user/hadoop/gcc-test</span><br></pre></td></tr></table></figure>
<p><img src="/../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/f70dd011c699b1830f5b92f1229327a0697559838-1746692007779-453-1747299497350-78-1747900721329-78-1749470495096-79.png" alt="image-20250327153115107"></p>
<p>判断文件是否存在</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">import org.apache.hadoop.conf.Configuration;</span><br><span class="line">import org.apache.hadoop.fs.FileSystem;</span><br><span class="line">import org.apache.hadoop.fs.Path;</span><br><span class="line"> </span><br><span class="line">public class panduan &#123;</span><br><span class="line">        public static void main(String[] args) &#123;</span><br><span class="line">                    try &#123;</span><br><span class="line">                            String filename = &quot;gcc-test&quot;;</span><br><span class="line"> </span><br><span class="line">                            Configuration conf = new Configuration();</span><br><span class="line">                            conf.set(&quot;fs.defaultFS&quot;,&quot;hdfs://localhost:9000&quot;);</span><br><span class="line">                            conf.set(&quot;fs.hdfs.impl&quot;,&quot;org.apache.hadoop.hdfs.DistributedFileSystem&quot;);</span><br><span class="line">                            FileSystem fs = FileSystem.get(conf);</span><br><span class="line">                            if(fs.exists(new Path(filename)))&#123;</span><br><span class="line">                                    System.out.println(&quot;文件存在&quot;);</span><br><span class="line">                            &#125;else&#123;</span><br><span class="line">                                    System.out.println(&quot;文件不存在&quot;);</span><br><span class="line">                            &#125;</span><br><span class="line">                            fs.close();</span><br><span class="line">                &#125; catch (Exception e) &#123;</span><br><span class="line">                        e.printStackTrace();</span><br><span class="line">                &#125;</span><br><span class="line">        &#125;</span><br><span class="line">&#125; </span><br></pre></td></tr></table></figure>
<p><img src="/../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/8d1bc9f2d385b1e188e920816c1bb7f3697559838-1746692007779-454-1747299497350-79-1747900721329-79-1749470495096-80.png" alt="image-20250327153328234"></p>
<p>读取文件</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">import java.io.BufferedReader;</span><br><span class="line">import java.io.InputStreamReader;</span><br><span class="line"> </span><br><span class="line">import org.apache.hadoop.conf.Configuration;</span><br><span class="line">import org.apache.hadoop.fs.FileSystem;</span><br><span class="line">import org.apache.hadoop.fs.Path;</span><br><span class="line">import org.apache.hadoop.fs.FSDataInputStream;</span><br><span class="line"> </span><br><span class="line">public class read &#123;</span><br><span class="line">        public static void main(String[] args) &#123;</span><br><span class="line">                try &#123;</span><br><span class="line">                        Configuration conf = new Configuration();</span><br><span class="line">                        conf.set(&quot;fs.defaultFS&quot;,&quot;hdfs://localhost:9000&quot;);</span><br><span class="line">                        conf.set(&quot;fs.hdfs.impl&quot;,&quot;org.apache.hadoop.hdfs.DistributedFileSystem&quot;);</span><br><span class="line">                        FileSystem fs = FileSystem.get(conf);</span><br><span class="line">                        Path file = new Path(&quot;gcc-test&quot;); </span><br><span class="line">                        FSDataInputStream getIt = fs.open(file);</span><br><span class="line">                        BufferedReader d = new BufferedReader(new InputStreamReader(getIt));</span><br><span class="line">                        String content = d.readLine(); //读取文件一行</span><br><span class="line">                        System.out.println(content);</span><br><span class="line">                        d.close(); //关闭文件</span><br><span class="line">                        fs.close(); //关闭hdfs</span><br><span class="line">                &#125; catch (Exception e) &#123;</span><br><span class="line">                        e.printStackTrace();</span><br><span class="line">                &#125;</span><br><span class="line">        &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><img src="/../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/30c4144922fa2e7c0d12ecce042a9174697559838-1746692007779-455-1747299497350-80-1747900721329-80-1749470495096-81.png" alt="image-20250327153426275"></p>
<h2 id="第二次实验">第二次实验</h2>
<p>编程实现以下指定功能，并利用Hadoop提供的Shell命令完成相同的任务。</p>
<p><code>① 向HDFS中上传任意文本文件，如果指定的文件在HDFS中已经存在，由用户指定是追加到原有文件末尾还是覆盖原有的文件。</code></p>
<p><mark>shell</mark></p>
<p>检查文件是否存在，可以使用如下命令:</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">echo</span> <span class="string">&quot;gcc-text&quot;</span> &gt; /home/hadoop/text.txt</span><br><span class="line">hdfs dfs -put /home/hadoop/text.txt /user/hadoop/text.txt</span><br><span class="line">hdfs dfs -<span class="built_in">test</span> -e text.txt</span><br><span class="line"><span class="built_in">echo</span> $?</span><br></pre></td></tr></table></figure>
<p><img src="/../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/732a232a618c74f52551daf4d3d15857697559838-1746692007779-456-1747299497350-81-1747900721329-81-1749470495096-82.png" alt="image-20250327163611055"></p>
<p>返回 <code>0</code> 表示文件存在。</p>
<p>返回 <code>1</code> 表示文件不存在。</p>
<p>如果结果显示文件已经存在，则用户可以选择追加到原来文件末尾或者覆盖原来文件，具体命令如下：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">echo</span> <span class="string">&quot;gcc-local&quot;</span> &gt; /home/hadoop/local.txt</span><br></pre></td></tr></table></figure>
<p><strong><code>local.txt</code></strong> 是本地文件的路径。</p>
<p><strong><code>/text.txt</code></strong> 是 HDFS 中的文件路径。</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#追加到原文件末尾</span></span><br><span class="line">hdfs dfs -appendToFile local.txt text.txt</span><br><span class="line">hdfs dfs -<span class="built_in">cat</span> text.txt</span><br><span class="line"><span class="comment">#覆盖原来文件，第一种命令形式</span></span><br><span class="line">hdfs dfs -copyFromLocal -f  local.txt text.txt</span><br><span class="line">hdfs dfs -<span class="built_in">cat</span> text.txt</span><br><span class="line"><span class="comment">#覆盖原来文件，第二种命令形式</span></span><br><span class="line">hdfs dfs -<span class="built_in">cp</span> -f  file:///home/hadoop/local.txt text.txt</span><br><span class="line">hdfs dfs -<span class="built_in">cat</span> text.txt</span><br></pre></td></tr></table></figure>
<p><img src="/../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/206dd11b8882e95f80f28b4e5b01e072697559838-1746692007779-457-1747299497350-82-1747900721329-82-1749470495096-83.png" alt="image-20250327163724735"></p>
<p><img src="/../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/bd4b3da872ab219749c41ad650c87c4c697559838-1746692007779-458-1747299497350-83-1747900721329-83-1749470495096-84.png" alt="image-20250327163755158"></p>
<p><img src="/../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/abb97e6170286bca4dc7942d1e5327b1697559838-1746692007779-459-1747299497350-84-1747900721329-84-1749470495096-85.png" alt="image-20250327163824318"></p>
<p>实际上，也可以不用上述方式，而是采用<strong>如下命令</strong>来实现：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">hdfs dfs -<span class="built_in">rm</span> text.txt</span><br><span class="line">hdfs dfs -put text.txt </span><br><span class="line">hdfs dfs -<span class="built_in">cat</span> text.txt</span><br><span class="line"><span class="keyword">if</span> $(hdfs dfs -<span class="built_in">test</span> -e text.txt);</span><br><span class="line"><span class="keyword">then</span> $(hdfs dfs -appendToFile local.txt text.txt);</span><br><span class="line"><span class="keyword">else</span> $(hdfs dfs -copyFromLocal -f local.txt text.txt);</span><br><span class="line"><span class="keyword">fi</span></span><br><span class="line">hdfs dfs -<span class="built_in">cat</span> text.txt</span><br></pre></td></tr></table></figure>
<p><img src="/../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/967e82c7f298e509d654c5a019137183697559838-1746692007779-460-1747299497350-86-1747900721329-85-1749470495096-87.png" alt="image-20250327163953466"></p>
<p><mark>Java</mark></p>
<blockquote>
<p><code>我这里只说一次，自己创建好HDFSApi.java后面的每个实验，都会覆盖前面一个实验的代码</code></p>
<p><code>你就不要手欠，去创建别的，你要是自己会也行</code></p>
<p><code>后面就不会再说了</code></p>
<p><img src="/../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/b526634908c47bc47e94463cb3eaf0fa697559838-1746692007779-461-1747299497350-85-1747900721329-86-1749470495096-86.png" alt="image-20250327173112868"></p>
</blockquote>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span>  org.apache.hadoop.conf.Configuration;</span><br><span class="line"><span class="keyword">import</span>  org.apache.hadoop.fs.*;</span><br><span class="line"><span class="keyword">import</span> java.io.*;</span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">HDFSApi</span> &#123;</span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 判断路径是否存在</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="type">boolean</span> <span class="title function_">test</span><span class="params">(Configuration  conf, String path)</span> <span class="keyword">throws</span> IOException &#123;</span><br><span class="line">        <span class="type">FileSystem</span> <span class="variable">fs</span> <span class="operator">=</span> FileSystem.get(conf);</span><br><span class="line">        <span class="keyword">return</span> fs.exists(<span class="keyword">new</span> <span class="title class_">Path</span>(path));</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 复制文件到指定路径</span></span><br><span class="line"><span class="comment">     * 若路径已存在，则进行覆盖</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span>  <span class="title function_">copyFromLocalFile</span><span class="params">(Configuration conf, String localFilePath, String  remoteFilePath)</span> <span class="keyword">throws</span> IOException &#123;</span><br><span class="line">        <span class="type">FileSystem</span> <span class="variable">fs</span> <span class="operator">=</span> FileSystem.get(conf);</span><br><span class="line">        <span class="type">Path</span> <span class="variable">localPath</span> <span class="operator">=</span> <span class="keyword">new</span>  <span class="title class_">Path</span>(localFilePath);</span><br><span class="line">        <span class="type">Path</span> <span class="variable">remotePath</span> <span class="operator">=</span> <span class="keyword">new</span>  <span class="title class_">Path</span>(remoteFilePath);</span><br><span class="line">        <span class="comment">/* fs.copyFromLocalFile 第一个参数表示是否删除源文件，第二个参数表示是否覆盖 */</span></span><br><span class="line">        fs.copyFromLocalFile(<span class="literal">false</span>, <span class="literal">true</span>,  localPath, remotePath);</span><br><span class="line">        fs.close();</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 追加文件内容</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span>  <span class="title function_">appendToFile</span><span class="params">(Configuration conf, String localFilePath, String remoteFilePath)</span>  <span class="keyword">throws</span> IOException &#123;</span><br><span class="line">        <span class="type">FileSystem</span> <span class="variable">fs</span> <span class="operator">=</span> FileSystem.get(conf);</span><br><span class="line">        <span class="type">Path</span> <span class="variable">remotePath</span> <span class="operator">=</span> <span class="keyword">new</span>  <span class="title class_">Path</span>(remoteFilePath);</span><br><span class="line">        <span class="comment">/* 创建一个文件读入流 */</span></span><br><span class="line">        <span class="type">FileInputStream</span> <span class="variable">in</span> <span class="operator">=</span> <span class="keyword">new</span>  <span class="title class_">FileInputStream</span>(localFilePath);</span><br><span class="line">        <span class="comment">/* 创建一个文件输出流，输出的内容将追加到文件末尾 */</span></span><br><span class="line">        <span class="type">FSDataOutputStream</span> <span class="variable">out</span> <span class="operator">=</span>  fs.append(remotePath);</span><br><span class="line">        <span class="comment">/* 读写文件内容 */</span></span><br><span class="line">        <span class="type">byte</span>[] data = <span class="keyword">new</span> <span class="title class_">byte</span>[<span class="number">1024</span>];</span><br><span class="line">        <span class="type">int</span> <span class="variable">read</span> <span class="operator">=</span> -<span class="number">1</span>;</span><br><span class="line">        <span class="keyword">while</span> ( (read = in.read(data)) &gt; <span class="number">0</span>  ) &#123;</span><br><span class="line">            out.write(data,  <span class="number">0</span>, read);</span><br><span class="line">        &#125;</span><br><span class="line">        out.close();</span><br><span class="line">        in.close();</span><br><span class="line">        fs.close();</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 主函数</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span>  &#123;</span><br><span class="line">        <span class="type">Configuration</span> <span class="variable">conf</span> <span class="operator">=</span> <span class="keyword">new</span>  <span class="title class_">Configuration</span>();</span><br><span class="line">        conf.set(<span class="string">&quot;fs.default.name&quot;</span>,<span class="string">&quot;hdfs://localhost:9000&quot;</span>);</span><br><span class="line">        <span class="type">String</span> <span class="variable">localFilePath</span> <span class="operator">=</span>  <span class="string">&quot;/home/hadoop/text.txt&quot;</span>;     <span class="comment">// 本地路径</span></span><br><span class="line">        <span class="type">String</span> <span class="variable">remoteFilePath</span> <span class="operator">=</span>  <span class="string">&quot;/user/hadoop/text.txt&quot;</span>;     <span class="comment">// HDFS路径</span></span><br><span class="line">        <span class="type">String</span> <span class="variable">choice</span> <span class="operator">=</span>  <span class="string">&quot;append&quot;</span>;    <span class="comment">// 若文件存在则追加到文件末尾</span></span><br><span class="line"><span class="comment">//            String choice =  &quot;overwrite&quot;;    // 若文件存在则覆盖</span></span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            <span class="comment">/* 判断文件是否存在 */</span></span><br><span class="line">            <span class="type">Boolean</span> <span class="variable">fileExists</span> <span class="operator">=</span>  <span class="literal">false</span>;</span><br><span class="line">            <span class="keyword">if</span> (HDFSApi.test(conf,  remoteFilePath)) &#123;</span><br><span class="line">                fileExists = <span class="literal">true</span>;</span><br><span class="line">                System.out.println(remoteFilePath  + <span class="string">&quot; 已存在.&quot;</span>);</span><br><span class="line">            &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                System.out.println(remoteFilePath  + <span class="string">&quot; 不存在.&quot;</span>);</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="comment">/* 进行处理 */</span></span><br><span class="line">            <span class="keyword">if</span> ( !fileExists) &#123; <span class="comment">// 文件不存在，则上传</span></span><br><span class="line">                HDFSApi.copyFromLocalFile(conf,  localFilePath, remoteFilePath);</span><br><span class="line">                System.out.println(localFilePath  + <span class="string">&quot; 已上传至 &quot;</span> + remoteFilePath);</span><br><span class="line">            &#125; <span class="keyword">else</span> <span class="keyword">if</span> (  choice.equals(<span class="string">&quot;overwrite&quot;</span>) ) &#123;     <span class="comment">// 选择覆盖</span></span><br><span class="line">                HDFSApi.copyFromLocalFile(conf,  localFilePath, remoteFilePath);</span><br><span class="line">                System.out.println(localFilePath  + <span class="string">&quot; 已覆盖 &quot;</span> + remoteFilePath);</span><br><span class="line">            &#125; <span class="keyword">else</span> <span class="keyword">if</span> (  choice.equals(<span class="string">&quot;append&quot;</span>) ) &#123;    <span class="comment">// 选择追加</span></span><br><span class="line">                HDFSApi.appendToFile(conf,  localFilePath, remoteFilePath);</span><br><span class="line">                System.out.println(localFilePath  + <span class="string">&quot; 已追加至 &quot;</span> + remoteFilePath);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><img src="/../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/31ec101590ca24d894bca6f0f11f6d42697559838-1746692007779-462-1747299497350-87-1747900721329-88-1749470495096-88.png" alt="image-20250327160802735"></p>
<p>验证</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hdfs dfs -cat text.txt</span><br></pre></td></tr></table></figure>
<p><img src="/../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/9574b088a46b592d385e083bc26be07e697559838-1746692007779-463-1747299497350-88-1747900721329-87-1749470495096-89.png" alt="image-20250327173741220"></p>
<p><code>② 从HDFS中下载指定文件，如果本地文件与要下载的文件名称相同，则自动对下载的文件重命名。</code></p>
<p><mark>shell</mark></p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">ls</span> | grep text</span><br><span class="line"><span class="keyword">if</span> $(hdfs dfs -<span class="built_in">test</span> -e  file:///home/hadoop/text.txt);</span><br><span class="line"><span class="keyword">then</span> $(hdfs dfs -copyToLocal text.txt ./text2.txt); </span><br><span class="line"><span class="keyword">else</span> $(hdfs dfs -copyToLocal text.txt ./text.txt); </span><br><span class="line"><span class="keyword">fi</span></span><br><span class="line"><span class="built_in">ls</span> | grep text</span><br></pre></td></tr></table></figure>
<p><img src="/../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/eade1ac0f8ce42ebc36ce74160f7f708697559838-1746692007779-464-1747299497350-89-1747900721329-89-1749470495096-91.png" alt="image-20250327161545345"></p>
<p><mark>Java</mark></p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span>  org.apache.hadoop.conf.Configuration;</span><br><span class="line"><span class="keyword">import</span>  org.apache.hadoop.fs.*;</span><br><span class="line"><span class="keyword">import</span> java.io.*;</span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">HDFSApi</span> &#123;</span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 下载文件到本地</span></span><br><span class="line"><span class="comment">     * 判断本地路径是否已存在，若已存在，则自动进行重命名</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span>  <span class="title function_">copyToLocal</span><span class="params">(Configuration conf, String remoteFilePath, String localFilePath)</span>  <span class="keyword">throws</span> IOException &#123;</span><br><span class="line">        <span class="type">FileSystem</span> <span class="variable">fs</span> <span class="operator">=</span> FileSystem.get(conf);</span><br><span class="line">        <span class="type">Path</span> <span class="variable">remotePath</span> <span class="operator">=</span> <span class="keyword">new</span>  <span class="title class_">Path</span>(remoteFilePath);</span><br><span class="line">        <span class="type">File</span> <span class="variable">f</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">File</span>(localFilePath);</span><br><span class="line">        <span class="comment">/* 如果文件名存在，自动重命名(在文件名后面加上 _0, _1  ...) */</span></span><br><span class="line">        <span class="keyword">if</span> (f.exists()) &#123;</span><br><span class="line">               System.out.println(localFilePath  + <span class="string">&quot; 已存在.&quot;</span>);</span><br><span class="line">               <span class="type">Integer</span>  <span class="variable">i</span> <span class="operator">=</span> <span class="number">0</span>;</span><br><span class="line">               <span class="keyword">while</span>  (<span class="literal">true</span>) &#123;</span><br><span class="line">                      f  = <span class="keyword">new</span> <span class="title class_">File</span>(localFilePath + <span class="string">&quot;_&quot;</span> + i.toString());</span><br><span class="line">                      <span class="keyword">if</span>  (!f.exists()) &#123;</span><br><span class="line">                             localFilePath  = localFilePath + <span class="string">&quot;_&quot;</span> + i.toString();</span><br><span class="line">                             <span class="keyword">break</span>;</span><br><span class="line">                      &#125;</span><br><span class="line">               &#125;</span><br><span class="line">               System.out.println(<span class="string">&quot;将重新命名为: &quot;</span> +  localFilePath);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">// 下载文件到本地</span></span><br><span class="line">       <span class="type">Path</span> <span class="variable">localPath</span> <span class="operator">=</span> <span class="keyword">new</span>  <span class="title class_">Path</span>(localFilePath);</span><br><span class="line">       fs.copyToLocalFile(remotePath,  localPath);</span><br><span class="line">       fs.close();</span><br><span class="line">    &#125;</span><br><span class="line">       <span class="comment">/**</span></span><br><span class="line"><span class="comment">        * 主函数</span></span><br><span class="line"><span class="comment">        */</span></span><br><span class="line">       <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span>  &#123;</span><br><span class="line">              <span class="type">Configuration</span> <span class="variable">conf</span> <span class="operator">=</span> <span class="keyword">new</span>  <span class="title class_">Configuration</span>();</span><br><span class="line">    conf.set(<span class="string">&quot;fs.default.name&quot;</span>,<span class="string">&quot;hdfs://localhost:9000&quot;</span>);</span><br><span class="line">              <span class="type">String</span> <span class="variable">localFilePath</span> <span class="operator">=</span>  <span class="string">&quot;/home/hadoop/text.txt&quot;</span>;     <span class="comment">// 本地路径</span></span><br><span class="line">              <span class="type">String</span> <span class="variable">remoteFilePath</span> <span class="operator">=</span>  <span class="string">&quot;/user/hadoop/text.txt&quot;</span>;     <span class="comment">// HDFS路径</span></span><br><span class="line">              <span class="keyword">try</span> &#123;</span><br><span class="line">                     HDFSApi.copyToLocal(conf,  remoteFilePath, localFilePath);</span><br><span class="line">                     System.out.println(<span class="string">&quot;下载完成&quot;</span>);</span><br><span class="line">              &#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">                     e.printStackTrace();</span><br><span class="line">              &#125;</span><br><span class="line">       &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p><img src="/../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/d0d2c5b5dd466df087017b7f20645a78697559838-1746692007779-465-1747299497350-90-1747900721329-90-1749470495096-92.png" alt="image-20250327173448075"></p>
<p>验证：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">ls</span> | grep text</span><br></pre></td></tr></table></figure>
<p><img src="/../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/5fe0e7c436df931dbaac91c05446504c697559838-1746692007779-466-1747299497351-91-1747900721329-91-1749470495096-90.png" alt="image-20250327162206125"></p>
<p><code>③ 将HDFS中指定文件的内容输出到终端。</code></p>
<p><mark>shell</mark></p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hdfs dfs -<span class="built_in">cat</span> text.txt</span><br></pre></td></tr></table></figure>
<p><img src="/../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/73e2b739dcc8316d62aa83730edf0503697559838-1746692007779-467-1747299497351-92-1747900721329-92-1749470495096-93.png" alt="image-20250327173824043"></p>
<p><mark>Java</mark></p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span>  org.apache.hadoop.conf.Configuration;</span><br><span class="line"><span class="keyword">import</span>  org.apache.hadoop.fs.*;</span><br><span class="line"><span class="keyword">import</span> java.io.*;</span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">HDFSApi</span> &#123;</span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 读取文件内容</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">cat</span><span class="params">(Configuration  conf, String remoteFilePath)</span> <span class="keyword">throws</span> IOException &#123;</span><br><span class="line">        <span class="type">FileSystem</span> <span class="variable">fs</span> <span class="operator">=</span> FileSystem.get(conf);</span><br><span class="line">        <span class="type">Path</span> <span class="variable">remotePath</span> <span class="operator">=</span> <span class="keyword">new</span>  <span class="title class_">Path</span>(remoteFilePath);</span><br><span class="line">        <span class="type">FSDataInputStream</span> <span class="variable">in</span> <span class="operator">=</span>  fs.open(remotePath);</span><br><span class="line">        <span class="type">BufferedReader</span> <span class="variable">d</span> <span class="operator">=</span> <span class="keyword">new</span>  <span class="title class_">BufferedReader</span>(<span class="keyword">new</span> <span class="title class_">InputStreamReader</span>(in));</span><br><span class="line">        <span class="type">String</span> <span class="variable">line</span> <span class="operator">=</span> <span class="literal">null</span>;</span><br><span class="line">        <span class="keyword">while</span> ( (line = d.readLine()) != <span class="literal">null</span>  ) &#123;</span><br><span class="line">              System.out.println(line);</span><br><span class="line">        &#125;</span><br><span class="line">       d.close();</span><br><span class="line">       in.close();</span><br><span class="line">       fs.close();</span><br><span class="line">    &#125;</span><br><span class="line">       <span class="comment">/**</span></span><br><span class="line"><span class="comment">        * 主函数</span></span><br><span class="line"><span class="comment">        */</span></span><br><span class="line">       <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span>  &#123;</span><br><span class="line">              <span class="type">Configuration</span> <span class="variable">conf</span> <span class="operator">=</span> <span class="keyword">new</span>  <span class="title class_">Configuration</span>();</span><br><span class="line">    conf.set(<span class="string">&quot;fs.default.name&quot;</span>,<span class="string">&quot;hdfs://localhost:9000&quot;</span>);</span><br><span class="line">              <span class="type">String</span> <span class="variable">remoteFilePath</span> <span class="operator">=</span>  <span class="string">&quot;/user/hadoop/text.txt&quot;</span>;     <span class="comment">// HDFS路径 </span></span><br><span class="line">              <span class="keyword">try</span> &#123;</span><br><span class="line">                     System.out.println(<span class="string">&quot;读取文件: &quot;</span> +  remoteFilePath);</span><br><span class="line">                     HDFSApi.cat(conf,  remoteFilePath);</span><br><span class="line">                     System.out.println(<span class="string">&quot;\n读取完成&quot;</span>);</span><br><span class="line">              &#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">                     e.printStackTrace();</span><br><span class="line">              &#125;</span><br><span class="line">       &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p><img src="/../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/ff9dc32429797c7ca63268995b6f23d9697559838-1746692007779-468-1747299497351-93-1747900721329-93-1749470495096-94.png" alt="image-20250327173919281"></p>
<p>④ 显示HDFS中指定的文件读写权限、大小、创建时间、路径等信息。</p>
<p><mark>shell</mark></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hdfs dfs -ls -h text.txt</span><br></pre></td></tr></table></figure>
<p><img src="/../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/378b994b1f5bc5db0e9634c4de77d316697559838-1746692007779-469-1747299497351-94-1747900721329-94-1749470495096-95.png" alt="image-20250327174107993"></p>
<p><mark>Java</mark></p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span>  org.apache.hadoop.conf.Configuration;</span><br><span class="line"><span class="keyword">import</span>  org.apache.hadoop.fs.*;</span><br><span class="line"><span class="keyword">import</span> java.io.*;</span><br><span class="line"><span class="keyword">import</span>  java.text.SimpleDateFormat;</span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">HDFSApi</span> &#123;</span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 显示指定文件的信息</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">ls</span><span class="params">(Configuration conf,  String remoteFilePath)</span> <span class="keyword">throws</span> IOException &#123;</span><br><span class="line">        <span class="type">FileSystem</span> <span class="variable">fs</span> <span class="operator">=</span> FileSystem.get(conf);</span><br><span class="line">        <span class="type">Path</span> <span class="variable">remotePath</span> <span class="operator">=</span> <span class="keyword">new</span>  <span class="title class_">Path</span>(remoteFilePath);</span><br><span class="line">        FileStatus[] fileStatuses =  fs.listStatus(remotePath);</span><br><span class="line">        <span class="keyword">for</span> (FileStatus s : fileStatuses) &#123;</span><br><span class="line">               System.out.println(<span class="string">&quot;路径: &quot;</span> +  s.getPath().toString());</span><br><span class="line">               System.out.println(<span class="string">&quot;权限: &quot;</span> +  s.getPermission().toString());</span><br><span class="line">               System.out.println(<span class="string">&quot;大小: &quot;</span> +  s.getLen());</span><br><span class="line">               <span class="comment">/*  返回的是时间戳,转化为时间日期格式 */</span></span><br><span class="line">               <span class="type">Long</span>  <span class="variable">timeStamp</span> <span class="operator">=</span> s.getModificationTime();</span><br><span class="line">               <span class="type">SimpleDateFormat</span>  <span class="variable">format</span> <span class="operator">=</span>  <span class="keyword">new</span>  <span class="title class_">SimpleDateFormat</span>(<span class="string">&quot;yyyy-MM-dd HH:mm:ss&quot;</span>);</span><br><span class="line">               <span class="type">String</span>  <span class="variable">date</span> <span class="operator">=</span> format.format(timeStamp);  </span><br><span class="line">               System.out.println(<span class="string">&quot;时间: &quot;</span> +  date);</span><br><span class="line">        &#125;</span><br><span class="line">        fs.close();</span><br><span class="line">    &#125;</span><br><span class="line">       <span class="comment">/**</span></span><br><span class="line"><span class="comment">        * 主函数</span></span><br><span class="line"><span class="comment">        */</span></span><br><span class="line">       <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span>  &#123;</span><br><span class="line">              <span class="type">Configuration</span> <span class="variable">conf</span> <span class="operator">=</span> <span class="keyword">new</span>  <span class="title class_">Configuration</span>();</span><br><span class="line">    conf.set(<span class="string">&quot;fs.default.name&quot;</span>,<span class="string">&quot;hdfs://localhost:9000&quot;</span>);</span><br><span class="line">              <span class="type">String</span> <span class="variable">remoteFilePath</span> <span class="operator">=</span>  <span class="string">&quot;/user/hadoop/text.txt&quot;</span>;     <span class="comment">// HDFS路径</span></span><br><span class="line">              <span class="keyword">try</span> &#123;</span><br><span class="line">                     System.out.println(<span class="string">&quot;读取文件信息: &quot;</span> +  remoteFilePath);</span><br><span class="line">                     HDFSApi.ls(conf,  remoteFilePath);</span><br><span class="line">                     System.out.println(<span class="string">&quot;\n读取完成&quot;</span>);</span><br><span class="line">              &#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">                     e.printStackTrace();</span><br><span class="line">              &#125;</span><br><span class="line">       &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p><img src="/../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/6e738a4c04440e31fd73f64e1e292fb4697559838-1746692007779-470-1747299497351-95-1747900721329-95-1749470495096-96.png" alt="image-20250327174122828"></p>
<p>⑤ 给定HDFS中某一个目录，输出该目录下的所有文件的读写权限、大小、创建时间、路径等信息，如果该文件是目录，则递归输出该目录下所有文件相关信息。</p>
<p><mark>shell</mark></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hdfs dfs -ls -R -h /user/hadoop</span><br></pre></td></tr></table></figure>
<p><img src="/../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/a01e0de8bc2984748005fa2d1735be70697559838-1746692007779-471-1747299497351-96-1747900721329-96-1749470495097-97.png" alt="image-20250327174252672"></p>
<p><code>别管我这里有什么文件，你能显示出来就行</code></p>
<p><mark>Java</mark></p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span>  org.apache.hadoop.conf.Configuration;</span><br><span class="line"><span class="keyword">import</span>  org.apache.hadoop.fs.*;</span><br><span class="line"><span class="keyword">import</span> java.io.*;</span><br><span class="line"><span class="keyword">import</span>  java.text.SimpleDateFormat;</span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">HDFSApi</span> &#123;</span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 显示指定文件夹下所有文件的信息（递归）</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">lsDir</span><span class="params">(Configuration  conf, String remoteDir)</span> <span class="keyword">throws</span> IOException &#123;</span><br><span class="line">        <span class="type">FileSystem</span> <span class="variable">fs</span> <span class="operator">=</span> FileSystem.get(conf);</span><br><span class="line">        <span class="type">Path</span> <span class="variable">dirPath</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Path</span>(remoteDir);</span><br><span class="line">        <span class="comment">/* 递归获取目录下的所有文件 */</span></span><br><span class="line">         RemoteIterator&lt;LocatedFileStatus&gt; remoteIterator =  fs.listFiles(dirPath, <span class="literal">true</span>);</span><br><span class="line">        <span class="comment">/* 输出每个文件的信息 */</span></span><br><span class="line">        <span class="keyword">while</span> (remoteIterator.hasNext()) &#123;</span><br><span class="line">               <span class="type">FileStatus</span>  <span class="variable">s</span> <span class="operator">=</span> remoteIterator.next();</span><br><span class="line">            System.out.println(<span class="string">&quot;路径: &quot;</span> +  s.getPath().toString());</span><br><span class="line">            System.out.println(<span class="string">&quot;权限: &quot;</span> +  s.getPermission().toString());</span><br><span class="line">            System.out.println(<span class="string">&quot;大小: &quot;</span> +  s.getLen());</span><br><span class="line">               <span class="comment">/*  返回的是时间戳,转化为时间日期格式 */</span></span><br><span class="line">               <span class="type">Long</span>  <span class="variable">timeStamp</span> <span class="operator">=</span> s.getModificationTime();</span><br><span class="line">               <span class="type">SimpleDateFormat</span>  <span class="variable">format</span> <span class="operator">=</span>  <span class="keyword">new</span>  <span class="title class_">SimpleDateFormat</span>(<span class="string">&quot;yyyy-MM-dd HH:mm:ss&quot;</span>);</span><br><span class="line">               <span class="type">String</span>  <span class="variable">date</span> <span class="operator">=</span> format.format(timeStamp);  </span><br><span class="line">               System.out.println(<span class="string">&quot;时间: &quot;</span> +  date);</span><br><span class="line">               System.out.println();</span><br><span class="line">        &#125;</span><br><span class="line">        fs.close();</span><br><span class="line">    &#125;     </span><br><span class="line">       <span class="comment">/**</span></span><br><span class="line"><span class="comment">        * 主函数</span></span><br><span class="line"><span class="comment">        */</span></span><br><span class="line">       <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span>  &#123;</span><br><span class="line">              <span class="type">Configuration</span> <span class="variable">conf</span> <span class="operator">=</span> <span class="keyword">new</span>  <span class="title class_">Configuration</span>();</span><br><span class="line">    conf.set(<span class="string">&quot;fs.default.name&quot;</span>,<span class="string">&quot;hdfs://localhost:9000&quot;</span>);</span><br><span class="line">              <span class="type">String</span> <span class="variable">remoteDir</span> <span class="operator">=</span>  <span class="string">&quot;/user/hadoop&quot;</span>;    <span class="comment">// HDFS路径</span></span><br><span class="line">              <span class="keyword">try</span> &#123;</span><br><span class="line">                     System.out.println(<span class="string">&quot;(递归)读取目录下所有文件的信息: &quot;</span> +  remoteDir);</span><br><span class="line">                     HDFSApi.lsDir(conf,  remoteDir);</span><br><span class="line">                     System.out.println(<span class="string">&quot;读取完成&quot;</span>);</span><br><span class="line">              &#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">                     e.printStackTrace();</span><br><span class="line">              &#125;</span><br><span class="line">       &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p><img src="/../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/64970cdb69adf4ff023608eca537ba91697559838-1746692007780-472-1747299497351-97-1747900721329-97-1749470495097-98.png" alt="image-20250327174420260"></p>
<p>⑥ 提供一个HDFS中的文件的路径，对该文件进行创建和删除操作。如果文件所在目录不存在，则自动创建目录。</p>
<p><mark>shell</mark></p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> $(hdfs dfs -<span class="built_in">test</span> -d dir1/dir2);</span><br><span class="line"><span class="keyword">then</span> $(hdfs dfs -touchz  dir1/dir2/filename);</span><br><span class="line"><span class="keyword">else</span> $(hdfs dfs -<span class="built_in">mkdir</span> -p dir1/dir2  &amp;&amp; hdfs dfs -touchz dir1/dir2/filename); </span><br><span class="line"><span class="keyword">fi</span></span><br><span class="line">hdfs dfs -<span class="built_in">rm</span> dir1/dir2/filename</span><br></pre></td></tr></table></figure>
<p><img src="/../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/f80ef99809ede779b9cb3f1af2335b64697559838-1746692007780-473-1747299497351-98-1747900721329-98-1749470495097-100.png" alt="image-20250327175606597"></p>
<p><mark>Java</mark></p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span>  org.apache.hadoop.conf.Configuration;</span><br><span class="line"><span class="keyword">import</span>  org.apache.hadoop.fs.*;</span><br><span class="line"><span class="keyword">import</span> java.io.*;</span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">HDFSApi</span> &#123;</span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 判断路径是否存在</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="type">boolean</span> <span class="title function_">test</span><span class="params">(Configuration  conf, String path)</span> <span class="keyword">throws</span> IOException &#123;</span><br><span class="line">        <span class="type">FileSystem</span> <span class="variable">fs</span> <span class="operator">=</span> FileSystem.get(conf);</span><br><span class="line">        <span class="keyword">return</span> fs.exists(<span class="keyword">new</span> <span class="title class_">Path</span>(path));</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 创建目录</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="type">boolean</span> <span class="title function_">mkdir</span><span class="params">(Configuration  conf, String remoteDir)</span> <span class="keyword">throws</span> IOException &#123;</span><br><span class="line">        <span class="type">FileSystem</span> <span class="variable">fs</span> <span class="operator">=</span> FileSystem.get(conf);</span><br><span class="line">        <span class="type">Path</span> <span class="variable">dirPath</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Path</span>(remoteDir);</span><br><span class="line">        <span class="type">boolean</span> <span class="variable">result</span> <span class="operator">=</span> fs.mkdirs(dirPath);</span><br><span class="line">        fs.close();</span><br><span class="line">        <span class="keyword">return</span> result;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 创建文件</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">touchz</span><span class="params">(Configuration  conf, String remoteFilePath)</span> <span class="keyword">throws</span> IOException &#123;</span><br><span class="line">        <span class="type">FileSystem</span> <span class="variable">fs</span> <span class="operator">=</span> FileSystem.get(conf);</span><br><span class="line">        <span class="type">Path</span> <span class="variable">remotePath</span> <span class="operator">=</span> <span class="keyword">new</span>  <span class="title class_">Path</span>(remoteFilePath);</span><br><span class="line">        <span class="type">FSDataOutputStream</span> <span class="variable">outputStream</span> <span class="operator">=</span>  fs.create(remotePath);</span><br><span class="line">        outputStream.close();</span><br><span class="line">        fs.close();</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 删除文件</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="type">boolean</span> <span class="title function_">rm</span><span class="params">(Configuration  conf, String remoteFilePath)</span> <span class="keyword">throws</span> IOException &#123;</span><br><span class="line">        <span class="type">FileSystem</span> <span class="variable">fs</span> <span class="operator">=</span> FileSystem.get(conf);</span><br><span class="line">        <span class="type">Path</span> <span class="variable">remotePath</span> <span class="operator">=</span> <span class="keyword">new</span>  <span class="title class_">Path</span>(remoteFilePath);</span><br><span class="line">        <span class="type">boolean</span> <span class="variable">result</span> <span class="operator">=</span>  fs.delete(remotePath, <span class="literal">false</span>);</span><br><span class="line">        fs.close();</span><br><span class="line">        <span class="keyword">return</span> result;</span><br><span class="line">    &#125;</span><br><span class="line">       <span class="comment">/**</span></span><br><span class="line"><span class="comment">        * 主函数</span></span><br><span class="line"><span class="comment">        */</span></span><br><span class="line">       <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span>  &#123;</span><br><span class="line">              <span class="type">Configuration</span> <span class="variable">conf</span> <span class="operator">=</span> <span class="keyword">new</span>  <span class="title class_">Configuration</span>();</span><br><span class="line">    conf.set(<span class="string">&quot;fs.default.name&quot;</span>,<span class="string">&quot;hdfs://localhost:9000&quot;</span>);</span><br><span class="line">              <span class="type">String</span> <span class="variable">remoteFilePath</span> <span class="operator">=</span>  <span class="string">&quot;/user/hadoop/input/text.txt&quot;</span>;     <span class="comment">// HDFS路径</span></span><br><span class="line">              <span class="type">String</span> <span class="variable">remoteDir</span> <span class="operator">=</span>  <span class="string">&quot;/user/hadoop/input&quot;</span>;    <span class="comment">//  HDFS路径对应的目录           </span></span><br><span class="line">              <span class="keyword">try</span> &#123;</span><br><span class="line">                     <span class="comment">/* 判断路径是否存在，存在则删除，否则进行创建 */</span></span><br><span class="line">                     <span class="keyword">if</span> ( HDFSApi.test(conf,  remoteFilePath) ) &#123;</span><br><span class="line">                            HDFSApi.rm(conf,  remoteFilePath); <span class="comment">// 删除</span></span><br><span class="line">                            System.out.println(<span class="string">&quot;删除路径: &quot;</span> +  remoteFilePath);</span><br><span class="line">                     &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                            <span class="keyword">if</span> (  !HDFSApi.test(conf, remoteDir) ) &#123; <span class="comment">// 若目录不存在，则进行创建</span></span><br><span class="line">                                   HDFSApi.mkdir(conf,  remoteDir);</span><br><span class="line">                                   System.out.println(<span class="string">&quot;创建文件夹: &quot;</span> +  remoteDir);</span><br><span class="line">                            &#125;</span><br><span class="line">                            HDFSApi.touchz(conf,  remoteFilePath);</span><br><span class="line">                            System.out.println(<span class="string">&quot;创建路径: &quot;</span> +  remoteFilePath);</span><br><span class="line">                     &#125;</span><br><span class="line">              &#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">                     e.printStackTrace();</span><br><span class="line">              &#125;</span><br><span class="line">       &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p><img src="/../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/a9509597a505b1052be048905290387d697559838-1746692007780-474-1747299497351-99-1747900721329-99-1749470495097-99.png" alt="image-20250327175819965"></p>
<p>⑦ 提供一个HDFS的目录的路径，对该目录进行创建和删除操作。创建目录时，如果目录文件所在目录不存在则自动创建相应目录；删除目录时，由用户指定当该目录不为空时是否还删除该目录。</p>
<p><mark>shell</mark></p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">hdfs dfs -<span class="built_in">mkdir</span> -p dir1/dir2</span><br><span class="line">hdfs dfs -<span class="built_in">rmdir</span> dir1/dir2</span><br><span class="line"><span class="comment">#上述命令执行以后，如果目录非空，则会提示not empty，删除操作不会执行。如果要强制删除目录，可以使用如下命令：</span></span><br><span class="line">hdfs dfs -<span class="built_in">rm</span> -R dir1/dir2</span><br></pre></td></tr></table></figure>
<p><img src="/../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/image-20250327175958011-1746692007780-475-1747299497351-100-1747900721330-100-1749470495097-102.png" alt="image-20250327175958011"></p>
<p><mark>Java</mark></p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span>  org.apache.hadoop.conf.Configuration;</span><br><span class="line"><span class="keyword">import</span>  org.apache.hadoop.fs.*;</span><br><span class="line"><span class="keyword">import</span> java.io.*;</span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">HDFSApi</span> &#123;</span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 判断路径是否存在</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="type">boolean</span> <span class="title function_">test</span><span class="params">(Configuration  conf, String path)</span> <span class="keyword">throws</span> IOException &#123;</span><br><span class="line">        <span class="type">FileSystem</span> <span class="variable">fs</span> <span class="operator">=</span> FileSystem.get(conf);</span><br><span class="line">        <span class="keyword">return</span> fs.exists(<span class="keyword">new</span> <span class="title class_">Path</span>(path));</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 判断目录是否为空</span></span><br><span class="line"><span class="comment">     * true: 空，false: 非空</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="type">boolean</span>  <span class="title function_">isDirEmpty</span><span class="params">(Configuration conf, String remoteDir)</span> <span class="keyword">throws</span> IOException &#123;</span><br><span class="line">        <span class="type">FileSystem</span> <span class="variable">fs</span> <span class="operator">=</span> FileSystem.get(conf);</span><br><span class="line">        <span class="type">Path</span> <span class="variable">dirPath</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Path</span>(remoteDir);</span><br><span class="line">         RemoteIterator&lt;LocatedFileStatus&gt; remoteIterator =  fs.listFiles(dirPath, <span class="literal">true</span>);</span><br><span class="line">        <span class="keyword">return</span> !remoteIterator.hasNext();</span><br><span class="line">    &#125;      </span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 创建目录</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="type">boolean</span> <span class="title function_">mkdir</span><span class="params">(Configuration  conf, String remoteDir)</span> <span class="keyword">throws</span> IOException &#123;</span><br><span class="line">        <span class="type">FileSystem</span> <span class="variable">fs</span> <span class="operator">=</span> FileSystem.get(conf);</span><br><span class="line">        <span class="type">Path</span> <span class="variable">dirPath</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Path</span>(remoteDir);</span><br><span class="line">        <span class="type">boolean</span> <span class="variable">result</span> <span class="operator">=</span> fs.mkdirs(dirPath);</span><br><span class="line">        fs.close();</span><br><span class="line">        <span class="keyword">return</span> result;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 删除目录</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="type">boolean</span> <span class="title function_">rmDir</span><span class="params">(Configuration  conf, String remoteDir)</span> <span class="keyword">throws</span> IOException &#123;</span><br><span class="line">        <span class="type">FileSystem</span> <span class="variable">fs</span> <span class="operator">=</span> FileSystem.get(conf);</span><br><span class="line">        <span class="type">Path</span> <span class="variable">dirPath</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Path</span>(remoteDir);</span><br><span class="line">        <span class="comment">/* 第二个参数表示是否递归删除所有文件 */</span></span><br><span class="line">        <span class="type">boolean</span> <span class="variable">result</span> <span class="operator">=</span> fs.delete(dirPath,  <span class="literal">true</span>);</span><br><span class="line">        fs.close();</span><br><span class="line">        <span class="keyword">return</span> result;</span><br><span class="line">    &#125;</span><br><span class="line">       <span class="comment">/**</span></span><br><span class="line"><span class="comment">        * 主函数</span></span><br><span class="line"><span class="comment">        */</span></span><br><span class="line">       <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span>  &#123;</span><br><span class="line">              <span class="type">Configuration</span> <span class="variable">conf</span> <span class="operator">=</span> <span class="keyword">new</span>  <span class="title class_">Configuration</span>();</span><br><span class="line">    conf.set(<span class="string">&quot;fs.default.name&quot;</span>,<span class="string">&quot;hdfs://localhost:9000&quot;</span>);</span><br><span class="line">              <span class="type">String</span> <span class="variable">remoteDir</span> <span class="operator">=</span>  <span class="string">&quot;/user/hadoop/input&quot;</span>;    <span class="comment">//  HDFS目录</span></span><br><span class="line">              <span class="type">Boolean</span> <span class="variable">forceDelete</span> <span class="operator">=</span>  <span class="literal">false</span>;  <span class="comment">// 是否强制删除</span></span><br><span class="line">              <span class="keyword">try</span> &#123;</span><br><span class="line">                     <span class="comment">/* 判断目录是否存在，不存在则创建，存在则删除 */</span></span><br><span class="line">                     <span class="keyword">if</span> ( !HDFSApi.test(conf,  remoteDir) ) &#123;</span><br><span class="line">                            HDFSApi.mkdir(conf,  remoteDir); <span class="comment">// 创建目录</span></span><br><span class="line">                            System.out.println(<span class="string">&quot;创建目录: &quot;</span> +  remoteDir);</span><br><span class="line">                     &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                            <span class="keyword">if</span> (  HDFSApi.isDirEmpty(conf, remoteDir) || forceDelete ) &#123; <span class="comment">// 目录为空或强制删除</span></span><br><span class="line">                                   HDFSApi.rmDir(conf,  remoteDir);</span><br><span class="line">                                   System.out.println(<span class="string">&quot;删除目录: &quot;</span> +  remoteDir);</span><br><span class="line">                            &#125; <span class="keyword">else</span>  &#123; <span class="comment">// 目录不为空</span></span><br><span class="line">                                   System.out.println(<span class="string">&quot;目录不为空，不删除: &quot;</span> +  remoteDir);</span><br><span class="line">                            &#125;</span><br><span class="line">                     &#125;</span><br><span class="line">              &#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">                     e.printStackTrace();</span><br><span class="line">              &#125;</span><br><span class="line">       &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p><img src="/../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/aa3dca52f3b01284a8ad8ba28db79349697559838-1746692007780-476-1747299497351-101-1747900721330-101-1749470495097-101.png" alt="image-20250327180216959"></p>
<p>⑧ 向HDFS中指定的文件追加内容，由用户指定将内容追加到原有文件的开头或结尾。</p>
<p><mark>shell</mark></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">rm -rf text.txt</span><br><span class="line">hdfs dfs -appendToFile local.txt text.txt</span><br><span class="line">hdfs dfs -get text.txt</span><br><span class="line">cat text.txt &gt;&gt; local.txt</span><br><span class="line">hdfs dfs -copyFromLocal -f text.txt text.txt</span><br><span class="line">hdfs dfs -cat text.txt</span><br></pre></td></tr></table></figure>
<p><img src="/../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/7cdd5e339904c6b2048dec92da1dfc73697559838-1746692007780-477-1747299497351-102-1747900721330-102-1749470495097-103.png" alt="image-20250327180622881"></p>
<p><mark>Java</mark></p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span>  org.apache.hadoop.conf.Configuration;</span><br><span class="line"><span class="keyword">import</span>  org.apache.hadoop.fs.*;</span><br><span class="line"><span class="keyword">import</span> java.io.*;</span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">HDFSApi</span> &#123;</span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 判断路径是否存在</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="type">boolean</span> <span class="title function_">test</span><span class="params">(Configuration  conf, String path)</span> <span class="keyword">throws</span> IOException &#123;</span><br><span class="line">        <span class="type">FileSystem</span> <span class="variable">fs</span> <span class="operator">=</span> FileSystem.get(conf);</span><br><span class="line">        <span class="keyword">return</span> fs.exists(<span class="keyword">new</span> <span class="title class_">Path</span>(path));</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 追加文本内容</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span>  <span class="title function_">appendContentToFile</span><span class="params">(Configuration conf, String content, String  remoteFilePath)</span> <span class="keyword">throws</span> IOException &#123;</span><br><span class="line">        <span class="type">FileSystem</span> <span class="variable">fs</span> <span class="operator">=</span> FileSystem.get(conf);</span><br><span class="line">        <span class="type">Path</span> <span class="variable">remotePath</span> <span class="operator">=</span> <span class="keyword">new</span>  <span class="title class_">Path</span>(remoteFilePath);</span><br><span class="line">        <span class="comment">/* 创建一个文件输出流，输出的内容将追加到文件末尾 */</span></span><br><span class="line">        <span class="type">FSDataOutputStream</span> <span class="variable">out</span> <span class="operator">=</span>  fs.append(remotePath);</span><br><span class="line">        out.write(content.getBytes());</span><br><span class="line">        out.close();</span><br><span class="line">        fs.close();</span><br><span class="line">&#125;</span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 追加文件内容</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span>  <span class="title function_">appendToFile</span><span class="params">(Configuration conf, String localFilePath, String remoteFilePath)</span>  <span class="keyword">throws</span> IOException &#123;</span><br><span class="line">        <span class="type">FileSystem</span> <span class="variable">fs</span> <span class="operator">=</span> FileSystem.get(conf);</span><br><span class="line">        <span class="type">Path</span> <span class="variable">remotePath</span> <span class="operator">=</span> <span class="keyword">new</span>  <span class="title class_">Path</span>(remoteFilePath);</span><br><span class="line">        <span class="comment">/* 创建一个文件读入流 */</span></span><br><span class="line">        <span class="type">FileInputStream</span> <span class="variable">in</span> <span class="operator">=</span> <span class="keyword">new</span>  <span class="title class_">FileInputStream</span>(localFilePath);</span><br><span class="line">        <span class="comment">/* 创建一个文件输出流，输出的内容将追加到文件末尾 */</span></span><br><span class="line">        <span class="type">FSDataOutputStream</span> <span class="variable">out</span> <span class="operator">=</span>  fs.append(remotePath);</span><br><span class="line">        <span class="comment">/* 读写文件内容 */</span></span><br><span class="line">        <span class="type">byte</span>[] data = <span class="keyword">new</span> <span class="title class_">byte</span>[<span class="number">1024</span>];</span><br><span class="line">        <span class="type">int</span> <span class="variable">read</span> <span class="operator">=</span> -<span class="number">1</span>;</span><br><span class="line">        <span class="keyword">while</span> ( (read = in.read(data)) &gt; <span class="number">0</span>  ) &#123;</span><br><span class="line">               out.write(data,  <span class="number">0</span>, read);</span><br><span class="line">        &#125;</span><br><span class="line">        out.close();</span><br><span class="line">        in.close();</span><br><span class="line">        fs.close();</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 移动文件到本地</span></span><br><span class="line"><span class="comment">     * 移动后，删除源文件</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span>  <span class="title function_">moveToLocalFile</span><span class="params">(Configuration conf, String remoteFilePath, String  localFilePath)</span> <span class="keyword">throws</span> IOException &#123;</span><br><span class="line">        <span class="type">FileSystem</span> <span class="variable">fs</span> <span class="operator">=</span> FileSystem.get(conf);</span><br><span class="line">        <span class="type">Path</span> <span class="variable">remotePath</span> <span class="operator">=</span> <span class="keyword">new</span>  <span class="title class_">Path</span>(remoteFilePath);</span><br><span class="line">        <span class="type">Path</span> <span class="variable">localPath</span> <span class="operator">=</span> <span class="keyword">new</span>  <span class="title class_">Path</span>(localFilePath);</span><br><span class="line">        fs.moveToLocalFile(remotePath,  localPath);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 创建文件</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">touchz</span><span class="params">(Configuration  conf, String remoteFilePath)</span> <span class="keyword">throws</span> IOException &#123;</span><br><span class="line">        <span class="type">FileSystem</span> <span class="variable">fs</span> <span class="operator">=</span> FileSystem.get(conf);</span><br><span class="line">        <span class="type">Path</span> <span class="variable">remotePath</span> <span class="operator">=</span> <span class="keyword">new</span>  <span class="title class_">Path</span>(remoteFilePath);</span><br><span class="line">        <span class="type">FSDataOutputStream</span> <span class="variable">outputStream</span> <span class="operator">=</span>  fs.create(remotePath);</span><br><span class="line">        outputStream.close();</span><br><span class="line">        fs.close();</span><br><span class="line">    &#125;</span><br><span class="line">       <span class="comment">/**</span></span><br><span class="line"><span class="comment">        * 主函数</span></span><br><span class="line"><span class="comment">        */</span></span><br><span class="line">       <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span>  &#123;</span><br><span class="line">              <span class="type">Configuration</span> <span class="variable">conf</span> <span class="operator">=</span> <span class="keyword">new</span>  <span class="title class_">Configuration</span>();</span><br><span class="line">    conf.set(<span class="string">&quot;fs.default.name&quot;</span>,<span class="string">&quot;hdfs://localhost:9000&quot;</span>);</span><br><span class="line">              <span class="type">String</span> <span class="variable">remoteFilePath</span> <span class="operator">=</span>  <span class="string">&quot;/user/hadoop/text.txt&quot;</span>;     <span class="comment">// HDFS文件</span></span><br><span class="line">              <span class="type">String</span> <span class="variable">content</span> <span class="operator">=</span> <span class="string">&quot;新追加的内容\n&quot;</span>;</span><br><span class="line">              <span class="type">String</span> <span class="variable">choice</span> <span class="operator">=</span>  <span class="string">&quot;after&quot;</span>;         <span class="comment">//追加到文件末尾</span></span><br><span class="line"><span class="comment">//            String choice =  &quot;before&quot;;    // 追加到文件开头</span></span><br><span class="line">              <span class="keyword">try</span> &#123;</span><br><span class="line">                     <span class="comment">/* 判断文件是否存在 */</span></span><br><span class="line">                     <span class="keyword">if</span> ( !HDFSApi.test(conf,  remoteFilePath) ) &#123;</span><br><span class="line">                            System.out.println(<span class="string">&quot;文件不存在: &quot;</span> +  remoteFilePath);</span><br><span class="line">                     &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                            <span class="keyword">if</span> (  choice.equals(<span class="string">&quot;after&quot;</span>) ) &#123; <span class="comment">// 追加在文件末尾</span></span><br><span class="line">                                   HDFSApi.appendContentToFile(conf,  content, remoteFilePath);</span><br><span class="line">                                   System.out.println(<span class="string">&quot;已追加内容到文件末尾&quot;</span> +  remoteFilePath);</span><br><span class="line">                            &#125; <span class="keyword">else</span> <span class="keyword">if</span> (  choice.equals(<span class="string">&quot;before&quot;</span>) )  &#123;  <span class="comment">// 追加到文件开头</span></span><br><span class="line">                                   <span class="comment">/* 没有相应的api可以直接操作，因此先把文件移动到本地*/</span></span><br><span class="line"><span class="comment">/*创建一个新的HDFS，再按顺序追加内容 */</span></span><br><span class="line">                                   <span class="type">String</span>  <span class="variable">localTmpPath</span> <span class="operator">=</span> <span class="string">&quot;/user/hadoop/tmp.txt&quot;</span>;</span><br><span class="line">                                   <span class="comment">// 移动到本地</span></span><br><span class="line">HDFSApi.moveToLocalFile(conf, remoteFilePath,  localTmpPath);</span><br><span class="line">   <span class="comment">// 创建一个新文件</span></span><br><span class="line">                          HDFSApi.touchz(conf,  remoteFilePath); </span><br><span class="line">                    <span class="comment">// 先写入新内容</span></span><br><span class="line">                          HDFSApi.appendContentToFile(conf,  content, remoteFilePath);</span><br><span class="line">                    <span class="comment">// 再写入原来内容</span></span><br><span class="line">                           HDFSApi.appendToFile(conf,  localTmpPath, remoteFilePath); </span><br><span class="line">                           System.out.println(<span class="string">&quot;已追加内容到文件开头: &quot;</span> +  remoteFilePath);</span><br><span class="line">                            &#125;</span><br><span class="line">                     &#125;</span><br><span class="line">              &#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">                     e.printStackTrace();</span><br><span class="line">              &#125;</span><br><span class="line">       &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p><img src="/../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/710a090fa1c394fe6e2808329cda4dc2697559838-1746692007780-478-1747299497351-103-1747900721330-103-1749470495097-105.png" alt="image-20250327180721307"></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hdfs dfs -cat text.txt</span><br></pre></td></tr></table></figure>
<p><img src="/../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/9f8d75e4b88732f54a55451338533fe6697559838-1746692007780-479-1747299497351-104-1747900721330-104-1749470495097-104.png" alt="image-20250327180742432"></p>
<p>⑨ 删除HDFS中指定的文件。</p>
<p><mark>shell</mark></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">rm text.txt</span><br><span class="line">hdfs dfs -get text.txt</span><br><span class="line">hdfs dfs -rm text.txt</span><br></pre></td></tr></table></figure>
<p><img src="/../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/0a49740aa72800dd9f780cd6e02db10d697559838-1746692007780-480-1747299497351-105-1747900721330-105-1749470495097-106.png" alt="image-20250327180918344"></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hdfs dfs -put text.txt</span><br></pre></td></tr></table></figure>
<p><mark>Java</mark></p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span>  org.apache.hadoop.conf.Configuration;</span><br><span class="line"><span class="keyword">import</span>  org.apache.hadoop.fs.*;</span><br><span class="line"><span class="keyword">import</span> java.io.*;</span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">HDFSApi</span> &#123;</span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 删除文件</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="type">boolean</span> <span class="title function_">rm</span><span class="params">(Configuration  conf, String remoteFilePath)</span> <span class="keyword">throws</span> IOException &#123;</span><br><span class="line">        <span class="type">FileSystem</span> <span class="variable">fs</span> <span class="operator">=</span> FileSystem.get(conf);</span><br><span class="line">        <span class="type">Path</span> <span class="variable">remotePath</span> <span class="operator">=</span> <span class="keyword">new</span>  <span class="title class_">Path</span>(remoteFilePath);</span><br><span class="line">        <span class="type">boolean</span> <span class="variable">result</span> <span class="operator">=</span>  fs.delete(remotePath, <span class="literal">false</span>);</span><br><span class="line">        fs.close();</span><br><span class="line">        <span class="keyword">return</span> result;</span><br><span class="line">    &#125;</span><br><span class="line">       <span class="comment">/**</span></span><br><span class="line"><span class="comment">        * 主函数</span></span><br><span class="line"><span class="comment">        */</span></span><br><span class="line">       <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span>  &#123;</span><br><span class="line">              <span class="type">Configuration</span> <span class="variable">conf</span> <span class="operator">=</span> <span class="keyword">new</span>  <span class="title class_">Configuration</span>();</span><br><span class="line">    conf.set(<span class="string">&quot;fs.default.name&quot;</span>,<span class="string">&quot;hdfs://localhost:9000&quot;</span>);</span><br><span class="line">              <span class="type">String</span> <span class="variable">remoteFilePath</span> <span class="operator">=</span>  <span class="string">&quot;/user/hadoop/text.txt&quot;</span>;     <span class="comment">// HDFS文件         </span></span><br><span class="line">              <span class="keyword">try</span> &#123;</span><br><span class="line">                     <span class="keyword">if</span> ( HDFSApi.rm(conf,  remoteFilePath) ) &#123;</span><br><span class="line">                            System.out.println(<span class="string">&quot;文件删除: &quot;</span> +  remoteFilePath);</span><br><span class="line">                     &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                            System.out.println(<span class="string">&quot;操作失败（文件不存在或删除失败）&quot;</span>);</span><br><span class="line">                     &#125;</span><br><span class="line">              &#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">                     e.printStackTrace();</span><br><span class="line">              &#125;</span><br><span class="line">       &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p><img src="/../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/08a6b2fb485de0b4a274d3ec647ad025697559838-1746692007780-481-1747299497351-106-1747900721330-106-1749470495097-107.png" alt="image-20250327181030978"></p>
<p>⑩ 在HDFS中将文件从源路径移动到目的路径。</p>
<p><mark>shell</mark></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">hdfs dfs -put text.txt</span><br><span class="line">hdfs dfs -mv text.txt text2.txt</span><br><span class="line">hdfs dfs -ls</span><br></pre></td></tr></table></figure>
<p><img src="/../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/78098652ed313c1aaf03bc4ad865abb0697559838-1746692007780-482-1747299497351-107-1747900721330-107-1749470495097-108.png" alt="image-20250327181119936"></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hdfs dfs -put text.txt</span><br></pre></td></tr></table></figure>
<p><mark>Java</mark></p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span>  org.apache.hadoop.conf.Configuration;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.fs.*;</span><br><span class="line"><span class="keyword">import</span> java.io.*;</span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">HDFSApi</span> &#123;</span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 移动文件</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="type">boolean</span> <span class="title function_">mv</span><span class="params">(Configuration  conf, String remoteFilePath, String remoteToFilePath)</span> <span class="keyword">throws</span> IOException &#123;</span><br><span class="line">        <span class="type">FileSystem</span> <span class="variable">fs</span> <span class="operator">=</span> FileSystem.get(conf);</span><br><span class="line">        <span class="type">Path</span> <span class="variable">srcPath</span> <span class="operator">=</span> <span class="keyword">new</span>  <span class="title class_">Path</span>(remoteFilePath);</span><br><span class="line">        <span class="type">Path</span> <span class="variable">dstPath</span> <span class="operator">=</span> <span class="keyword">new</span>  <span class="title class_">Path</span>(remoteToFilePath);</span><br><span class="line">        <span class="type">boolean</span> <span class="variable">result</span> <span class="operator">=</span> fs.rename(srcPath,  dstPath);</span><br><span class="line">        fs.close();</span><br><span class="line">        <span class="keyword">return</span> result;</span><br><span class="line">    &#125;</span><br><span class="line">       <span class="comment">/**</span></span><br><span class="line"><span class="comment">        * 主函数</span></span><br><span class="line"><span class="comment">        */</span></span><br><span class="line">       <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> &#123;</span><br><span class="line">              <span class="type">Configuration</span> <span class="variable">conf</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Configuration</span>();</span><br><span class="line">    conf.set(<span class="string">&quot;fs.default.name&quot;</span>,<span class="string">&quot;hdfs://localhost:9000&quot;</span>);</span><br><span class="line">              <span class="type">String</span> <span class="variable">remoteFilePath</span> <span class="operator">=</span>  <span class="string">&quot;hdfs:///user/hadoop/text.txt&quot;</span>;     <span class="comment">// 源文件HDFS路径</span></span><br><span class="line">              <span class="type">String</span> <span class="variable">remoteToFilePath</span> <span class="operator">=</span>  <span class="string">&quot;hdfs:///user/hadoop/new.txt&quot;</span>;     <span class="comment">// 目的HDFS路径</span></span><br><span class="line">              <span class="keyword">try</span> &#123;</span><br><span class="line">                     <span class="keyword">if</span> ( HDFSApi.mv(conf, remoteFilePath,  remoteToFilePath) ) &#123;</span><br><span class="line">                            System.out.println(<span class="string">&quot;将文件 &quot;</span> +  remoteFilePath + <span class="string">&quot; 移动到 &quot;</span> + remoteToFilePath);</span><br><span class="line">                     &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                                   System.out.println(<span class="string">&quot;操作失败(源文件不存在或移动失败)&quot;</span>);</span><br><span class="line">                     &#125;</span><br><span class="line">              &#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">                     e.printStackTrace();</span><br><span class="line">              &#125;</span><br><span class="line">       &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p><img src="/../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/3ef11dae7bf3e355fb37a037de122b87697559838-1746692007780-483-1747299497351-108-1747900721330-108-1749470495097-109.png" alt="image-20250327181230298"></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hdfs dfs -ls | grep new</span><br></pre></td></tr></table></figure>
<p><img src="/../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/e943e8ea612d9c03d72de2eb33a9270f697559838-1746692007780-484-1747299497351-109-1747900721330-109-1749470495097-110.png" alt="image-20250327181334769"></p>
<p>（2）编程实现一个类“MyFSDataInputStream”，该类继承“org.apache.hadoop.fs.FSDataInput Stream”，要求如下： 实现按行读取HDFS中指定文件的方法“readLine()”，如果读到文件末尾，则返回空，否则返回文件一行的文本。</p>
<p><mark>shell</mark></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hdfs dfs -put text.txt</span><br></pre></td></tr></table></figure>
<p><mark>Java</mark></p>
<blockquote>
<p><code>自己创建好MyFSDataInputStream.java</code></p>
</blockquote>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span>  org.apache.hadoop.conf.Configuration;</span><br><span class="line"><span class="keyword">import</span>  org.apache.hadoop.fs.FSDataInputStream;</span><br><span class="line"><span class="keyword">import</span>  org.apache.hadoop.fs.FileSystem;</span><br><span class="line"><span class="keyword">import</span>  org.apache.hadoop.fs.Path;</span><br><span class="line"><span class="keyword">import</span>  java.io.*;</span><br><span class="line"><span class="keyword">public</span>  <span class="keyword">class</span> <span class="title class_">MyFSDataInputStream</span> <span class="keyword">extends</span> <span class="title class_">FSDataInputStream</span> &#123;</span><br><span class="line">       <span class="keyword">public</span> <span class="title function_">MyFSDataInputStream</span><span class="params">(InputStream  in)</span> &#123;</span><br><span class="line">              <span class="built_in">super</span>(in);</span><br><span class="line">       &#125;</span><br><span class="line">       <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 实现按行读取</span></span><br><span class="line"><span class="comment">     * 每次读入一个字符，遇到&quot;\n&quot;结束，返回一行内容</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">       <span class="keyword">public</span> <span class="keyword">static</span> String  <span class="title function_">readline</span><span class="params">(BufferedReader br)</span> <span class="keyword">throws</span> IOException &#123;</span><br><span class="line">              <span class="type">char</span>[] data = <span class="keyword">new</span> <span class="title class_">char</span>[<span class="number">1024</span>];</span><br><span class="line">              <span class="type">int</span> <span class="variable">read</span> <span class="operator">=</span> -<span class="number">1</span>;</span><br><span class="line">              <span class="type">int</span> <span class="variable">off</span> <span class="operator">=</span> <span class="number">0</span>; </span><br><span class="line"><span class="comment">// 循环执行时，br 每次会从上一次读取结束的位置继续读取</span></span><br><span class="line"><span class="comment">//因此该函数里，off 每次都从0开始</span></span><br><span class="line">              <span class="keyword">while</span> ( (read = br.read(data,  off, <span class="number">1</span>)) != -<span class="number">1</span> ) &#123;</span><br><span class="line">                     <span class="keyword">if</span>  (String.valueOf(data[off].equals(<span class="string">&quot;\n&quot;</span>) ) &#123;</span><br><span class="line">                            off += <span class="number">1</span>;</span><br><span class="line">                            <span class="keyword">break</span>;</span><br><span class="line">                     &#125;</span><br><span class="line">                     off += <span class="number">1</span>;</span><br><span class="line">              &#125;          </span><br><span class="line">              <span class="keyword">if</span> (off &gt; <span class="number">0</span>) &#123;</span><br><span class="line">                     <span class="keyword">return</span>  String.valueOf(data);</span><br><span class="line">              &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                     <span class="keyword">return</span> <span class="literal">null</span>;</span><br><span class="line">              &#125;</span><br><span class="line">       &#125;</span><br><span class="line">       <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 读取文件内容</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">cat</span><span class="params">(Configuration  conf, String remoteFilePath)</span> <span class="keyword">throws</span> IOException &#123;</span><br><span class="line">        <span class="type">FileSystem</span> <span class="variable">fs</span> <span class="operator">=</span> FileSystem.get(conf);</span><br><span class="line">        <span class="type">Path</span> <span class="variable">remotePath</span> <span class="operator">=</span> <span class="keyword">new</span>  <span class="title class_">Path</span>(remoteFilePath);</span><br><span class="line">        <span class="type">FSDataInputStream</span> <span class="variable">in</span> <span class="operator">=</span>  fs.open(remotePath);</span><br><span class="line">        <span class="type">BufferedReader</span> <span class="variable">br</span> <span class="operator">=</span> <span class="keyword">new</span>  <span class="title class_">BufferedReader</span>(<span class="keyword">new</span> <span class="title class_">InputStreamReader</span>(in));</span><br><span class="line">        <span class="type">String</span> <span class="variable">line</span> <span class="operator">=</span> <span class="literal">null</span>;</span><br><span class="line">        <span class="keyword">while</span> ( (line =  MyFSDataInputStream.readline(br)) != <span class="literal">null</span> ) &#123;</span><br><span class="line">               System.out.println(line);</span><br><span class="line">        &#125;</span><br><span class="line">        br.close();</span><br><span class="line">        in.close();</span><br><span class="line">        fs.close();</span><br><span class="line">    &#125;   </span><br><span class="line">       <span class="comment">/**</span></span><br><span class="line"><span class="comment">        * 主函数</span></span><br><span class="line"><span class="comment">        */</span></span><br><span class="line">       <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span>  &#123;</span><br><span class="line">              <span class="type">Configuration</span> <span class="variable">conf</span> <span class="operator">=</span> <span class="keyword">new</span>  <span class="title class_">Configuration</span>();</span><br><span class="line">    conf.set(<span class="string">&quot;fs.default.name&quot;</span>,<span class="string">&quot;hdfs://localhost:9000&quot;</span>);</span><br><span class="line">              <span class="type">String</span> <span class="variable">remoteFilePath</span> <span class="operator">=</span>  <span class="string">&quot;/user/hadoop/text.txt&quot;</span>;     <span class="comment">// HDFS路径</span></span><br><span class="line">              <span class="keyword">try</span> &#123;</span><br><span class="line">                     MyFSDataInputStream.cat(conf,  remoteFilePath);</span><br><span class="line">              &#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">                     e.printStackTrace();</span><br><span class="line">              &#125;</span><br><span class="line">       &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p><img src="/../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/4d9c8b1a54195c6a3ce4f8a9d1162065697559838-1746692007780-485-1747299497351-110-1747900721330-110-1749470495097-111.png" alt="image-20250327181734199"></p>
<p>（3）查看Java帮助手册或其他资料，用“java.net.URL”和“org.apache.hadoop.fs.FsURLStream HandlerFactory”编程来输出HDFS中指定文件的文本到终端中。</p>
<p><mark>Java</mark></p>
<p>用回<code>HDFSApi</code></p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> org.apache.hadoop.fs.*;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.IOUtils;</span><br><span class="line"><span class="keyword">import</span> java.io.*;</span><br><span class="line"><span class="keyword">import</span> java.net.URL;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">HDFSApi</span> &#123;</span><br><span class="line">    <span class="keyword">static</span> &#123;</span><br><span class="line">        URL.setURLStreamHandlerFactory(<span class="keyword">new</span> <span class="title class_">FsUrlStreamHandlerFactory</span>());</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 主函数</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception &#123;</span><br><span class="line">        <span class="comment">// HDFS文件路径，需包含主机名和端口号</span></span><br><span class="line">        <span class="type">String</span> <span class="variable">remoteFilePath</span> <span class="operator">=</span> <span class="string">&quot;hdfs://localhost:9000/user/hadoop/text.txt&quot;</span>; <span class="comment">// 修改为正确的HDFS URI</span></span><br><span class="line">        <span class="type">InputStream</span> <span class="variable">in</span> <span class="operator">=</span> <span class="literal">null</span>;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            <span class="comment">/* 通过URL对象打开数据流，从中读取数据 */</span></span><br><span class="line">            in = <span class="keyword">new</span> <span class="title class_">URL</span>(remoteFilePath).openStream();</span><br><span class="line">            IOUtils.copyBytes(in, System.out, <span class="number">4096</span>, <span class="literal">false</span>); <span class="comment">// 将数据输出到控制台</span></span><br><span class="line">        &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">            IOUtils.closeStream(in); <span class="comment">// 关闭输入流</span></span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><img src="/../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/224356211e87ed627058fbdf9d557f92697559838-1746692007780-486-1747299497351-111-1747900721330-111-1749470495097-113.png" alt="image-20250327182240291"></p>
<h2 id="Hbase安装-4-6-1">Hbase安装(4.6.1)</h2>
<p>这里有两个题，就是要交两个截图，我会注明</p>
<p><code>进hadoop用户</code></p>
<p><img src="/../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/21494f461a2bcfa10ef3533188e26bff55933597-1746692007780-487-1747299497351-112-1747900721330-112-1749470495097-112.png" alt="image-20250408162058097"></p>
<p><code>自行启动hadoop</code></p>
<h3 id="安装hbase">安装hbase</h3>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo ls</span><br></pre></td></tr></table></figure>
<p><img src="/../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/76c9277a9bea6c8f5f60a0bce8b5de3a55933597-1746692007780-488-1747299497351-113-1747900721330-113-1749470495097-114.png" alt="image-20250408162139854"></p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">sudo</span> tar -xf hbase-2.5.4-bin.tar.gz -C /usr/local/</span><br><span class="line"><span class="built_in">sudo</span> <span class="built_in">mv</span> /usr/local/hbase-2.5.4 /usr/local/hbase</span><br><span class="line"><span class="built_in">sudo</span> <span class="built_in">chown</span> -R hadoop:hadoop /usr/local/hbase</span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;export HBASE_HOME=/usr/local/hbase&quot;</span> &gt;&gt; ~/.bashrc</span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;export PATH=\$PATH:\$HBASE_HOME/bin&quot;</span> &gt;&gt; ~/.bashrc</span><br><span class="line"><span class="built_in">source</span> ~/.bashrc</span><br><span class="line"><span class="built_in">sudo</span> sed -i <span class="string">&quot;s/CLASSPATH=\$&#123;CLASSPATH&#125;:\$JAVA_HOME\/lib\/tools.jar/CLASSPATH=\$&#123;CLASSPATH&#125;:\$JAVA_HOME\/lib\/tools.jar:\/usr\/local\/hbase\/lib\/*/g&quot;</span> /usr/local/hbase/bin/hbase</span><br><span class="line"></span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;export JAVA_HOME=/usr/lib/jvm/jdk1.8.0_162&quot;</span> &gt;&gt; <span class="variable">$HBASE_HOME</span>/conf/hbase-env.sh</span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;export HBASE_CLASSPATH=/usr/local/hbase/conf&quot;</span> &gt;&gt; <span class="variable">$HBASE_HOME</span>/conf/hbase-env.sh</span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;export HBASE_MANAGES_ZK=true&quot;</span> &gt;&gt; <span class="variable">$HBASE_HOME</span>/conf/hbase-env.sh</span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;export HBASE_DISABLE_HADOOP_CLASSPATH_LOOKUP=true&quot;</span> &gt;&gt; <span class="variable">$HBASE_HOME</span>/conf/hbase-env.sh</span><br><span class="line"></span><br><span class="line"><span class="built_in">cat</span> &gt;<span class="variable">$HBASE_HOME</span>/conf/hbase-site.xml&lt;&lt;<span class="string">&quot;EOF&quot;</span></span><br><span class="line">&lt;configuration&gt;</span><br><span class="line">        &lt;property&gt;</span><br><span class="line">                &lt;name&gt;hbase.rootdir&lt;/name&gt;</span><br><span class="line">                &lt;value&gt;hdfs://localhost:9000/hbase&lt;/value&gt;</span><br><span class="line">        &lt;/property&gt;</span><br><span class="line">        &lt;property&gt;</span><br><span class="line">                &lt;name&gt;hbase.cluster.distributed&lt;/name&gt;</span><br><span class="line">                &lt;value&gt;<span class="literal">true</span>&lt;/value&gt;</span><br><span class="line">        &lt;/property&gt;</span><br><span class="line">        &lt;property&gt;</span><br><span class="line">                &lt;name&gt;hbase.unsafe.stream.capability.enforce&lt;/name&gt;</span><br><span class="line">                &lt;value&gt;<span class="literal">false</span>&lt;/value&gt;</span><br><span class="line">        &lt;/property&gt;</span><br><span class="line">&lt;/configuration&gt;</span><br><span class="line">EOF</span><br><span class="line">hbase version</span><br></pre></td></tr></table></figure>
<blockquote>
<p><code>这个截图交到4.6.1开头第一个作业</code></p>
</blockquote>
<p><img src="/../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/91151a2feff536bb833551d46297998855933597-1746692007780-489-1747299497351-114-1747900721330-114-1749470495097-115.png" alt="image-20250408162305665"></p>
<h3 id="启动hbase">启动hbase</h3>
<p><code>开机顺序：一定是先启动hadoop（大）在启动hbase（小）</code></p>
<p><code>开机顺序：一定是先启动hadoop（大）在启动hbase（小）</code></p>
<p><code>开机顺序：一定是先启动hadoop（大）在启动hbase（小）</code></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">start-all.sh</span><br><span class="line">start-hbase.sh</span><br></pre></td></tr></table></figure>
<p>然后输入jps,有以下三个个就安装成功</p>
<blockquote>
<p><code>这是4.6.1里最下面的第二个作业截图</code></p>
</blockquote>
<p><img src="/../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/eac0cd31a5b01c64eef55ab24e277f8555933597-1746692007780-490-1747299497351-115-1747900721330-115-1749470495097-116.png" alt="image-20250408162520533"></p>
<p>测试hbase</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">hbase shell</span><br><span class="line">list</span><br></pre></td></tr></table></figure>
<p><img src="/../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/c8239e3d81e133e56e4209d0e451523755933597-1746692007780-491-1747299497351-116-1747900721330-116-1749470495097-117.png" alt="image-20250408162546768"></p>
<p>能运行没报错就行</p>
<p>退出hbase数据库用<code>exit</code></p>
<p><img src="/../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/66ed6e4c766ea1fc194a4657f260987d55933597-1746692007780-492-1747299497351-117-1747900721330-117-1749470495097-118.png" alt="image-20250401165245612"></p>
<p>访问hbase网页</p>
<p><a target="_blank" rel="noopener" href="http://ip:16010/">http://ip:16010/</a></p>
<p><img src="/../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/fba67e9070ac30030461dd890b011fa955933597-1746692007780-493-1747299497351-118-1747900721330-118-1749470495097-119.png" alt="image-20250408162639789"></p>
<h3 id="关闭hbase">关闭hbase</h3>
<p><code>关机顺序：先关habse(小)再关hadoop（大）</code></p>
<p><code>关机顺序：先关habse(小)再关hadoop（大）</code></p>
<p><code>关机顺序：先关habse(小)再关hadoop（大）</code></p>
<p><code>关机顺序：先关habse(小)再关hadoop（大）</code></p>
<p>不按操作来，机器坏了，自己重装吧</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">stop-hbase.sh</span><br><span class="line">stop-all.sh</span><br><span class="line">sudo poweroff</span><br></pre></td></tr></table></figure>
<p><code>关机后自己打个habse的快照</code></p>
<h2 id="（4-6-2）实验">（4.6.2）实验</h2>
<h3 id="启动eclipse">启动eclipse</h3>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">eclipse</span><br></pre></td></tr></table></figure>
<p><img src="/../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/1923b4c74871006064488c96e58ca45855933597-1746692007780-494-1747299497351-120-1747900721330-119-1749470495097-120.png" alt="image-20250408164622803"></p>
<p><img src="/../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/9a4ecb36e968a02b73e7623a8fda4f8a55933597-1746692007780-495-1747299497351-119-1747900721330-120-1749470495097-121.png" alt="image-20250408164638364"></p>
<h3 id="新建项目">新建项目</h3>
<p>名为<code>HBaseExample</code></p>
<p><img src="/../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/636129eb6dee23242d4e2d6c8081873f55933597-1746692007781-496-1747299497351-121-1747900721330-121-1749470495097-122.png" alt="image-20250408164919609"></p>
<p><img src="/../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/6e3bb9833a72d6546944cbae664a474455933597-1746692007781-497-1747299497351-122-1747900721330-122-1749470495097-123.png" alt="image-20250408164950280"></p>
<p><code>现在有几个目录要添加注意了！！！</code></p>
<p><code>现在有几个目录要添加注意了！！！</code></p>
<p><code>现在有几个目录要添加注意了！！！</code></p>
<p><code>现在有几个目录要添加注意了！！！</code></p>
<blockquote>
<p><code>/usr/local/hbase/lib</code>下所有的jar包</p>
<p><code>/usr/local/hbase/lib/client-facing-thirdparty</code>下所有的jar包</p>
</blockquote>
<p><img src="/../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/2b2dbcc5dcd4b9bead17749b9df213fa55933597-1746692007781-498-1747299497351-123-1747900721330-123-1749470495097-124.png" alt="image-20250408165300706"></p>
<p><img src="/../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/a3fc6310f34a3ef1daa99b09452f0a7455933597-1746692007781-499-1747299497351-124-1747900721330-124-1749470495097-125.png" alt="image-20250408165316864"></p>
<p><img src="/../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/4c79bcd883e1303d5997906eef903d0155933597-1746692007781-500-1747299497351-125-1747900721330-125-1749470495097-126.png" alt="image-20250408165342189"></p>
<p>最后直接点击finish完成创建</p>
<h3 id="新建class">新建class</h3>
<p><img src="/../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/f6137b4051dab5c88e26d29ce588847e55933597-1746692007781-501-1747299497351-126-1747900721330-126-1749470495097-127.png" alt="image-20250408165715828"></p>
<p>然后在你创建的这个java文件输入，别运行</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> org.apache.hadoop.conf.Configuration;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.hbase.*;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.hbase.client.*;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.hbase.util.Bytes;</span><br><span class="line"> </span><br><span class="line"><span class="keyword">import</span> java.io.IOException;</span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">ExampleForHBase</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> Configuration configuration;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> Connection connection;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> Admin admin;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span><span class="keyword">throws</span> IOException&#123;</span><br><span class="line">        init();</span><br><span class="line">        createTable(<span class="string">&quot;student&quot;</span>,<span class="keyword">new</span> <span class="title class_">String</span>[]&#123;<span class="string">&quot;score&quot;</span>&#125;);</span><br><span class="line">        insertData(<span class="string">&quot;student&quot;</span>,<span class="string">&quot;zhangsan&quot;</span>,<span class="string">&quot;score&quot;</span>,<span class="string">&quot;English&quot;</span>,<span class="string">&quot;69&quot;</span>);</span><br><span class="line">        insertData(<span class="string">&quot;student&quot;</span>,<span class="string">&quot;zhangsan&quot;</span>,<span class="string">&quot;score&quot;</span>,<span class="string">&quot;Math&quot;</span>,<span class="string">&quot;86&quot;</span>);</span><br><span class="line">        insertData(<span class="string">&quot;student&quot;</span>,<span class="string">&quot;zhangsan&quot;</span>,<span class="string">&quot;score&quot;</span>,<span class="string">&quot;Computer&quot;</span>,<span class="string">&quot;77&quot;</span>);</span><br><span class="line">        getData(<span class="string">&quot;student&quot;</span>, <span class="string">&quot;zhangsan&quot;</span>, <span class="string">&quot;score&quot;</span>,<span class="string">&quot;English&quot;</span>);</span><br><span class="line">        close();</span><br><span class="line">    &#125;</span><br><span class="line"> </span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">init</span><span class="params">()</span>&#123;</span><br><span class="line">        configuration  = HBaseConfiguration.create();</span><br><span class="line">        configuration.set(<span class="string">&quot;hbase.rootdir&quot;</span>,<span class="string">&quot;hdfs://localhost:9000/hbase&quot;</span>);</span><br><span class="line">        <span class="keyword">try</span>&#123;</span><br><span class="line">            connection = ConnectionFactory.createConnection(configuration);</span><br><span class="line">            admin = connection.getAdmin();</span><br><span class="line">        &#125;<span class="keyword">catch</span> (IOException e)&#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"> </span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">close</span><span class="params">()</span>&#123;</span><br><span class="line">        <span class="keyword">try</span>&#123;</span><br><span class="line">            <span class="keyword">if</span>(admin != <span class="literal">null</span>)&#123;</span><br><span class="line">                admin.close();</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">if</span>(<span class="literal">null</span> != connection)&#123;</span><br><span class="line">                connection.close();</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;<span class="keyword">catch</span> (IOException e)&#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"> </span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">createTable</span><span class="params">(String myTableName,String[] colFamily)</span> <span class="keyword">throws</span> IOException &#123;</span><br><span class="line">        <span class="type">TableName</span> <span class="variable">tableName</span> <span class="operator">=</span> TableName.valueOf(myTableName);</span><br><span class="line">        <span class="keyword">if</span>(admin.tableExists(tableName))&#123;</span><br><span class="line">            System.out.println(<span class="string">&quot;talbe is exists!&quot;</span>);</span><br><span class="line">        &#125;<span class="keyword">else</span> &#123;</span><br><span class="line">            <span class="type">TableDescriptorBuilder</span> <span class="variable">tableDescriptor</span> <span class="operator">=</span> TableDescriptorBuilder.newBuilder(tableName);</span><br><span class="line">            <span class="keyword">for</span>(String str:colFamily)&#123;</span><br><span class="line">                <span class="type">ColumnFamilyDescriptor</span> <span class="variable">family</span> <span class="operator">=</span> </span><br><span class="line">ColumnFamilyDescriptorBuilder.newBuilder(Bytes.toBytes(str)).build();</span><br><span class="line">                tableDescriptor.setColumnFamily(family);</span><br><span class="line">            &#125;</span><br><span class="line">            admin.createTable(tableDescriptor.build());</span><br><span class="line">        &#125; </span><br><span class="line">    &#125;</span><br><span class="line"> </span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">insertData</span><span class="params">(String tableName,String rowKey,String colFamily,String col,String val)</span> <span class="keyword">throws</span> IOException &#123; </span><br><span class="line">        <span class="type">Table</span> <span class="variable">table</span> <span class="operator">=</span> connection.getTable(TableName.valueOf(tableName));</span><br><span class="line">        <span class="type">Put</span> <span class="variable">put</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Put</span>(rowKey.getBytes());</span><br><span class="line">        put.addColumn(colFamily.getBytes(),col.getBytes(), val.getBytes());</span><br><span class="line">        table.put(put);</span><br><span class="line">        table.close(); </span><br><span class="line">    &#125;</span><br><span class="line"> </span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">getData</span><span class="params">(String tableName,String rowKey,String colFamily, String col)</span><span class="keyword">throws</span>  IOException&#123; </span><br><span class="line">        <span class="type">Table</span> <span class="variable">table</span> <span class="operator">=</span> connection.getTable(TableName.valueOf(tableName));</span><br><span class="line">        <span class="type">Get</span> <span class="variable">get</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Get</span>(rowKey.getBytes());</span><br><span class="line">        get.addColumn(colFamily.getBytes(),col.getBytes());</span><br><span class="line">        <span class="type">Result</span> <span class="variable">result</span> <span class="operator">=</span> table.get(get);</span><br><span class="line">        System.out.println(<span class="keyword">new</span> <span class="title class_">String</span>(result.getValue(colFamily.getBytes(),col==<span class="literal">null</span>?<span class="literal">null</span>:col.getBytes())));</span><br><span class="line">        table.close(); </span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>自行启动hadoop和hbase，不记得了回去翻记录，我有写启动顺序，别搞错了，<code>搞错了就恢复快照吧</code>，下面是关闭和启动的顺序</p>
<p><a href="#%E5%90%AF%E5%8A%A8hbase">9.2 启动hbase</a></p>
<p><a href="#%E5%85%B3%E9%97%ADhbase">9.3 关闭hbase</a></p>
<p><code>没启动就不要做下面的内容！！！</code></p>
<p><code>没启动就不要做下面的内容！！！</code></p>
<p><code>没启动就不要做下面的内容！！！</code></p>
<p><code>没启动就不要做下面的内容！！！</code></p>
<p>运行代码</p>
<p><img src="/../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/617bb420d0196e81f2eb7cd73664bc9455933597-1746692007781-502-1747299497351-127-1747900721330-127-1749470495097-128.png" alt="image-20250408170354469"></p>
<p>就会出现这样的结果</p>
<blockquote>
<p><code>4.6.2实验要交的截图1</code></p>
</blockquote>
<p><img src="/../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/8fb2b2bdc0962691f05c04c233375a1c55933597-1746692007781-503-1747299497351-128-1747900721330-128-1749470495097-129.png" alt="image-20250408170422533"></p>
<p>这时候进入hbase数据库查看有没有student表</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hbase shell</span><br></pre></td></tr></table></figure>
<p><code>这是进入hbase数据库的命令，我前面也有写后面不会再说了，记不住就自己找办法</code></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">list</span><br><span class="line">scan &#x27;student&#x27;</span><br></pre></td></tr></table></figure>
<blockquote>
<p><code>4.6.2实验要交的截图2</code></p>
</blockquote>
<p><img src="/../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/ffffe943d8c41a3fe1565a88efe89ae755933597-1746692007781-504-1747299497351-130-1747900721330-129-1749470495097-131.png" alt="image-20250408170549890"></p>
<h2 id="4-8实验3">(4.8实验3)</h2>
<p><code>如果这里你输入第一条和第二条命令就报错，自己找找原因，我不想说了</code></p>
<hr>
<h3 id="第一题">第一题</h3>
<p><code>（1）编程实现以下指定功能，并用Hadoop提供的HBaseShell命令完成相同的任务。</code></p>
<p>①列出HBase所有表的相关信息，如表名、创建时间等。</p>
<p><mark>shell</mark></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">hbase shell</span><br><span class="line">list</span><br></pre></td></tr></table></figure>
<p><img src="/../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/d7c69d7997f40d717b95e140a09c8cd855933597-1746692007781-505-1747299497351-129-1747900721330-130-1749470495097-130.png" alt="image-20250408172837610"></p>
<p><mark>java</mark></p>
<p>自己创建一个<code>test.java</code>,要在<code>HBaseExample</code>的项目下,后面一直都会用这个java</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> org.apache.hadoop.conf.Configuration;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.hbase.*;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.hbase.client.*;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.hbase.util.Bytes;</span><br><span class="line"><span class="keyword">import</span> java.util.List;</span><br><span class="line"><span class="keyword">import</span> java.io.IOException;</span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">test</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> Configuration configuration;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> Connection connection;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> Admin admin;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span><span class="keyword">throws</span> IOException&#123;</span><br><span class="line">        init();</span><br><span class="line">        List&lt;TableDescriptor&gt;  tableDescriptors = admin.listTableDescriptors();</span><br><span class="line">        <span class="keyword">for</span>(TableDescriptor tableDescriptor :  tableDescriptors)&#123; </span><br><span class="line">        <span class="type">TableName</span> <span class="variable">tableName</span> <span class="operator">=</span>  tableDescriptor.getTableName(); </span><br><span class="line">        System.out.println(<span class="string">&quot;Table:&quot;</span> + tableName);</span><br><span class="line">        &#125;</span><br><span class="line">        close();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">init</span><span class="params">()</span> &#123;</span><br><span class="line">        configuration = HBaseConfiguration.create();</span><br><span class="line">        configuration.set(<span class="string">&quot;hbase.rootdir&quot;</span>, <span class="string">&quot;hbase://localhost:9000/hbase&quot;</span>);</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            connection = ConnectionFactory.createConnection(configuration);</span><br><span class="line">            <span class="keyword">if</span> (connection == <span class="literal">null</span>) &#123;</span><br><span class="line">                System.err.println(<span class="string">&quot;Failed to create HBase connection.&quot;</span>);</span><br><span class="line">            &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                System.out.println(<span class="string">&quot;HBase connection created successfully.&quot;</span>);</span><br><span class="line">            &#125;</span><br><span class="line">            admin = connection.getAdmin();</span><br><span class="line">            <span class="keyword">if</span> (admin == <span class="literal">null</span>) &#123;</span><br><span class="line">                System.err.println(<span class="string">&quot;Failed to get HBase Admin.&quot;</span>);</span><br><span class="line">            &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                System.out.println(<span class="string">&quot;HBase Admin initialized successfully.&quot;</span>);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125; <span class="keyword">catch</span> (IOException e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"> </span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">close</span><span class="params">()</span>&#123;</span><br><span class="line">        <span class="keyword">try</span>&#123;</span><br><span class="line">            <span class="keyword">if</span>(admin != <span class="literal">null</span>)&#123;</span><br><span class="line">                admin.close();</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">if</span>(<span class="literal">null</span> != connection)&#123;</span><br><span class="line">                connection.close();</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;<span class="keyword">catch</span> (IOException e)&#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"> </span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">createTable</span><span class="params">(String myTableName,String[] colFamily)</span> <span class="keyword">throws</span> IOException &#123;</span><br><span class="line">        <span class="type">TableName</span> <span class="variable">tableName</span> <span class="operator">=</span> TableName.valueOf(myTableName);</span><br><span class="line">        <span class="keyword">if</span>(admin.tableExists(tableName))&#123;</span><br><span class="line">            System.out.println(<span class="string">&quot;talbe is exists!&quot;</span>);</span><br><span class="line">        &#125;<span class="keyword">else</span> &#123;</span><br><span class="line">            <span class="type">TableDescriptorBuilder</span> <span class="variable">tableDescriptor</span> <span class="operator">=</span> TableDescriptorBuilder.newBuilder(tableName);</span><br><span class="line">            <span class="keyword">for</span>(String str:colFamily)&#123;</span><br><span class="line">                <span class="type">ColumnFamilyDescriptor</span> <span class="variable">family</span> <span class="operator">=</span> </span><br><span class="line">ColumnFamilyDescriptorBuilder.newBuilder(Bytes.toBytes(str)).build();</span><br><span class="line">                tableDescriptor.setColumnFamily(family);</span><br><span class="line">            &#125;</span><br><span class="line">            admin.createTable(tableDescriptor.build());</span><br><span class="line">        &#125; </span><br><span class="line">    &#125;</span><br><span class="line"> </span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">insertData</span><span class="params">(String tableName,String rowKey,String colFamily,String col,String val)</span> <span class="keyword">throws</span> IOException &#123; </span><br><span class="line">        <span class="type">Table</span> <span class="variable">table</span> <span class="operator">=</span> connection.getTable(TableName.valueOf(tableName));</span><br><span class="line">        <span class="type">Put</span> <span class="variable">put</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Put</span>(rowKey.getBytes());</span><br><span class="line">        put.addColumn(colFamily.getBytes(),col.getBytes(), val.getBytes());</span><br><span class="line">        table.put(put);</span><br><span class="line">        table.close(); </span><br><span class="line">    &#125;</span><br><span class="line"> </span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">getData</span><span class="params">(String tableName,String rowKey,String colFamily, String col)</span><span class="keyword">throws</span>  IOException&#123; </span><br><span class="line">        <span class="type">Table</span> <span class="variable">table</span> <span class="operator">=</span> connection.getTable(TableName.valueOf(tableName));</span><br><span class="line">        <span class="type">Get</span> <span class="variable">get</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Get</span>(rowKey.getBytes());</span><br><span class="line">        get.addColumn(colFamily.getBytes(),col.getBytes());</span><br><span class="line">        <span class="type">Result</span> <span class="variable">result</span> <span class="operator">=</span> table.get(get);</span><br><span class="line">        System.out.println(<span class="keyword">new</span> <span class="title class_">String</span>(result.getValue(colFamily.getBytes(),col==<span class="literal">null</span>?<span class="literal">null</span>:col.getBytes())));</span><br><span class="line">        table.close(); </span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><img src="/../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/661b8bf5388c32a8028982d7495d41eb55933597-1746692007781-506-1747299497351-131-1747900721330-131-1749470495097-133.png" alt="image-20250408180910551"></p>
<p>②在终端输出指定表的所有记录数据。</p>
<p><mark>shell</mark></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">scan &#x27;student&#x27;</span><br></pre></td></tr></table></figure>
<p><img src="/../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/a9bf5f6896beb92e8720ba6cb643bfcd55933597-1746692007781-507-1747299497351-132-1747900721330-133-1749470495097-134.png" alt="image-20250408175605631"></p>
<p><mark>java</mark></p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> org.apache.hadoop.conf.Configuration;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.hbase.*;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.hbase.client.*;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.hbase.util.Bytes;</span><br><span class="line"><span class="keyword">import</span> java.util.List;</span><br><span class="line"><span class="keyword">import</span> java.io.IOException;</span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">test</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> Configuration configuration;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> Connection connection;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> Admin admin;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> IOException &#123;</span><br><span class="line">    	  <span class="comment">// 指定表名 &quot;student&quot; 并获取所有记录</span></span><br><span class="line">    	  <span class="type">String</span> <span class="variable">tableName</span> <span class="operator">=</span> <span class="string">&quot;student&quot;</span>;</span><br><span class="line">    	  getData(tableName);</span><br><span class="line">    	 &#125;</span><br><span class="line">    	 <span class="comment">// 在终端打印出指定表的所有记录数据</span></span><br><span class="line">    	 <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">getData</span><span class="params">(String tableName)</span> <span class="keyword">throws</span> IOException &#123;</span><br><span class="line">    	  init(); <span class="comment">// 初始化连接</span></span><br><span class="line">    	  <span class="type">Table</span> <span class="variable">table</span> <span class="operator">=</span> connection.getTable(TableName.valueOf(tableName)); <span class="comment">// 获取表对象</span></span><br><span class="line">    	  <span class="type">Scan</span> <span class="variable">scan</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Scan</span>(); <span class="comment">// 创建扫描器</span></span><br><span class="line">    	  <span class="type">ResultScanner</span> <span class="variable">scanner</span> <span class="operator">=</span> table.getScanner(scan); <span class="comment">// 获取扫描结果</span></span><br><span class="line">    	  System.out.println(<span class="string">&quot;表 &quot;</span> + tableName + <span class="string">&quot; 的所有记录如下：&quot;</span>);</span><br><span class="line">    	  <span class="keyword">for</span> (Result result : scanner) &#123; <span class="comment">// 遍历每一行数据</span></span><br><span class="line">    	printRecoder(result); <span class="comment">// 打印每条记录的详情</span></span><br><span class="line">    	  &#125;</span><br><span class="line">    	  close(); <span class="comment">// 关闭连接</span></span><br><span class="line">    	 &#125;</span><br><span class="line">    	 <span class="comment">// 打印一条记录的详情</span></span><br><span class="line">    	 <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">printRecoder</span><span class="params">(Result result)</span> <span class="keyword">throws</span> IOException &#123;</span><br><span class="line">    	  <span class="keyword">for</span> (Cell cell : result.rawCells()) &#123; <span class="comment">// 遍历每个单元格</span></span><br><span class="line">    	System.out.print(<span class="string">&quot;行键: &quot;</span> + <span class="keyword">new</span> <span class="title class_">String</span>(Bytes.toString(cell.getRowArray(), cell.getRowOffset(), cell.getRowLength())));</span><br><span class="line">    	System.out.print(<span class="string">&quot; 列簇: &quot;</span> + <span class="keyword">new</span> <span class="title class_">String</span>(Bytes.toString(cell.getFamilyArray(), cell.getFamilyOffset(), cell.getFamilyLength())));</span><br><span class="line">    	System.out.print(<span class="string">&quot; 列: &quot;</span> + <span class="keyword">new</span> <span class="title class_">String</span>(Bytes.toString(cell.getQualifierArray(), cell.getQualifierOffset(), cell.getQualifierLength())));</span><br><span class="line">    	System.out.print(<span class="string">&quot; 值: &quot;</span> + <span class="keyword">new</span> <span class="title class_">String</span>(Bytes.toString(cell.getValueArray(), cell.getValueOffset(), cell.getValueLength())));</span><br><span class="line">    	System.out.println(<span class="string">&quot; 时间戳: &quot;</span> + cell.getTimestamp());</span><br><span class="line">    	  &#125;</span><br><span class="line">    	 &#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">init</span><span class="params">()</span> &#123;</span><br><span class="line">        configuration = HBaseConfiguration.create();</span><br><span class="line">        configuration.set(<span class="string">&quot;hbase.rootdir&quot;</span>, <span class="string">&quot;hbase://localhost:9000/hbase&quot;</span>);</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            connection = ConnectionFactory.createConnection(configuration);</span><br><span class="line">            <span class="keyword">if</span> (connection == <span class="literal">null</span>) &#123;</span><br><span class="line">                System.err.println(<span class="string">&quot;Failed to create HBase connection.&quot;</span>);</span><br><span class="line">            &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                System.out.println(<span class="string">&quot;HBase connection created successfully.&quot;</span>);</span><br><span class="line">            &#125;</span><br><span class="line">            admin = connection.getAdmin();</span><br><span class="line">            <span class="keyword">if</span> (admin == <span class="literal">null</span>) &#123;</span><br><span class="line">                System.err.println(<span class="string">&quot;Failed to get HBase Admin.&quot;</span>);</span><br><span class="line">            &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                System.out.println(<span class="string">&quot;HBase Admin initialized successfully.&quot;</span>);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125; <span class="keyword">catch</span> (IOException e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"> </span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">close</span><span class="params">()</span>&#123;</span><br><span class="line">        <span class="keyword">try</span>&#123;</span><br><span class="line">            <span class="keyword">if</span>(admin != <span class="literal">null</span>)&#123;</span><br><span class="line">                admin.close();</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">if</span>(<span class="literal">null</span> != connection)&#123;</span><br><span class="line">                connection.close();</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;<span class="keyword">catch</span> (IOException e)&#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"> </span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">createTable</span><span class="params">(String myTableName,String[] colFamily)</span> <span class="keyword">throws</span> IOException &#123;</span><br><span class="line">        <span class="type">TableName</span> <span class="variable">tableName</span> <span class="operator">=</span> TableName.valueOf(myTableName);</span><br><span class="line">        <span class="keyword">if</span>(admin.tableExists(tableName))&#123;</span><br><span class="line">            System.out.println(<span class="string">&quot;talbe is exists!&quot;</span>);</span><br><span class="line">        &#125;<span class="keyword">else</span> &#123;</span><br><span class="line">            <span class="type">TableDescriptorBuilder</span> <span class="variable">tableDescriptor</span> <span class="operator">=</span> TableDescriptorBuilder.newBuilder(tableName);</span><br><span class="line">            <span class="keyword">for</span>(String str:colFamily)&#123;</span><br><span class="line">                <span class="type">ColumnFamilyDescriptor</span> <span class="variable">family</span> <span class="operator">=</span> </span><br><span class="line">ColumnFamilyDescriptorBuilder.newBuilder(Bytes.toBytes(str)).build();</span><br><span class="line">                tableDescriptor.setColumnFamily(family);</span><br><span class="line">            &#125;</span><br><span class="line">            admin.createTable(tableDescriptor.build());</span><br><span class="line">        &#125; </span><br><span class="line">    &#125;</span><br><span class="line"> </span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">insertData</span><span class="params">(String tableName,String rowKey,String colFamily,String col,String val)</span> <span class="keyword">throws</span> IOException &#123; </span><br><span class="line">        <span class="type">Table</span> <span class="variable">table</span> <span class="operator">=</span> connection.getTable(TableName.valueOf(tableName));</span><br><span class="line">        <span class="type">Put</span> <span class="variable">put</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Put</span>(rowKey.getBytes());</span><br><span class="line">        put.addColumn(colFamily.getBytes(),col.getBytes(), val.getBytes());</span><br><span class="line">        table.put(put);</span><br><span class="line">        table.close(); </span><br><span class="line">    &#125;</span><br><span class="line"> </span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">getData</span><span class="params">(String tableName,String rowKey,String colFamily, String col)</span><span class="keyword">throws</span>  IOException&#123; </span><br><span class="line">        <span class="type">Table</span> <span class="variable">table</span> <span class="operator">=</span> connection.getTable(TableName.valueOf(tableName));</span><br><span class="line">        <span class="type">Get</span> <span class="variable">get</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Get</span>(rowKey.getBytes());</span><br><span class="line">        get.addColumn(colFamily.getBytes(),col.getBytes());</span><br><span class="line">        <span class="type">Result</span> <span class="variable">result</span> <span class="operator">=</span> table.get(get);</span><br><span class="line">        System.out.println(<span class="keyword">new</span> <span class="title class_">String</span>(result.getValue(colFamily.getBytes(),col==<span class="literal">null</span>?<span class="literal">null</span>:col.getBytes())));</span><br><span class="line">        table.close(); </span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>运行结果如下</p>
<p><img src="/../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/f5f936356529f42ce9823d1a641abb3e55933597-1746692007781-508-1747299497351-133-1747900721330-132-1749470495097-132.png" alt="image-20250408180840552"></p>
<p>③向已经创建好的表添加和删除指定的列族或列。</p>
<p><mark>shell</mark></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">create &#x27;s1&#x27;,&#x27;score&#x27;</span><br><span class="line">put &#x27;s1&#x27;,&#x27;zhangsan&#x27;,&#x27;score:Math&#x27;,&#x27;69&#x27;</span><br><span class="line">delete &#x27;s1&#x27;,&#x27;zhangsan&#x27;,&#x27;score:Math&#x27;</span><br></pre></td></tr></table></figure>
<p><img src="/../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/2e51321547d302cea1a9024b5bb2f1ad55933597-1746692007781-509-1747299497351-134-1747900721330-134-1749470495098-135.png" alt="image-20250408175944024"></p>
<p><mark>JAVA</mark></p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> org.apache.hadoop.conf.Configuration;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.hbase.*;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.hbase.client.*;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.hbase.util.Bytes;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.io.IOException;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">test</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> Configuration configuration;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> Connection connection;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> Admin admin;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> IOException &#123;</span><br><span class="line">        init(); <span class="comment">// 初始化连接</span></span><br><span class="line"></span><br><span class="line">        <span class="type">String</span> <span class="variable">tableName</span> <span class="operator">=</span> <span class="string">&quot;s1&quot;</span>; <span class="comment">// 表名</span></span><br><span class="line">        String[] columnFamilies = &#123;<span class="string">&quot;score&quot;</span>&#125;; <span class="comment">// 列簇</span></span><br><span class="line">        <span class="type">String</span> <span class="variable">rowKey</span> <span class="operator">=</span> <span class="string">&quot;zhangsan&quot;</span>; <span class="comment">// 行键</span></span><br><span class="line">        <span class="type">String</span> <span class="variable">colFamily</span> <span class="operator">=</span> <span class="string">&quot;score&quot;</span>; <span class="comment">// 列簇</span></span><br><span class="line">        <span class="type">String</span> <span class="variable">col</span> <span class="operator">=</span> <span class="string">&quot;Math&quot;</span>; <span class="comment">// 列名</span></span><br><span class="line">        <span class="type">String</span> <span class="variable">val</span> <span class="operator">=</span> <span class="string">&quot;69&quot;</span>; <span class="comment">// 值</span></span><br><span class="line"></span><br><span class="line">        <span class="comment">// 创建表</span></span><br><span class="line">        System.out.println(<span class="string">&quot;开始创建表...&quot;</span>);</span><br><span class="line">        createTable(tableName, columnFamilies);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 插入数据</span></span><br><span class="line">        System.out.println(<span class="string">&quot;开始插入数据...&quot;</span>);</span><br><span class="line">        insertRow(tableName, rowKey, colFamily, col, val);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 查询数据</span></span><br><span class="line">        System.out.println(<span class="string">&quot;验证插入的数据...&quot;</span>);</span><br><span class="line">        getData(tableName, rowKey, colFamily, col);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 删除数据</span></span><br><span class="line">        System.out.println(<span class="string">&quot;开始删除数据...&quot;</span>);</span><br><span class="line">        deleteRow(tableName, rowKey, colFamily, col);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 验证删除</span></span><br><span class="line">        System.out.println(<span class="string">&quot;验证删除后的数据...&quot;</span>);</span><br><span class="line">        getData(tableName, rowKey, colFamily, col);</span><br><span class="line"></span><br><span class="line">        close(); <span class="comment">// 关闭连接</span></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">init</span><span class="params">()</span> &#123;</span><br><span class="line">        configuration = HBaseConfiguration.create();</span><br><span class="line">        configuration.set(<span class="string">&quot;hbase.rootdir&quot;</span>, <span class="string">&quot;hdfs://localhost:9000/hbase&quot;</span>); <span class="comment">// 注意这里用的是 hdfs</span></span><br><span class="line">        configuration.set(<span class="string">&quot;hbase.zookeeper.quorum&quot;</span>, <span class="string">&quot;localhost&quot;</span>); <span class="comment">// 指定 zookeeper 地址</span></span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            connection = ConnectionFactory.createConnection(configuration);</span><br><span class="line">            admin = connection.getAdmin();</span><br><span class="line">            System.out.println(<span class="string">&quot;HBase connection and Admin initialized successfully.&quot;</span>);</span><br><span class="line">        &#125; <span class="keyword">catch</span> (IOException e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">close</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            <span class="keyword">if</span> (admin != <span class="literal">null</span>) &#123;</span><br><span class="line">                admin.close();</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">if</span> (connection != <span class="literal">null</span>) &#123;</span><br><span class="line">                connection.close();</span><br><span class="line">            &#125;</span><br><span class="line">        &#125; <span class="keyword">catch</span> (IOException e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">createTable</span><span class="params">(String myTableName, String[] colFamilies)</span> <span class="keyword">throws</span> IOException &#123;</span><br><span class="line">        <span class="type">TableName</span> <span class="variable">tableName</span> <span class="operator">=</span> TableName.valueOf(myTableName);</span><br><span class="line">        <span class="keyword">if</span> (admin.tableExists(tableName)) &#123;</span><br><span class="line">            System.out.println(<span class="string">&quot;表已存在！&quot;</span>);</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            <span class="type">TableDescriptorBuilder</span> <span class="variable">tableDescriptor</span> <span class="operator">=</span> TableDescriptorBuilder.newBuilder(tableName);</span><br><span class="line">            <span class="keyword">for</span> (String cf : colFamilies) &#123;</span><br><span class="line">                <span class="type">ColumnFamilyDescriptor</span> <span class="variable">family</span> <span class="operator">=</span></span><br><span class="line">                        ColumnFamilyDescriptorBuilder.newBuilder(Bytes.toBytes(cf)).build();</span><br><span class="line">                tableDescriptor.setColumnFamily(family);</span><br><span class="line">            &#125;</span><br><span class="line">            admin.createTable(tableDescriptor.build());</span><br><span class="line">            System.out.println(<span class="string">&quot;表 &quot;</span> + myTableName + <span class="string">&quot; 创建成功！&quot;</span>);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">insertRow</span><span class="params">(String tableName, String rowKey, String colFamily, String col, String val)</span> <span class="keyword">throws</span> IOException &#123;</span><br><span class="line">        <span class="type">Table</span> <span class="variable">table</span> <span class="operator">=</span> connection.getTable(TableName.valueOf(tableName));</span><br><span class="line">        <span class="type">Put</span> <span class="variable">put</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Put</span>(Bytes.toBytes(rowKey));</span><br><span class="line">        put.addColumn(Bytes.toBytes(colFamily), Bytes.toBytes(col), Bytes.toBytes(val));</span><br><span class="line">        table.put(put);</span><br><span class="line">        table.close();</span><br><span class="line">        System.out.println(<span class="string">&quot;数据插入成功！&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">getData</span><span class="params">(String tableName, String rowKey, String colFamily, String col)</span> <span class="keyword">throws</span> IOException &#123;</span><br><span class="line">        <span class="type">Table</span> <span class="variable">table</span> <span class="operator">=</span> connection.getTable(TableName.valueOf(tableName));</span><br><span class="line">        <span class="type">Get</span> <span class="variable">get</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Get</span>(Bytes.toBytes(rowKey));</span><br><span class="line">        get.addColumn(Bytes.toBytes(colFamily), Bytes.toBytes(col));</span><br><span class="line">        <span class="type">Result</span> <span class="variable">result</span> <span class="operator">=</span> table.get(get);</span><br><span class="line">        <span class="type">byte</span>[] value = result.getValue(Bytes.toBytes(colFamily), Bytes.toBytes(col));</span><br><span class="line">        <span class="keyword">if</span> (value != <span class="literal">null</span>) &#123;</span><br><span class="line">            System.out.println(<span class="string">&quot;获取到数据: &quot;</span> + <span class="keyword">new</span> <span class="title class_">String</span>(value));</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            System.out.println(<span class="string">&quot;未找到数据。&quot;</span>);</span><br><span class="line">        &#125;</span><br><span class="line">        table.close();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">deleteRow</span><span class="params">(String tableName, String rowKey, String colFamily, String col)</span> <span class="keyword">throws</span> IOException &#123;</span><br><span class="line">        <span class="type">Table</span> <span class="variable">table</span> <span class="operator">=</span> connection.getTable(TableName.valueOf(tableName));</span><br><span class="line">        <span class="type">Delete</span> <span class="variable">delete</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Delete</span>(Bytes.toBytes(rowKey));</span><br><span class="line">        delete.addColumn(Bytes.toBytes(colFamily), Bytes.toBytes(col));</span><br><span class="line">        table.delete(delete);</span><br><span class="line">        table.close();</span><br><span class="line">        System.out.println(<span class="string">&quot;数据删除成功！&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p><img src="/../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/4952ac8d1d540a6e277b0582297fbf2055933597-1746692007781-510-1747299497351-136-1747900721330-135-1749470495098-136.png" alt="image-20250408181938555"></p>
<hr>
<p>④清空指定表的所有记录数据。</p>
<p><mark>shell</mark></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">create &#x27;s1&#x27;,&#x27;score&#x27;</span><br><span class="line">put &#x27;s1&#x27;,&#x27;zhangsan&#x27;,&#x27;score:Math&#x27;,&#x27;69&#x27;</span><br><span class="line">truncate &#x27;s1&#x27;</span><br><span class="line">scan &#x27;s1&#x27;</span><br></pre></td></tr></table></figure>
<p><img src="/../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/7afb99cf0df777c1ef237f2b838b508a55933597-1746692007781-511-1747299497351-135-1747900721330-136-1749470495098-137.png" alt="image-20250408182046843"></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">put &#x27;s1&#x27;,&#x27;zhangsan&#x27;,&#x27;score:Math&#x27;,&#x27;69&#x27;</span><br></pre></td></tr></table></figure>
<p><mark>java</mark></p>
<p>教材中的代码</p>
<p><code>clearRows()</code> 方法缺了一个 <strong>关键点</strong>：</p>
<blockquote>
<p>在删除表之后重新创建时，需要重新添加原来的列簇（否则建出来的表是空结构）。</p>
</blockquote>
<p>所以我用新的</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> org.apache.hadoop.conf.Configuration;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.hbase.HBaseConfiguration;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.hbase.TableName;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.hbase.client.*;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.hbase.util.Bytes;</span><br><span class="line"><span class="keyword">import</span> java.io.IOException;</span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">test</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> Configuration configuration;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> Connection connection;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> Admin admin;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> IOException &#123;</span><br><span class="line">        <span class="type">String</span> <span class="variable">tableName</span> <span class="operator">=</span> <span class="string">&quot;s1&quot;</span>; <span class="comment">// 你要清空的表名</span></span><br><span class="line">        clearRows(tableName);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// 初始化 HBase 连接</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">init</span><span class="params">()</span> <span class="keyword">throws</span> IOException &#123;</span><br><span class="line">        configuration = HBaseConfiguration.create();</span><br><span class="line">        configuration.set(<span class="string">&quot;hbase.rootdir&quot;</span>, <span class="string">&quot;hdfs://localhost:9000/hbase&quot;</span>);</span><br><span class="line">        configuration.set(<span class="string">&quot;hbase.zookeeper.quorum&quot;</span>, <span class="string">&quot;localhost&quot;</span>);</span><br><span class="line">        connection = ConnectionFactory.createConnection(configuration);</span><br><span class="line">        admin = connection.getAdmin();</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// 关闭 HBase 连接</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">close</span><span class="params">()</span> <span class="keyword">throws</span> IOException &#123;</span><br><span class="line">        <span class="keyword">if</span> (admin != <span class="literal">null</span>) admin.close();</span><br><span class="line">        <span class="keyword">if</span> (connection != <span class="literal">null</span>) connection.close();</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// 清空指定表的所有数据，保留列簇结构</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">clearRows</span><span class="params">(String tableNameStr)</span> <span class="keyword">throws</span> IOException &#123;</span><br><span class="line">        init(); <span class="comment">// 初始化连接</span></span><br><span class="line">        <span class="type">TableName</span> <span class="variable">tableName</span> <span class="operator">=</span> TableName.valueOf(tableNameStr);</span><br><span class="line">        <span class="keyword">if</span> (!admin.tableExists(tableName)) &#123;</span><br><span class="line">            System.out.println(<span class="string">&quot;表不存在，无法清空！&quot;</span>);</span><br><span class="line">            close();</span><br><span class="line">            <span class="keyword">return</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">// 获取原始表结构</span></span><br><span class="line">        <span class="type">TableDescriptor</span> <span class="variable">descriptor</span> <span class="operator">=</span> admin.getDescriptor(tableName);</span><br><span class="line">        <span class="comment">// 禁用表</span></span><br><span class="line">        <span class="keyword">if</span> (!admin.isTableDisabled(tableName)) &#123;</span><br><span class="line">            admin.disableTable(tableName);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">// 删除表</span></span><br><span class="line">        admin.deleteTable(tableName);</span><br><span class="line">        <span class="comment">// 重新创建表（使用原结构）</span></span><br><span class="line">        admin.createTable(descriptor);</span><br><span class="line">        System.out.println(<span class="string">&quot;表 [&quot;</span> + tableNameStr + <span class="string">&quot;] 已清空（保留列簇结构）&quot;</span>);</span><br><span class="line">        close(); <span class="comment">// 关闭连接</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p><img src="/../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/073c2af343c85961acffe8bcfe440c1855933597-1746692007781-512-1747299497351-137-1747900721330-137-1749470495098-138.png" alt="image-20250408182815289"></p>
<p>这时候再去查表</p>
<p><img src="/../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/af59211330068025067a668b71a2da5b55933597-1746692007781-513-1747299497351-138-1747900721330-138-1749470495098-139.png" alt="image-20250408182848140"></p>
<hr>
<p>⑤统计表的行数。</p>
<p><mark>shell</mark></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">put &#x27;s1&#x27;,&#x27;zhangsan&#x27;,&#x27;score:Math&#x27;,&#x27;69&#x27;</span><br><span class="line">count  &#x27;s1&#x27;</span><br></pre></td></tr></table></figure>
<p><img src="/../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/981c0e0a9e8be7f01f8de72ca3ddb26555933597-1746692007781-514-1747299497351-139-1747900721330-139-1749470495098-140.png" alt="image-20250408182937568"></p>
<p><mark>java</mark></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br></pre></td><td class="code"><pre><span class="line">import org.apache.hadoop.conf.Configuration;</span><br><span class="line">import org.apache.hadoop.hbase.HBaseConfiguration;</span><br><span class="line">import org.apache.hadoop.hbase.TableName;</span><br><span class="line">import org.apache.hadoop.hbase.client.*;</span><br><span class="line"></span><br><span class="line">import java.io.IOException;</span><br><span class="line"></span><br><span class="line">public class test &#123;</span><br><span class="line">    public static Configuration configuration;</span><br><span class="line">    public static Connection connection;</span><br><span class="line">    public static Admin admin;</span><br><span class="line"></span><br><span class="line">    public static void main(String[] args) throws IOException &#123;</span><br><span class="line">        String tableName = &quot;s1&quot;; // 你要统计的表名</span><br><span class="line">        countRows(tableName);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    // 初始化 HBase 连接</span><br><span class="line">    public static void init() throws IOException &#123;</span><br><span class="line">        configuration = HBaseConfiguration.create();</span><br><span class="line">        configuration.set(&quot;hbase.rootdir&quot;, &quot;hdfs://localhost:9000/hbase&quot;);</span><br><span class="line">        configuration.set(&quot;hbase.zookeeper.quorum&quot;, &quot;localhost&quot;);</span><br><span class="line">        connection = ConnectionFactory.createConnection(configuration);</span><br><span class="line">        admin = connection.getAdmin();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    // 关闭 HBase 连接</span><br><span class="line">    public static void close() throws IOException &#123;</span><br><span class="line">        if (admin != null) admin.close();</span><br><span class="line">        if (connection != null) connection.close();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    // 统计表的行数</span><br><span class="line">    public static void countRows(String tableName) throws IOException &#123;</span><br><span class="line">        init(); // 初始化连接</span><br><span class="line"></span><br><span class="line">        Table table = connection.getTable(TableName.valueOf(tableName));</span><br><span class="line">        Scan scan = new Scan();</span><br><span class="line">        scan.setCaching(500); // 可选优化，加快扫描速度</span><br><span class="line"></span><br><span class="line">        ResultScanner scanner = table.getScanner(scan);</span><br><span class="line"></span><br><span class="line">        int num = 0;</span><br><span class="line">        for (Result result = scanner.next(); result != null; result = scanner.next()) &#123;</span><br><span class="line">            num++;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        System.out.println(&quot;表 [&quot; + tableName + &quot;] 的总行数为: &quot; + num);</span><br><span class="line"></span><br><span class="line">        scanner.close();</span><br><span class="line">        table.close(); // 关闭 Table 对象</span><br><span class="line">        close();       // 关闭连接</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p><img src="/../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/6a04692ff70305b199bc63ac2b63d60b55933597-1746692007781-515-1747299497351-140-1747900721330-140-1749470495098-141.png" alt="image-20250408183057896"></p>
<h3 id="第二题">第二题</h3>
<p>（2）现有以下关系数据库中的表（见表4-21、表4-22和表4-23），要求将其转换为适合HBase存储的表并插入数据。</p>
<p>表4-21 学生（Student）表</p>
<table>
<thead>
<tr>
<th>学号（S_No）</th>
<th>姓名（S_Name）</th>
<th>性别（S_Sex）</th>
<th>年龄（S_Age）</th>
</tr>
</thead>
<tbody>
<tr>
<td>2015001</td>
<td>Zhangsan</td>
<td>male</td>
<td>23</td>
</tr>
<tr>
<td>2015002</td>
<td>Mary</td>
<td>female</td>
<td>22</td>
</tr>
<tr>
<td>2015003</td>
<td>Lisi</td>
<td>male</td>
<td>24</td>
</tr>
</tbody>
</table>
<p>表4-22 课程（Course）表</p>
<table>
<thead>
<tr>
<th>课程号（C_No）</th>
<th>课程名（C_Name）</th>
<th>学分（C_Credit）</th>
</tr>
</thead>
<tbody>
<tr>
<td>123001</td>
<td>Math</td>
<td>2.0</td>
</tr>
<tr>
<td>123002</td>
<td>Computer Science</td>
<td>5.0</td>
</tr>
<tr>
<td>123003</td>
<td>English</td>
<td>3.0</td>
</tr>
</tbody>
</table>
<p>表4-23  选课（SC）表</p>
<table>
<thead>
<tr>
<th>学号（SC_Sno）</th>
<th>课程号（SC_Cno）</th>
<th>成绩（SC_Score）</th>
</tr>
</thead>
<tbody>
<tr>
<td>2015001</td>
<td>123001</td>
<td>86</td>
</tr>
<tr>
<td>2015001</td>
<td>123003</td>
<td>69</td>
</tr>
<tr>
<td>2015002</td>
<td>123002</td>
<td>77</td>
</tr>
<tr>
<td>2015002</td>
<td>123003</td>
<td>99</td>
</tr>
<tr>
<td>2015003</td>
<td>123001</td>
<td>98</td>
</tr>
<tr>
<td>2015003</td>
<td>123002</td>
<td>95</td>
</tr>
</tbody>
</table>
<p><mark>shell</mark></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">disable &#x27;student&#x27;</span><br><span class="line">drop &#x27;student&#x27;</span><br></pre></td></tr></table></figure>
<p>创建学生 student表</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">create &#x27;Student&#x27;,&#x27;S_No&#x27;,&#x27;S_Name&#x27;,&#x27;S_Sex&#x27;,&#x27;S_Age&#x27;</span><br><span class="line">put &#x27;Student&#x27;,&#x27;s001&#x27;,&#x27;S_No&#x27;,&#x27;2015001&#x27;</span><br><span class="line">put &#x27;Student&#x27;,&#x27;s001&#x27;,&#x27;S_Name&#x27;,&#x27;Zhangsan&#x27;</span><br><span class="line">put &#x27;Student&#x27;,&#x27;s001&#x27;,&#x27;S_Sex&#x27;,&#x27;male&#x27;</span><br><span class="line">put &#x27;Student&#x27;,&#x27;s001&#x27;,&#x27;S_Age&#x27;,&#x27;23&#x27;</span><br><span class="line">put &#x27;Student&#x27;,&#x27;s002&#x27;,&#x27;S_No&#x27;,&#x27;2015002&#x27;</span><br><span class="line">put &#x27;Student&#x27;,&#x27;s002&#x27;,&#x27;S_Name&#x27;,&#x27;Mary&#x27;</span><br><span class="line">put &#x27;Student&#x27;,&#x27;s002&#x27;,&#x27;S_Sex&#x27;,&#x27;female&#x27;</span><br><span class="line">put &#x27;Student&#x27;,&#x27;s002&#x27;,&#x27;S_Age&#x27;,&#x27;22&#x27;</span><br><span class="line">put &#x27;Student&#x27;,&#x27;s003&#x27;,&#x27;S_No&#x27;,&#x27;2015003&#x27;</span><br><span class="line">put &#x27;Student&#x27;,&#x27;s003&#x27;,&#x27;S_Name&#x27;,&#x27;Lisi&#x27;</span><br><span class="line">put &#x27;Student&#x27;,&#x27;s003&#x27;,&#x27;S_Sex&#x27;,&#x27;male&#x27;</span><br><span class="line">put &#x27;Student&#x27;,&#x27;s003&#x27;,&#x27;S_Age&#x27;,&#x27;24&#x27;</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p><img src="/../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/5e31a2708e11baa119c76ecde299ab6355933597-1746692007781-516-1747299497351-141-1747900721330-141-1749470495098-142.png" alt="image-20250408183744904"></p>
<p>创建课程 Course 表</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">create &#x27;Course&#x27;,&#x27;C_No&#x27;,&#x27;C_Name&#x27;,&#x27;C_Credit&#x27;</span><br><span class="line">put &#x27;Course&#x27;,&#x27;c001&#x27;,&#x27;C_No&#x27;,&#x27;123001&#x27;</span><br><span class="line">put &#x27;Course&#x27;,&#x27;c001&#x27;,&#x27;C_Name&#x27;,&#x27;Math&#x27;</span><br><span class="line">put &#x27;Course&#x27;,&#x27;c001&#x27;,&#x27;C_Credit&#x27;,&#x27;2.0&#x27;</span><br><span class="line">put &#x27;Course&#x27;,&#x27;c002&#x27;,&#x27;C_No&#x27;,&#x27;123002&#x27;</span><br><span class="line">put &#x27;Course&#x27;,&#x27;c002&#x27;,&#x27;C_Name&#x27;,&#x27;Computer&#x27;</span><br><span class="line">put &#x27;Course&#x27;,&#x27;c002&#x27;,&#x27;C_Credit&#x27;,&#x27;5.0&#x27;</span><br><span class="line">put &#x27;Course&#x27;,&#x27;c003&#x27;,&#x27;C_No&#x27;,&#x27;123003&#x27;</span><br><span class="line">put &#x27;Course&#x27;,&#x27;c003&#x27;,&#x27;C_Name&#x27;,&#x27;English&#x27;</span><br><span class="line">put &#x27;Course&#x27;,&#x27;c003&#x27;,&#x27;C_Credit&#x27;,&#x27;3.0&#x27;</span><br></pre></td></tr></table></figure>
<p><img src="/../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/b90f6dce4ae75d8d6aae1ff094bbddb455933597-1746692007781-517-1747299497351-142-1747900721330-142-1749470495098-144.png" alt="image-20250408183801194"></p>
<p>创建选课 SC 表</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">create &#x27;SC&#x27;,&#x27;SC_Sno&#x27;,&#x27;SC_Cno&#x27;,&#x27;SC_Score&#x27;</span><br><span class="line">put &#x27;SC&#x27;,&#x27;sc001&#x27;,&#x27;SC_Sno&#x27;,&#x27;2015001&#x27;</span><br><span class="line">put &#x27;SC&#x27;,&#x27;sc001&#x27;,&#x27;SC_Cno&#x27;,&#x27;123001&#x27;</span><br><span class="line">put &#x27;SC&#x27;,&#x27;sc001&#x27;,&#x27;SC_Score&#x27;,&#x27;86&#x27;</span><br><span class="line">put &#x27;SC&#x27;,&#x27;sc002&#x27;,&#x27;SC_Sno&#x27;,&#x27;2015001&#x27;</span><br><span class="line">put &#x27;SC&#x27;,&#x27;sc002&#x27;,&#x27;SC_Cno&#x27;,&#x27;123003&#x27;</span><br><span class="line">put &#x27;SC&#x27;,&#x27;sc002&#x27;,&#x27;SC_Score&#x27;,&#x27;69&#x27;</span><br><span class="line">put &#x27;SC&#x27;,&#x27;sc003&#x27;,&#x27;SC_Sno&#x27;,&#x27;2015002&#x27;</span><br><span class="line">put &#x27;SC&#x27;,&#x27;sc003&#x27;,&#x27;SC_Cno&#x27;,&#x27;123002&#x27;</span><br><span class="line">put &#x27;SC&#x27;,&#x27;sc003&#x27;,&#x27;SC_Score&#x27;,&#x27;77&#x27;</span><br><span class="line">put &#x27;SC&#x27;,&#x27;sc004&#x27;,&#x27;SC_Sno&#x27;,&#x27;2015002&#x27;</span><br><span class="line">put &#x27;SC&#x27;,&#x27;sc004&#x27;,&#x27;SC_Cno&#x27;,&#x27;123003&#x27;</span><br><span class="line">put &#x27;SC&#x27;,&#x27;sc004&#x27;,&#x27;SC_Score&#x27;,&#x27;99&#x27;</span><br><span class="line">put &#x27;SC&#x27;,&#x27;sc005&#x27;,&#x27;SC_Sno&#x27;,&#x27;2015003&#x27;</span><br><span class="line">put &#x27;SC&#x27;,&#x27;sc005&#x27;,&#x27;SC_Cno&#x27;,&#x27;123001&#x27;</span><br><span class="line">put &#x27;SC&#x27;,&#x27;sc005&#x27;,&#x27;SC_Score&#x27;,&#x27;98&#x27;</span><br><span class="line">put &#x27;SC&#x27;,&#x27;sc006&#x27;,&#x27;SC_Sno&#x27;,&#x27;2015003&#x27;</span><br><span class="line">put &#x27;SC&#x27;,&#x27;sc006&#x27;,&#x27;SC_Cno&#x27;,&#x27;123002&#x27;</span><br><span class="line">put &#x27;SC&#x27;,&#x27;sc006&#x27;,&#x27;SC_Score&#x27;,&#x27;95&#x27;</span><br></pre></td></tr></table></figure>
<p><img src="/../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/5c7e6e07073a4fc9aaab422f5d7ea6ff55933597-1746692007781-518-1747299497351-144-1747900721330-143-1749470495098-143.png" alt="image-20250408183820490"></p>
<p>验证</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">scan &#x27;Student&#x27;</span><br><span class="line">scan &#x27;Course&#x27;</span><br><span class="line">scan &#x27;SC&#x27;</span><br></pre></td></tr></table></figure>
<p><img src="/../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/32917960477379ca6d005534185fbfd555933597-1746692007781-519-1747299497351-143-1747900721330-144-1749470495098-145.png" alt="image-20250408184041557"></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">disable &#x27;Student&#x27;</span><br><span class="line">drop &#x27;Student&#x27;</span><br><span class="line">disable &#x27;Course&#x27;</span><br><span class="line">drop &#x27;Course&#x27;</span><br><span class="line">disable &#x27;SC&#x27;</span><br><span class="line">drop &#x27;SC&#x27;</span><br></pre></td></tr></table></figure>
<p><mark>java</mark></p>
<p>① createTable(String tableName, String[] fields)。</p>
<p>② addRecord(String tableName, String row, String[] fields, String[]values)。</p>
<p>③ scanColumn(String tableName, String column)。</p>
<p>④ modifyData(String tableName, String row, String column)。</p>
<p>⑤ deleteRow(String tableName, String row)。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> java.io.IOException;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.conf.Configuration;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.hbase.*;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.hbase.client.*;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.hbase.util.Bytes;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">test</span> &#123;</span><br><span class="line">    <span class="keyword">static</span> Connection connection;</span><br><span class="line">    <span class="keyword">static</span> Admin admin;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">init</span><span class="params">()</span> <span class="keyword">throws</span> IOException &#123;</span><br><span class="line">        <span class="type">Configuration</span> <span class="variable">conf</span> <span class="operator">=</span> HBaseConfiguration.create();</span><br><span class="line">        conf.set(<span class="string">&quot;hbase.zookeeper.quorum&quot;</span>, <span class="string">&quot;localhost&quot;</span>);</span><br><span class="line">        connection = ConnectionFactory.createConnection(conf);</span><br><span class="line">        admin = connection.getAdmin();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">close</span><span class="params">()</span> <span class="keyword">throws</span> IOException &#123;</span><br><span class="line">        <span class="keyword">if</span> (admin != <span class="literal">null</span>) admin.close();</span><br><span class="line">        <span class="keyword">if</span> (connection != <span class="literal">null</span>) connection.close();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">createTable</span><span class="params">(String tableName, String[] fields)</span> <span class="keyword">throws</span> IOException &#123;</span><br><span class="line">        init();</span><br><span class="line">        <span class="type">TableName</span> <span class="variable">tablename</span> <span class="operator">=</span> TableName.valueOf(tableName);</span><br><span class="line">        <span class="keyword">if</span> (admin.tableExists(tablename)) &#123;</span><br><span class="line">            System.out.println(<span class="string">&quot;表 &quot;</span> + tableName + <span class="string">&quot; 已存在，正在删除...&quot;</span>);</span><br><span class="line">            admin.disableTable(tablename);</span><br><span class="line">            admin.deleteTable(tablename);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="type">TableDescriptorBuilder</span> <span class="variable">tableDescriptor</span> <span class="operator">=</span> TableDescriptorBuilder.newBuilder(tablename);</span><br><span class="line">        <span class="keyword">for</span> (String str : fields) &#123;</span><br><span class="line">            tableDescriptor.setColumnFamily(ColumnFamilyDescriptorBuilder.newBuilder(Bytes.toBytes(str)).build());</span><br><span class="line">        &#125;</span><br><span class="line">        admin.createTable(tableDescriptor.build());</span><br><span class="line">        System.out.println(<span class="string">&quot;表 &quot;</span> + tableName + <span class="string">&quot; 创建成功&quot;</span>);</span><br><span class="line">        close();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">addRecord</span><span class="params">(String tableName, String row, String[] fields, String[] values)</span> <span class="keyword">throws</span> IOException &#123;</span><br><span class="line">        init();</span><br><span class="line">        <span class="type">Table</span> <span class="variable">table</span> <span class="operator">=</span> connection.getTable(TableName.valueOf(tableName));</span><br><span class="line">        <span class="type">Put</span> <span class="variable">put</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Put</span>(Bytes.toBytes(row));</span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> <span class="variable">i</span> <span class="operator">=</span> <span class="number">0</span>; i &lt; fields.length; i++) &#123;</span><br><span class="line">            String[] parts = fields[i].split(<span class="string">&quot;:&quot;</span>);</span><br><span class="line">            put.addColumn(Bytes.toBytes(parts[<span class="number">0</span>], Bytes.toBytes(parts[<span class="number">1</span>], Bytes.toBytes(values[i]);</span><br><span class="line">        &#125;</span><br><span class="line">        table.put(put);</span><br><span class="line">        table.close();</span><br><span class="line">        close();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">scanColumn</span><span class="params">(String tableName, String column)</span> <span class="keyword">throws</span> IOException &#123;</span><br><span class="line">        init();</span><br><span class="line">        <span class="type">Table</span> <span class="variable">table</span> <span class="operator">=</span> connection.getTable(TableName.valueOf(tableName));</span><br><span class="line">        <span class="type">Scan</span> <span class="variable">scan</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Scan</span>();</span><br><span class="line">        <span class="keyword">if</span> (column.contains(<span class="string">&quot;:&quot;</span>)) &#123;</span><br><span class="line">            String[] parts = column.split(<span class="string">&quot;:&quot;</span>);</span><br><span class="line">            scan.addColumn(Bytes.toBytes(parts[<span class="number">0</span>], Bytes.toBytes(parts[<span class="number">1</span>]);</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            scan.addFamily(Bytes.toBytes(column));</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="type">ResultScanner</span> <span class="variable">scanner</span> <span class="operator">=</span> table.getScanner(scan);</span><br><span class="line">        <span class="keyword">for</span> (<span class="type">Result</span> <span class="variable">result</span> <span class="operator">=</span> scanner.next(); result != <span class="literal">null</span>; result = scanner.next()) &#123;</span><br><span class="line">            showCell(result);</span><br><span class="line">        &#125;</span><br><span class="line">        scanner.close();</span><br><span class="line">        table.close();</span><br><span class="line">        close();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">showCell</span><span class="params">(Result result)</span> &#123;</span><br><span class="line">        <span class="keyword">for</span> (Cell cell : result.rawCells()) &#123;</span><br><span class="line">            System.out.println(<span class="string">&quot;RowName: &quot;</span> + Bytes.toString(CellUtil.cloneRow(cell)));</span><br><span class="line">            System.out.println(<span class="string">&quot;Timestamp: &quot;</span> + cell.getTimestamp());</span><br><span class="line">            System.out.println(<span class="string">&quot;ColumnFamily: &quot;</span> + Bytes.toString(CellUtil.cloneFamily(cell)));</span><br><span class="line">            System.out.println(<span class="string">&quot;Column: &quot;</span> + Bytes.toString(CellUtil.cloneQualifier(cell)));</span><br><span class="line">            System.out.println(<span class="string">&quot;Value: &quot;</span> + Bytes.toString(CellUtil.cloneValue(cell)));</span><br><span class="line">            System.out.println(<span class="string">&quot;----------------------------------------&quot;</span>);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">modifyData</span><span class="params">(String tableName, String row, String column, String val)</span> <span class="keyword">throws</span> IOException &#123;</span><br><span class="line">        init();</span><br><span class="line">        <span class="type">Table</span> <span class="variable">table</span> <span class="operator">=</span> connection.getTable(TableName.valueOf(tableName));</span><br><span class="line">        String[] parts = column.split(<span class="string">&quot;:&quot;</span>);</span><br><span class="line">        <span class="type">Put</span> <span class="variable">put</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Put</span>(Bytes.toBytes(row));</span><br><span class="line">        put.addColumn(Bytes.toBytes(parts[<span class="number">0</span>], Bytes.toBytes(parts[<span class="number">1</span>], Bytes.toBytes(val));</span><br><span class="line">        table.put(put);</span><br><span class="line">        System.out.println(<span class="string">&quot;修改表 &quot;</span> + tableName + <span class="string">&quot; 中 &quot;</span> + row + <span class="string">&quot; 行的列 &quot;</span> + column + <span class="string">&quot; 为 &quot;</span> + val);</span><br><span class="line">        table.close();</span><br><span class="line">        close();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">deleteRow</span><span class="params">(String tableName, String row)</span> <span class="keyword">throws</span> IOException &#123;</span><br><span class="line">        init();</span><br><span class="line">        <span class="type">Table</span> <span class="variable">table</span> <span class="operator">=</span> connection.getTable(TableName.valueOf(tableName));</span><br><span class="line">        <span class="type">Delete</span> <span class="variable">delete</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Delete</span>(Bytes.toBytes(row));</span><br><span class="line">        table.delete(delete);</span><br><span class="line">        System.out.println(<span class="string">&quot;删除表 &quot;</span> + tableName + <span class="string">&quot; 中的行 &quot;</span> + row);</span><br><span class="line">        table.close();</span><br><span class="line">        close();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> IOException &#123;</span><br><span class="line">        <span class="comment">// Student 表</span></span><br><span class="line">        createTable(<span class="string">&quot;Student&quot;</span>, <span class="keyword">new</span> <span class="title class_">String</span>[]&#123;<span class="string">&quot;S_No&quot;</span>, <span class="string">&quot;S_Name&quot;</span>, <span class="string">&quot;S_Sex&quot;</span>, <span class="string">&quot;S_Age&quot;</span>&#125;);</span><br><span class="line">        addRecord(<span class="string">&quot;Student&quot;</span>, <span class="string">&quot;s001&quot;</span>, <span class="keyword">new</span> <span class="title class_">String</span>[]&#123;<span class="string">&quot;S_No:S_No&quot;</span>, <span class="string">&quot;S_Name:S_Name&quot;</span>, <span class="string">&quot;S_Sex:S_Sex&quot;</span>, <span class="string">&quot;S_Age:S_Age&quot;</span>&#125;,</span><br><span class="line">                <span class="keyword">new</span> <span class="title class_">String</span>[]&#123;<span class="string">&quot;2015001&quot;</span>, <span class="string">&quot;Zhangsan&quot;</span>, <span class="string">&quot;male&quot;</span>, <span class="string">&quot;23&quot;</span>&#125;);</span><br><span class="line">        addRecord(<span class="string">&quot;Student&quot;</span>, <span class="string">&quot;s002&quot;</span>, <span class="keyword">new</span> <span class="title class_">String</span>[]&#123;<span class="string">&quot;S_No:S_No&quot;</span>, <span class="string">&quot;S_Name:S_Name&quot;</span>, <span class="string">&quot;S_Sex:S_Sex&quot;</span>, <span class="string">&quot;S_Age:S_Age&quot;</span>&#125;,</span><br><span class="line">                <span class="keyword">new</span> <span class="title class_">String</span>[]&#123;<span class="string">&quot;2015002&quot;</span>, <span class="string">&quot;Mary&quot;</span>, <span class="string">&quot;female&quot;</span>, <span class="string">&quot;22&quot;</span>&#125;);</span><br><span class="line">        addRecord(<span class="string">&quot;Student&quot;</span>, <span class="string">&quot;s003&quot;</span>, <span class="keyword">new</span> <span class="title class_">String</span>[]&#123;<span class="string">&quot;S_No:S_No&quot;</span>, <span class="string">&quot;S_Name:S_Name&quot;</span>, <span class="string">&quot;S_Sex:S_Sex&quot;</span>, <span class="string">&quot;S_Age:S_Age&quot;</span>&#125;,</span><br><span class="line">                <span class="keyword">new</span> <span class="title class_">String</span>[]&#123;<span class="string">&quot;2015003&quot;</span>, <span class="string">&quot;Lisi&quot;</span>, <span class="string">&quot;male&quot;</span>, <span class="string">&quot;24&quot;</span>&#125;);</span><br><span class="line">        System.out.println(<span class="string">&quot;Student 表插入数据成功&quot;</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// Course 表</span></span><br><span class="line">        createTable(<span class="string">&quot;Course&quot;</span>, <span class="keyword">new</span> <span class="title class_">String</span>[]&#123;<span class="string">&quot;C_No&quot;</span>, <span class="string">&quot;C_Name&quot;</span>, <span class="string">&quot;C_Credit&quot;</span>&#125;);</span><br><span class="line">        addRecord(<span class="string">&quot;Course&quot;</span>, <span class="string">&quot;c001&quot;</span>, <span class="keyword">new</span> <span class="title class_">String</span>[]&#123;<span class="string">&quot;C_No:C_No&quot;</span>, <span class="string">&quot;C_Name:C_Name&quot;</span>, <span class="string">&quot;C_Credit:C_Credit&quot;</span>&#125;,</span><br><span class="line">                <span class="keyword">new</span> <span class="title class_">String</span>[]&#123;<span class="string">&quot;123001&quot;</span>, <span class="string">&quot;Math&quot;</span>, <span class="string">&quot;2.0&quot;</span>&#125;);</span><br><span class="line">        addRecord(<span class="string">&quot;Course&quot;</span>, <span class="string">&quot;c002&quot;</span>, <span class="keyword">new</span> <span class="title class_">String</span>[]&#123;<span class="string">&quot;C_No:C_No&quot;</span>, <span class="string">&quot;C_Name:C_Name&quot;</span>, <span class="string">&quot;C_Credit:C_Credit&quot;</span>&#125;,</span><br><span class="line">                <span class="keyword">new</span> <span class="title class_">String</span>[]&#123;<span class="string">&quot;123002&quot;</span>, <span class="string">&quot;Computer&quot;</span>, <span class="string">&quot;5.0&quot;</span>&#125;);</span><br><span class="line">        addRecord(<span class="string">&quot;Course&quot;</span>, <span class="string">&quot;c003&quot;</span>, <span class="keyword">new</span> <span class="title class_">String</span>[]&#123;<span class="string">&quot;C_No:C_No&quot;</span>, <span class="string">&quot;C_Name:C_Name&quot;</span>, <span class="string">&quot;C_Credit:C_Credit&quot;</span>&#125;,</span><br><span class="line">                <span class="keyword">new</span> <span class="title class_">String</span>[]&#123;<span class="string">&quot;123003&quot;</span>, <span class="string">&quot;English&quot;</span>, <span class="string">&quot;3.0&quot;</span>&#125;);</span><br><span class="line">        System.out.println(<span class="string">&quot;Course 表插入数据成功&quot;</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// SC 表</span></span><br><span class="line">        createTable(<span class="string">&quot;SC&quot;</span>, <span class="keyword">new</span> <span class="title class_">String</span>[]&#123;<span class="string">&quot;SC_Sno&quot;</span>, <span class="string">&quot;SC_Cno&quot;</span>, <span class="string">&quot;SC_Score&quot;</span>&#125;);</span><br><span class="line">        addRecord(<span class="string">&quot;SC&quot;</span>, <span class="string">&quot;sc001&quot;</span>, <span class="keyword">new</span> <span class="title class_">String</span>[]&#123;<span class="string">&quot;SC_Sno:SC_Sno&quot;</span>, <span class="string">&quot;SC_Cno:SC_Cno&quot;</span>, <span class="string">&quot;SC_Score:SC_Score&quot;</span>&#125;,</span><br><span class="line">                <span class="keyword">new</span> <span class="title class_">String</span>[]&#123;<span class="string">&quot;2015001&quot;</span>, <span class="string">&quot;123001&quot;</span>, <span class="string">&quot;86&quot;</span>&#125;);</span><br><span class="line">        addRecord(<span class="string">&quot;SC&quot;</span>, <span class="string">&quot;sc002&quot;</span>, <span class="keyword">new</span> <span class="title class_">String</span>[]&#123;<span class="string">&quot;SC_Sno:SC_Sno&quot;</span>, <span class="string">&quot;SC_Cno:SC_Cno&quot;</span>, <span class="string">&quot;SC_Score:SC_Score&quot;</span>&#125;,</span><br><span class="line">                <span class="keyword">new</span> <span class="title class_">String</span>[]&#123;<span class="string">&quot;2015001&quot;</span>, <span class="string">&quot;123003&quot;</span>, <span class="string">&quot;69&quot;</span>&#125;);</span><br><span class="line">        addRecord(<span class="string">&quot;SC&quot;</span>, <span class="string">&quot;sc003&quot;</span>, <span class="keyword">new</span> <span class="title class_">String</span>[]&#123;<span class="string">&quot;SC_Sno:SC_Sno&quot;</span>, <span class="string">&quot;SC_Cno:SC_Cno&quot;</span>, <span class="string">&quot;SC_Score:SC_Score&quot;</span>&#125;,</span><br><span class="line">                <span class="keyword">new</span> <span class="title class_">String</span>[]&#123;<span class="string">&quot;2015002&quot;</span>, <span class="string">&quot;123002&quot;</span>, <span class="string">&quot;77&quot;</span>&#125;);</span><br><span class="line">        addRecord(<span class="string">&quot;SC&quot;</span>, <span class="string">&quot;sc004&quot;</span>, <span class="keyword">new</span> <span class="title class_">String</span>[]&#123;<span class="string">&quot;SC_Sno:SC_Sno&quot;</span>, <span class="string">&quot;SC_Cno:SC_Cno&quot;</span>, <span class="string">&quot;SC_Score:SC_Score&quot;</span>&#125;,</span><br><span class="line">                <span class="keyword">new</span> <span class="title class_">String</span>[]&#123;<span class="string">&quot;2015002&quot;</span>, <span class="string">&quot;123003&quot;</span>, <span class="string">&quot;99&quot;</span>&#125;);</span><br><span class="line">        addRecord(<span class="string">&quot;SC&quot;</span>, <span class="string">&quot;sc005&quot;</span>, <span class="keyword">new</span> <span class="title class_">String</span>[]&#123;<span class="string">&quot;SC_Sno:SC_Sno&quot;</span>, <span class="string">&quot;SC_Cno:SC_Cno&quot;</span>, <span class="string">&quot;SC_Score:SC_Score&quot;</span>&#125;,</span><br><span class="line">                <span class="keyword">new</span> <span class="title class_">String</span>[]&#123;<span class="string">&quot;2015003&quot;</span>, <span class="string">&quot;123001&quot;</span>, <span class="string">&quot;98&quot;</span>&#125;);</span><br><span class="line">        addRecord(<span class="string">&quot;SC&quot;</span>, <span class="string">&quot;sc006&quot;</span>, <span class="keyword">new</span> <span class="title class_">String</span>[]&#123;<span class="string">&quot;SC_Sno:SC_Sno&quot;</span>, <span class="string">&quot;SC_Cno:SC_Cno&quot;</span>, <span class="string">&quot;SC_Score:SC_Score&quot;</span>&#125;,</span><br><span class="line">                <span class="keyword">new</span> <span class="title class_">String</span>[]&#123;<span class="string">&quot;2015003&quot;</span>, <span class="string">&quot;123002&quot;</span>, <span class="string">&quot;95&quot;</span>&#125;);</span><br><span class="line">        System.out.println(<span class="string">&quot;SC 表插入数据成功&quot;</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 示例输出</span></span><br><span class="line">        System.out.println(<span class="string">&quot;===== 浏览 Student 表的全部 S_Name 列族 =====&quot;</span>);</span><br><span class="line">        scanColumn(<span class="string">&quot;Student&quot;</span>, <span class="string">&quot;S_Name&quot;</span>);</span><br><span class="line"></span><br><span class="line">        System.out.println(<span class="string">&quot;===== 修改 Student 表中 s002 的 S_Age 为 25 =====&quot;</span>);</span><br><span class="line">        modifyData(<span class="string">&quot;Student&quot;</span>, <span class="string">&quot;s002&quot;</span>, <span class="string">&quot;S_Age:S_Age&quot;</span>, <span class="string">&quot;25&quot;</span>);</span><br><span class="line"></span><br><span class="line">        System.out.println(<span class="string">&quot;===== 删除 Student 表中的 s003 =====&quot;</span>);</span><br><span class="line">        deleteRow(<span class="string">&quot;Student&quot;</span>, <span class="string">&quot;s003&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p><img src="/../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/6558a1532abdadb376905f6513ac10ce55933597-1746692007782-520-1747299497351-145-1747900721330-145-1749470495098-146.png" alt="image-20250408190024787"></p>
<h2 id="（7-5-5）">（7.5.5）</h2>
<h3 id="基础">基础</h3>
<p>自行开启hadoop集群和hbase</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">cd</span><br><span class="line">cat &gt; wordfile1.txt&lt;&lt;&quot;EOF&quot;</span><br><span class="line">I love Spark</span><br><span class="line">I love Hadoop</span><br><span class="line">EOF</span><br><span class="line">cat &gt; wordfile2.txt&lt;&lt;&quot;EOF&quot;</span><br><span class="line">Hadoop is good</span><br><span class="line">Spark is fast</span><br><span class="line">EOF</span><br><span class="line">hdfs dfs -rm -r input</span><br><span class="line">hdfs dfs -rm -r output</span><br><span class="line">hdfs dfs -mkdir input</span><br><span class="line">hdfs dfs -put wordfile1.txt input</span><br><span class="line">hdfs dfs -put wordfile2.txt input</span><br></pre></td></tr></table></figure>
<p><img src="/../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/b7c6ae4b33cc17a2deb9057b404fe7a655933597-1746692007782-521-1747299497351-146-1747900721330-146-1749470495098-147.png" alt="image-20250508151954700"></p>
<h3 id="在eclipse创建项目">在eclipse创建项目</h3>
<p>启动eclipse</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">eclipse</span><br></pre></td></tr></table></figure>
<p>创建项目</p>
<p>File-new-project</p>
<p>名字：<code>WordCount</code></p>
<p><img src="/../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/ee7d820cccc370c09b7e12965ac9f30655933597-1746692007782-522-1747299497351-147-1747900721330-147-1749470495098-149.png" alt="image-20250508152019222"></p>
<p>为了编写一个MapReduce程序，一般需要向Java工程中添加以下JAR包：<br>
（1)<code>/usr/local/hadoop/share/hadoop/common</code>目录下的<code>hadoop-common-3.1.3.jar</code>和<code>haoop-nfs-3.1.3.jar</code>；<br>
（2)<code>/usr/local/hadoop/share/hadoop/common/lib</code>目录下的<code>所有JAR包</code>；<br>
（3)<code>/usr/local/hadoop/share/hadoop/mapreduce</code>目录下的<code>所有JAR包</code>，但是，<code>不包括jdiff、lib-examples和sources目录</code>.</p>
<p><img src="/../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/6e5dba872fef1b72dcb96aa60032bcaa55933597-1746692007782-523-1747299497351-148-1747900721330-148-1749470495098-148.png" alt="image-20250508152028054"></p>
<p>添加完成就finish就行</p>
<h3 id="编写Java应用程序-2">编写Java应用程序</h3>
<p>创建<code>WordCount.java</code>,自己看好，以后不会再说了</p>
<p><img src="/../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/d12d00e0e59333d347ab4f14c335af9d55933597-1746692007782-524-1747299497351-149-1747900721330-149-1749470495098-150.png" alt="image-20250508152037946"></p>
<p>添加代码</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> java.io.IOException;</span><br><span class="line"><span class="keyword">import</span> java.util.Iterator;</span><br><span class="line"><span class="keyword">import</span> java.util.StringTokenizer;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.conf.Configuration;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.fs.Path;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.IntWritable;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.Text;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.Job;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.Mapper;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.Reducer;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.lib.input.FileInputFormat;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.util.GenericOptionsParser;</span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">WordCount</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="title function_">WordCount</span><span class="params">()</span> &#123;</span><br><span class="line">    &#125;</span><br><span class="line">     <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception &#123;</span><br><span class="line">        <span class="type">Configuration</span> <span class="variable">conf</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Configuration</span>();</span><br><span class="line">        String[] otherArgs = (<span class="keyword">new</span> <span class="title class_">GenericOptionsParser</span>(conf, args)).getRemainingArgs();</span><br><span class="line">        <span class="keyword">if</span>(otherArgs.length &lt; <span class="number">2</span>) &#123;</span><br><span class="line">            System.err.println(<span class="string">&quot;Usage: wordcount &lt;in&gt; [&lt;in&gt;...] &lt;out&gt;&quot;</span>);</span><br><span class="line">            System.exit(<span class="number">2</span>);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="type">Job</span> <span class="variable">job</span> <span class="operator">=</span> Job.getInstance(conf, <span class="string">&quot;word count&quot;</span>);</span><br><span class="line">        job.setJarByClass(WordCount.class);</span><br><span class="line">        job.setMapperClass(WordCount.TokenizerMapper.class);</span><br><span class="line">        job.setCombinerClass(WordCount.IntSumReducer.class);</span><br><span class="line">        job.setReducerClass(WordCount.IntSumReducer.class);</span><br><span class="line">        job.setOutputKeyClass(Text.class);</span><br><span class="line">        job.setOutputValueClass(IntWritable.class); </span><br><span class="line">        <span class="keyword">for</span>(<span class="type">int</span> <span class="variable">i</span> <span class="operator">=</span> <span class="number">0</span>; i &lt; otherArgs.length - <span class="number">1</span>; ++i) &#123;</span><br><span class="line">            FileInputFormat.addInputPath(job, <span class="keyword">new</span> <span class="title class_">Path</span>(otherArgs[i]);</span><br><span class="line">        &#125;</span><br><span class="line">        FileOutputFormat.setOutputPath(job, <span class="keyword">new</span> <span class="title class_">Path</span>(otherArgs[otherArgs.length - <span class="number">1</span>]);</span><br><span class="line">        System.exit(job.waitForCompletion(<span class="literal">true</span>)?<span class="number">0</span>:<span class="number">1</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">class</span> <span class="title class_">TokenizerMapper</span> <span class="keyword">extends</span> <span class="title class_">Mapper</span>&lt;Object, Text, Text, IntWritable&gt; &#123;</span><br><span class="line">        <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="type">IntWritable</span> <span class="variable">one</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">IntWritable</span>(<span class="number">1</span>);</span><br><span class="line">        <span class="keyword">private</span> <span class="type">Text</span> <span class="variable">word</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Text</span>();</span><br><span class="line">        <span class="keyword">public</span> <span class="title function_">TokenizerMapper</span><span class="params">()</span> &#123;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">map</span><span class="params">(Object key, Text value, Mapper&lt;Object, Text, Text, IntWritable&gt;.Context context)</span> <span class="keyword">throws</span> IOException, InterruptedException &#123;</span><br><span class="line">            <span class="type">StringTokenizer</span> <span class="variable">itr</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">StringTokenizer</span>(value.toString()); </span><br><span class="line">            <span class="keyword">while</span>(itr.hasMoreTokens()) &#123;</span><br><span class="line">                <span class="built_in">this</span>.word.set(itr.nextToken());</span><br><span class="line">                context.write(<span class="built_in">this</span>.word, one);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">class</span> <span class="title class_">IntSumReducer</span> <span class="keyword">extends</span> <span class="title class_">Reducer</span>&lt;Text, IntWritable, Text, IntWritable&gt; &#123;</span><br><span class="line">        <span class="keyword">private</span> <span class="type">IntWritable</span> <span class="variable">result</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">IntWritable</span>();</span><br><span class="line">        <span class="keyword">public</span> <span class="title function_">IntSumReducer</span><span class="params">()</span> &#123;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">reduce</span><span class="params">(Text key, Iterable&lt;IntWritable&gt; values, Reducer&lt;Text, IntWritable, Text, IntWritable&gt;.Context context)</span> <span class="keyword">throws</span> IOException, InterruptedException &#123;</span><br><span class="line">            <span class="type">int</span> <span class="variable">sum</span> <span class="operator">=</span> <span class="number">0</span>;</span><br><span class="line">            IntWritable val;</span><br><span class="line">            <span class="keyword">for</span>(<span class="type">Iterator</span> <span class="variable">i$</span> <span class="operator">=</span> values.iterator(); i$.hasNext(); sum += val.get()) &#123;</span><br><span class="line">                val = (IntWritable)i$.next();</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="built_in">this</span>.result.set(sum);</span><br><span class="line">            context.write(key, <span class="built_in">this</span>.result);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>运行一下</p>
<p><img src="/../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/ed5660e7f99bf786444e3ca5dc01aeca55933597-1746692007782-525-1747299497351-151-1747900721330-150-1749470495098-151.png" alt="image-20250508152047998"></p>
<blockquote>
<p>7.5.5截图1</p>
</blockquote>
<h3 id="编译打包程序">编译打包程序</h3>
<p>如果你没有myapp文件夹你就自己创建，我的是有的</p>
<p><img src="/../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/61642003432b78f55cab6505fa1742ac55933597-1746692007782-526-1747299497351-150-1747900721330-151-1749470495098-152.png" alt="image-20250508152056980"></p>
<p><img src="/../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/248cd9a79f38735b1cd8594baf84d9d555933597-1746692007782-527-1747299497351-152-1747900721330-153-1749470495098-153.png" alt="image-20250508152109370"></p>
<p><img src="/../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/d5da5d88e74e5be4a0209559bbeefad455933597-1746692007782-528-1747299497351-153-1747900721330-152-1749470495098-155.png" alt="image-20250508152443407"></p>
<p>选择<code>WordCount</code>项目</p>
<p>填写路径<code>/usr/local/hadoop/myapp/WordCount.jar</code></p>
<p>然后<code>finish</code></p>
<p>这时候会有弹窗，一路<code>ok下来</code>就行了</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ll  /usr/local/hadoop/myapp</span><br></pre></td></tr></table></figure>
<p><img src="/../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/c37f9d8706aaf5419770baf2a840253755933597-1746692007782-529-1747299497352-154-1747900721330-154-1749470495098-154.png" alt="image-20250508152129030"></p>
<h3 id="运行程序">运行程序</h3>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">hadoop jar /usr/local/hadoop/myapp/WordCount.jar input output</span><br><span class="line">hdfs dfs -cat output/*</span><br></pre></td></tr></table></figure>
<p><img src="/../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/4136c00c46c5a26bf1daef363b79467455933597-1746692007782-530-1747299497352-155-1747900721330-155-1749470495098-156.png" alt="image-20250508152139398"></p>
<p><img src="/../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/0e03c562f7b2919d9a19b3be3a0d176255933597-1746692007782-531-1747299497352-156-1747900721330-156-1749470495098-158.png" alt="image-20250508152151659"></p>
<blockquote>
<p>7.5.5 截图2和3</p>
</blockquote>
<h2 id="（7-3-4）">（7.3.4）</h2>
<p><mark>第四题</mark></p>
<p><mark>shell</mark></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">cat &gt; avg.txt &lt;&lt;&quot;EOF&quot;</span><br><span class="line">math 80</span><br><span class="line">math 90</span><br><span class="line">english 70</span><br><span class="line">english 100</span><br><span class="line">EOF</span><br><span class="line">hdfs dfs -rm -r input</span><br><span class="line">hdfs dfs -rm -r output</span><br><span class="line">hdfs dfs -mkdir input</span><br><span class="line">hdfs dfs -put avg.txt input</span><br></pre></td></tr></table></figure>
<p>创建<code>AverageCalculator.java</code></p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> org.apache.hadoop.conf.Configuration;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.fs.Path;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.IntWritable;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.LongWritable;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.Text;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.Job;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.Mapper;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.Reducer;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.lib.input.FileInputFormat;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.io.IOException;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">AverageCalculator</span> &#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">class</span> <span class="title class_">AvgMapper</span> <span class="keyword">extends</span> <span class="title class_">Mapper</span>&lt;LongWritable, Text, Text, IntWritable&gt; &#123;</span><br><span class="line">        <span class="keyword">private</span> <span class="type">Text</span> <span class="variable">keyOut</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Text</span>();</span><br><span class="line">        <span class="keyword">private</span> <span class="type">IntWritable</span> <span class="variable">valOut</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">IntWritable</span>();</span><br><span class="line"></span><br><span class="line">        <span class="meta">@Override</span></span><br><span class="line">        <span class="keyword">protected</span> <span class="keyword">void</span> <span class="title function_">map</span><span class="params">(LongWritable key, Text value, Context context)</span></span><br><span class="line">                <span class="keyword">throws</span> IOException, InterruptedException &#123;</span><br><span class="line">            String[] parts = value.toString().split(<span class="string">&quot;\\s+&quot;</span>);</span><br><span class="line">            <span class="keyword">if</span> (parts.length == <span class="number">2</span>) &#123;</span><br><span class="line">                keyOut.set(parts[<span class="number">0</span>];</span><br><span class="line">                valOut.set(Integer.parseInt(parts[<span class="number">1</span>]);</span><br><span class="line">                context.write(keyOut, valOut);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">class</span> <span class="title class_">AvgReducer</span> <span class="keyword">extends</span> <span class="title class_">Reducer</span>&lt;Text, IntWritable, Text, IntWritable&gt; &#123;</span><br><span class="line">        <span class="keyword">private</span> <span class="type">IntWritable</span> <span class="variable">result</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">IntWritable</span>();</span><br><span class="line"></span><br><span class="line">        <span class="meta">@Override</span></span><br><span class="line">        <span class="keyword">protected</span> <span class="keyword">void</span> <span class="title function_">reduce</span><span class="params">(Text key, Iterable&lt;IntWritable&gt; values, Context context)</span></span><br><span class="line">                <span class="keyword">throws</span> IOException, InterruptedException &#123;</span><br><span class="line">            <span class="type">int</span> <span class="variable">sum</span> <span class="operator">=</span> <span class="number">0</span>;</span><br><span class="line">            <span class="type">int</span> <span class="variable">count</span> <span class="operator">=</span> <span class="number">0</span>;</span><br><span class="line">            <span class="keyword">for</span> (IntWritable val : values) &#123;</span><br><span class="line">                sum += val.get();</span><br><span class="line">                count++;</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">if</span> (count != <span class="number">0</span>) &#123;</span><br><span class="line">                result.set(sum / count);</span><br><span class="line">                context.write(key, result);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception &#123;</span><br><span class="line">        <span class="keyword">if</span> (args.length != <span class="number">2</span>) &#123;</span><br><span class="line">            System.err.println(<span class="string">&quot;Usage: AverageCalculator &lt;input path&gt; &lt;output path&gt;&quot;</span>);</span><br><span class="line">            System.exit(-<span class="number">1</span>);</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="type">Configuration</span> <span class="variable">conf</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Configuration</span>();</span><br><span class="line">        <span class="type">Job</span> <span class="variable">job</span> <span class="operator">=</span> Job.getInstance(conf, <span class="string">&quot;Average Calculator&quot;</span>);</span><br><span class="line">        job.setJarByClass(AverageCalculator.class);</span><br><span class="line"></span><br><span class="line">        job.setMapperClass(AvgMapper.class);</span><br><span class="line">        job.setReducerClass(AvgReducer.class);</span><br><span class="line"></span><br><span class="line">        job.setOutputKeyClass(Text.class);</span><br><span class="line">        job.setOutputValueClass(IntWritable.class);</span><br><span class="line"></span><br><span class="line">        FileInputFormat.setInputPaths(job, <span class="keyword">new</span> <span class="title class_">Path</span>(args[<span class="number">0</span>]);</span><br><span class="line">        FileOutputFormat.setOutputPath(job, <span class="keyword">new</span> <span class="title class_">Path</span>(args[<span class="number">1</span>]);</span><br><span class="line"></span><br><span class="line">        System.exit(job.waitForCompletion(<span class="literal">true</span>) ? <span class="number">0</span> : <span class="number">1</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>自己运行一下，不然下面打包程序出现不了，运行报错别管，运行就对了，别问</p>
<p>自己运行一下，不然下面打包程序出现不了，运行报错别管，运行就对了，别问</p>
<p>自己运行一下，不然下面打包程序出现不了，运行报错别管，运行就对了，别问</p>
<p>自己运行一下，不然下面打包程序出现不了，运行报错别管，运行就对了，别问</p>
<p><mark>打包项目</mark></p>
<p>这是打包java项目的路径教程，自己看，后面还会有各种java要打包，后面不会再说了</p>
<p><img src="/../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/248cd9a79f38735b1cd8594baf84d9d555933597-1746692007782-527-1747299497351-152-1747900721330-153-1749470495098-153.png" alt="image-20250508152109370"></p>
<p><img src="/../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/6097eb929713ca7dc7077f72409911b455933597-1746692007782-533-1747299497352-157-1747900721330-158-1749470495098-157.png" alt="image-20250508144848815"></p>
<p>一路ok</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">hadoop jar /usr/local/hadoop/myapp/AverageCalculator.jar input output</span><br><span class="line">hadoop dfs -cat output/*</span><br></pre></td></tr></table></figure>
<p><img src="/../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/88ceb627c2201a1dbb32a8372e649e6355933597-1746692007782-534-1747299497352-158-1747900721330-157-1749470495098-160.png" alt="image-20250508145036243"></p>
<blockquote>
<p>这个是第四题的图片</p>
</blockquote>
<p><mark>第八题和第九题</mark></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">cat &gt; maxmin.txt &lt;&lt;&quot;EOF&quot;</span><br><span class="line">23</span><br><span class="line">45</span><br><span class="line">12</span><br><span class="line">67</span><br><span class="line">89</span><br><span class="line">34</span><br><span class="line">56</span><br><span class="line">EOF</span><br><span class="line">hdfs dfs -rm -r input</span><br><span class="line">hdfs dfs -rm -r output</span><br><span class="line">hdfs dfs -mkdir input</span><br><span class="line">hdfs dfs -put maxmin.txt input</span><br></pre></td></tr></table></figure>
<p>创建<code>MaxMinValue.java</code></p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> org.apache.hadoop.conf.Configuration;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.fs.Path;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.IntWritable;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.LongWritable;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.Text;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.Job;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.Mapper;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.Reducer;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.lib.input.FileInputFormat;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.io.IOException;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">MaxMinValue</span> &#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">class</span> <span class="title class_">MaxMinMapper</span> <span class="keyword">extends</span> <span class="title class_">Mapper</span>&lt;LongWritable, Text, Text, IntWritable&gt; &#123;</span><br><span class="line">        <span class="keyword">private</span> <span class="type">IntWritable</span> <span class="variable">valueOut</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">IntWritable</span>();</span><br><span class="line"></span><br><span class="line">        <span class="meta">@Override</span></span><br><span class="line">        <span class="keyword">protected</span> <span class="keyword">void</span> <span class="title function_">map</span><span class="params">(LongWritable key, Text value, Context context)</span> <span class="keyword">throws</span> IOException, InterruptedException &#123;</span><br><span class="line">            <span class="type">int</span> <span class="variable">num</span> <span class="operator">=</span> Integer.parseInt(value.toString());</span><br><span class="line">            valueOut.set(num);</span><br><span class="line">            context.write(<span class="keyword">new</span> <span class="title class_">Text</span>(<span class="string">&quot;max&quot;</span>), valueOut);</span><br><span class="line">            context.write(<span class="keyword">new</span> <span class="title class_">Text</span>(<span class="string">&quot;min&quot;</span>), valueOut);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">class</span> <span class="title class_">MaxMinReducer</span> <span class="keyword">extends</span> <span class="title class_">Reducer</span>&lt;Text, IntWritable, Text, IntWritable&gt; &#123;</span><br><span class="line">        <span class="keyword">private</span> <span class="type">IntWritable</span> <span class="variable">result</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">IntWritable</span>();</span><br><span class="line"></span><br><span class="line">        <span class="meta">@Override</span></span><br><span class="line">        <span class="keyword">protected</span> <span class="keyword">void</span> <span class="title function_">reduce</span><span class="params">(Text key, Iterable&lt;IntWritable&gt; values, Context context)</span></span><br><span class="line">                <span class="keyword">throws</span> IOException, InterruptedException &#123;</span><br><span class="line">            <span class="type">int</span> <span class="variable">finalValue</span> <span class="operator">=</span> key.toString().equals(<span class="string">&quot;max&quot;</span>) ? Integer.MIN_VALUE : Integer.MAX_VALUE;</span><br><span class="line"></span><br><span class="line">            <span class="keyword">for</span> (IntWritable val : values) &#123;</span><br><span class="line">                <span class="keyword">if</span> (key.toString().equals(<span class="string">&quot;max&quot;</span>)) &#123;</span><br><span class="line">                    finalValue = Math.max(finalValue, val.get());</span><br><span class="line">                &#125; <span class="keyword">else</span> <span class="keyword">if</span> (key.toString().equals(<span class="string">&quot;min&quot;</span>)) &#123;</span><br><span class="line">                    finalValue = Math.min(finalValue, val.get());</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">            result.set(finalValue);</span><br><span class="line">            context.write(key, result);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception &#123;</span><br><span class="line">        <span class="type">Configuration</span> <span class="variable">conf</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Configuration</span>();</span><br><span class="line">        <span class="type">Job</span> <span class="variable">job</span> <span class="operator">=</span> Job.getInstance(conf, <span class="string">&quot;Max and Min Values&quot;</span>);</span><br><span class="line"></span><br><span class="line">        job.setJarByClass(MaxMinValue.class);</span><br><span class="line">        job.setMapperClass(MaxMinMapper.class);</span><br><span class="line">        job.setReducerClass(MaxMinReducer.class);</span><br><span class="line"></span><br><span class="line">        job.setOutputKeyClass(Text.class);</span><br><span class="line">        job.setOutputValueClass(IntWritable.class);</span><br><span class="line"></span><br><span class="line">        FileInputFormat.setInputPaths(job, <span class="keyword">new</span> <span class="title class_">Path</span>(args[<span class="number">0</span>]);</span><br><span class="line">        FileOutputFormat.setOutputPath(job, <span class="keyword">new</span> <span class="title class_">Path</span>(args[<span class="number">1</span>]);</span><br><span class="line"></span><br><span class="line">        System.exit(job.waitForCompletion(<span class="literal">true</span>) ? <span class="number">0</span> : <span class="number">1</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>然后自己<code>打包程序</code>，不会就去翻前面，前面有说</p>
<p><img src="/../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/b790a45036594ee7a01ec92264eae17455933597-1746692007782-535-1747299497352-159-1747900721330-159-1749470495098-159.png" alt="image-20250508150606591"></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">hadoop jar /usr/local/hadoop/myapp/MaxMinValue.jar input output</span><br><span class="line">hadoop dfs -cat output/*</span><br></pre></td></tr></table></figure>
<p><img src="/../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/e226581c924c43648f17a029be07dd7a55933597-1746692007782-536-1747299497352-160-1747900721330-160-1749470495098-161.png" alt="image-20250508150707867"></p>
<blockquote>
<p>这个是第八题和第九题的图片</p>
</blockquote>
<p>接下来的创建java打包程序不说了，自己翻前面的</p>
<p><mark>第十题</mark></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">cat &gt; SalesVolume.txt &lt;&lt;&quot;EOF&quot;</span><br><span class="line">2025-01-01 200</span><br><span class="line">2025-01-15 150</span><br><span class="line">2025-02-10 300</span><br><span class="line">2025-02-25 250</span><br><span class="line">2025-03-05 400</span><br><span class="line">2025-03-15 350</span><br><span class="line">EOF</span><br><span class="line">hdfs dfs -rm -r input</span><br><span class="line">hdfs dfs -rm -r output</span><br><span class="line">hdfs dfs -mkdir input</span><br><span class="line">hdfs dfs -put SalesVolume.txt input</span><br></pre></td></tr></table></figure>
<p>创建<code>SalesByMonth.java</code></p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> org.apache.hadoop.conf.Configuration;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.fs.Path;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.IntWritable;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.LongWritable;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.Text;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.Job;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.Mapper;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.Reducer;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.lib.input.FileInputFormat;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.io.IOException;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">SalesByMonth</span> &#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">class</span> <span class="title class_">SalesMapper</span> <span class="keyword">extends</span> <span class="title class_">Mapper</span>&lt;LongWritable, Text, Text, IntWritable&gt; &#123;</span><br><span class="line">        <span class="keyword">private</span> <span class="type">Text</span> <span class="variable">month</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Text</span>();</span><br><span class="line">        <span class="keyword">private</span> <span class="type">IntWritable</span> <span class="variable">salesAmount</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">IntWritable</span>();</span><br><span class="line"></span><br><span class="line">        <span class="meta">@Override</span></span><br><span class="line">        <span class="keyword">protected</span> <span class="keyword">void</span> <span class="title function_">map</span><span class="params">(LongWritable key, Text value, Context context)</span> <span class="keyword">throws</span> IOException, InterruptedException &#123;</span><br><span class="line">            String[] parts = value.toString().split(<span class="string">&quot;\\s+&quot;</span>);</span><br><span class="line">            <span class="type">String</span> <span class="variable">date</span> <span class="operator">=</span> parts[<span class="number">0</span>];  <span class="comment">// 日期格式为 YYYY-MM-DD</span></span><br><span class="line">            <span class="type">int</span> <span class="variable">amount</span> <span class="operator">=</span> Integer.parseInt(parts[<span class="number">1</span>];  <span class="comment">// 销售金额</span></span><br><span class="line"></span><br><span class="line">            <span class="comment">// 提取月份（格式为 YYYY-MM）</span></span><br><span class="line">            <span class="type">String</span> <span class="variable">yearMonth</span> <span class="operator">=</span> date.substring(<span class="number">0</span>, <span class="number">7</span>);</span><br><span class="line">            month.set(yearMonth);</span><br><span class="line">            salesAmount.set(amount);</span><br><span class="line"></span><br><span class="line">            context.write(month, salesAmount);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">class</span> <span class="title class_">SalesReducer</span> <span class="keyword">extends</span> <span class="title class_">Reducer</span>&lt;Text, IntWritable, Text, IntWritable&gt; &#123;</span><br><span class="line">        <span class="keyword">private</span> <span class="type">IntWritable</span> <span class="variable">result</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">IntWritable</span>();</span><br><span class="line"></span><br><span class="line">        <span class="meta">@Override</span></span><br><span class="line">        <span class="keyword">protected</span> <span class="keyword">void</span> <span class="title function_">reduce</span><span class="params">(Text key, Iterable&lt;IntWritable&gt; values, Context context)</span></span><br><span class="line">                <span class="keyword">throws</span> IOException, InterruptedException &#123;</span><br><span class="line">            <span class="type">int</span> <span class="variable">totalSales</span> <span class="operator">=</span> <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line">            <span class="keyword">for</span> (IntWritable val : values) &#123;</span><br><span class="line">                totalSales += val.get();</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">            result.set(totalSales);</span><br><span class="line">            context.write(key, result);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception &#123;</span><br><span class="line">        <span class="type">Configuration</span> <span class="variable">conf</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Configuration</span>();</span><br><span class="line">        <span class="type">Job</span> <span class="variable">job</span> <span class="operator">=</span> Job.getInstance(conf, <span class="string">&quot;Sales by Month&quot;</span>);</span><br><span class="line"></span><br><span class="line">        job.setJarByClass(SalesByMonth.class);</span><br><span class="line">        job.setMapperClass(SalesMapper.class);</span><br><span class="line">        job.setReducerClass(SalesReducer.class);</span><br><span class="line"></span><br><span class="line">        job.setOutputKeyClass(Text.class);</span><br><span class="line">        job.setOutputValueClass(IntWritable.class);</span><br><span class="line"></span><br><span class="line">        FileInputFormat.setInputPaths(job, <span class="keyword">new</span> <span class="title class_">Path</span>(args[<span class="number">0</span>]);</span><br><span class="line">        FileOutputFormat.setOutputPath(job, <span class="keyword">new</span> <span class="title class_">Path</span>(args[<span class="number">1</span>]);</span><br><span class="line"></span><br><span class="line">        System.exit(job.waitForCompletion(<span class="literal">true</span>) ? <span class="number">0</span> : <span class="number">1</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>自己打包程序，然后运行程序</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">hadoop jar /usr/local/hadoop/myapp/SalesByMonth.jar input output</span><br><span class="line">hadoop dfs -cat output/*</span><br></pre></td></tr></table></figure>
<p><img src="/../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/b139c3b6ed2dd067a6205773a6886d8555933597-1746692007782-537-1747299497352-161-1747900721330-161-1749470495098-162.png" alt="image-20250508151430701"></p>
<blockquote>
<p>这是第十题的图片</p>
</blockquote>
<h2 id="实验四">实验四</h2>
<h3 id="第一题-2">第一题</h3>
<h4 id="shell">shell</h4>
<p>1．编程实现文件合并和去重操作</p>
<p><mark>shell</mark></p>
<p>对于两个输入文件，即文件A和文件B，请编写MapReduce程序，对两个文件进行合并，并剔除其中重复的内容，得到一个新的输出文件C。下面是输入文件和输出文件的一个样例，以供参考。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">cat &gt;a.txt&lt;&lt;&quot;EOF&quot;</span><br><span class="line">20150101    x</span><br><span class="line">20150102    y</span><br><span class="line">20150103    x</span><br><span class="line">20150104    y</span><br><span class="line">20150105    z</span><br><span class="line">20150106    x</span><br><span class="line">EOF</span><br><span class="line">cat &gt;b.txt&lt;&lt;&quot;EOF&quot;</span><br><span class="line">20150101     y</span><br><span class="line">20150102     y</span><br><span class="line">20150103     x</span><br><span class="line">20150104     z</span><br><span class="line">20150105     y</span><br><span class="line">EOF</span><br><span class="line">hdfs dfs -rm -r input</span><br><span class="line">hdfs dfs -rm -r output</span><br><span class="line">hdfs dfs -mkdir input</span><br><span class="line">hdfs dfs -put a.txt input</span><br><span class="line">hdfs dfs -put b.txt input</span><br></pre></td></tr></table></figure>
<p><img src="/../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/ae79fafc4e921a8b98dc0a3ca1b7a7e155933597-1747299497352-162-1747900721330-162-1749470495098-163.png" alt="image-20250508155455652"></p>
<p>创建<code>Merge.java</code></p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.io.IOException;</span><br><span class="line"><span class="keyword">import</span> java.util.StringTokenizer;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.conf.Configuration;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.fs.Path;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.Text;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.Job;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.Mapper;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.Reducer;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.lib.input.FileInputFormat;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">Merge</span> &#123;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 对A,B两个文件进行合并，并剔除其中重复的内容，得到一个新的输出文件C</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">// Mapper: 清理每行多余的空白，并作为 key 输出</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">class</span> <span class="title class_">Map</span> <span class="keyword">extends</span> <span class="title class_">Mapper</span>&lt;Object, Text, Text, Text&gt; &#123;</span><br><span class="line">        <span class="keyword">private</span> <span class="type">Text</span> <span class="variable">outKey</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Text</span>();</span><br><span class="line"></span><br><span class="line">        <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">map</span><span class="params">(Object key, Text value, Context context)</span> <span class="keyword">throws</span> IOException, InterruptedException &#123;</span><br><span class="line">            <span class="type">String</span> <span class="variable">line</span> <span class="operator">=</span> value.toString().trim(); <span class="comment">// 去除首尾空格</span></span><br><span class="line">            <span class="type">StringTokenizer</span> <span class="variable">tokenizer</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">StringTokenizer</span>(line);</span><br><span class="line">            <span class="type">StringBuilder</span> <span class="variable">sb</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">StringBuilder</span>();</span><br><span class="line">            <span class="keyword">while</span> (tokenizer.hasMoreTokens()) &#123;</span><br><span class="line">                sb.append(tokenizer.nextToken()).append(<span class="string">&quot; &quot;</span>); <span class="comment">// 用单空格连接</span></span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">if</span> (sb.length() &gt; <span class="number">0</span>) sb.setLength(sb.length() - <span class="number">1</span>); <span class="comment">// 去掉最后一个空格</span></span><br><span class="line">            outKey.set(sb.toString());</span><br><span class="line">            context.write(outKey, <span class="keyword">new</span> <span class="title class_">Text</span>(<span class="string">&quot;&quot;</span>));</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// Reducer: 每个 key 写出一次，达到去重目的</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">class</span> <span class="title class_">Reduce</span> <span class="keyword">extends</span> <span class="title class_">Reducer</span>&lt;Text, Text, Text, Text&gt; &#123;</span><br><span class="line">        <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">reduce</span><span class="params">(Text key, Iterable&lt;Text&gt; values, Context context)</span> <span class="keyword">throws</span> IOException, InterruptedException &#123;</span><br><span class="line">            context.write(key, <span class="keyword">new</span> <span class="title class_">Text</span>(<span class="string">&quot;&quot;</span>));</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception &#123;</span><br><span class="line">        <span class="type">Configuration</span> <span class="variable">conf</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Configuration</span>();</span><br><span class="line">        conf.set(<span class="string">&quot;fs.default.name&quot;</span>, <span class="string">&quot;hdfs://localhost:9000&quot;</span>);</span><br><span class="line"></span><br><span class="line">        String[] otherArgs = <span class="keyword">new</span> <span class="title class_">String</span>[]&#123;<span class="string">&quot;input&quot;</span>, <span class="string">&quot;output&quot;</span>&#125;;</span><br><span class="line">        <span class="keyword">if</span> (otherArgs.length != <span class="number">2</span>) &#123;</span><br><span class="line">            System.err.println(<span class="string">&quot;Usage: Merge &lt;in&gt; &lt;out&gt;&quot;</span>);</span><br><span class="line">            System.exit(<span class="number">2</span>);</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="type">Job</span> <span class="variable">job</span> <span class="operator">=</span> Job.getInstance(conf, <span class="string">&quot;Merge and Deduplicate&quot;</span>);</span><br><span class="line">        job.setJarByClass(Merge.class);</span><br><span class="line">        job.setMapperClass(Map.class);</span><br><span class="line">        job.setCombinerClass(Reduce.class);</span><br><span class="line">        job.setReducerClass(Reduce.class);</span><br><span class="line"></span><br><span class="line">        job.setOutputKeyClass(Text.class);</span><br><span class="line">        job.setOutputValueClass(Text.class);</span><br><span class="line"></span><br><span class="line">        FileInputFormat.addInputPath(job, <span class="keyword">new</span> <span class="title class_">Path</span>(otherArgs[<span class="number">0</span>]);</span><br><span class="line">        FileOutputFormat.setOutputPath(job, <span class="keyword">new</span> <span class="title class_">Path</span>(otherArgs[<span class="number">1</span>]);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 强制使用一个 reducer，确保全局去重</span></span><br><span class="line">        job.setNumReduceTasks(<span class="number">1</span>);</span><br><span class="line"></span><br><span class="line">        System.exit(job.waitForCompletion(<span class="literal">true</span>) ? <span class="number">0</span> : <span class="number">1</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>打包程序，然后运行</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">hadoop jar /usr/local/hadoop/myapp/Merge.jar input output</span><br><span class="line">hadoop dfs -cat output/*</span><br></pre></td></tr></table></figure>
<p><img src="/../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/90c8bbd767dd5de11bd41dc9d22bd7bc55933597-1747299497352-163-1747900721330-163-1749470495098-165.png" alt="image-20250508160448250"></p>
<h4 id="java">java</h4>
<p><mark>java</mark></p>
<p>导入hdfs包</p>
<p><img src="/../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/image-20250515163900774-1747900721330-164-1749470495098-164.png" alt="image-20250515163900774"></p>
<p><img src="/../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/image-20250515163913862-1747900721330-165-1749470495099-166.png" alt="image-20250515163913862"></p>
<p><code>/usr/local/hadoop/share/hadoop/yarn/lib</code>下的<code>所有jar包</code></p>
<p><code>/usr/local/hadoop/share/hadoop/yarn</code>下的<code>所有jar包</code></p>
<p><code>/usr/local/hadoop/share/hadoop/hdfs</code>下的这两个包也要添加</p>
<p><img src="/../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/1265942a61b2a35512e94d2e86d7b6f7697559838-1747900721330-166-1749470495099-167.png" alt="image-20250517182949447"></p>
<p>测试文件</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">cat &gt;a.txt&lt;&lt;&quot;EOF&quot;</span><br><span class="line">20150101    x</span><br><span class="line">20150102    y</span><br><span class="line">20150103    x</span><br><span class="line">20150104    y</span><br><span class="line">20150105    z</span><br><span class="line">20150106    x</span><br><span class="line">EOF</span><br><span class="line">cat &gt;b.txt&lt;&lt;&quot;EOF&quot;</span><br><span class="line">20150101     y</span><br><span class="line">20150102     y</span><br><span class="line">20150103     x</span><br><span class="line">20150104     z</span><br><span class="line">20150105     y</span><br><span class="line">EOF</span><br><span class="line">hdfs dfs -rm -r input</span><br><span class="line">hdfs dfs -rm -r output</span><br><span class="line">hdfs dfs -mkdir input</span><br><span class="line">hdfs dfs -put a.txt input</span><br><span class="line">hdfs dfs -put b.txt input</span><br></pre></td></tr></table></figure>
<p>更新<code>Merge.java</code>代码</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> java.io.IOException;</span><br><span class="line"><span class="keyword">import</span> java.util.StringTokenizer;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.conf.Configuration;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.fs.Path;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.Text;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.Job;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.Mapper;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.Reducer;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.lib.input.FileInputFormat;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">Merge</span> &#123;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 对A,B两个文件进行合并，并剔除其中重复的内容，得到一个新的输出文件C</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">// Mapper: 清理每行多余的空白，并作为 key 输出</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">class</span> <span class="title class_">Map</span> <span class="keyword">extends</span> <span class="title class_">Mapper</span>&lt;Object, Text, Text, Text&gt; &#123;</span><br><span class="line">        <span class="keyword">private</span> <span class="type">Text</span> <span class="variable">outKey</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Text</span>();</span><br><span class="line"></span><br><span class="line">        <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">map</span><span class="params">(Object key, Text value, Context context)</span> <span class="keyword">throws</span> IOException, InterruptedException &#123;</span><br><span class="line">            <span class="type">String</span> <span class="variable">line</span> <span class="operator">=</span> value.toString().trim(); <span class="comment">// 去除首尾空格</span></span><br><span class="line">            <span class="type">StringTokenizer</span> <span class="variable">tokenizer</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">StringTokenizer</span>(line);</span><br><span class="line">            <span class="type">StringBuilder</span> <span class="variable">sb</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">StringBuilder</span>();</span><br><span class="line">            <span class="keyword">while</span> (tokenizer.hasMoreTokens()) &#123;</span><br><span class="line">                sb.append(tokenizer.nextToken()).append(<span class="string">&quot; &quot;</span>); <span class="comment">// 用单空格连接</span></span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">if</span> (sb.length() &gt; <span class="number">0</span>) sb.setLength(sb.length() - <span class="number">1</span>); <span class="comment">// 去掉最后一个空格</span></span><br><span class="line">            outKey.set(sb.toString());</span><br><span class="line">            context.write(outKey, <span class="keyword">new</span> <span class="title class_">Text</span>(<span class="string">&quot;&quot;</span>));</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// Reducer: 每个 key 写出一次，达到去重目的</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">class</span> <span class="title class_">Reduce</span> <span class="keyword">extends</span> <span class="title class_">Reducer</span>&lt;Text, Text, Text, Text&gt; &#123;</span><br><span class="line">        <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">reduce</span><span class="params">(Text key, Iterable&lt;Text&gt; values, Context context)</span> <span class="keyword">throws</span> IOException, InterruptedException &#123;</span><br><span class="line">            context.write(key, <span class="keyword">new</span> <span class="title class_">Text</span>(<span class="string">&quot;&quot;</span>));</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception &#123;</span><br><span class="line">        <span class="type">Configuration</span> <span class="variable">conf</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Configuration</span>();</span><br><span class="line">        conf.set(<span class="string">&quot;fs.default.name&quot;</span>, <span class="string">&quot;hdfs://localhost:9000&quot;</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 写死输入输出路径</span></span><br><span class="line">        <span class="type">String</span> <span class="variable">inputPath</span> <span class="operator">=</span> <span class="string">&quot;hdfs://localhost:9000/user/hadoop/input&quot;</span>;</span><br><span class="line">        <span class="type">String</span> <span class="variable">outputPath</span> <span class="operator">=</span> <span class="string">&quot;hdfs://localhost:9000/user/hadoop/output&quot;</span>;</span><br><span class="line"></span><br><span class="line">        <span class="type">Job</span> <span class="variable">job</span> <span class="operator">=</span> Job.getInstance(conf, <span class="string">&quot;Merge and Deduplicate&quot;</span>);</span><br><span class="line">        job.setJarByClass(Merge.class);</span><br><span class="line">        job.setMapperClass(Map.class);</span><br><span class="line">        job.setCombinerClass(Reduce.class);</span><br><span class="line">        job.setReducerClass(Reduce.class);</span><br><span class="line"></span><br><span class="line">        job.setOutputKeyClass(Text.class);</span><br><span class="line">        job.setOutputValueClass(Text.class);</span><br><span class="line"></span><br><span class="line">        FileInputFormat.addInputPath(job, <span class="keyword">new</span> <span class="title class_">Path</span>(inputPath));</span><br><span class="line">        FileOutputFormat.setOutputPath(job, <span class="keyword">new</span> <span class="title class_">Path</span>(outputPath));</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 强制使用一个 reducer，确保全局去重</span></span><br><span class="line">        job.setNumReduceTasks(<span class="number">1</span>);</span><br><span class="line"></span><br><span class="line">        System.exit(job.waitForCompletion(<span class="literal">true</span>) ? <span class="number">0</span> : <span class="number">1</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><img src="/../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/image-20250515164951693-1747900721330-167-1749470495099-168.png" alt="image-20250515164951693"></p>
<p>查看结果</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop dfs -cat output/*</span><br></pre></td></tr></table></figure>
<p><img src="/../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/image-20250515165032947-1747900721330-168-1749470495099-169.png" alt="image-20250515165032947"></p>
<h3 id="第二题-2">第二题</h3>
<h4 id="shell-2">shell</h4>
<p>2．编程实现对输入文件的排序</p>
<p>现在有多个输入文件，每个文件中的每行内容均为一个整数。要求读取所有文件中的整数，进行升序排列后，将其输出到一个新的文件中，输出的数据格式为每行两个整数，第一个整数为第二个整数的排序位次，第二个整数为原待排列的整数。下面是输入文件和输出文件的一个样例，以供参考。</p>
<p><mark>shell</mark></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">cat &gt;a.txt&lt;&lt;&quot;EOF&quot;</span><br><span class="line">33</span><br><span class="line">37</span><br><span class="line">12</span><br><span class="line">40</span><br><span class="line">EOF</span><br><span class="line">cat &gt;b.txt&lt;&lt;&quot;EOF&quot;</span><br><span class="line">4</span><br><span class="line">16</span><br><span class="line">39</span><br><span class="line">5</span><br><span class="line">EOF</span><br><span class="line">cat &gt;c.txt&lt;&lt;&quot;EOF&quot;</span><br><span class="line">1</span><br><span class="line">45</span><br><span class="line">25</span><br><span class="line">EOF</span><br><span class="line">hdfs dfs -rm -r input</span><br><span class="line">hdfs dfs -rm -r output</span><br><span class="line">hdfs dfs -mkdir input</span><br><span class="line">hdfs dfs -put a.txt input</span><br><span class="line">hdfs dfs -put b.txt input</span><br><span class="line">hdfs dfs -put c.txt input</span><br></pre></td></tr></table></figure>
<p>创建<code>MergeSort.java</code></p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> java.io.IOException;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.conf.Configuration;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.fs.Path;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.IntWritable;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.Text;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.Job;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.Mapper;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.Partitioner;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.Reducer;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.lib.input.FileInputFormat;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.util.GenericOptionsParser;</span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">MergeSort</span> &#123;</span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> args</span></span><br><span class="line"><span class="comment">     * 输入多个文件，每个文件中的每行内容均为一个整数</span></span><br><span class="line"><span class="comment">     * 输出到一个新的文件中，输出的数据格式为每行两个整数，第一个数字为第二个整数的排序位次，第二个整数为原待排列的整数</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="comment">//map函数读取输入中的value，将其转化成IntWritable类型，最后作为输出key</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">class</span> <span class="title class_">Map</span> <span class="keyword">extends</span> <span class="title class_">Mapper</span>&lt;Object, Text, IntWritable, IntWritable&gt;&#123;</span><br><span class="line">        <span class="keyword">private</span> <span class="keyword">static</span> <span class="type">IntWritable</span> <span class="variable">data</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">IntWritable</span>();</span><br><span class="line">        <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">map</span><span class="params">(Object key, Text value, Context context)</span> <span class="keyword">throws</span> IOException,InterruptedException&#123;</span><br><span class="line">            <span class="type">String</span> <span class="variable">text</span> <span class="operator">=</span> value.toString();</span><br><span class="line">            data.set(Integer.parseInt(text));</span><br><span class="line">            context.write(data, <span class="keyword">new</span> <span class="title class_">IntWritable</span>(<span class="number">1</span>));</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">//reduce函数将map输入的key复制到输出的value上，然后根据输入的value-list中元素的个数决定key的输出次数,定义一个全局变量line_num来代表key的位次</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">class</span> <span class="title class_">Reduce</span> <span class="keyword">extends</span> <span class="title class_">Reducer</span>&lt;IntWritable, IntWritable, IntWritable,  IntWritable&gt;&#123;</span><br><span class="line">        <span class="keyword">private</span> <span class="keyword">static</span> <span class="type">IntWritable</span> <span class="variable">line_num</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">IntWritable</span>(<span class="number">1</span>);       </span><br><span class="line">        <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">reduce</span><span class="params">(IntWritable key, Iterable&lt;IntWritable&gt; values, Context  context)</span> <span class="keyword">throws</span> IOException,InterruptedException&#123;</span><br><span class="line">            <span class="keyword">for</span>(IntWritable val : values)&#123; </span><br><span class="line">                context.write(line_num, key);</span><br><span class="line">                line_num = <span class="keyword">new</span> <span class="title class_">IntWritable</span>(line_num.get() + <span class="number">1</span>);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">//自定义Partition函数，此函数根据输入数据的最大值和MapReduce框架中Partition的数量获取将输入数据按照大小分块的边界，然后根据输入数值和边界的关系返回对应的Partiton ID</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">class</span> <span class="title class_">Partition</span> <span class="keyword">extends</span> <span class="title class_">Partitioner</span>&lt;IntWritable, IntWritable&gt;&#123;</span><br><span class="line">        <span class="keyword">public</span> <span class="type">int</span> <span class="title function_">getPartition</span><span class="params">(IntWritable key, IntWritable value, <span class="type">int</span> num_Partition)</span>&#123;</span><br><span class="line">            <span class="type">int</span> <span class="variable">Maxnumber</span> <span class="operator">=</span> <span class="number">65223</span>;<span class="comment">//int型的最大数值</span></span><br><span class="line">            <span class="type">int</span> <span class="variable">bound</span> <span class="operator">=</span> Maxnumber/num_Partition+<span class="number">1</span>;</span><br><span class="line">            <span class="type">int</span> <span class="variable">keynumber</span> <span class="operator">=</span> key.get();</span><br><span class="line">            <span class="keyword">for</span> (<span class="type">int</span> <span class="variable">i</span> <span class="operator">=</span> <span class="number">0</span>; i&lt;num_Partition; i++)&#123;</span><br><span class="line">                <span class="keyword">if</span>(keynumber&lt;bound * (i+<span class="number">1</span>) &amp;&amp; keynumber&gt;=bound * i)&#123; </span><br><span class="line">                   <span class="keyword">return</span> i;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">return</span> -<span class="number">1</span>;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span>  <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception&#123; </span><br><span class="line">        <span class="comment">// TODO  Auto-generated method stub</span></span><br><span class="line">        <span class="type">Configuration</span>  <span class="variable">conf</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Configuration</span>();</span><br><span class="line">               conf.set(<span class="string">&quot;fs.default.name&quot;</span>,<span class="string">&quot;hdfs://localhost:9000&quot;</span>);</span><br><span class="line">        String[] otherArgs = <span class="keyword">new</span> <span class="title class_">String</span>[]&#123;<span class="string">&quot;input&quot;</span>,<span class="string">&quot;output&quot;</span>&#125;; <span class="comment">/* 直接设置输入参数 */</span></span><br><span class="line">        <span class="keyword">if</span> (otherArgs.length != <span class="number">2</span>) &#123;</span><br><span class="line">            System.err.println(<span class="string">&quot;Usage: wordcount &lt;in&gt;&lt;out&gt;&quot;</span>);</span><br><span class="line">            System.exit(<span class="number">2</span>);</span><br><span class="line">            &#125;</span><br><span class="line">               <span class="type">Job</span> <span class="variable">job</span> <span class="operator">=</span> Job.getInstance(conf,<span class="string">&quot;Merge and sort&quot;</span>);</span><br><span class="line">        job.setJarByClass(MergeSort.class);</span><br><span class="line">        job.setMapperClass(Map.class); </span><br><span class="line">        job.setReducerClass(Reduce.class);</span><br><span class="line">        job.setPartitionerClass(Partition.class);</span><br><span class="line">        job.setOutputKeyClass(IntWritable.class); </span><br><span class="line">        job.setOutputValueClass(IntWritable.class); </span><br><span class="line">        FileInputFormat.addInputPath(job, <span class="keyword">new</span> <span class="title class_">Path</span>(otherArgs[<span class="number">0</span>]);</span><br><span class="line">        FileOutputFormat.setOutputPath(job, <span class="keyword">new</span> <span class="title class_">Path</span>(otherArgs[<span class="number">1</span>]);</span><br><span class="line">        System.exit(job.waitForCompletion(<span class="literal">true</span>) ? <span class="number">0</span> : <span class="number">1</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>自己打包项目</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">hadoop jar /usr/local/hadoop/myapp/MergeSort.jar input output</span><br><span class="line">hadoop dfs -cat output/*</span><br></pre></td></tr></table></figure>
<p><img src="/../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/7564f49802db8df0e5e5de4a1c96222c55933597-1747299497352-164-1747900721330-169-1749470495099-171.png" alt="image-20250508160625143"></p>
<h4 id="java-2">java</h4>
<p><mark>java</mark></p>
<p>写入测试文件</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">cat &gt;a.txt&lt;&lt;&quot;EOF&quot;</span><br><span class="line">33</span><br><span class="line">37</span><br><span class="line">12</span><br><span class="line">40</span><br><span class="line">EOF</span><br><span class="line">cat &gt;b.txt&lt;&lt;&quot;EOF&quot;</span><br><span class="line">4</span><br><span class="line">16</span><br><span class="line">39</span><br><span class="line">5</span><br><span class="line">EOF</span><br><span class="line">cat &gt;c.txt&lt;&lt;&quot;EOF&quot;</span><br><span class="line">1</span><br><span class="line">45</span><br><span class="line">25</span><br><span class="line">EOF</span><br><span class="line">hdfs dfs -rm -r input</span><br><span class="line">hdfs dfs -rm -r output</span><br><span class="line">hdfs dfs -mkdir input</span><br><span class="line">hdfs dfs -put a.txt input</span><br><span class="line">hdfs dfs -put b.txt input</span><br><span class="line">hdfs dfs -put c.txt input</span><br></pre></td></tr></table></figure>
<p>更新代码</p>
<p><code>MergeSort.java</code></p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> java.io.IOException;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.conf.Configuration;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.fs.Path;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.IntWritable;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.Text;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.Job;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.Mapper;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.Partitioner;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.Reducer;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.lib.input.FileInputFormat;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">MergeSort</span> &#123;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> args</span></span><br><span class="line"><span class="comment">     * 输入多个文件，每个文件中的每行内容均为一个整数</span></span><br><span class="line"><span class="comment">     * 输出到一个新的文件中，输出的数据格式为每行两个整数，</span></span><br><span class="line"><span class="comment">     * 第一个数字为第二个整数的排序位次（从1开始），第二个整数为原待排列的整数</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">// Mapper：读取每行整数，作为 key 输出</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">class</span> <span class="title class_">Map</span> <span class="keyword">extends</span> <span class="title class_">Mapper</span>&lt;Object, Text, IntWritable, IntWritable&gt; &#123;</span><br><span class="line">        <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="type">IntWritable</span> <span class="variable">data</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">IntWritable</span>();</span><br><span class="line"></span><br><span class="line">        <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">map</span><span class="params">(Object key, Text value, Context context)</span> <span class="keyword">throws</span> IOException, InterruptedException &#123;</span><br><span class="line">            <span class="type">String</span> <span class="variable">text</span> <span class="operator">=</span> value.toString().trim();</span><br><span class="line">            <span class="keyword">if</span> (!text.isEmpty()) &#123;</span><br><span class="line">                data.set(Integer.parseInt(text));</span><br><span class="line">                context.write(data, <span class="keyword">new</span> <span class="title class_">IntWritable</span>(<span class="number">1</span>));</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// Reducer：根据 key 的顺序输出排名和对应的整数</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">class</span> <span class="title class_">Reduce</span> <span class="keyword">extends</span> <span class="title class_">Reducer</span>&lt;IntWritable, IntWritable, IntWritable, IntWritable&gt; &#123;</span><br><span class="line">        <span class="keyword">private</span> <span class="keyword">static</span> <span class="type">IntWritable</span> <span class="variable">line_num</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">IntWritable</span>(<span class="number">1</span>);</span><br><span class="line"></span><br><span class="line">        <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">reduce</span><span class="params">(IntWritable key, Iterable&lt;IntWritable&gt; values, Context context)</span></span><br><span class="line">                <span class="keyword">throws</span> IOException, InterruptedException &#123;</span><br><span class="line">            <span class="keyword">for</span> (IntWritable val : values) &#123;</span><br><span class="line">                context.write(line_num, key);</span><br><span class="line">                line_num = <span class="keyword">new</span> <span class="title class_">IntWritable</span>(line_num.get() + <span class="number">1</span>);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 自定义 Partitioner：按数值大小分块，提升并行效率</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">class</span> <span class="title class_">Partition</span> <span class="keyword">extends</span> <span class="title class_">Partitioner</span>&lt;IntWritable, IntWritable&gt; &#123;</span><br><span class="line">        <span class="keyword">public</span> <span class="type">int</span> <span class="title function_">getPartition</span><span class="params">(IntWritable key, IntWritable value, <span class="type">int</span> num_Partition)</span> &#123;</span><br><span class="line">            <span class="type">int</span> <span class="variable">Maxnumber</span> <span class="operator">=</span> <span class="number">65223</span>; <span class="comment">// 可以根据数据范围调整</span></span><br><span class="line">            <span class="type">int</span> <span class="variable">bound</span> <span class="operator">=</span> Maxnumber / num_Partition + <span class="number">1</span>;</span><br><span class="line">            <span class="type">int</span> <span class="variable">keynumber</span> <span class="operator">=</span> key.get();</span><br><span class="line">            <span class="keyword">for</span> (<span class="type">int</span> <span class="variable">i</span> <span class="operator">=</span> <span class="number">0</span>; i &lt; num_Partition; i++) &#123;</span><br><span class="line">                <span class="keyword">if</span> (keynumber &lt; bound * (i + <span class="number">1</span>) &amp;&amp; keynumber &gt;= bound * i) &#123;</span><br><span class="line">                    <span class="keyword">return</span> i;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">return</span> -<span class="number">1</span>;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception &#123;</span><br><span class="line">        <span class="type">Configuration</span> <span class="variable">conf</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Configuration</span>();</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 设置新的 fs.defaultFS，并设置本地执行模式</span></span><br><span class="line">        conf.set(<span class="string">&quot;fs.defaultFS&quot;</span>, <span class="string">&quot;hdfs://localhost:9000&quot;</span>);</span><br><span class="line">        conf.set(<span class="string">&quot;mapreduce.framework.name&quot;</span>, <span class="string">&quot;local&quot;</span>);</span><br><span class="line">        conf.set(<span class="string">&quot;mapreduce.jobtracker.address&quot;</span>, <span class="string">&quot;local&quot;</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 写死输入输出路径</span></span><br><span class="line">        <span class="type">String</span> <span class="variable">inputPath</span> <span class="operator">=</span> <span class="string">&quot;hdfs://localhost:9000/user/hadoop/input&quot;</span>;</span><br><span class="line">        <span class="type">String</span> <span class="variable">outputPath</span> <span class="operator">=</span> <span class="string">&quot;hdfs://localhost:9000/user/hadoop/output&quot;</span>;</span><br><span class="line"></span><br><span class="line">        <span class="type">Job</span> <span class="variable">job</span> <span class="operator">=</span> Job.getInstance(conf, <span class="string">&quot;Merge and Sort&quot;</span>);</span><br><span class="line">        job.setJarByClass(MergeSort.class);</span><br><span class="line">        job.setMapperClass(Map.class);</span><br><span class="line">        job.setReducerClass(Reduce.class);</span><br><span class="line">        job.setPartitionerClass(Partition.class);</span><br><span class="line"></span><br><span class="line">        job.setOutputKeyClass(IntWritable.class);</span><br><span class="line">        job.setOutputValueClass(IntWritable.class);</span><br><span class="line"></span><br><span class="line">        FileInputFormat.addInputPath(job, <span class="keyword">new</span> <span class="title class_">Path</span>(inputPath));</span><br><span class="line">        FileOutputFormat.setOutputPath(job, <span class="keyword">new</span> <span class="title class_">Path</span>(outputPath));</span><br><span class="line"></span><br><span class="line">        System.exit(job.waitForCompletion(<span class="literal">true</span>) ? <span class="number">0</span> : <span class="number">1</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><img src="/../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/image-20250515165402525-1747900721330-170-1749470495099-170.png" alt="image-20250515165402525"></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop dfs -cat output/*</span><br></pre></td></tr></table></figure>
<p><img src="/../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/image-20250515165432143-1747900721330-171-1749470495099-172.png" alt="image-20250515165432143"></p>
<h3 id="第三题">第三题</h3>
<h4 id="shell-3">shell</h4>
<p>3．对给定的表格进行信息挖掘</p>
<p>下面给出一个child-parent的表格，要求挖掘其中的父子关系，给出祖孙关系的表格。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">cat &gt;a.txt&lt;&lt;&quot;EOF&quot;</span><br><span class="line">child parent</span><br><span class="line">Steven Lucy</span><br><span class="line">Steven Jack</span><br><span class="line">Jone Lucy</span><br><span class="line">Jone Jack</span><br><span class="line">Lucy Mary</span><br><span class="line">Lucy Frank</span><br><span class="line">Jack Alice</span><br><span class="line">Jack Jesse</span><br><span class="line">David Alice</span><br><span class="line">David Jesse</span><br><span class="line">Philip David</span><br><span class="line">Philip Alma</span><br><span class="line">Mark David</span><br><span class="line">Mark Alma</span><br><span class="line">EOF</span><br><span class="line">hdfs dfs -rm -r input</span><br><span class="line">hdfs dfs -rm -r output</span><br><span class="line">hdfs dfs -mkdir input</span><br><span class="line">hdfs dfs -put a.txt input</span><br></pre></td></tr></table></figure>
<p>创建<code>simple_data_mining.java</code></p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> java.io.IOException;</span><br><span class="line"><span class="keyword">import</span> java.util.*;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.conf.Configuration;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.fs.Path;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.IntWritable;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.Text;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.Job;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.Mapper;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.Reducer;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.lib.input.FileInputFormat;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.util.GenericOptionsParser;</span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">simple_data_mining</span> &#123; </span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="type">int</span> <span class="variable">time</span> <span class="operator">=</span> <span class="number">0</span>;</span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> args </span></span><br><span class="line"><span class="comment">     * 输入一个child-parent的表格</span></span><br><span class="line"><span class="comment">     * 输出一个体现grandchild-grandparent关系的表格</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="comment">//Map将输入文件按照空格分割成child和parent，然后正序输出一次作为右表，反序输出一次作为左表，需要注意的是在输出的value中必须加上左右表区别标志</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">class</span> <span class="title class_">Map</span> <span class="keyword">extends</span> <span class="title class_">Mapper</span>&lt;Object, Text, Text, Text&gt;&#123;</span><br><span class="line">        <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">map</span><span class="params">(Object key, Text value, Context context)</span> <span class="keyword">throws</span> IOException,InterruptedException&#123;</span><br><span class="line">            <span class="type">String</span> <span class="variable">child_name</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">String</span>();</span><br><span class="line">            <span class="type">String</span> <span class="variable">parent_name</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">String</span>();</span><br><span class="line">            <span class="type">String</span> <span class="variable">relation_type</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">String</span>();</span><br><span class="line">            <span class="type">String</span> <span class="variable">line</span> <span class="operator">=</span> value.toString();</span><br><span class="line">            <span class="type">int</span> <span class="variable">i</span> <span class="operator">=</span> <span class="number">0</span>;</span><br><span class="line">            <span class="keyword">while</span>(line.charAt(i)!= <span class="string">&#x27; &#x27;</span>)&#123;</span><br><span class="line">                i++;</span><br><span class="line">            &#125;</span><br><span class="line">            String[] values = &#123;line.substring(<span class="number">0</span>,i),line.substring(i+<span class="number">1</span>)&#125;; </span><br><span class="line">            <span class="keyword">if</span>(values[<span class="number">0</span>].compareTo(<span class="string">&quot;child&quot;</span>)!= <span class="number">0</span>)&#123;</span><br><span class="line">                child_name = values[<span class="number">0</span>];</span><br><span class="line">                parent_name = values[<span class="number">1</span>];</span><br><span class="line">                relation_type = <span class="string">&quot;1&quot;</span>;<span class="comment">//左右表区分标志</span></span><br><span class="line">                context.write(<span class="keyword">new</span> <span class="title class_">Text</span>(values[<span class="number">1</span>], <span class="keyword">new</span> <span class="title class_">Text</span>(relation_type+<span class="string">&quot;+&quot;</span>+child_name+<span class="string">&quot;+&quot;</span>+parent_name));</span><br><span class="line">                <span class="comment">//左表</span></span><br><span class="line">                relation_type = <span class="string">&quot;2&quot;</span>;</span><br><span class="line">                context.write(<span class="keyword">new</span> <span class="title class_">Text</span>(values[<span class="number">0</span>], <span class="keyword">new</span> <span class="title class_">Text</span>(relation_type+<span class="string">&quot;+&quot;</span>+child_name+<span class="string">&quot;+&quot;</span>+parent_name));</span><br><span class="line">                <span class="comment">//右表</span></span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">class</span> <span class="title class_">Reduce</span> <span class="keyword">extends</span> <span class="title class_">Reducer</span>&lt;Text, Text, Text, Text&gt;&#123;</span><br><span class="line">        <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">reduce</span><span class="params">(Text key, Iterable&lt;Text&gt; values,Context context)</span> <span class="keyword">throws</span> IOException,InterruptedException&#123;</span><br><span class="line">            <span class="keyword">if</span>(time == <span class="number">0</span>)&#123;   <span class="comment">//输出表头</span></span><br><span class="line">                context.write(<span class="keyword">new</span> <span class="title class_">Text</span>(<span class="string">&quot;grand_child&quot;</span>), <span class="keyword">new</span> <span class="title class_">Text</span>(<span class="string">&quot;grand_parent&quot;</span>));</span><br><span class="line">                time++;</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="type">int</span> <span class="variable">grand_child_num</span> <span class="operator">=</span> <span class="number">0</span>; </span><br><span class="line">            String grand_child[] = <span class="keyword">new</span> <span class="title class_">String</span>[<span class="number">10</span>];</span><br><span class="line">            <span class="type">int</span> <span class="variable">grand_parent_num</span> <span class="operator">=</span> <span class="number">0</span>;</span><br><span class="line">            String grand_parent[]= <span class="keyword">new</span> <span class="title class_">String</span>[<span class="number">10</span>];</span><br><span class="line">            <span class="type">Iterator</span> <span class="variable">ite</span> <span class="operator">=</span> values.iterator();</span><br><span class="line">            <span class="keyword">while</span>(ite.hasNext())&#123;</span><br><span class="line">                <span class="type">String</span> <span class="variable">record</span> <span class="operator">=</span> ite.next().toString();</span><br><span class="line">                <span class="type">int</span> <span class="variable">len</span> <span class="operator">=</span> record.length();</span><br><span class="line">                <span class="type">int</span> <span class="variable">i</span> <span class="operator">=</span> <span class="number">2</span>;</span><br><span class="line">                <span class="keyword">if</span>(len == <span class="number">0</span>) <span class="keyword">continue</span>;</span><br><span class="line">                <span class="type">char</span> <span class="variable">relation_type</span> <span class="operator">=</span> record.charAt(<span class="number">0</span>);</span><br><span class="line">                <span class="type">String</span> <span class="variable">child_name</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">String</span>();</span><br><span class="line">                <span class="type">String</span> <span class="variable">parent_name</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">String</span>();</span><br><span class="line">                <span class="comment">//获取value-list中value的child</span></span><br><span class="line">                <span class="keyword">while</span>(record.charAt(i)!= <span class="string">&#x27;+&#x27;</span>)&#123;</span><br><span class="line">                   child_name = child_name + record.charAt(i);</span><br><span class="line">                   i++;</span><br><span class="line">                &#125;</span><br><span class="line">                i=i+<span class="number">1</span>;</span><br><span class="line">                <span class="comment">//获取value-list中value的parent</span></span><br><span class="line">                <span class="keyword">while</span>(i&lt;len)&#123;</span><br><span class="line">                   parent_name = parent_name+record.charAt(i);</span><br><span class="line">                   i++;</span><br><span class="line">                &#125; </span><br><span class="line">                <span class="comment">//左表，取出child放入grand_child</span></span><br><span class="line">                <span class="keyword">if</span>(relation_type  == <span class="string">&#x27;1&#x27;</span>)&#123;</span><br><span class="line">                   grand_child[grand_child_num]  = child_name; </span><br><span class="line">                   grand_child_num++;</span><br><span class="line">                &#125;</span><br><span class="line">                <span class="keyword">else</span>&#123;<span class="comment">//右表，取出parent放入grand_parent</span></span><br><span class="line">                   grand_parent[grand_parent_num]  = parent_name;</span><br><span class="line">                   grand_parent_num++;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125; </span><br><span class="line">            <span class="keyword">if</span>(grand_parent_num != <span class="number">0</span> &amp;&amp; grand_child_num != <span class="number">0</span> )&#123;</span><br><span class="line">                <span class="keyword">for</span>(<span class="type">int</span> <span class="variable">m</span> <span class="operator">=</span> <span class="number">0</span>;m&lt;grand_child_num;m++)&#123;</span><br><span class="line">                  <span class="keyword">for</span>(<span class="type">int</span> n=<span class="number">0</span>;n&lt;grand_parent_num;n++)&#123;</span><br><span class="line">                                                                        context.write(<span class="keyword">new</span>  <span class="title class_">Text</span>(grand_child[m], <span class="keyword">new</span> <span class="title class_">Text</span>(grand_parent[n]);</span><br><span class="line">                       <span class="comment">//输出结果</span></span><br><span class="line">                   &#125;</span><br><span class="line">                &#125; </span><br><span class="line">            &#125;</span><br><span class="line">        &#125; </span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception&#123;</span><br><span class="line">        <span class="comment">//  TODO Auto-generated method stub </span></span><br><span class="line">        <span class="type">Configuration</span> <span class="variable">conf</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Configuration</span>();</span><br><span class="line">               conf.set(<span class="string">&quot;fs.default.name&quot;</span>,<span class="string">&quot;hdfs://localhost:9000&quot;</span>);</span><br><span class="line">        String[] otherArgs = <span class="keyword">new</span> <span class="title class_">String</span>[]&#123;<span class="string">&quot;input&quot;</span>,<span class="string">&quot;output&quot;</span>&#125;; <span class="comment">/* 直接设置输入参数 */</span></span><br><span class="line">        <span class="keyword">if</span> (otherArgs.length != <span class="number">2</span>) &#123;</span><br><span class="line">            System.err.println(<span class="string">&quot;Usage: wordcount &lt;in&gt;&lt;out&gt;&quot;</span>);</span><br><span class="line">            System.exit(<span class="number">2</span>);</span><br><span class="line">            &#125;</span><br><span class="line">               <span class="type">Job</span> <span class="variable">job</span> <span class="operator">=</span>  Job.getInstance(conf,<span class="string">&quot;Single table join&quot;</span>);</span><br><span class="line">        job.setJarByClass(simple_data_mining.class);</span><br><span class="line">        job.setMapperClass(Map.class); </span><br><span class="line">        job.setReducerClass(Reduce.class); </span><br><span class="line">        job.setOutputKeyClass(Text.class);</span><br><span class="line">        job.setOutputValueClass(Text.class);</span><br><span class="line">        FileInputFormat.addInputPath(job, <span class="keyword">new</span> <span class="title class_">Path</span>(otherArgs[<span class="number">0</span>]);</span><br><span class="line">        FileOutputFormat.setOutputPath(job, <span class="keyword">new</span> <span class="title class_">Path</span>(otherArgs[<span class="number">1</span>]);</span><br><span class="line">        System.exit(job.waitForCompletion(<span class="literal">true</span>) ? <span class="number">0</span> : <span class="number">1</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>自己打包文件</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">hadoop jar /usr/local/hadoop/myapp/simple_data_mining.jar input output</span><br><span class="line">hadoop dfs -cat output/*</span><br></pre></td></tr></table></figure>
<p><img src="/../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/a1126764960165978203787b9ae638c355933597-1747299497352-165-1747900721330-172-1749470495099-173.png" alt="image-20250508160923581"></p>
<h4 id="java-3">java</h4>
<p><mark>java</mark></p>
<p>更新测试文件</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">cat &gt;a.txt&lt;&lt;&quot;EOF&quot;</span><br><span class="line">child parent</span><br><span class="line">Steven Lucy</span><br><span class="line">Steven Jack</span><br><span class="line">Jone Lucy</span><br><span class="line">Jone Jack</span><br><span class="line">Lucy Mary</span><br><span class="line">Lucy Frank</span><br><span class="line">Jack Alice</span><br><span class="line">Jack Jesse</span><br><span class="line">David Alice</span><br><span class="line">David Jesse</span><br><span class="line">Philip David</span><br><span class="line">Philip Alma</span><br><span class="line">Mark David</span><br><span class="line">Mark Alma</span><br><span class="line">EOF</span><br><span class="line">hdfs dfs -rm -r input</span><br><span class="line">hdfs dfs -rm -r output</span><br><span class="line">hdfs dfs -mkdir input</span><br><span class="line">hdfs dfs -put a.txt input</span><br></pre></td></tr></table></figure>
<p>更新<code>simple_data_mining.java</code></p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> java.io.IOException;</span><br><span class="line"><span class="keyword">import</span> java.util.*;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.conf.Configuration;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.fs.Path;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.Text;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.Job;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.Mapper;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.Reducer;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.lib.input.FileInputFormat;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">simple_data_mining</span> &#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="type">int</span> <span class="variable">time</span> <span class="operator">=</span> <span class="number">0</span>; <span class="comment">// 控制表头只输出一次</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 输入：每行两个字段 child parent</span></span><br><span class="line"><span class="comment">     * 输出：grand_child grand_parent</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">// Mapper：将每条记录正序和逆序分别输出，标识左表和右表</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">class</span> <span class="title class_">Map</span> <span class="keyword">extends</span> <span class="title class_">Mapper</span>&lt;Object, Text, Text, Text&gt; &#123;</span><br><span class="line">        <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">map</span><span class="params">(Object key, Text value, Context context)</span> <span class="keyword">throws</span> IOException, InterruptedException &#123;</span><br><span class="line">            <span class="type">String</span> <span class="variable">line</span> <span class="operator">=</span> value.toString().trim();</span><br><span class="line">            <span class="keyword">if</span> (line.isEmpty() || line.startsWith(<span class="string">&quot;child&quot;</span>)) <span class="keyword">return</span>;</span><br><span class="line"></span><br><span class="line">            String[] parts = line.split(<span class="string">&quot;\\s+&quot;</span>);</span><br><span class="line">            <span class="keyword">if</span> (parts.length &lt; <span class="number">2</span>) <span class="keyword">return</span>;</span><br><span class="line"></span><br><span class="line">            <span class="type">String</span> <span class="variable">child</span> <span class="operator">=</span> parts[<span class="number">0</span>];</span><br><span class="line">            <span class="type">String</span> <span class="variable">parent</span> <span class="operator">=</span> parts[<span class="number">1</span>];</span><br><span class="line"></span><br><span class="line">            <span class="comment">// 左表输出：parent -&gt; left+child+parent</span></span><br><span class="line">            context.write(<span class="keyword">new</span> <span class="title class_">Text</span>(parent), <span class="keyword">new</span> <span class="title class_">Text</span>(<span class="string">&quot;1+&quot;</span> + child + <span class="string">&quot;+&quot;</span> + parent));</span><br><span class="line">            <span class="comment">// 右表输出：child -&gt; right+child+parent</span></span><br><span class="line">            context.write(<span class="keyword">new</span> <span class="title class_">Text</span>(child), <span class="keyword">new</span> <span class="title class_">Text</span>(<span class="string">&quot;2+&quot;</span> + child + <span class="string">&quot;+&quot;</span> + parent));</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// Reducer：将同一key下的左右表数据组合，找出所有祖孙关系</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">class</span> <span class="title class_">Reduce</span> <span class="keyword">extends</span> <span class="title class_">Reducer</span>&lt;Text, Text, Text, Text&gt; &#123;</span><br><span class="line">        <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">reduce</span><span class="params">(Text key, Iterable&lt;Text&gt; values, Context context)</span></span><br><span class="line">                <span class="keyword">throws</span> IOException, InterruptedException &#123;</span><br><span class="line"></span><br><span class="line">            List&lt;String&gt; leftList = <span class="keyword">new</span> <span class="title class_">ArrayList</span>&lt;&gt;();</span><br><span class="line">            List&lt;String&gt; rightList = <span class="keyword">new</span> <span class="title class_">ArrayList</span>&lt;&gt;();</span><br><span class="line"></span><br><span class="line">            <span class="keyword">for</span> (Text val : values) &#123;</span><br><span class="line">                <span class="type">String</span> <span class="variable">record</span> <span class="operator">=</span> val.toString();</span><br><span class="line">                <span class="keyword">if</span> (record.isEmpty()) <span class="keyword">continue</span>;</span><br><span class="line"></span><br><span class="line">                <span class="type">char</span> <span class="variable">relationType</span> <span class="operator">=</span> record.charAt(<span class="number">0</span>);</span><br><span class="line">                String[] fields = record.substring(<span class="number">2</span>).split(<span class="string">&quot;\\+&quot;</span>);</span><br><span class="line">                <span class="keyword">if</span> (fields.length &lt; <span class="number">2</span>) <span class="keyword">continue</span>;</span><br><span class="line"></span><br><span class="line">                <span class="type">String</span> <span class="variable">child</span> <span class="operator">=</span> fields[<span class="number">0</span>];</span><br><span class="line">                <span class="type">String</span> <span class="variable">parent</span> <span class="operator">=</span> fields[<span class="number">1</span>];</span><br><span class="line"></span><br><span class="line">                <span class="keyword">if</span> (relationType == <span class="string">&#x27;1&#x27;</span>) &#123;</span><br><span class="line">                    leftList.add(child); <span class="comment">// 左表：child 是孙子</span></span><br><span class="line">                &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                    rightList.add(parent); <span class="comment">// 右表：parent 是祖父</span></span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">            <span class="comment">// 输出所有可能的祖孙组合</span></span><br><span class="line">            <span class="keyword">if</span> (time == <span class="number">0</span>) &#123;</span><br><span class="line">                context.write(<span class="keyword">new</span> <span class="title class_">Text</span>(<span class="string">&quot;grand_child&quot;</span>), <span class="keyword">new</span> <span class="title class_">Text</span>(<span class="string">&quot;grand_parent&quot;</span>));</span><br><span class="line">                time++;</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">            <span class="keyword">for</span> (String lc : leftList) &#123;</span><br><span class="line">                <span class="keyword">for</span> (String rp : rightList) &#123;</span><br><span class="line">                    context.write(<span class="keyword">new</span> <span class="title class_">Text</span>(lc), <span class="keyword">new</span> <span class="title class_">Text</span>(rp));</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception &#123;</span><br><span class="line">        <span class="type">Configuration</span> <span class="variable">conf</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Configuration</span>();</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 设置新的 fs.defaultFS，并设置本地执行模式</span></span><br><span class="line">        conf.set(<span class="string">&quot;fs.defaultFS&quot;</span>, <span class="string">&quot;hdfs://localhost:9000&quot;</span>);</span><br><span class="line">        conf.set(<span class="string">&quot;mapreduce.framework.name&quot;</span>, <span class="string">&quot;local&quot;</span>);</span><br><span class="line">        conf.set(<span class="string">&quot;mapreduce.jobtracker.address&quot;</span>, <span class="string">&quot;local&quot;</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 写死输入输出路径</span></span><br><span class="line">        <span class="type">String</span> <span class="variable">inputPath</span> <span class="operator">=</span> <span class="string">&quot;hdfs://localhost:9000/user/hadoop/input&quot;</span>;</span><br><span class="line">        <span class="type">String</span> <span class="variable">outputPath</span> <span class="operator">=</span> <span class="string">&quot;hdfs://localhost:9000/user/hadoop/output&quot;</span>;</span><br><span class="line"></span><br><span class="line">        <span class="type">Job</span> <span class="variable">job</span> <span class="operator">=</span> Job.getInstance(conf, <span class="string">&quot;Simple Data Mining - Grandchild to Grandparent&quot;</span>);</span><br><span class="line">        job.setJarByClass(simple_data_mining.class);</span><br><span class="line"></span><br><span class="line">        job.setMapperClass(Map.class);</span><br><span class="line">        job.setReducerClass(Reduce.class);</span><br><span class="line"></span><br><span class="line">        job.setOutputKeyClass(Text.class);</span><br><span class="line">        job.setOutputValueClass(Text.class);</span><br><span class="line"></span><br><span class="line">        FileInputFormat.addInputPath(job, <span class="keyword">new</span> <span class="title class_">Path</span>(inputPath));</span><br><span class="line">        FileOutputFormat.setOutputPath(job, <span class="keyword">new</span> <span class="title class_">Path</span>(outputPath));</span><br><span class="line"></span><br><span class="line">        System.exit(job.waitForCompletion(<span class="literal">true</span>) ? <span class="number">0</span> : <span class="number">1</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><img src="/../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/image-20250515165610418-1747900721330-173-1749470495099-174.png" alt="image-20250515165610418"></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop dfs -cat output/*</span><br></pre></td></tr></table></figure>
<p><img src="/../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/image-20250515165632038-1747900721330-174-1749470495099-175.png" alt="image-20250515165632038"></p>
<h2 id="Hive">Hive</h2>
<p><img src="/../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/image-20250522140819106-1749470495099-176.png" alt="image-20250522140819106"></p>
<p>就在下载页面空白处，右键打开终端</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo ls</span><br></pre></td></tr></table></figure>
<p><img src="/../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/image-20250522141330178-1749470495099-177.png" alt="image-20250522141330178"></p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">sudo</span> tar -xf apache-hive-3.1.3-bin.tar.gz</span><br><span class="line"><span class="built_in">sudo</span> <span class="built_in">mv</span> apache-hive-3.1.3-bin /usr/local/hive</span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;export HIVE_HOME=/usr/local/hive&quot;</span> &gt;&gt; ~/.bashrc</span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;export PATH=\$HIVE_HOME/bin:\$PATH&quot;</span> &gt;&gt; ~/.bashrc</span><br><span class="line"><span class="built_in">source</span> ~/.bashrc</span><br><span class="line"><span class="built_in">sudo</span> <span class="built_in">tee</span> /usr/local/hive/conf/hive-site.xml &gt; /dev/null &lt;&lt;<span class="string">&#x27;EOF&#x27;</span></span><br><span class="line">&lt;?xml version=<span class="string">&quot;1.0&quot;</span> encoding=<span class="string">&quot;UTF-8&quot;</span> standalone=<span class="string">&quot;no&quot;</span>?&gt;</span><br><span class="line">&lt;?xml-stylesheet <span class="built_in">type</span>=<span class="string">&quot;text/xsl&quot;</span> href=<span class="string">&quot;configuration.xsl&quot;</span>?&gt;</span><br><span class="line">&lt;configuration&gt;</span><br><span class="line">  &lt;property&gt;</span><br><span class="line">    &lt;name&gt;javax.jdo.option.ConnectionURL&lt;/name&gt;</span><br><span class="line">    &lt;value&gt;jdbc:mysql://localhost:3306/hive?createDatabaseIfNotExist=<span class="literal">true</span>&amp;amp;useSSL=<span class="literal">false</span>&lt;/value&gt;</span><br><span class="line">    &lt;description&gt;JDBC connect string <span class="keyword">for</span> a JDBC metastore&lt;/description&gt;</span><br><span class="line">  &lt;/property&gt;</span><br><span class="line">  &lt;property&gt;</span><br><span class="line">    &lt;name&gt;javax.jdo.option.ConnectionDriverName&lt;/name&gt;</span><br><span class="line">    &lt;value&gt;com.mysql.jdbc.Driver&lt;/value&gt;</span><br><span class="line">    &lt;description&gt;Driver class name <span class="keyword">for</span> a JDBC metastore&lt;/description&gt;</span><br><span class="line">  &lt;/property&gt;</span><br><span class="line">  &lt;property&gt;</span><br><span class="line">    &lt;name&gt;javax.jdo.option.ConnectionUserName&lt;/name&gt;</span><br><span class="line">    &lt;value&gt;hive&lt;/value&gt;</span><br><span class="line">    &lt;description&gt;username to use against metastore database&lt;/description&gt;</span><br><span class="line">  &lt;/property&gt;</span><br><span class="line">  &lt;property&gt;</span><br><span class="line">    &lt;name&gt;javax.jdo.option.ConnectionPassword&lt;/name&gt;</span><br><span class="line">    &lt;value&gt;hive&lt;/value&gt;</span><br><span class="line">    &lt;description&gt;password to use against metastore database&lt;/description&gt;</span><br><span class="line">  &lt;/property&gt;</span><br><span class="line">  &lt;property&gt;</span><br><span class="line">    &lt;name&gt;hive.exec.mode.local.auto&lt;/name&gt;</span><br><span class="line">    &lt;value&gt;<span class="literal">true</span>&lt;/value&gt;</span><br><span class="line">  &lt;/property&gt;</span><br><span class="line">&lt;/configuration&gt;</span><br><span class="line">EOF</span><br><span class="line"><span class="built_in">sudo</span> <span class="built_in">mv</span> mysql-connector-java-5.1.46.tar&#123;\(2\).gz,.gz&#125;</span><br><span class="line"><span class="built_in">sudo</span> tar -xf mysql-connector-java-5.1.46*.tar.gz</span><br><span class="line"></span><br><span class="line"><span class="built_in">sudo</span> <span class="built_in">mv</span> mysql-connector-java-5.1.46/mysql-connector-java-5.1.46.jar /usr/local/hive/lib/</span><br><span class="line"><span class="built_in">sudo</span> <span class="built_in">chown</span> hadoop:hadoop /usr/local/hive/lib/mysql-connector-java-5.1.46.jar</span><br><span class="line"><span class="built_in">sudo</span> <span class="built_in">chmod</span> 644 /usr/local/hive/lib/mysql-connector-java-5.1.46.jar</span><br></pre></td></tr></table></figure>
<p>安装mysql</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">sudo</span> apt remove mariadb* -y</span><br><span class="line"><span class="comment">#上面报错不用管</span></span><br><span class="line"><span class="built_in">sudo</span> apt install -y net-tools wget mysql-server</span><br><span class="line"><span class="built_in">sudo</span> systemctl <span class="built_in">enable</span> --now mysql</span><br></pre></td></tr></table></figure>
<p>进入mysql初始化</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo mysql_secure_installation</span><br></pre></td></tr></table></figure>
<p>下面开始要手动输入了，输入yes或no</p>
<p>下面开始要手动输入了，输入yes或no</p>
<p>下面开始要手动输入了，输入yes或no</p>
<p>下面开始要手动输入了，输入yes或no</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">1. Press y|Y <span class="keyword">for</span> Yes, any other key <span class="keyword">for</span> No:   no</span><br><span class="line">Please <span class="built_in">set</span> the password <span class="keyword">for</span> root here.</span><br><span class="line"></span><br><span class="line">New password:                 输入密码123456</span><br><span class="line">Re-enter new password:        输入密码123456</span><br><span class="line">....</span><br><span class="line"></span><br><span class="line">2. Remove anonymous <span class="built_in">users</span>?  :   <span class="built_in">yes</span></span><br><span class="line">....</span><br><span class="line">3.Disallow root login remotely?  : no</span><br><span class="line">....</span><br><span class="line">4.Remove <span class="built_in">test</span> database and access to it?: <span class="built_in">yes</span></span><br><span class="line"> ....</span><br><span class="line">5.Reload privilege tables now? : <span class="built_in">yes</span></span><br></pre></td></tr></table></figure>
<p>登入数据库床创建用户</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">cd</span><br><span class="line">sudo mysql -uroot -p123456</span><br><span class="line">UNINSTALL PLUGIN validate_password;</span><br><span class="line">create database hive;</span><br><span class="line">grant all on *.* to hive@localhost identified by &#x27;hive&#x27;;</span><br><span class="line">flush privileges; </span><br><span class="line">exit</span><br><span class="line">sudo sed -i &#x27;s/^bind-address\s*=\s*127.0.0.1/bind-address = 0.0.0.0/&#x27; /etc/mysql/mysql.conf.d/mysqld.cnf</span><br><span class="line">sudo sed -i &#x27;s/^mysqlx-bind-address\s*=\s*127.0.0.1/mysqlx-bind-address = 0.0.0.0/&#x27; /etc/mysql/mysql.conf.d/mysqld.cnf</span><br><span class="line">sudo systemctl restart mysql</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p><img src="/../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/image-20250522144324814-1749470495099-178.png" alt="image-20250522144324814"></p>
<p>升级元数据</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">sudo rm -rf /usr/local/hive/lib/guava*.jar</span><br><span class="line">sudo cp /usr/local/hadoop/share/hadoop/common/lib/guava-*.jar /usr/local/hive/lib/</span><br><span class="line">sudo cp /home/hadoop/下载/mysql-connector-java-5.1.46.tar* /usr/local/hive/lib/</span><br><span class="line">sudo cp /home/hadoop/Downloads/mysql-connector-java-5.1.46.tar* /usr/local/hive/lib/</span><br><span class="line">start-all.sh</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">#hive初始化，这个命令只需要运行一次</span><br><span class="line">schematool -dbType mysql -initSchema</span><br></pre></td></tr></table></figure>
<p><img src="/../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/image-20250522150929161-1749470495099-180.png" alt="image-20250522150929161"></p>
<p>这个是成功的意思</p>
<p>启动hive，要启动hadoop</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">hive</span><br><span class="line">show databases;</span><br><span class="line">exit;</span><br></pre></td></tr></table></figure>
<p><img src="/../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/image-20250522151212300-1749470495099-179.png" alt="image-20250522151212300"></p>
<p>这个图片交到9.9去</p>
<h2 id="实验五">实验五</h2>
<p><img src="/../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/image-20250522152320297-1749470495099-181.png" alt="image-20250522152320297"></p>
<p>自己启动hadoop，在下载文件夹空白处右键</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">sudo mv data ../</span><br><span class="line">cd</span><br><span class="line">ls | grep data</span><br></pre></td></tr></table></figure>
<p><img src="/../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/image-20250522152519618-1749470495099-182.png" alt="image-20250522152519618"></p>
<p>启动hive</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive</span><br></pre></td></tr></table></figure>
<p>（1）创建内部表 <code>stocks</code></p>
<p>表A-6 stocks表结构</p>
<table>
<thead>
<tr>
<th>col_name</th>
<th>data_type</th>
</tr>
</thead>
<tbody>
<tr>
<td>exchange</td>
<td>string</td>
</tr>
<tr>
<td>symbol</td>
<td>string</td>
</tr>
<tr>
<td>ymd</td>
<td>string</td>
</tr>
<tr>
<td>price_open</td>
<td>float</td>
</tr>
<tr>
<td>price_high</td>
<td>float</td>
</tr>
<tr>
<td>price_low</td>
<td>float</td>
</tr>
<tr>
<td>price_close</td>
<td>float</td>
</tr>
<tr>
<td>volume</td>
<td>int</td>
</tr>
<tr>
<td>price_adj_close</td>
<td>float</td>
</tr>
</tbody>
</table>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">create table if not exists stocks</span><br><span class="line">(</span><br><span class="line">`exchange` string,</span><br><span class="line">`symbol` string,</span><br><span class="line">`ymd` string,</span><br><span class="line">`price_open` float,</span><br><span class="line">`price_high` float,</span><br><span class="line">`price_low` float,</span><br><span class="line">`price_close` float,</span><br><span class="line">`volume` int,</span><br><span class="line">`price_adj_close` float</span><br><span class="line">)</span><br><span class="line">row format delimited fields terminated by &#x27;,&#x27;;</span><br></pre></td></tr></table></figure>
<p><img src="/../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/image-20250522152934167-1749470495099-183.png" alt="image-20250522152934167"></p>
<p>（2）创建一个外部分区表dividends（分区字段为exchange和symbol）</p>
<p>表A-7 dividends表结构</p>
<table>
<thead>
<tr>
<th>col_name</th>
<th>data_type</th>
</tr>
</thead>
<tbody>
<tr>
<td>ymd</td>
<td>string</td>
</tr>
<tr>
<td>dividend</td>
<td>float</td>
</tr>
<tr>
<td>exchange</td>
<td>string</td>
</tr>
<tr>
<td>symbol</td>
<td>string</td>
</tr>
</tbody>
</table>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">create external table if not exists dividends</span><br><span class="line">(</span><br><span class="line">`ymd` string,</span><br><span class="line">`dividend` float</span><br><span class="line">)</span><br><span class="line">partitioned by(`exchange` string ,`symbol` string)</span><br><span class="line">row format delimited fields terminated by &#x27;,&#x27;;</span><br></pre></td></tr></table></figure>
<p><img src="/../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/image-20250522153028622-1749470495099-184.png" alt="image-20250522153028622"></p>
<p>（3）从stocks.csv文件向stocks表中导入数据。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">load data local inpath &#x27;/home/hadoop/data/stocks/stocks.csv&#x27; overwrite into table stocks;</span><br></pre></td></tr></table></figure>
<p><img src="/../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/image-20250522153255569-1749470495099-185.png" alt="image-20250522153255569"></p>
<p>（4） 创建一个未分区的外部表dividends_unpartitioned，并从dividends.csv向其中导入数据，表结构如表A-8所示。</p>
<p>​    表A-8 dividends_unpartitioned表结构</p>
<table>
<thead>
<tr>
<th>col_name</th>
<th>data_type</th>
</tr>
</thead>
<tbody>
<tr>
<td>ymd</td>
<td>string</td>
</tr>
<tr>
<td>dividend</td>
<td>float</td>
</tr>
<tr>
<td>exchange</td>
<td>string</td>
</tr>
<tr>
<td>symbol</td>
<td>string</td>
</tr>
</tbody>
</table>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">create external table if not exists dividends_unpartitioned</span><br><span class="line">(</span><br><span class="line">`exchange` string ,</span><br><span class="line">`symbol` string,</span><br><span class="line">`ymd` string,</span><br><span class="line">`dividend` float</span><br><span class="line">)</span><br><span class="line">row format delimited fields terminated by &#x27;,&#x27;;</span><br><span class="line">load data local inpath &#x27;/home/hadoop/data/dividends/dividends.csv&#x27; overwrite into table dividends_unpartitioned;</span><br></pre></td></tr></table></figure>
<p><img src="/../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/image-20250522153350030-1749470495099-186.png" alt="image-20250522153350030"></p>
<p>（5）通过对dividends_unpartitioned的查询语句，利用Hive自动分区特性向分区表dividends各个分区中插入对应数据。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">set hive.exec.dynamic.partition=true;</span><br><span class="line">set hive.exec.dynamic.partition.mode=nonstrict;</span><br><span class="line">set hive.exec.max.dynamic.partitions.pernode=1000;</span><br><span class="line">insert overwrite table dividends partition(`exchange`,`symbol`) select `ymd`,`dividend`,`exchange`,`symbol` from dividends_unpartitioned;</span><br></pre></td></tr></table></figure>
<p>运行一分钟，有点慢</p>
<p><img src="/../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/image-20250522153604286-1749470495099-187.png" alt="image-20250522153604286"></p>
<p>（6）查询IBM公司(symbol=IBM)从2000年起所有支付股息的交易日(dividends表中有对应记录)的收盘价(price_close)。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">select s.ymd,s.symbol,s.price_close</span><br><span class="line">from stocks s </span><br><span class="line">LEFT SEMI JOIN </span><br><span class="line">dividends d</span><br><span class="line">ON s.ymd=d.ymd and s.symbol=d.symbol</span><br><span class="line">where s.symbol=&#x27;IBM&#x27; and year(ymd)&gt;=2000;</span><br></pre></td></tr></table></figure>
<p><img src="/../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/image-20250522153702090-1749470495099-188.png" alt="image-20250522153702090"></p>
<p>（7）查询苹果公司(symbol=AAPL)2008年10月每个交易日的涨跌情况，涨显示rise，跌显示fall,不变显示unchange。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">select ymd,</span><br><span class="line">case</span><br><span class="line">    when price_close-price_open&gt;0 then &#x27;rise&#x27;</span><br><span class="line">    when price_close-price_open&lt;0 then &#x27;fall&#x27;</span><br><span class="line">    else &#x27;unchanged&#x27;</span><br><span class="line">end as situation</span><br><span class="line">from stocks</span><br><span class="line">where symbol=&#x27;AAPL&#x27; and substring(ymd,0,7)=&#x27;2008-10&#x27;;</span><br></pre></td></tr></table></figure>
<p><img src="/../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/image-20250522153845775-1749470495099-189.png" alt="image-20250522153845775"></p>
<p>（8）查询stocks表中收盘价(price_close)比开盘价(price_open)高得最多的那条记录的交易所(exchange)、股票代码(symbol)、日期(ymd)、收盘价、开盘价及二者差价。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">select `exchange`,symbol,ymd,price_close-price_open as `diff`</span><br><span class="line">from</span><br><span class="line">(</span><br><span class="line">    select *</span><br><span class="line">    from stocks</span><br><span class="line">    order by price_close-price_open desc</span><br><span class="line">    limit 1</span><br><span class="line">)t;</span><br></pre></td></tr></table></figure>
<p><img src="/../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/image-20250522153914410-1749470495099-190.png" alt="image-20250522153914410"></p>
<p>（9）从stocks表中查询苹果公司（symbol=AAPL）年平均调整后收盘价(price_adj_close) 大于50美元的年份及年平均调整后收盘价。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">select</span><br><span class="line">    year(ymd) as `year`,</span><br><span class="line">    avg(price_adj_close) as avg_price from stocks</span><br><span class="line">where `exchange`=&#x27;NASDAQ&#x27; and symbol=&#x27;AAPL&#x27;</span><br><span class="line">group by year(ymd)</span><br><span class="line">having avg_price &gt; 50;</span><br></pre></td></tr></table></figure>
<p><img src="/../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/image-20250522154025370-1749470495099-191.png" alt="image-20250522154025370"></p>
<p>（10）查询每年年平均调整后收盘价(price_adj_close)前三名的公司的股票代码及年平均调整后收盘价。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">SET mapreduce.job.reduces=2;</span><br><span class="line">select t2.year, t2.symbol, t2.avg_price</span><br><span class="line">from (</span><br><span class="line">    select *,</span><br><span class="line">           row_number() over (partition by year order by avg_price desc) as rn</span><br><span class="line">    from (</span><br><span class="line">        select</span><br><span class="line">            year(ymd) as year,</span><br><span class="line">            symbol,</span><br><span class="line">            avg(price_adj_close) as avg_price</span><br><span class="line">        from stocks</span><br><span class="line">        group by year(ymd), symbol</span><br><span class="line">    ) t1</span><br><span class="line">) t2</span><br><span class="line">where t2.rn &lt;= 3;</span><br></pre></td></tr></table></figure>
<p><img src="/../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/image-20250522161403513-1749470495099-192.png" alt="image-20250522161403513"></p>
<h2 id="9-9-3">(9.9.3)</h2>
<p>1.利用mapreduce实现词频统计</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo ls &amp;&amp; start-all.sh</span><br></pre></td></tr></table></figure>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cd</span></span><br><span class="line">hdfs dfs -<span class="built_in">rm</span> -r input</span><br><span class="line">hdfs dfs -<span class="built_in">rm</span> -r output</span><br><span class="line">hdfs dfs -<span class="built_in">mkdir</span> input</span><br><span class="line"><span class="built_in">rm</span> -rf input</span><br><span class="line"><span class="built_in">mkdir</span> input</span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;hello world&quot;</span> &gt; input/file1.txt</span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;hello hadoop&quot;</span> &gt; input/file2.txt</span><br><span class="line">hdfs dfs -put input/* input/</span><br><span class="line">hadoop jar <span class="variable">$HADOOP_HOME</span>/share/hadoop/mapreduce/hadoop-mapreduce-examples-3.1.3.jar wordcount input output</span><br><span class="line">hdfs dfs -<span class="built_in">cat</span> output/*</span><br></pre></td></tr></table></figure>
<p><img src="/../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/image-20250609195315190.png" alt="image-20250609195315190"></p>
<p>2.利用hive实现词频统计</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive</span><br></pre></td></tr></table></figure>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">create table</span> docs(line string);</span><br><span class="line">load data inpath <span class="string">&#x27;file:///home/hadoop/input&#x27;</span> overwrite <span class="keyword">into</span> <span class="keyword">table</span> docs;</span><br><span class="line"><span class="keyword">create table</span> word_count <span class="keyword">as</span> </span><br><span class="line"><span class="keyword">select</span> word, <span class="built_in">count</span>(<span class="number">1</span>) <span class="keyword">as</span> count <span class="keyword">from</span></span><br><span class="line">(<span class="keyword">select</span> explode(split(line,<span class="string">&#x27; &#x27;</span>))<span class="keyword">as</span> word <span class="keyword">from</span> docs) w</span><br><span class="line"><span class="keyword">group</span> <span class="keyword">by</span> word</span><br><span class="line"><span class="keyword">order</span> <span class="keyword">by</span> word;</span><br></pre></td></tr></table></figure>
<p>对文本进行“分词 + 炸裂”，得到所有单词列表</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> explode(split(line, <span class="string">&#x27; &#x27;</span>)) <span class="keyword">AS</span> word <span class="keyword">FROM</span> docs;</span><br></pre></td></tr></table></figure>
<p><img src="/../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/image-20250609195635791.png" alt="image-20250609195635791"></p>
<p>对单词进行分组并计数</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> word, <span class="built_in">COUNT</span>(<span class="operator">*</span>) <span class="keyword">AS</span> count</span><br><span class="line"><span class="keyword">FROM</span> (</span><br><span class="line">  <span class="keyword">SELECT</span> explode(split(line, <span class="string">&#x27; &#x27;</span>)) <span class="keyword">AS</span> word <span class="keyword">FROM</span> docs</span><br><span class="line">) w</span><br><span class="line"><span class="keyword">GROUP</span> <span class="keyword">BY</span> word;</span><br></pre></td></tr></table></figure>
<p><img src="/../img/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E9%AA%8C/image-20250609195734111.png" alt="image-20250609195734111"></p>
<blockquote>
<p><code>三张图片都交到9.9.3</code></p>
</blockquote>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta"><i class="fas fa-circle-user fa-fw"></i>文章作者: </span><span class="post-copyright-info"><a href="https://blog.qianyios.top">严千屹</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta"><i class="fas fa-square-arrow-up-right fa-fw"></i>文章链接: </span><span class="post-copyright-info"><a href="https://blog.qianyios.top/posts/d721e715/">https://blog.qianyios.top/posts/d721e715/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta"><i class="fas fa-circle-exclamation fa-fw"></i>版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来源 <a href="https://blog.qianyios.top" target="_blank">严千屹博客</a>！</span></div></div><div class="tag_share"><div class="post-share"><div class="social-share" data-image="https://i0.hdslb.com/bfs/article/daddec263720c95dfc5b4f53b45a96fd55933597.png" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="/pluginsSrc/butterfly-extsrc/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="/pluginsSrc/butterfly-extsrc/sharejs/dist/js/social-share.min.js" defer></script></div></div><div class="post-reward"><div class="reward-button"><i class="fas fa-qrcode"></i>赞助</div><div class="reward-main"><ul class="reward-all"><li class="reward-item"><a href="/img/wxzf.png" target="_blank"><img class="post-qr-code-img" src="/img/wxzf.png" alt="微信"/></a><div class="post-qr-code-desc">微信</div></li><li class="reward-item"><a href="/img/zfb.png" target="_blank"><img class="post-qr-code-img" src="/img/zfb.png" alt="支付宝"/></a><div class="post-qr-code-desc">支付宝</div></li></ul></div></div><nav class="pagination-post" id="pagination"><a class="pagination-related" href="/posts/69efb119/" title="巨完美的Docker镜像加速方案"><img class="cover" src="/../img/Docker%E5%8A%A0%E9%80%9F%E5%90%8C%E6%AD%A5%E6%96%B9%E6%A1%88/1.png" onerror="onerror=null;src='/img/404.jpg'" alt="cover of previous post"><div class="info"><div class="info-1"><div class="info-item-1">上一篇</div><div class="info-item-2">巨完美的Docker镜像加速方案</div></div><div class="info-2"><div class="info-item-1">超级方便的docker镜像仓库同步网站</div></div></div></a><a class="pagination-related" href="/posts/a735afbd/" title="ZeroTier免费远控工具"><img class="cover" src="https://i0.hdslb.com/bfs/article/d63e7dc1301110b4b6e8b084b0e162ca55933597.png" onerror="onerror=null;src='/img/404.jpg'" alt="cover of next post"><div class="info text-right"><div class="info-1"><div class="info-item-1">下一篇</div><div class="info-item-2">ZeroTier免费远控工具</div></div><div class="info-2"><div class="info-item-1">异地组网</div></div></div></a></nav><hr class="custom-hr"/><div id="post-comment"><div class="comment-head"><div class="comment-headline"><i class="fas fa-comments fa-fw"></i><span> 评论</span></div></div><div class="comment-wrap"><div><div id="twikoo-wrap"></div></div></div></div></div><div class="aside-content" id="aside-content"><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%A4%A7%E6%95%B0%E6%8D%AEhadoop%E5%AE%9E%E9%AA%8C"><span class="toc-number">1.</span> <span class="toc-text">大数据hadoop实验</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%A4%A7%E4%BD%9C%E4%B8%9A"><span class="toc-number">1.1.</span> <span class="toc-text">大作业</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%AE%89%E8%A3%85ubuntu%E7%B3%BB%E7%BB%9F"><span class="toc-number">1.2.</span> <span class="toc-text">安装ubuntu系统</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%88%9B%E5%BB%BAhadoop%E7%94%A8%E6%88%B7"><span class="toc-number">1.3.</span> <span class="toc-text">创建hadoop用户</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%AE%BE%E7%BD%AEssh%E5%85%8D%E5%AF%86"><span class="toc-number">1.4.</span> <span class="toc-text">设置ssh免密</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%AE%89%E8%A3%85java%E5%92%8Chadoop"><span class="toc-number">1.5.</span> <span class="toc-text">安装java和hadoop</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BC%AA%E5%88%86%E5%B8%83%E5%AE%89%E8%A3%85"><span class="toc-number">1.6.</span> <span class="toc-text">伪分布安装</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%BC%96%E5%86%99cort-site-yaml%E6%96%87%E4%BB%B6"><span class="toc-number">1.6.1.</span> <span class="toc-text">编写cort-site.yaml文件</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%BC%96%E5%86%99hdfs-site-xml"><span class="toc-number">1.6.2.</span> <span class="toc-text">编写hdfs-site.xml</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%90%AF%E5%8A%A8hhdfs%E6%9C%8D%E5%8A%A1"><span class="toc-number">1.6.3.</span> <span class="toc-text">启动hhdfs服务</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%B7%BB%E5%8A%A0hdfs-yarn%E7%9A%84%E7%8E%AF%E5%A2%83%E5%8F%98%E9%87%8F"><span class="toc-number">1.6.4.</span> <span class="toc-text">添加hdfs yarn的环境变量</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%AE%BF%E9%97%AEhadoop%E7%BD%91%E9%A1%B5"><span class="toc-number">1.6.5.</span> <span class="toc-text">访问hadoop网页</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%85%B3%E6%9C%BA%E6%AD%A5%E9%AA%A4"><span class="toc-number">1.6.6.</span> <span class="toc-text">关机步骤</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%AC%AC%E4%B8%80%E6%AC%A1%E5%AE%9E%E9%AA%8C"><span class="toc-number">1.7.</span> <span class="toc-text">第一次实验</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%86%9F%E6%82%89%E5%B8%B8%E7%94%A8%E7%9A%84Linux%E6%93%8D%E4%BD%9C"><span class="toc-number">1.7.1.</span> <span class="toc-text">熟悉常用的Linux操作</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%86%9F%E6%82%89%E5%B8%B8%E7%94%A8%E7%9A%84Hadoop%E6%93%8D%E4%BD%9C"><span class="toc-number">1.7.2.</span> <span class="toc-text">熟悉常用的Hadoop操作</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%EF%BC%883-7-3%EF%BC%89%E5%AE%9E%E9%AA%8C"><span class="toc-number">1.8.</span> <span class="toc-text">（3.7.3）实验</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%AE%89%E8%A3%85eclipse"><span class="toc-number">1.8.1.</span> <span class="toc-text">安装eclipse</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%9C%A8Eclipse%E4%B8%AD%E5%88%9B%E5%BB%BA%E9%A1%B9%E7%9B%AE"><span class="toc-number">1.8.2.</span> <span class="toc-text">在Eclipse中创建项目</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%B8%BA%E9%A1%B9%E7%9B%AE%E6%B7%BB%E5%8A%A0%E9%9C%80%E8%A6%81%E7%94%A8%E5%88%B0%E7%9A%84JAR%E5%8C%85"><span class="toc-number">1.8.3.</span> <span class="toc-text">为项目添加需要用到的JAR包</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%BC%96%E5%86%99Java%E5%BA%94%E7%94%A8%E7%A8%8B%E5%BA%8F"><span class="toc-number">1.8.4.</span> <span class="toc-text">编写Java应用程序</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%BC%96%E8%AF%91%E8%BF%90%E8%A1%8C%E7%A8%8B%E5%BA%8F"><span class="toc-number">1.8.5.</span> <span class="toc-text">编译运行程序</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%BA%94%E7%94%A8%E7%A8%8B%E5%BA%8F%E7%9A%84%E9%83%A8%E7%BD%B2"><span class="toc-number">1.8.6.</span> <span class="toc-text">应用程序的部署</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%88%9B%E5%BB%BAmyapp%E7%9B%AE%E5%BD%95"><span class="toc-number">1.8.6.1.</span> <span class="toc-text">创建myapp目录</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%BC%80%E5%A7%8B%E6%89%93%E5%8C%85%E7%A8%8B%E5%BA%8F"><span class="toc-number">1.8.6.2.</span> <span class="toc-text">开始打包程序</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%9F%A5%E7%9C%8B%E6%98%AF%E5%90%A6%E7%94%9F%E6%88%90"><span class="toc-number">1.8.6.3.</span> <span class="toc-text">查看是否生成</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E9%87%8D%E6%96%B0%E9%AA%8C%E8%AF%81%E9%A1%B9%E7%9B%AE%E7%9A%84%E8%BF%90%E8%A1%8C"><span class="toc-number">1.8.6.4.</span> <span class="toc-text">重新验证项目的运行</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%BB%83%E4%B9%A0%E6%96%87%E4%BB%B6"><span class="toc-number">1.8.7.</span> <span class="toc-text">练习文件</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%AC%AC%E4%BA%8C%E6%AC%A1%E5%AE%9E%E9%AA%8C"><span class="toc-number">1.9.</span> <span class="toc-text">第二次实验</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Hbase%E5%AE%89%E8%A3%85-4-6-1"><span class="toc-number">1.10.</span> <span class="toc-text">Hbase安装(4.6.1)</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%AE%89%E8%A3%85hbase"><span class="toc-number">1.10.1.</span> <span class="toc-text">安装hbase</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%90%AF%E5%8A%A8hbase"><span class="toc-number">1.10.2.</span> <span class="toc-text">启动hbase</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%85%B3%E9%97%ADhbase"><span class="toc-number">1.10.3.</span> <span class="toc-text">关闭hbase</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%EF%BC%884-6-2%EF%BC%89%E5%AE%9E%E9%AA%8C"><span class="toc-number">1.11.</span> <span class="toc-text">（4.6.2）实验</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%90%AF%E5%8A%A8eclipse"><span class="toc-number">1.11.1.</span> <span class="toc-text">启动eclipse</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%96%B0%E5%BB%BA%E9%A1%B9%E7%9B%AE"><span class="toc-number">1.11.2.</span> <span class="toc-text">新建项目</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%96%B0%E5%BB%BAclass"><span class="toc-number">1.11.3.</span> <span class="toc-text">新建class</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#4-8%E5%AE%9E%E9%AA%8C3"><span class="toc-number">1.12.</span> <span class="toc-text">(4.8实验3)</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%AC%AC%E4%B8%80%E9%A2%98"><span class="toc-number">1.12.1.</span> <span class="toc-text">第一题</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%AC%AC%E4%BA%8C%E9%A2%98"><span class="toc-number">1.12.2.</span> <span class="toc-text">第二题</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%EF%BC%887-5-5%EF%BC%89"><span class="toc-number">1.13.</span> <span class="toc-text">（7.5.5）</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%9F%BA%E7%A1%80"><span class="toc-number">1.13.1.</span> <span class="toc-text">基础</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%9C%A8eclipse%E5%88%9B%E5%BB%BA%E9%A1%B9%E7%9B%AE"><span class="toc-number">1.13.2.</span> <span class="toc-text">在eclipse创建项目</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%BC%96%E5%86%99Java%E5%BA%94%E7%94%A8%E7%A8%8B%E5%BA%8F-2"><span class="toc-number">1.13.3.</span> <span class="toc-text">编写Java应用程序</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%BC%96%E8%AF%91%E6%89%93%E5%8C%85%E7%A8%8B%E5%BA%8F"><span class="toc-number">1.13.4.</span> <span class="toc-text">编译打包程序</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%BF%90%E8%A1%8C%E7%A8%8B%E5%BA%8F"><span class="toc-number">1.13.5.</span> <span class="toc-text">运行程序</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%EF%BC%887-3-4%EF%BC%89"><span class="toc-number">1.14.</span> <span class="toc-text">（7.3.4）</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%AE%9E%E9%AA%8C%E5%9B%9B"><span class="toc-number">1.15.</span> <span class="toc-text">实验四</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%AC%AC%E4%B8%80%E9%A2%98-2"><span class="toc-number">1.15.1.</span> <span class="toc-text">第一题</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#shell"><span class="toc-number">1.15.1.1.</span> <span class="toc-text">shell</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#java"><span class="toc-number">1.15.1.2.</span> <span class="toc-text">java</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%AC%AC%E4%BA%8C%E9%A2%98-2"><span class="toc-number">1.15.2.</span> <span class="toc-text">第二题</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#shell-2"><span class="toc-number">1.15.2.1.</span> <span class="toc-text">shell</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#java-2"><span class="toc-number">1.15.2.2.</span> <span class="toc-text">java</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%AC%AC%E4%B8%89%E9%A2%98"><span class="toc-number">1.15.3.</span> <span class="toc-text">第三题</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#shell-3"><span class="toc-number">1.15.3.1.</span> <span class="toc-text">shell</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#java-3"><span class="toc-number">1.15.3.2.</span> <span class="toc-text">java</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Hive"><span class="toc-number">1.16.</span> <span class="toc-text">Hive</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%AE%9E%E9%AA%8C%E4%BA%94"><span class="toc-number">1.17.</span> <span class="toc-text">实验五</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#9-9-3"><span class="toc-number">1.18.</span> <span class="toc-text">(9.9.3)</span></a></li></ol></li></ol></div></div></div></div></main><footer id="footer" style="background-image: url(/img/bg.png);"><div class="footer-other"><div class="footer-copyright"></div><div class="footer_custom_text"><span style="display: block; text-align: center; color: white;">严千屹博客</span>
<a href="http://beian.miit.gov.cn/" target="_blank" rel="noopener" style="display: block; text-align: center; color: white; text-decoration: none; cursor: pointer; position: relative; z-index: 9999;">
  ICP备案号:粤ICP备2024250479号
</a>
<div class="post-reward" style="margin-top:11px;margin-bottom:20px"><div class="reward-button"><i class="fas fa-qrcode"></i>赞助</div><div class="reward-main"><ul class="reward-all"><li class="reward-item"><a href="/img/wxzf.png" target="_blank"><img class="post-qr-code-img" src="/img/wxzf.png" alt="微信"></a><div class="post-qr-code-desc">微信</div></li><li class="reward-item"><a href="/img/zfb.png" target="_blank"><img class="post-qr-code-img" src="/img/zfb.png" alt="支付宝"></a><div class="post-qr-code-desc">支付宝</div></li></ul></div></div>
<a href="https://www.foreverblog.cn/" target="_blank" > <img src="https://img.foreverblog.cn/logo_en_default.png" alt="" style="width:auto;height:16px;"> </a>
</div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="日间和夜间模式切换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside-config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><a id="to_comment" href="#post-comment" title="前往评论"><i class="fas fa-comments"></i></a><button id="go-up" type="button" title="回到顶部"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="/pluginsSrc/@fancyapps/ui/dist/fancybox/fancybox.umd.js"></script><script src="/pluginsSrc/instant.page/instantpage.js" type="module"></script><script src="/pluginsSrc/node-snackbar/dist/snackbar.min.js"></script><div class="js-pjax"><script>(() => {
  const isShuoshuo = GLOBAL_CONFIG_SITE.pageType === 'shuoshuo'
  const option = null

  const getCount = () => {
    const countELement = document.getElementById('twikoo-count')
    if(!countELement) return
    twikoo.getCommentsCount({
      envId: 'https://twikoo.qianyios.top',
      region: '',
      urls: [window.location.pathname],
      includeReply: false
    }).then(res => {
      countELement.textContent = res[0].count
    }).catch(err => {
      console.error(err)
    })
  }

  const init = (el = document, path = location.pathname) => {
    twikoo.init({
      el: el.querySelector('#twikoo-wrap'),
      envId: 'https://twikoo.qianyios.top',
      region: '',
      onCommentLoaded: () => {
        btf.loadLightbox(document.querySelectorAll('#twikoo .tk-content img:not(.tk-owo-emotion)'))
      },
      ...option,
      path: isShuoshuo ? path : (option && option.path) || path
    })

    

    isShuoshuo && (window.shuoshuoComment.destroyTwikoo = () => {
      if (el.children.length) {
        el.innerHTML = ''
        el.classList.add('no-comment')
      }
    })
  }

  const loadTwikoo = (el, path) => {
    if (typeof twikoo === 'object') setTimeout(() => init(el, path), 0)
    else btf.getScript('https://s4.zstatic.net/ajax/libs/twikoo/1.6.39/twikoo.all.min.js').then(() => init(el, path))
  }

  if (isShuoshuo) {
    'Twikoo' === 'Twikoo'
      ? window.shuoshuoComment = { loadComment: loadTwikoo }
      : window.loadOtherComment = loadTwikoo
    return
  }

  if ('Twikoo' === 'Twikoo' || !false) {
    if (false) btf.loadComment(document.getElementById('twikoo-wrap'), loadTwikoo)
    else loadTwikoo()
  } else {
    window.loadOtherComment = loadTwikoo
  }
})()</script></div><canvas class="fireworks" mobile="false"></canvas><script src="/pluginsSrc/butterfly-extsrc/dist/fireworks.min.js"></script><script id="canvas_nest" defer="defer" color="0,0,255" opacity="0.7" zIndex="-1" count="99" mobile="false" src="/pluginsSrc/butterfly-extsrc/dist/canvas-nest.min.js"></script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><div id="local-search"><div class="search-dialog"><nav class="search-nav"><span class="search-dialog-title">搜索</span><span id="loading-status"></span><button class="search-close-button"><i class="fas fa-times"></i></button></nav><div class="text-center" id="loading-database"><i class="fas fa-spinner fa-pulse"></i><span>  数据加载中</span></div><div class="search-wrap"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章" type="text"/></div></div><hr/><div id="local-search-results"></div><div id="local-search-stats-wrap"></div></div></div><div id="search-mask"></div><script src="/js/search/local-search.js"></script></div></div></body></html>